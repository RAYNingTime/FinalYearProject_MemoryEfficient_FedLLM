2025-06-08 05:39:36.191 | Repo card metadata block was not found. Setting CardData to empty.
2025-06-08 05:41:57.542 | 
2025-06-08 05:42:31.079 | 
2025-06-08 05:42:31.923 | 
2025-06-08 05:42:32.306 | /app/client.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-06-08 05:42:32.306 |   trainer = Trainer(
2025-06-08 05:42:33.312 | WARNING :   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
2025-06-08 05:42:33.312 | 	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
2025-06-08 05:42:33.312 | 	flwr.client.start_client(
2025-06-08 05:42:33.312 | 		server_address='<IP>:<PORT>',
2025-06-08 05:42:33.312 | 		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
2025-06-08 05:42:33.312 | 	)
2025-06-08 05:42:33.312 | 	Using `start_numpy_client()` is deprecated.
2025-06-08 05:42:33.312 | 
2025-06-08 05:42:33.312 |             This is a deprecated feature. It will be removed
2025-06-08 05:42:33.312 |             entirely in future versions of Flower.
2025-06-08 05:42:33.312 |         
2025-06-08 05:42:33.312 | WARNING :   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
2025-06-08 05:42:33.312 | 	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:
2025-06-08 05:42:33.312 | 
2025-06-08 05:42:33.312 | 		$ flower-supernode --insecure --superlink='<IP>:<PORT>'
2025-06-08 05:42:33.313 | 
2025-06-08 05:42:33.313 | 	To view all available options, run:
2025-06-08 05:42:33.313 | 
2025-06-08 05:42:33.313 | 		$ flower-supernode --help
2025-06-08 05:42:33.313 | 
2025-06-08 05:42:33.313 | 	Using `start_client()` is deprecated.
2025-06-08 05:42:33.313 | 
2025-06-08 05:42:33.313 |             This is a deprecated feature. It will be removed
2025-06-08 05:42:33.313 |             entirely in future versions of Flower.
2025-06-08 05:42:33.313 |         
2025-06-08 05:42:33.327 | Traceback (most recent call last):
2025-06-08 05:42:33.327 |   File "/app/client.py", line 105, in <module>
2025-06-08 05:42:33.327 |     fl.client.start_numpy_client(server_address=server_ip, client=FlowerClient())
2025-06-08 05:42:33.327 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/app.py", line 731, in start_numpy_client
2025-06-08 05:42:33.327 |     start_client(
2025-06-08 05:42:33.327 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/app.py", line 201, in start_client
2025-06-08 05:42:33.327 |     start_client_internal(
2025-06-08 05:42:33.327 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/app.py", line 438, in start_client_internal
2025-06-08 05:42:33.327 |     message = receive()
2025-06-08 05:42:33.327 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/grpc_client/connection.py", line 142, in receive
2025-06-08 05:42:33.327 |     proto = next(server_message_iterator)
2025-06-08 05:42:33.327 |   File "/usr/local/lib/python3.10/site-packages/grpc/_channel.py", line 543, in __next__
2025-06-08 05:42:33.328 |     return self._next()
2025-06-08 05:42:33.328 |   File "/usr/local/lib/python3.10/site-packages/grpc/_channel.py", line 952, in _next
2025-06-08 05:42:33.328 |     raise self
2025-06-08 05:42:33.328 | grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
2025-06-08 05:42:33.328 | 	status = StatusCode.UNAVAILABLE
2025-06-08 05:42:33.328 | 	details = "failed to connect to all addresses; last error: UNKNOWN: ipv4:172.18.0.2:8080: Failed to connect to remote host: connect: Connection refused (111)"
2025-06-08 05:42:33.328 | 	debug_error_string = "UNKNOWN:Error received from peer  {grpc_status:14, grpc_message:"failed to connect to all addresses; last error: UNKNOWN: ipv4:172.18.0.2:8080: Failed to connect to remote host: connect: Connection refused (111)"}"
2025-06-08 05:42:33.328 | >
2025-06-08 05:43:55.064 | Repo card metadata block was not found. Setting CardData to empty.
2025-06-08 05:43:58.478 | /app/client.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-06-08 05:43:58.478 |   trainer = Trainer(
2025-06-08 05:43:59.060 | WARNING :   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
2025-06-08 05:43:59.060 | 	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
2025-06-08 05:43:59.060 | 	flwr.client.start_client(
2025-06-08 05:43:59.060 | 		server_address='<IP>:<PORT>',
2025-06-08 05:43:59.060 | 		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
2025-06-08 05:43:59.060 | 	)
2025-06-08 05:43:59.060 | 	Using `start_numpy_client()` is deprecated.
2025-06-08 05:43:59.060 | 
2025-06-08 05:43:59.060 |             This is a deprecated feature. It will be removed
2025-06-08 05:43:59.060 |             entirely in future versions of Flower.
2025-06-08 05:43:59.060 |         
2025-06-08 05:43:59.060 | WARNING :   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
2025-06-08 05:43:59.060 | 	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:
2025-06-08 05:43:59.060 | 
2025-06-08 05:43:59.060 | 		$ flower-supernode --insecure --superlink='<IP>:<PORT>'
2025-06-08 05:43:59.060 | 
2025-06-08 05:43:59.060 | 	To view all available options, run:
2025-06-08 05:43:59.060 | 
2025-06-08 05:43:59.060 | 		$ flower-supernode --help
2025-06-08 05:43:59.060 | 
2025-06-08 05:43:59.060 | 	Using `start_client()` is deprecated.
2025-06-08 05:43:59.060 | 
2025-06-08 05:43:59.060 |             This is a deprecated feature. It will be removed
2025-06-08 05:43:59.060 |             entirely in future versions of Flower.
2025-06-08 05:43:59.060 |         
2025-06-08 05:43:59.084 | INFO :      
2025-06-08 05:43:59.084 | INFO :      Received: get_parameters message bbaaac7b-781b-4ad3-8c92-ae971a69443c
2025-06-08 05:44:09.019 | INFO :      Sent reply
2025-06-08 05:56:25.776 | INFO :      
2025-06-08 05:56:25.776 | INFO :      Received: train message 408d9c13-4a78-4b6d-8cd5-53a0374811c0
2025-06-08 05:57:54.556 | {'loss': 2.9868, 'grad_norm': 20.18727684020996, 'learning_rate': 9.925e-06, 'epoch': 0.025}
2025-06-08 05:58:15.409 | {'loss': 2.8511, 'grad_norm': 23.294519424438477, 'learning_rate': 9.841666666666668e-06, 'epoch': 0.05}
2025-06-08 05:58:34.096 | {'loss': 2.5982, 'grad_norm': 19.6263370513916, 'learning_rate': 9.758333333333334e-06, 'epoch': 0.075}
2025-06-08 05:58:59.996 | {'loss': 2.3476, 'grad_norm': 15.648191452026367, 'learning_rate': 9.675000000000001e-06, 'epoch': 0.1}
2025-06-08 05:59:18.485 | {'loss': 2.5033, 'grad_norm': 21.088966369628906, 'learning_rate': 9.591666666666667e-06, 'epoch': 0.125}
2025-06-08 05:59:38.686 | {'loss': 2.3798, 'grad_norm': 18.46758270263672, 'learning_rate': 9.508333333333333e-06, 'epoch': 0.15}
2025-06-08 06:00:08.741 | {'loss': 2.481, 'grad_norm': 21.286760330200195, 'learning_rate': 9.425e-06, 'epoch': 0.175}
2025-06-08 06:00:27.747 | {'loss': 2.4918, 'grad_norm': 19.19398307800293, 'learning_rate': 9.341666666666667e-06, 'epoch': 0.2}
2025-06-08 06:00:48.521 | {'loss': 2.4936, 'grad_norm': 21.345008850097656, 'learning_rate': 9.258333333333334e-06, 'epoch': 0.225}
2025-06-08 06:01:16.546 | {'loss': 2.2023, 'grad_norm': 21.32921028137207, 'learning_rate': 9.175000000000001e-06, 'epoch': 0.25}
2025-06-08 06:01:35.892 | {'loss': 2.3608, 'grad_norm': 15.871367454528809, 'learning_rate': 9.091666666666668e-06, 'epoch': 0.275}
2025-06-08 06:01:55.004 | {'loss': 2.5753, 'grad_norm': 19.936227798461914, 'learning_rate': 9.008333333333335e-06, 'epoch': 0.3}
2025-06-08 06:02:13.739 | {'loss': 2.6733, 'grad_norm': 20.277572631835938, 'learning_rate': 8.925e-06, 'epoch': 0.325}
2025-06-08 06:02:32.975 | {'loss': 2.5955, 'grad_norm': 18.402496337890625, 'learning_rate': 8.841666666666667e-06, 'epoch': 0.35}
2025-06-08 06:02:52.632 | {'loss': 2.6726, 'grad_norm': 19.70487403869629, 'learning_rate': 8.758333333333334e-06, 'epoch': 0.375}
2025-06-08 06:03:22.285 | {'loss': 2.3295, 'grad_norm': 17.51610565185547, 'learning_rate': 8.675e-06, 'epoch': 0.4}
2025-06-08 06:03:42.959 | {'loss': 2.6219, 'grad_norm': 20.519317626953125, 'learning_rate': 8.591666666666668e-06, 'epoch': 0.425}
2025-06-08 06:04:13.780 | {'loss': 2.2194, 'grad_norm': 21.02997589111328, 'learning_rate': 8.508333333333335e-06, 'epoch': 0.45}
2025-06-08 06:04:34.822 | {'loss': 2.5751, 'grad_norm': 18.2038631439209, 'learning_rate': 8.425000000000001e-06, 'epoch': 0.475}
2025-06-08 06:04:56.966 | {'loss': 2.2948, 'grad_norm': 18.378068923950195, 'learning_rate': 8.341666666666667e-06, 'epoch': 0.5}
2025-06-08 06:05:39.703 | {'loss': 2.4166, 'grad_norm': 14.003506660461426, 'learning_rate': 8.258333333333334e-06, 'epoch': 0.525}
2025-06-08 06:06:01.121 | {'loss': 2.4735, 'grad_norm': 19.337068557739258, 'learning_rate': 8.175e-06, 'epoch': 0.55}
2025-06-08 06:06:23.598 | {'loss': 1.9786, 'grad_norm': 12.67800235748291, 'learning_rate': 8.091666666666667e-06, 'epoch': 0.575}
2025-06-08 06:06:45.440 | {'loss': 1.9547, 'grad_norm': 9.082915306091309, 'learning_rate': 8.008333333333334e-06, 'epoch': 0.6}
2025-06-08 06:07:21.711 | {'loss': 2.7762, 'grad_norm': 15.33777904510498, 'learning_rate': 7.925000000000001e-06, 'epoch': 0.625}
2025-06-08 06:07:45.084 | {'loss': 2.3152, 'grad_norm': 17.42620086669922, 'learning_rate': 7.841666666666668e-06, 'epoch': 0.65}
2025-06-08 06:08:09.352 | {'loss': 2.3304, 'grad_norm': 13.294329643249512, 'learning_rate': 7.758333333333335e-06, 'epoch': 0.675}
2025-06-08 06:08:44.118 | {'loss': 2.4516, 'grad_norm': 16.925867080688477, 'learning_rate': 7.675e-06, 'epoch': 0.7}
2025-06-08 06:09:18.519 | {'loss': 2.5988, 'grad_norm': 20.846454620361328, 'learning_rate': 7.591666666666667e-06, 'epoch': 0.725}
2025-06-08 06:09:42.032 | {'loss': 2.2906, 'grad_norm': 18.98188018798828, 'learning_rate': 7.508333333333334e-06, 'epoch': 0.75}
2025-06-08 06:10:05.878 | {'loss': 2.4636, 'grad_norm': 15.721267700195312, 'learning_rate': 7.425000000000001e-06, 'epoch': 0.775}
2025-06-08 06:10:41.542 | {'loss': 2.7428, 'grad_norm': 19.419254302978516, 'learning_rate': 7.341666666666667e-06, 'epoch': 0.8}
2025-06-08 06:11:17.135 | {'loss': 2.752, 'grad_norm': 16.601444244384766, 'learning_rate': 7.258333333333334e-06, 'epoch': 0.825}
2025-06-08 06:11:41.523 | {'loss': 1.7974, 'grad_norm': 16.544696807861328, 'learning_rate': 7.175000000000001e-06, 'epoch': 0.85}
2025-06-08 06:12:05.125 | {'loss': 2.172, 'grad_norm': 19.944869995117188, 'learning_rate': 7.091666666666667e-06, 'epoch': 0.875}
2025-06-08 06:12:41.002 | {'loss': 2.2641, 'grad_norm': 21.57023048400879, 'learning_rate': 7.008333333333334e-06, 'epoch': 0.9}
2025-06-08 06:13:04.825 | {'loss': 2.1484, 'grad_norm': 18.18906021118164, 'learning_rate': 6.925000000000001e-06, 'epoch': 0.925}
2025-06-08 06:13:28.820 | {'loss': 1.8443, 'grad_norm': 13.475192070007324, 'learning_rate': 6.8416666666666675e-06, 'epoch': 0.95}
2025-06-08 06:14:03.995 | {'loss': 2.2464, 'grad_norm': 18.024234771728516, 'learning_rate': 6.7583333333333336e-06, 'epoch': 0.975}
2025-06-08 06:14:27.615 | {'loss': 2.1225, 'grad_norm': 16.5316162109375, 'learning_rate': 6.6750000000000005e-06, 'epoch': 1.0}
2025-06-08 06:15:01.731 | {'loss': 1.8934, 'grad_norm': 16.951847076416016, 'learning_rate': 6.591666666666667e-06, 'epoch': 1.025}
2025-06-08 06:15:25.824 | {'loss': 1.9514, 'grad_norm': 16.997833251953125, 'learning_rate': 6.508333333333334e-06, 'epoch': 1.05}
2025-06-08 06:15:49.248 | {'loss': 1.8193, 'grad_norm': 12.9046049118042, 'learning_rate': 6.425e-06, 'epoch': 1.075}
2025-06-08 06:16:24.263 | {'loss': 1.923, 'grad_norm': 20.588254928588867, 'learning_rate': 6.341666666666667e-06, 'epoch': 1.1}
2025-06-08 06:16:47.428 | {'loss': 1.967, 'grad_norm': 14.459918975830078, 'learning_rate': 6.258333333333334e-06, 'epoch': 1.125}
2025-06-08 06:17:23.038 | {'loss': 1.7809, 'grad_norm': 15.16666030883789, 'learning_rate': 6.175000000000001e-06, 'epoch': 1.15}
2025-06-08 06:17:47.672 | {'loss': 2.0437, 'grad_norm': 12.710433006286621, 'learning_rate': 6.091666666666667e-06, 'epoch': 1.175}
2025-06-08 06:18:23.205 | {'loss': 1.6879, 'grad_norm': 15.415599822998047, 'learning_rate': 6.008333333333334e-06, 'epoch': 1.2}
2025-06-08 06:18:47.689 | {'loss': 1.9614, 'grad_norm': 16.746379852294922, 'learning_rate': 5.925000000000001e-06, 'epoch': 1.225}
2025-06-08 06:19:11.735 | {'loss': 1.9598, 'grad_norm': 16.000715255737305, 'learning_rate': 5.841666666666667e-06, 'epoch': 1.25}
2025-06-08 06:19:36.259 | {'loss': 1.353, 'grad_norm': 9.076578140258789, 'learning_rate': 5.758333333333334e-06, 'epoch': 1.275}
2025-06-08 06:20:11.310 | {'loss': 2.2562, 'grad_norm': 16.685441970825195, 'learning_rate': 5.675000000000001e-06, 'epoch': 1.3}
2025-06-08 06:20:36.687 | {'loss': 1.8978, 'grad_norm': 11.864326477050781, 'learning_rate': 5.591666666666668e-06, 'epoch': 1.325}
2025-06-08 06:21:01.821 | {'loss': 1.647, 'grad_norm': 13.1267728805542, 'learning_rate': 5.508333333333334e-06, 'epoch': 1.35}
2025-06-08 06:21:37.651 | {'loss': 1.6627, 'grad_norm': 13.253393173217773, 'learning_rate': 5.4250000000000006e-06, 'epoch': 1.375}
2025-06-08 06:22:01.187 | {'loss': 2.0737, 'grad_norm': 16.601802825927734, 'learning_rate': 5.3416666666666675e-06, 'epoch': 1.4}
2025-06-08 06:22:25.067 | {'loss': 1.9161, 'grad_norm': 14.208270072937012, 'learning_rate': 5.258333333333334e-06, 'epoch': 1.425}
2025-06-08 06:22:49.286 | {'loss': 1.7258, 'grad_norm': 13.895552635192871, 'learning_rate': 5.1750000000000004e-06, 'epoch': 1.45}
2025-06-08 06:23:25.452 | {'loss': 1.8906, 'grad_norm': 14.477919578552246, 'learning_rate': 5.091666666666667e-06, 'epoch': 1.475}
2025-06-08 06:23:49.154 | {'loss': 2.018, 'grad_norm': 12.590267181396484, 'learning_rate': 5.008333333333334e-06, 'epoch': 1.5}
2025-06-08 06:24:15.046 | {'loss': 1.7536, 'grad_norm': 21.467700958251953, 'learning_rate': 4.925e-06, 'epoch': 1.525}
2025-06-08 06:24:55.074 | {'loss': 2.0214, 'grad_norm': 17.0949764251709, 'learning_rate': 4.841666666666667e-06, 'epoch': 1.55}
2025-06-08 06:25:22.580 | {'loss': 1.8801, 'grad_norm': 13.704524993896484, 'learning_rate': 4.758333333333334e-06, 'epoch': 1.575}
2025-06-08 06:26:02.775 | {'loss': 1.8735, 'grad_norm': 22.565296173095703, 'learning_rate': 4.675000000000001e-06, 'epoch': 1.6}
2025-06-08 06:26:31.073 | {'loss': 2.0802, 'grad_norm': 16.754844665527344, 'learning_rate': 4.591666666666667e-06, 'epoch': 1.625}
2025-06-08 06:27:11.491 | {'loss': 1.7577, 'grad_norm': 12.103642463684082, 'learning_rate': 4.508333333333333e-06, 'epoch': 1.65}
2025-06-08 06:27:37.932 | {'loss': 1.8408, 'grad_norm': 18.286907196044922, 'learning_rate': 4.425e-06, 'epoch': 1.675}
2025-06-08 06:28:05.175 | {'loss': 1.9112, 'grad_norm': 15.386109352111816, 'learning_rate': 4.341666666666667e-06, 'epoch': 1.7}
2025-06-08 06:28:32.241 | {'loss': 1.9401, 'grad_norm': 10.241154670715332, 'learning_rate': 4.258333333333334e-06, 'epoch': 1.725}
2025-06-08 06:29:13.400 | {'loss': 2.0987, 'grad_norm': 16.6086483001709, 'learning_rate': 4.175e-06, 'epoch': 1.75}
2025-06-08 06:29:39.389 | {'loss': 2.0649, 'grad_norm': 16.745338439941406, 'learning_rate': 4.091666666666667e-06, 'epoch': 1.775}
2025-06-08 06:30:07.050 | {'loss': 1.8055, 'grad_norm': 12.80776309967041, 'learning_rate': 4.008333333333334e-06, 'epoch': 1.8}
2025-06-08 06:30:35.235 | {'loss': 2.1224, 'grad_norm': 16.341835021972656, 'learning_rate': 3.9250000000000005e-06, 'epoch': 1.825}
2025-06-08 06:31:01.842 | {'loss': 2.0909, 'grad_norm': 13.500673294067383, 'learning_rate': 3.841666666666667e-06, 'epoch': 1.85}
2025-06-08 06:31:42.672 | {'loss': 2.0614, 'grad_norm': 18.631126403808594, 'learning_rate': 3.758333333333334e-06, 'epoch': 1.875}
2025-06-08 06:32:09.875 | {'loss': 2.0831, 'grad_norm': 17.567827224731445, 'learning_rate': 3.6750000000000004e-06, 'epoch': 1.9}
2025-06-08 06:32:37.087 | {'loss': 2.2603, 'grad_norm': 13.8214111328125, 'learning_rate': 3.5916666666666673e-06, 'epoch': 1.925}
2025-06-08 06:33:32.091 | {'loss': 1.8086, 'grad_norm': 14.803466796875, 'learning_rate': 3.5083333333333338e-06, 'epoch': 1.95}
2025-06-08 06:34:00.198 | {'loss': 2.094, 'grad_norm': 17.030588150024414, 'learning_rate': 3.4250000000000007e-06, 'epoch': 1.975}
2025-06-08 06:34:28.424 | {'loss': 1.805, 'grad_norm': 16.069265365600586, 'learning_rate': 3.341666666666667e-06, 'epoch': 2.0}
2025-06-08 06:34:55.204 | {'loss': 1.9772, 'grad_norm': 16.51131820678711, 'learning_rate': 3.258333333333333e-06, 'epoch': 2.025}
2025-06-08 06:35:35.619 | {'loss': 1.9084, 'grad_norm': 17.746150970458984, 'learning_rate': 3.175e-06, 'epoch': 2.05}
2025-06-08 06:36:03.258 | {'loss': 2.0534, 'grad_norm': 14.974604606628418, 'learning_rate': 3.0916666666666666e-06, 'epoch': 2.075}
2025-06-08 06:36:42.365 | {'loss': 1.425, 'grad_norm': 12.527349472045898, 'learning_rate': 3.0083333333333335e-06, 'epoch': 2.1}
2025-06-08 06:37:08.990 | {'loss': 1.569, 'grad_norm': 11.851018905639648, 'learning_rate': 2.925e-06, 'epoch': 2.125}
2025-06-08 06:37:35.056 | {'loss': 1.9713, 'grad_norm': 14.184896469116211, 'learning_rate': 2.841666666666667e-06, 'epoch': 2.15}
2025-06-08 06:38:14.569 | {'loss': 1.6258, 'grad_norm': 15.288968086242676, 'learning_rate': 2.7583333333333333e-06, 'epoch': 2.175}
2025-06-08 06:38:41.194 | {'loss': 1.5294, 'grad_norm': 16.500656127929688, 'learning_rate': 2.6750000000000002e-06, 'epoch': 2.2}
2025-06-08 06:39:08.143 | {'loss': 1.8428, 'grad_norm': 12.992874145507812, 'learning_rate': 2.5916666666666667e-06, 'epoch': 2.225}
2025-06-08 06:39:49.215 | {'loss': 2.0001, 'grad_norm': 13.136853218078613, 'learning_rate': 2.5083333333333336e-06, 'epoch': 2.25}
2025-06-08 06:40:17.028 | {'loss': 1.6156, 'grad_norm': 10.480268478393555, 'learning_rate': 2.425e-06, 'epoch': 2.275}
2025-06-08 06:40:45.318 | {'loss': 1.4048, 'grad_norm': 13.003608703613281, 'learning_rate': 2.341666666666667e-06, 'epoch': 2.3}
2025-06-08 06:41:28.003 | {'loss': 1.7458, 'grad_norm': 16.763578414916992, 'learning_rate': 2.2583333333333335e-06, 'epoch': 2.325}
2025-06-08 06:41:55.911 | {'loss': 1.5053, 'grad_norm': 12.329292297363281, 'learning_rate': 2.1750000000000004e-06, 'epoch': 2.35}
2025-06-08 06:42:24.271 | {'loss': 1.4784, 'grad_norm': 7.788717746734619, 'learning_rate': 2.091666666666667e-06, 'epoch': 2.375}
2025-06-08 06:43:06.519 | {'loss': 1.519, 'grad_norm': 10.001033782958984, 'learning_rate': 2.0083333333333337e-06, 'epoch': 2.4}
2025-06-08 06:43:34.600 | {'loss': 1.7914, 'grad_norm': 16.17971420288086, 'learning_rate': 1.925e-06, 'epoch': 2.425}
2025-06-08 06:44:01.477 | {'loss': 1.4959, 'grad_norm': 15.50933837890625, 'learning_rate': 1.8416666666666669e-06, 'epoch': 2.45}
2025-06-08 06:44:43.343 | {'loss': 1.5388, 'grad_norm': 15.099030494689941, 'learning_rate': 1.7583333333333336e-06, 'epoch': 2.475}
2025-06-08 06:45:11.925 | {'loss': 1.4045, 'grad_norm': 15.820683479309082, 'learning_rate': 1.6750000000000003e-06, 'epoch': 2.5}
2025-06-08 06:45:41.155 | {'loss': 1.7288, 'grad_norm': 12.290589332580566, 'learning_rate': 1.591666666666667e-06, 'epoch': 2.525}
2025-06-08 06:46:23.617 | {'loss': 1.7159, 'grad_norm': 18.03338050842285, 'learning_rate': 1.5083333333333336e-06, 'epoch': 2.55}
2025-06-08 06:46:52.367 | {'loss': 1.711, 'grad_norm': 16.64389419555664, 'learning_rate': 1.425e-06, 'epoch': 2.575}
2025-06-08 06:47:20.581 | {'loss': 1.6592, 'grad_norm': 15.064861297607422, 'learning_rate': 1.3416666666666666e-06, 'epoch': 2.6}
2025-06-08 06:48:01.494 | {'loss': 1.9602, 'grad_norm': 16.49806022644043, 'learning_rate': 1.2583333333333333e-06, 'epoch': 2.625}
2025-06-08 06:48:29.624 | {'loss': 1.3001, 'grad_norm': 14.27895736694336, 'learning_rate': 1.175e-06, 'epoch': 2.65}
2025-06-08 06:48:57.367 | {'loss': 1.6526, 'grad_norm': 13.38996410369873, 'learning_rate': 1.0916666666666667e-06, 'epoch': 2.675}
2025-06-08 06:49:25.960 | {'loss': 1.7654, 'grad_norm': 17.097787857055664, 'learning_rate': 1.0083333333333333e-06, 'epoch': 2.7}
2025-06-08 06:50:07.225 | {'loss': 1.6639, 'grad_norm': 12.346697807312012, 'learning_rate': 9.25e-07, 'epoch': 2.725}
2025-06-08 06:50:37.188 | {'loss': 1.6199, 'grad_norm': 16.634981155395508, 'learning_rate': 8.416666666666667e-07, 'epoch': 2.75}
2025-06-08 06:51:06.536 | {'loss': 1.6221, 'grad_norm': 16.70832061767578, 'learning_rate': 7.583333333333334e-07, 'epoch': 2.775}
2025-06-08 06:51:36.797 | {'loss': 1.8592, 'grad_norm': 18.633909225463867, 'learning_rate': 6.750000000000001e-07, 'epoch': 2.8}
2025-06-08 06:52:04.745 | {'loss': 1.7549, 'grad_norm': 17.71604347229004, 'learning_rate': 5.916666666666667e-07, 'epoch': 2.825}
2025-06-08 06:52:46.343 | {'loss': 1.6672, 'grad_norm': 13.383727073669434, 'learning_rate': 5.083333333333334e-07, 'epoch': 2.85}
2025-06-08 06:53:16.124 | {'loss': 1.5406, 'grad_norm': 12.184269905090332, 'learning_rate': 4.2500000000000006e-07, 'epoch': 2.875}
2025-06-08 06:53:45.950 | {'loss': 1.6863, 'grad_norm': 15.774744033813477, 'learning_rate': 3.416666666666667e-07, 'epoch': 2.9}
2025-06-08 06:54:12.582 | {'loss': 1.8052, 'grad_norm': 16.50127601623535, 'learning_rate': 2.5833333333333333e-07, 'epoch': 2.925}
2025-06-08 06:54:53.150 | {'loss': 1.9823, 'grad_norm': 17.86563491821289, 'learning_rate': 1.7500000000000002e-07, 'epoch': 2.95}
2025-06-08 06:55:20.855 | {'loss': 1.7637, 'grad_norm': 16.703594207763672, 'learning_rate': 9.166666666666668e-08, 'epoch': 2.975}
2025-06-08 06:55:48.693 | {'loss': 2.1409, 'grad_norm': 18.869840621948242, 'learning_rate': 8.333333333333335e-09, 'epoch': 3.0}
2025-06-08 06:55:48.693 | {'train_runtime': 3561.7443, 'train_samples_per_second': 0.674, 'train_steps_per_second': 0.337, 'train_loss': 2.009806529680888, 'epoch': 3.0}
2025-06-08 06:56:57.041 | {'eval_loss': 2.175032138824463, 'eval_runtime': 68.2976, 'eval_samples_per_second': 2.928, 'eval_steps_per_second': 0.366, 'epoch': 3.0}
2025-06-08 06:59:41.038 | INFO :      Sent reply
2025-06-08 07:13:16.174 | INFO :      
2025-06-08 07:13:16.174 | INFO :      Received: evaluate message 8deac595-be24-4e45-b3b7-da8f6a959975
2025-06-08 07:13:41.620 | {'eval_loss': 2.1165578365325928, 'eval_runtime': 21.0881, 'eval_samples_per_second': 9.484, 'eval_steps_per_second': 1.186, 'epoch': 3.0}
2025-06-08 07:13:41.626 | INFO :      Sent reply
2025-06-08 07:13:59.583 | INFO :      
2025-06-08 07:13:59.583 | INFO :      Received: train message 0f042227-324b-4e91-b250-6b9fbbca1c20
2025-06-08 07:16:03.954 | {'loss': 1.9325, 'grad_norm': 15.848374366760254, 'learning_rate': 9.925e-06, 'epoch': 0.025}
2025-06-08 07:16:30.687 | {'loss': 2.0277, 'grad_norm': 16.785112380981445, 'learning_rate': 9.841666666666668e-06, 'epoch': 0.05}
2025-06-08 07:16:57.402 | {'loss': 1.6762, 'grad_norm': 13.33106517791748, 'learning_rate': 9.758333333333334e-06, 'epoch': 0.075}
2025-06-08 07:17:23.947 | {'loss': 1.7061, 'grad_norm': 9.947060585021973, 'learning_rate': 9.675000000000001e-06, 'epoch': 0.1}
2025-06-08 07:18:03.183 | {'loss': 1.9433, 'grad_norm': 20.543434143066406, 'learning_rate': 9.591666666666667e-06, 'epoch': 0.125}
2025-06-08 07:18:30.127 | {'loss': 1.817, 'grad_norm': 16.3959903717041, 'learning_rate': 9.508333333333333e-06, 'epoch': 0.15}
2025-06-08 07:18:58.326 | {'loss': 1.9076, 'grad_norm': 20.385778427124023, 'learning_rate': 9.425e-06, 'epoch': 0.175}
2025-06-08 07:19:38.454 | {'loss': 1.9561, 'grad_norm': 17.23855972290039, 'learning_rate': 9.341666666666667e-06, 'epoch': 0.2}
2025-06-08 07:20:07.341 | {'loss': 2.0317, 'grad_norm': 18.88395881652832, 'learning_rate': 9.258333333333334e-06, 'epoch': 0.225}
2025-06-08 07:20:35.586 | {'loss': 1.7909, 'grad_norm': 20.72237777709961, 'learning_rate': 9.175000000000001e-06, 'epoch': 0.25}
2025-06-08 07:21:14.885 | {'loss': 1.9003, 'grad_norm': 15.37523365020752, 'learning_rate': 9.091666666666668e-06, 'epoch': 0.275}
2025-06-08 07:21:41.731 | {'loss': 2.0347, 'grad_norm': 17.808921813964844, 'learning_rate': 9.008333333333335e-06, 'epoch': 0.3}
2025-06-08 07:22:08.621 | {'loss': 2.2115, 'grad_norm': 19.601158142089844, 'learning_rate': 8.925e-06, 'epoch': 0.325}
2025-06-08 07:22:48.648 | {'loss': 2.083, 'grad_norm': 11.92999267578125, 'learning_rate': 8.841666666666667e-06, 'epoch': 0.35}
2025-06-08 07:23:17.241 | {'loss': 2.1475, 'grad_norm': 18.991283416748047, 'learning_rate': 8.758333333333334e-06, 'epoch': 0.375}
2025-06-08 07:23:58.119 | {'loss': 1.8345, 'grad_norm': 15.745729446411133, 'learning_rate': 8.675e-06, 'epoch': 0.4}
2025-06-08 07:24:28.560 | {'loss': 2.072, 'grad_norm': 19.825946807861328, 'learning_rate': 8.591666666666668e-06, 'epoch': 0.425}
2025-06-08 07:24:55.059 | {'loss': 1.8592, 'grad_norm': 17.536211013793945, 'learning_rate': 8.508333333333335e-06, 'epoch': 0.45}
2025-06-08 07:25:33.762 | {'loss': 2.1653, 'grad_norm': 18.728530883789062, 'learning_rate': 8.425000000000001e-06, 'epoch': 0.475}
2025-06-08 07:26:00.452 | {'loss': 1.9057, 'grad_norm': 17.17679214477539, 'learning_rate': 8.341666666666667e-06, 'epoch': 0.5}
2025-06-08 07:26:28.315 | {'loss': 2.0702, 'grad_norm': 12.288858413696289, 'learning_rate': 8.258333333333334e-06, 'epoch': 0.525}
2025-06-08 07:26:53.827 | {'loss': 2.0571, 'grad_norm': 18.43721580505371, 'learning_rate': 8.175e-06, 'epoch': 0.55}
2025-06-08 07:27:31.515 | {'loss': 1.6297, 'grad_norm': 10.13869571685791, 'learning_rate': 8.091666666666667e-06, 'epoch': 0.575}
2025-06-08 07:27:58.392 | {'loss': 1.6, 'grad_norm': 8.207265853881836, 'learning_rate': 8.008333333333334e-06, 'epoch': 0.6}
2025-06-08 07:28:23.706 | {'loss': 2.3979, 'grad_norm': 14.795548439025879, 'learning_rate': 7.925000000000001e-06, 'epoch': 0.625}
2025-06-08 07:29:05.186 | {'loss': 1.9137, 'grad_norm': 16.614234924316406, 'learning_rate': 7.841666666666668e-06, 'epoch': 0.65}
2025-06-08 07:29:31.767 | {'loss': 1.9662, 'grad_norm': 13.25317668914795, 'learning_rate': 7.758333333333335e-06, 'epoch': 0.675}
2025-06-08 07:29:59.365 | {'loss': 2.052, 'grad_norm': 15.394792556762695, 'learning_rate': 7.675e-06, 'epoch': 0.7}
2025-06-08 07:30:38.980 | {'loss': 2.1282, 'grad_norm': 27.448631286621094, 'learning_rate': 7.591666666666667e-06, 'epoch': 0.725}
2025-06-08 07:31:06.655 | {'loss': 1.8734, 'grad_norm': 19.237993240356445, 'learning_rate': 7.508333333333334e-06, 'epoch': 0.75}
2025-06-08 07:31:33.196 | {'loss': 2.1326, 'grad_norm': 16.043149948120117, 'learning_rate': 7.425000000000001e-06, 'epoch': 0.775}
2025-06-08 07:32:13.990 | {'loss': 2.337, 'grad_norm': 16.72323989868164, 'learning_rate': 7.341666666666667e-06, 'epoch': 0.8}
2025-06-08 07:32:41.624 | {'loss': 2.3435, 'grad_norm': 12.175333976745605, 'learning_rate': 7.258333333333334e-06, 'epoch': 0.825}
2025-06-08 07:33:21.282 | {'loss': 1.5099, 'grad_norm': 16.2681827545166, 'learning_rate': 7.175000000000001e-06, 'epoch': 0.85}
2025-06-08 07:33:46.740 | {'loss': 1.8042, 'grad_norm': 20.044660568237305, 'learning_rate': 7.091666666666667e-06, 'epoch': 0.875}
2025-06-08 07:34:12.159 | {'loss': 1.9253, 'grad_norm': 20.69390296936035, 'learning_rate': 7.008333333333334e-06, 'epoch': 0.9}
2025-06-08 07:34:38.342 | {'loss': 1.8343, 'grad_norm': 17.66291046142578, 'learning_rate': 6.925000000000001e-06, 'epoch': 0.925}
2025-06-08 07:35:17.429 | {'loss': 1.5754, 'grad_norm': 12.537923812866211, 'learning_rate': 6.8416666666666675e-06, 'epoch': 0.95}
2025-06-08 07:35:45.591 | {'loss': 1.8815, 'grad_norm': 18.46723747253418, 'learning_rate': 6.7583333333333336e-06, 'epoch': 0.975}
2025-06-08 07:36:17.671 | {'loss': 1.7562, 'grad_norm': 16.8149356842041, 'learning_rate': 6.6750000000000005e-06, 'epoch': 1.0}
2025-06-08 07:36:58.306 | {'loss': 1.5521, 'grad_norm': 17.070632934570312, 'learning_rate': 6.591666666666667e-06, 'epoch': 1.025}
2025-06-08 07:37:25.306 | {'loss': 1.602, 'grad_norm': 16.198532104492188, 'learning_rate': 6.508333333333334e-06, 'epoch': 1.05}
2025-06-08 07:37:52.233 | {'loss': 1.5592, 'grad_norm': 12.307936668395996, 'learning_rate': 6.425e-06, 'epoch': 1.075}
2025-06-08 07:38:34.202 | {'loss': 1.625, 'grad_norm': 14.16124439239502, 'learning_rate': 6.341666666666667e-06, 'epoch': 1.1}
2025-06-08 07:39:01.223 | {'loss': 1.6864, 'grad_norm': 14.52054500579834, 'learning_rate': 6.258333333333334e-06, 'epoch': 1.125}
2025-06-08 07:39:26.682 | {'loss': 1.4286, 'grad_norm': 13.812647819519043, 'learning_rate': 6.175000000000001e-06, 'epoch': 1.15}
2025-06-08 07:39:52.802 | {'loss': 1.7338, 'grad_norm': 12.013168334960938, 'learning_rate': 6.091666666666667e-06, 'epoch': 1.175}
2025-06-08 07:40:32.775 | {'loss': 1.4326, 'grad_norm': 15.700963020324707, 'learning_rate': 6.008333333333334e-06, 'epoch': 1.2}
2025-06-08 07:41:05.401 | {'loss': 1.6634, 'grad_norm': 16.591733932495117, 'learning_rate': 5.925000000000001e-06, 'epoch': 1.225}
2025-06-08 07:41:33.465 | {'loss': 1.6283, 'grad_norm': 14.117992401123047, 'learning_rate': 5.841666666666667e-06, 'epoch': 1.25}
2025-06-08 07:42:11.562 | {'loss': 1.0983, 'grad_norm': 8.096179008483887, 'learning_rate': 5.758333333333334e-06, 'epoch': 1.275}
2025-06-08 07:42:36.492 | {'loss': 1.9288, 'grad_norm': 16.25605583190918, 'learning_rate': 5.675000000000001e-06, 'epoch': 1.3}
2025-06-08 07:43:03.745 | {'loss': 1.6066, 'grad_norm': 10.146258354187012, 'learning_rate': 5.591666666666668e-06, 'epoch': 1.325}
2025-06-08 07:43:44.762 | {'loss': 1.4175, 'grad_norm': 12.60654067993164, 'learning_rate': 5.508333333333334e-06, 'epoch': 1.35}
2025-06-08 07:44:13.088 | {'loss': 1.4083, 'grad_norm': 13.587057113647461, 'learning_rate': 5.4250000000000006e-06, 'epoch': 1.375}
2025-06-08 07:44:40.033 | {'loss': 1.8017, 'grad_norm': 16.016328811645508, 'learning_rate': 5.3416666666666675e-06, 'epoch': 1.4}
2025-06-08 07:45:06.408 | {'loss': 1.6034, 'grad_norm': 12.403193473815918, 'learning_rate': 5.258333333333334e-06, 'epoch': 1.425}
2025-06-08 07:45:46.826 | {'loss': 1.5175, 'grad_norm': 14.444238662719727, 'learning_rate': 5.1750000000000004e-06, 'epoch': 1.45}
2025-06-08 07:46:16.096 | {'loss': 1.6043, 'grad_norm': 13.38708209991455, 'learning_rate': 5.091666666666667e-06, 'epoch': 1.475}
2025-06-08 07:46:42.761 | {'loss': 1.7811, 'grad_norm': 11.771499633789062, 'learning_rate': 5.008333333333334e-06, 'epoch': 1.5}
2025-06-08 07:47:22.747 | {'loss': 1.5001, 'grad_norm': 19.165285110473633, 'learning_rate': 4.925e-06, 'epoch': 1.525}
2025-06-08 07:47:49.256 | {'loss': 1.7091, 'grad_norm': 18.61451530456543, 'learning_rate': 4.841666666666667e-06, 'epoch': 1.55}
2025-06-08 07:48:16.738 | {'loss': 1.632, 'grad_norm': 15.09933853149414, 'learning_rate': 4.758333333333334e-06, 'epoch': 1.575}
2025-06-08 07:48:57.119 | {'loss': 1.6187, 'grad_norm': 21.957639694213867, 'learning_rate': 4.675000000000001e-06, 'epoch': 1.6}
2025-06-08 07:49:25.267 | {'loss': 1.7778, 'grad_norm': 15.257919311523438, 'learning_rate': 4.591666666666667e-06, 'epoch': 1.625}
2025-06-08 07:49:53.676 | {'loss': 1.4655, 'grad_norm': 13.463129997253418, 'learning_rate': 4.508333333333333e-06, 'epoch': 1.65}
2025-06-08 07:50:32.801 | {'loss': 1.5752, 'grad_norm': 18.49308204650879, 'learning_rate': 4.425e-06, 'epoch': 1.675}
2025-06-08 07:50:59.057 | {'loss': 1.6749, 'grad_norm': 16.699655532836914, 'learning_rate': 4.341666666666667e-06, 'epoch': 1.7}
2025-06-08 07:51:26.892 | {'loss': 1.7127, 'grad_norm': 9.577000617980957, 'learning_rate': 4.258333333333334e-06, 'epoch': 1.725}
2025-06-08 07:52:07.307 | {'loss': 1.8571, 'grad_norm': 16.788789749145508, 'learning_rate': 4.175e-06, 'epoch': 1.75}
2025-06-08 07:52:46.470 | {'loss': 1.7818, 'grad_norm': 16.396142959594727, 'learning_rate': 4.091666666666667e-06, 'epoch': 1.775}
2025-06-08 07:53:14.696 | {'loss': 1.5795, 'grad_norm': 12.6257905960083, 'learning_rate': 4.008333333333334e-06, 'epoch': 1.8}
2025-06-08 07:53:42.771 | {'loss': 1.8392, 'grad_norm': 15.75575065612793, 'learning_rate': 3.9250000000000005e-06, 'epoch': 1.825}
2025-06-08 07:54:10.154 | {'loss': 1.8633, 'grad_norm': 12.67026138305664, 'learning_rate': 3.841666666666667e-06, 'epoch': 1.85}
2025-06-08 07:54:50.033 | {'loss': 1.8115, 'grad_norm': 19.435914993286133, 'learning_rate': 3.758333333333334e-06, 'epoch': 1.875}
2025-06-08 07:55:17.807 | {'loss': 1.8012, 'grad_norm': 16.996074676513672, 'learning_rate': 3.6750000000000004e-06, 'epoch': 1.9}
2025-06-08 07:55:44.928 | {'loss': 2.0042, 'grad_norm': 17.889678955078125, 'learning_rate': 3.5916666666666673e-06, 'epoch': 1.925}
2025-06-08 07:56:24.932 | {'loss': 1.5842, 'grad_norm': 13.359789848327637, 'learning_rate': 3.5083333333333338e-06, 'epoch': 1.95}
2025-06-08 07:56:52.175 | {'loss': 1.7902, 'grad_norm': 16.14047622680664, 'learning_rate': 3.4250000000000007e-06, 'epoch': 1.975}
2025-06-08 07:57:19.726 | {'loss': 1.5179, 'grad_norm': 14.465696334838867, 'learning_rate': 3.341666666666667e-06, 'epoch': 2.0}
2025-06-08 07:57:58.778 | {'loss': 1.7213, 'grad_norm': 14.325615882873535, 'learning_rate': 3.258333333333333e-06, 'epoch': 2.025}
2025-06-08 07:58:28.145 | {'loss': 1.6334, 'grad_norm': 17.07654571533203, 'learning_rate': 3.175e-06, 'epoch': 2.05}
2025-06-08 07:59:07.665 | {'loss': 1.7831, 'grad_norm': 14.59282398223877, 'learning_rate': 3.0916666666666666e-06, 'epoch': 2.075}
2025-06-08 07:59:34.703 | {'loss': 1.2213, 'grad_norm': 12.8876314163208, 'learning_rate': 3.0083333333333335e-06, 'epoch': 2.1}
2025-06-08 08:00:00.448 | {'loss': 1.3401, 'grad_norm': 12.425786972045898, 'learning_rate': 2.925e-06, 'epoch': 2.125}
2025-06-08 08:00:39.687 | {'loss': 1.6838, 'grad_norm': 13.66445255279541, 'learning_rate': 2.841666666666667e-06, 'epoch': 2.15}
2025-06-08 08:01:06.797 | {'loss': 1.3715, 'grad_norm': 16.611003875732422, 'learning_rate': 2.7583333333333333e-06, 'epoch': 2.175}
2025-06-08 08:01:34.323 | {'loss': 1.2994, 'grad_norm': 18.126861572265625, 'learning_rate': 2.6750000000000002e-06, 'epoch': 2.2}
2025-06-08 08:02:02.124 | {'loss': 1.5807, 'grad_norm': 13.44679069519043, 'learning_rate': 2.5916666666666667e-06, 'epoch': 2.225}
2025-06-08 08:02:42.089 | {'loss': 1.7689, 'grad_norm': 13.286261558532715, 'learning_rate': 2.5083333333333336e-06, 'epoch': 2.25}
2025-06-08 08:03:10.787 | {'loss': 1.3996, 'grad_norm': 10.622335433959961, 'learning_rate': 2.425e-06, 'epoch': 2.275}
2025-06-08 08:03:51.315 | {'loss': 1.1921, 'grad_norm': 13.586447715759277, 'learning_rate': 2.341666666666667e-06, 'epoch': 2.3}
2025-06-08 08:04:18.439 | {'loss': 1.4851, 'grad_norm': 17.660730361938477, 'learning_rate': 2.2583333333333335e-06, 'epoch': 2.325}
2025-06-08 08:04:45.977 | {'loss': 1.304, 'grad_norm': 12.404257774353027, 'learning_rate': 2.1750000000000004e-06, 'epoch': 2.35}
2025-06-08 08:05:13.857 | {'loss': 1.2437, 'grad_norm': 7.255178928375244, 'learning_rate': 2.091666666666667e-06, 'epoch': 2.375}
2025-06-08 08:05:56.957 | {'loss': 1.3321, 'grad_norm': 8.501457214355469, 'learning_rate': 2.0083333333333337e-06, 'epoch': 2.4}
2025-06-08 08:06:23.749 | {'loss': 1.5752, 'grad_norm': 17.304325103759766, 'learning_rate': 1.925e-06, 'epoch': 2.425}
2025-06-08 08:07:04.448 | {'loss': 1.284, 'grad_norm': 15.239192962646484, 'learning_rate': 1.8416666666666669e-06, 'epoch': 2.45}
2025-06-08 08:07:32.323 | {'loss': 1.296, 'grad_norm': 13.626725196838379, 'learning_rate': 1.7583333333333336e-06, 'epoch': 2.475}
2025-06-08 08:07:59.428 | {'loss': 1.1919, 'grad_norm': 14.721553802490234, 'learning_rate': 1.6750000000000003e-06, 'epoch': 2.5}
2025-06-08 08:08:24.933 | {'loss': 1.4339, 'grad_norm': 11.309290885925293, 'learning_rate': 1.591666666666667e-06, 'epoch': 2.525}
2025-06-08 08:09:05.337 | {'loss': 1.5061, 'grad_norm': 17.485219955444336, 'learning_rate': 1.5083333333333336e-06, 'epoch': 2.55}
2025-06-08 08:09:31.869 | {'loss': 1.4997, 'grad_norm': 15.659224510192871, 'learning_rate': 1.425e-06, 'epoch': 2.575}
2025-06-08 08:09:58.435 | {'loss': 1.4348, 'grad_norm': 15.793740272521973, 'learning_rate': 1.3416666666666666e-06, 'epoch': 2.6}
2025-06-08 08:10:35.800 | {'loss': 1.7268, 'grad_norm': 15.580278396606445, 'learning_rate': 1.2583333333333333e-06, 'epoch': 2.625}
2025-06-08 08:11:01.803 | {'loss': 1.1116, 'grad_norm': 18.471769332885742, 'learning_rate': 1.175e-06, 'epoch': 2.65}
2025-06-08 08:11:39.766 | {'loss': 1.3757, 'grad_norm': 12.979791641235352, 'learning_rate': 1.0916666666666667e-06, 'epoch': 2.675}
2025-06-08 08:12:05.394 | {'loss': 1.5568, 'grad_norm': 17.131032943725586, 'learning_rate': 1.0083333333333333e-06, 'epoch': 2.7}
2025-06-08 08:12:30.749 | {'loss': 1.469, 'grad_norm': 12.501211166381836, 'learning_rate': 9.25e-07, 'epoch': 2.725}
2025-06-08 08:13:08.508 | {'loss': 1.4288, 'grad_norm': 16.420381546020508, 'learning_rate': 8.416666666666667e-07, 'epoch': 2.75}
2025-06-08 08:13:34.185 | {'loss': 1.3887, 'grad_norm': 17.3054256439209, 'learning_rate': 7.583333333333334e-07, 'epoch': 2.775}
2025-06-08 08:13:59.916 | {'loss': 1.6083, 'grad_norm': 17.567913055419922, 'learning_rate': 6.750000000000001e-07, 'epoch': 2.8}
2025-06-08 08:14:26.139 | {'loss': 1.522, 'grad_norm': 18.224454879760742, 'learning_rate': 5.916666666666667e-07, 'epoch': 2.825}
2025-06-08 08:15:03.432 | {'loss': 1.4145, 'grad_norm': 12.721080780029297, 'learning_rate': 5.083333333333334e-07, 'epoch': 2.85}
2025-06-08 08:15:29.016 | {'loss': 1.3351, 'grad_norm': 10.06210994720459, 'learning_rate': 4.2500000000000006e-07, 'epoch': 2.875}
2025-06-08 08:16:06.911 | {'loss': 1.4878, 'grad_norm': 15.130110740661621, 'learning_rate': 3.416666666666667e-07, 'epoch': 2.9}
2025-06-08 08:16:20.344 | {'loss': 1.5797, 'grad_norm': 17.016542434692383, 'learning_rate': 2.5833333333333333e-07, 'epoch': 2.925}
2025-06-08 08:17:11.662 | {'loss': 1.7255, 'grad_norm': 18.48851776123047, 'learning_rate': 1.7500000000000002e-07, 'epoch': 2.95}
2025-06-08 08:17:37.871 | {'loss': 1.4705, 'grad_norm': 14.998950004577637, 'learning_rate': 9.166666666666668e-08, 'epoch': 2.975}
2025-06-08 08:17:58.055 | {'loss': 1.6829, 'grad_norm': 16.666288375854492, 'learning_rate': 8.333333333333335e-09, 'epoch': 3.0}
2025-06-08 08:17:58.055 | {'train_runtime': 3811.6452, 'train_samples_per_second': 0.63, 'train_steps_per_second': 0.315, 'train_loss': 1.6835995841026306, 'epoch': 3.0}
2025-06-08 08:18:08.403 | {'eval_loss': 2.129446029663086, 'eval_runtime': 10.3412, 'eval_samples_per_second': 19.34, 'eval_steps_per_second': 2.418, 'epoch': 3.0}
2025-06-08 08:18:16.415 | INFO :      Sent reply
2025-06-08 08:30:26.979 | INFO :      
2025-06-08 08:30:26.979 | INFO :      Received: evaluate message 34c7f96b-a024-4985-b283-5d767e0ba907
2025-06-08 08:30:37.340 | {'eval_loss': 2.0718705654144287, 'eval_runtime': 9.3628, 'eval_samples_per_second': 21.361, 'eval_steps_per_second': 2.67, 'epoch': 3.0}
2025-06-08 08:30:37.342 | INFO :      Sent reply
2025-06-08 08:31:05.769 | INFO :      
2025-06-08 08:31:05.769 | INFO :      Received: train message 76473c0a-0110-4d8b-8b8c-0aad5ebdec8a
2025-06-08 08:32:41.489 | {'loss': 1.7024, 'grad_norm': 14.583459854125977, 'learning_rate': 9.925e-06, 'epoch': 0.025}
2025-06-08 08:33:21.950 | {'loss': 1.8168, 'grad_norm': 16.80901336669922, 'learning_rate': 9.841666666666668e-06, 'epoch': 0.05}
2025-06-08 08:33:49.067 | {'loss': 1.4021, 'grad_norm': 10.464092254638672, 'learning_rate': 9.758333333333334e-06, 'epoch': 0.075}
2025-06-08 08:34:15.539 | {'loss': 1.4802, 'grad_norm': 8.30158519744873, 'learning_rate': 9.675000000000001e-06, 'epoch': 0.1}
2025-06-08 08:34:42.697 | {'loss': 1.7411, 'grad_norm': 20.44147300720215, 'learning_rate': 9.591666666666667e-06, 'epoch': 0.125}
2025-06-08 08:35:24.475 | {'loss': 1.5781, 'grad_norm': 15.387862205505371, 'learning_rate': 9.508333333333333e-06, 'epoch': 0.15}
2025-06-08 08:35:53.218 | {'loss': 1.7151, 'grad_norm': 21.806123733520508, 'learning_rate': 9.425e-06, 'epoch': 0.175}
2025-06-08 08:36:21.013 | {'loss': 1.7639, 'grad_norm': 18.10418128967285, 'learning_rate': 9.341666666666667e-06, 'epoch': 0.2}
2025-06-08 08:36:59.178 | {'loss': 1.8365, 'grad_norm': 18.887882232666016, 'learning_rate': 9.258333333333334e-06, 'epoch': 0.225}
2025-06-08 08:37:24.620 | {'loss': 1.618, 'grad_norm': 19.72096824645996, 'learning_rate': 9.175000000000001e-06, 'epoch': 0.25}
2025-06-08 08:37:51.351 | {'loss': 1.6994, 'grad_norm': 13.756912231445312, 'learning_rate': 9.091666666666668e-06, 'epoch': 0.275}
2025-06-08 08:38:18.224 | {'loss': 1.845, 'grad_norm': 19.085342407226562, 'learning_rate': 9.008333333333335e-06, 'epoch': 0.3}
2025-06-08 08:38:59.218 | {'loss': 2.0171, 'grad_norm': 18.086780548095703, 'learning_rate': 8.925e-06, 'epoch': 0.325}
2025-06-08 08:39:35.964 | {'loss': 1.8489, 'grad_norm': 11.809877395629883, 'learning_rate': 8.841666666666667e-06, 'epoch': 0.35}
2025-06-08 08:40:03.466 | {'loss': 1.9243, 'grad_norm': 17.66051483154297, 'learning_rate': 8.758333333333334e-06, 'epoch': 0.375}
2025-06-08 08:40:29.511 | {'loss': 1.6427, 'grad_norm': 15.470661163330078, 'learning_rate': 8.675e-06, 'epoch': 0.4}
2025-06-08 08:41:07.503 | {'loss': 1.8465, 'grad_norm': 19.417150497436523, 'learning_rate': 8.591666666666668e-06, 'epoch': 0.425}
2025-06-08 08:41:34.713 | {'loss': 1.6806, 'grad_norm': 18.542903900146484, 'learning_rate': 8.508333333333335e-06, 'epoch': 0.45}
2025-06-08 08:42:18.066 | {'loss': 1.9587, 'grad_norm': 19.20770835876465, 'learning_rate': 8.425000000000001e-06, 'epoch': 0.475}
2025-06-08 08:42:44.218 | {'loss': 1.6875, 'grad_norm': 17.63916015625, 'learning_rate': 8.341666666666667e-06, 'epoch': 0.5}
2025-06-08 08:43:22.720 | {'loss': 1.8678, 'grad_norm': 10.651668548583984, 'learning_rate': 8.258333333333334e-06, 'epoch': 0.525}
2025-06-08 08:43:49.453 | {'loss': 1.837, 'grad_norm': 16.856063842773438, 'learning_rate': 8.175e-06, 'epoch': 0.55}
2025-06-08 08:44:16.197 | {'loss': 1.4592, 'grad_norm': 8.239408493041992, 'learning_rate': 8.091666666666667e-06, 'epoch': 0.575}
2025-06-08 08:44:56.506 | {'loss': 1.4418, 'grad_norm': 7.658624172210693, 'learning_rate': 8.008333333333334e-06, 'epoch': 0.6}
2025-06-08 08:45:22.316 | {'loss': 2.1838, 'grad_norm': 14.900250434875488, 'learning_rate': 7.925000000000001e-06, 'epoch': 0.625}
2025-06-08 08:45:48.286 | {'loss': 1.6913, 'grad_norm': 17.657943725585938, 'learning_rate': 7.841666666666668e-06, 'epoch': 0.65}
2025-06-08 08:46:26.233 | {'loss': 1.7387, 'grad_norm': 13.833849906921387, 'learning_rate': 7.758333333333335e-06, 'epoch': 0.675}
2025-06-08 08:46:53.194 | {'loss': 1.8402, 'grad_norm': 17.271482467651367, 'learning_rate': 7.675e-06, 'epoch': 0.7}
2025-06-08 08:47:20.545 | {'loss': 1.8859, 'grad_norm': 22.580888748168945, 'learning_rate': 7.591666666666667e-06, 'epoch': 0.725}
2025-06-08 08:47:59.343 | {'loss': 1.6802, 'grad_norm': 19.7589168548584, 'learning_rate': 7.508333333333334e-06, 'epoch': 0.75}
2025-06-08 08:48:36.767 | {'loss': 1.9392, 'grad_norm': 15.61264419555664, 'learning_rate': 7.425000000000001e-06, 'epoch': 0.775}
2025-06-08 08:49:16.320 | {'loss': 2.1447, 'grad_norm': 16.78745460510254, 'learning_rate': 7.341666666666667e-06, 'epoch': 0.8}
2025-06-08 08:49:42.833 | {'loss': 2.1458, 'grad_norm': 11.782875061035156, 'learning_rate': 7.258333333333334e-06, 'epoch': 0.825}
2025-06-08 08:50:21.944 | {'loss': 1.3928, 'grad_norm': 15.306647300720215, 'learning_rate': 7.175000000000001e-06, 'epoch': 0.85}
2025-06-08 08:50:47.416 | {'loss': 1.6055, 'grad_norm': 19.161771774291992, 'learning_rate': 7.091666666666667e-06, 'epoch': 0.875}
2025-06-08 08:51:12.468 | {'loss': 1.7568, 'grad_norm': 29.913585662841797, 'learning_rate': 7.008333333333334e-06, 'epoch': 0.9}
2025-06-08 08:51:51.039 | {'loss': 1.6727, 'grad_norm': 19.53660774230957, 'learning_rate': 6.925000000000001e-06, 'epoch': 0.925}
2025-06-08 08:52:30.180 | {'loss': 1.4546, 'grad_norm': 13.795933723449707, 'learning_rate': 6.8416666666666675e-06, 'epoch': 0.95}
2025-06-08 08:52:57.657 | {'loss': 1.7162, 'grad_norm': 18.414968490600586, 'learning_rate': 6.7583333333333336e-06, 'epoch': 0.975}
2025-06-08 08:53:25.100 | {'loss': 1.6141, 'grad_norm': 16.379541397094727, 'learning_rate': 6.6750000000000005e-06, 'epoch': 1.0}
2025-06-08 08:53:53.061 | {'loss': 1.367, 'grad_norm': 16.93810272216797, 'learning_rate': 6.591666666666667e-06, 'epoch': 1.025}
2025-06-08 08:54:21.834 | {'loss': 1.4021, 'grad_norm': 16.679960250854492, 'learning_rate': 6.508333333333334e-06, 'epoch': 1.05}
2025-06-08 08:54:59.559 | {'loss': 1.398, 'grad_norm': 12.589789390563965, 'learning_rate': 6.425e-06, 'epoch': 1.075}
2025-06-08 08:55:25.947 | {'loss': 1.4394, 'grad_norm': 13.82385540008545, 'learning_rate': 6.341666666666667e-06, 'epoch': 1.1}
2025-06-08 08:55:52.875 | {'loss': 1.4997, 'grad_norm': 16.192413330078125, 'learning_rate': 6.258333333333334e-06, 'epoch': 1.125}
2025-06-08 08:56:35.984 | {'loss': 1.2474, 'grad_norm': 13.785869598388672, 'learning_rate': 6.175000000000001e-06, 'epoch': 1.15}
2025-06-08 08:57:01.218 | {'loss': 1.5517, 'grad_norm': 12.112486839294434, 'learning_rate': 6.091666666666667e-06, 'epoch': 1.175}
2025-06-08 08:57:27.564 | {'loss': 1.2741, 'grad_norm': 14.940951347351074, 'learning_rate': 6.008333333333334e-06, 'epoch': 1.2}
2025-06-08 08:57:53.864 | {'loss': 1.5024, 'grad_norm': 16.874544143676758, 'learning_rate': 5.925000000000001e-06, 'epoch': 1.225}
2025-06-08 08:58:34.889 | {'loss': 1.4396, 'grad_norm': 11.550993919372559, 'learning_rate': 5.841666666666667e-06, 'epoch': 1.25}
2025-06-08 08:59:01.529 | {'loss': 0.9697, 'grad_norm': 9.81209945678711, 'learning_rate': 5.758333333333334e-06, 'epoch': 1.275}
2025-06-08 08:59:41.736 | {'loss': 1.7326, 'grad_norm': 16.020124435424805, 'learning_rate': 5.675000000000001e-06, 'epoch': 1.3}
2025-06-08 09:00:10.197 | {'loss': 1.4318, 'grad_norm': 8.969949722290039, 'learning_rate': 5.591666666666668e-06, 'epoch': 1.325}
2025-06-08 09:00:51.551 | {'loss': 1.2891, 'grad_norm': 12.695666313171387, 'learning_rate': 5.508333333333334e-06, 'epoch': 1.35}
2025-06-08 09:01:18.636 | {'loss': 1.26, 'grad_norm': 12.942232131958008, 'learning_rate': 5.4250000000000006e-06, 'epoch': 1.375}
2025-06-08 09:01:45.224 | {'loss': 1.6351, 'grad_norm': 14.947138786315918, 'learning_rate': 5.3416666666666675e-06, 'epoch': 1.4}
2025-06-08 09:02:25.221 | {'loss': 1.4204, 'grad_norm': 13.324545860290527, 'learning_rate': 5.258333333333334e-06, 'epoch': 1.425}
2025-06-08 09:02:51.742 | {'loss': 1.397, 'grad_norm': 13.216638565063477, 'learning_rate': 5.1750000000000004e-06, 'epoch': 1.45}
2025-06-08 09:03:32.365 | {'loss': 1.4428, 'grad_norm': 14.537704467773438, 'learning_rate': 5.091666666666667e-06, 'epoch': 1.475}
2025-06-08 09:03:59.562 | {'loss': 1.6293, 'grad_norm': 14.038997650146484, 'learning_rate': 5.008333333333334e-06, 'epoch': 1.5}
2025-06-08 09:04:26.878 | {'loss': 1.3532, 'grad_norm': 17.347383499145508, 'learning_rate': 4.925e-06, 'epoch': 1.525}
2025-06-08 09:05:06.332 | {'loss': 1.4764, 'grad_norm': 17.674968719482422, 'learning_rate': 4.841666666666667e-06, 'epoch': 1.55}
2025-06-08 09:05:35.867 | {'loss': 1.4886, 'grad_norm': 12.041374206542969, 'learning_rate': 4.758333333333334e-06, 'epoch': 1.575}
2025-06-08 09:06:14.273 | {'loss': 1.4583, 'grad_norm': 19.29141616821289, 'learning_rate': 4.675000000000001e-06, 'epoch': 1.6}
2025-06-08 09:06:40.591 | {'loss': 1.6231, 'grad_norm': 18.426467895507812, 'learning_rate': 4.591666666666667e-06, 'epoch': 1.625}
2025-06-08 09:07:10.051 | {'loss': 1.293, 'grad_norm': 12.204036712646484, 'learning_rate': 4.508333333333333e-06, 'epoch': 1.65}
2025-06-08 09:07:49.120 | {'loss': 1.4191, 'grad_norm': 18.883316040039062, 'learning_rate': 4.425e-06, 'epoch': 1.675}
2025-06-08 09:08:15.182 | {'loss': 1.5132, 'grad_norm': 16.163328170776367, 'learning_rate': 4.341666666666667e-06, 'epoch': 1.7}
2025-06-08 09:08:41.693 | {'loss': 1.5371, 'grad_norm': 9.931875228881836, 'learning_rate': 4.258333333333334e-06, 'epoch': 1.725}
2025-06-08 09:09:22.734 | {'loss': 1.6671, 'grad_norm': 18.80113410949707, 'learning_rate': 4.175e-06, 'epoch': 1.75}
2025-06-08 09:09:51.070 | {'loss': 1.5759, 'grad_norm': 16.765151977539062, 'learning_rate': 4.091666666666667e-06, 'epoch': 1.775}
2025-06-08 09:10:29.790 | {'loss': 1.4149, 'grad_norm': 12.74693489074707, 'learning_rate': 4.008333333333334e-06, 'epoch': 1.8}
2025-06-08 09:11:12.129 | {'loss': 1.6872, 'grad_norm': 15.255279541015625, 'learning_rate': 3.9250000000000005e-06, 'epoch': 1.825}
2025-06-08 09:11:39.152 | {'loss': 1.6951, 'grad_norm': 12.277488708496094, 'learning_rate': 3.841666666666667e-06, 'epoch': 1.85}
2025-06-08 09:12:07.549 | {'loss': 1.6595, 'grad_norm': 18.729433059692383, 'learning_rate': 3.758333333333334e-06, 'epoch': 1.875}
2025-06-08 09:12:35.079 | {'loss': 1.6336, 'grad_norm': 17.814626693725586, 'learning_rate': 3.6750000000000004e-06, 'epoch': 1.9}
2025-06-08 09:13:18.625 | {'loss': 1.8267, 'grad_norm': 13.013201713562012, 'learning_rate': 3.5916666666666673e-06, 'epoch': 1.925}
2025-06-08 09:13:46.067 | {'loss': 1.4518, 'grad_norm': 13.04643440246582, 'learning_rate': 3.5083333333333338e-06, 'epoch': 1.95}
2025-06-08 09:14:26.810 | {'loss': 1.6479, 'grad_norm': 15.816542625427246, 'learning_rate': 3.4250000000000007e-06, 'epoch': 1.975}
2025-06-08 09:14:55.079 | {'loss': 1.3633, 'grad_norm': 15.506827354431152, 'learning_rate': 3.341666666666667e-06, 'epoch': 2.0}
2025-06-08 09:15:22.174 | {'loss': 1.5203, 'grad_norm': 15.232739448547363, 'learning_rate': 3.258333333333333e-06, 'epoch': 2.025}
2025-06-08 09:16:03.653 | {'loss': 1.4353, 'grad_norm': 19.32419776916504, 'learning_rate': 3.175e-06, 'epoch': 2.05}
2025-06-08 09:16:30.993 | {'loss': 1.6135, 'grad_norm': 15.788291931152344, 'learning_rate': 3.0916666666666666e-06, 'epoch': 2.075}
2025-06-08 09:17:12.184 | {'loss': 1.0851, 'grad_norm': 12.018689155578613, 'learning_rate': 3.0083333333333335e-06, 'epoch': 2.1}
2025-06-08 09:17:53.541 | {'loss': 1.1947, 'grad_norm': 11.936864852905273, 'learning_rate': 2.925e-06, 'epoch': 2.125}
2025-06-08 09:18:22.640 | {'loss': 1.5161, 'grad_norm': 13.83109188079834, 'learning_rate': 2.841666666666667e-06, 'epoch': 2.15}
2025-06-08 09:18:52.738 | {'loss': 1.2088, 'grad_norm': 15.87671184539795, 'learning_rate': 2.7583333333333333e-06, 'epoch': 2.175}
2025-06-08 09:19:34.251 | {'loss': 1.1512, 'grad_norm': 18.791017532348633, 'learning_rate': 2.6750000000000002e-06, 'epoch': 2.2}
2025-06-08 09:20:03.407 | {'loss': 1.3954, 'grad_norm': 13.934215545654297, 'learning_rate': 2.5916666666666667e-06, 'epoch': 2.225}
2025-06-08 09:20:45.017 | {'loss': 1.5706, 'grad_norm': 12.791671752929688, 'learning_rate': 2.5083333333333336e-06, 'epoch': 2.25}
2025-06-08 09:21:15.482 | {'loss': 1.2527, 'grad_norm': 12.315875053405762, 'learning_rate': 2.425e-06, 'epoch': 2.275}
2025-06-08 09:21:44.270 | {'loss': 1.0452, 'grad_norm': 13.121747970581055, 'learning_rate': 2.341666666666667e-06, 'epoch': 2.3}
2025-06-08 09:22:29.018 | {'loss': 1.3154, 'grad_norm': 18.616535186767578, 'learning_rate': 2.2583333333333335e-06, 'epoch': 2.325}
2025-06-08 09:22:59.610 | {'loss': 1.1771, 'grad_norm': 11.680269241333008, 'learning_rate': 2.1750000000000004e-06, 'epoch': 2.35}
2025-06-08 09:23:28.084 | {'loss': 1.1015, 'grad_norm': 7.263424396514893, 'learning_rate': 2.091666666666667e-06, 'epoch': 2.375}
2025-06-08 09:23:56.403 | {'loss': 1.1804, 'grad_norm': 8.067005157470703, 'learning_rate': 2.0083333333333337e-06, 'epoch': 2.4}
2025-06-08 09:24:37.608 | {'loss': 1.4223, 'grad_norm': 16.535736083984375, 'learning_rate': 1.925e-06, 'epoch': 2.425}
2025-06-08 09:25:06.200 | {'loss': 1.1385, 'grad_norm': 14.021940231323242, 'learning_rate': 1.8416666666666669e-06, 'epoch': 2.45}
2025-06-08 09:25:47.398 | {'loss': 1.1434, 'grad_norm': 13.519615173339844, 'learning_rate': 1.7583333333333336e-06, 'epoch': 2.475}
2025-06-08 09:26:12.023 | {'loss': 1.0647, 'grad_norm': 14.417455673217773, 'learning_rate': 1.6750000000000003e-06, 'epoch': 2.5}
2025-06-08 09:26:40.013 | {'loss': 1.2558, 'grad_norm': 11.958772659301758, 'learning_rate': 1.591666666666667e-06, 'epoch': 2.525}
2025-06-08 09:27:09.273 | {'loss': 1.365, 'grad_norm': 17.12960433959961, 'learning_rate': 1.5083333333333336e-06, 'epoch': 2.55}
2025-06-08 09:27:49.835 | {'loss': 1.3563, 'grad_norm': 14.639883995056152, 'learning_rate': 1.425e-06, 'epoch': 2.575}
2025-06-08 09:28:17.392 | {'loss': 1.297, 'grad_norm': 14.489381790161133, 'learning_rate': 1.3416666666666666e-06, 'epoch': 2.6}
2025-06-08 09:28:42.938 | {'loss': 1.5741, 'grad_norm': 17.741514205932617, 'learning_rate': 1.2583333333333333e-06, 'epoch': 2.625}
2025-06-08 09:29:23.434 | {'loss': 0.9961, 'grad_norm': 14.266058921813965, 'learning_rate': 1.175e-06, 'epoch': 2.65}
2025-06-08 09:29:50.258 | {'loss': 1.2279, 'grad_norm': 12.216997146606445, 'learning_rate': 1.0916666666666667e-06, 'epoch': 2.675}
2025-06-08 09:30:17.477 | {'loss': 1.431, 'grad_norm': 17.610185623168945, 'learning_rate': 1.0083333333333333e-06, 'epoch': 2.7}
2025-06-08 09:30:57.331 | {'loss': 1.3354, 'grad_norm': 11.837308883666992, 'learning_rate': 9.25e-07, 'epoch': 2.725}
2025-06-08 09:31:22.538 | {'loss': 1.2818, 'grad_norm': 16.369823455810547, 'learning_rate': 8.416666666666667e-07, 'epoch': 2.75}
2025-06-08 09:31:50.347 | {'loss': 1.2387, 'grad_norm': 16.56578826904297, 'learning_rate': 7.583333333333334e-07, 'epoch': 2.775}
2025-06-08 09:32:17.296 | {'loss': 1.4628, 'grad_norm': 20.6323184967041, 'learning_rate': 6.750000000000001e-07, 'epoch': 2.8}
2025-06-08 09:32:56.118 | {'loss': 1.3492, 'grad_norm': 16.92705726623535, 'learning_rate': 5.916666666666667e-07, 'epoch': 2.825}
2025-06-08 09:33:22.481 | {'loss': 1.265, 'grad_norm': 12.859903335571289, 'learning_rate': 5.083333333333334e-07, 'epoch': 2.85}
2025-06-08 09:33:50.540 | {'loss': 1.2001, 'grad_norm': 9.43532657623291, 'learning_rate': 4.2500000000000006e-07, 'epoch': 2.875}
2025-06-08 09:34:28.286 | {'loss': 1.3356, 'grad_norm': 14.966140747070312, 'learning_rate': 3.416666666666667e-07, 'epoch': 2.9}
2025-06-08 09:34:53.990 | {'loss': 1.4121, 'grad_norm': 17.190797805786133, 'learning_rate': 2.5833333333333333e-07, 'epoch': 2.925}
2025-06-08 09:35:21.263 | {'loss': 1.5762, 'grad_norm': 17.895124435424805, 'learning_rate': 1.7500000000000002e-07, 'epoch': 2.95}
2025-06-08 09:36:01.817 | {'loss': 1.3052, 'grad_norm': 15.877691268920898, 'learning_rate': 9.166666666666668e-08, 'epoch': 2.975}
2025-06-08 09:36:30.796 | {'loss': 1.4475, 'grad_norm': 16.672943115234375, 'learning_rate': 8.333333333333335e-09, 'epoch': 3.0}
2025-06-08 09:36:30.796 | {'train_runtime': 3903.6841, 'train_samples_per_second': 0.615, 'train_steps_per_second': 0.307, 'train_loss': 1.5102681732177734, 'epoch': 3.0}
2025-06-08 09:37:22.014 | {'eval_loss': 2.1302061080932617, 'eval_runtime': 51.2131, 'eval_samples_per_second': 3.905, 'eval_steps_per_second': 0.488, 'epoch': 3.0}
2025-06-08 09:37:30.503 | INFO :      Sent reply
2025-06-08 09:50:27.587 | INFO :      
2025-06-08 09:50:27.587 | INFO :      Received: evaluate message c96214ea-1cf4-4b54-92e9-06a9c009b4df
2025-06-08 09:50:46.242 | {'eval_loss': 2.074345827102661, 'eval_runtime': 11.819, 'eval_samples_per_second': 16.922, 'eval_steps_per_second': 2.115, 'epoch': 3.0}
2025-06-08 09:50:46.268 | INFO :      Sent reply
2025-06-08 09:51:07.848 | INFO :      
2025-06-08 09:51:07.848 | INFO :      Received: train message 0015f517-f04c-4ab4-ac91-2db016adb2fe
2025-06-08 09:51:52.037 | {'loss': 1.5255, 'grad_norm': 15.26718807220459, 'learning_rate': 9.925e-06, 'epoch': 0.025}
2025-06-08 09:52:18.333 | {'loss': 1.6378, 'grad_norm': 18.141883850097656, 'learning_rate': 9.841666666666668e-06, 'epoch': 0.05}
2025-06-08 09:52:37.149 | {'loss': 1.2559, 'grad_norm': 10.287834167480469, 'learning_rate': 9.758333333333334e-06, 'epoch': 0.075}
2025-06-08 09:52:56.552 | {'loss': 1.32, 'grad_norm': 7.210689067840576, 'learning_rate': 9.675000000000001e-06, 'epoch': 0.1}
2025-06-08 09:53:15.091 | {'loss': 1.5728, 'grad_norm': 22.227678298950195, 'learning_rate': 9.591666666666667e-06, 'epoch': 0.125}
2025-06-08 09:53:42.840 | {'loss': 1.4359, 'grad_norm': 13.788850784301758, 'learning_rate': 9.508333333333333e-06, 'epoch': 0.15}
2025-06-08 09:54:03.063 | {'loss': 1.5383, 'grad_norm': 20.558897018432617, 'learning_rate': 9.425e-06, 'epoch': 0.175}
2025-06-08 09:54:22.606 | {'loss': 1.5868, 'grad_norm': 18.005783081054688, 'learning_rate': 9.341666666666667e-06, 'epoch': 0.2}
2025-06-08 09:54:51.676 | {'loss': 1.6496, 'grad_norm': 20.06024742126465, 'learning_rate': 9.258333333333334e-06, 'epoch': 0.225}
2025-06-08 09:55:12.110 | {'loss': 1.4857, 'grad_norm': 20.627473831176758, 'learning_rate': 9.175000000000001e-06, 'epoch': 0.25}
2025-06-08 09:55:32.794 | {'loss': 1.5691, 'grad_norm': 14.553515434265137, 'learning_rate': 9.091666666666668e-06, 'epoch': 0.275}
2025-06-08 09:55:53.010 | {'loss': 1.6885, 'grad_norm': 18.931190490722656, 'learning_rate': 9.008333333333335e-06, 'epoch': 0.3}
2025-06-08 09:56:22.268 | {'loss': 1.8641, 'grad_norm': 18.839540481567383, 'learning_rate': 8.925e-06, 'epoch': 0.325}
2025-06-08 09:56:42.700 | {'loss': 1.6935, 'grad_norm': 12.112447738647461, 'learning_rate': 8.841666666666667e-06, 'epoch': 0.35}
2025-06-08 09:57:02.786 | {'loss': 1.7644, 'grad_norm': 18.825857162475586, 'learning_rate': 8.758333333333334e-06, 'epoch': 0.375}
2025-06-08 09:57:32.293 | {'loss': 1.5048, 'grad_norm': 16.428953170776367, 'learning_rate': 8.675e-06, 'epoch': 0.4}
2025-06-08 09:57:52.322 | {'loss': 1.6813, 'grad_norm': 19.872995376586914, 'learning_rate': 8.591666666666668e-06, 'epoch': 0.425}
2025-06-08 09:58:12.429 | {'loss': 1.5623, 'grad_norm': 19.240995407104492, 'learning_rate': 8.508333333333335e-06, 'epoch': 0.45}
2025-06-08 09:58:42.070 | {'loss': 1.7785, 'grad_norm': 18.129743576049805, 'learning_rate': 8.425000000000001e-06, 'epoch': 0.475}
2025-06-08 09:59:02.908 | {'loss': 1.5481, 'grad_norm': 17.04196548461914, 'learning_rate': 8.341666666666667e-06, 'epoch': 0.5}
2025-06-08 09:59:24.871 | {'loss': 1.7243, 'grad_norm': 12.217487335205078, 'learning_rate': 8.258333333333334e-06, 'epoch': 0.525}
2025-06-08 09:59:56.428 | {'loss': 1.6575, 'grad_norm': 18.006561279296875, 'learning_rate': 8.175e-06, 'epoch': 0.55}
2025-06-08 10:00:18.522 | {'loss': 1.3364, 'grad_norm': 8.112898826599121, 'learning_rate': 8.091666666666667e-06, 'epoch': 0.575}
2025-06-08 10:00:40.290 | {'loss': 1.3319, 'grad_norm': 7.309945583343506, 'learning_rate': 8.008333333333334e-06, 'epoch': 0.6}
2025-06-08 10:01:10.370 | {'loss': 1.9845, 'grad_norm': 15.288896560668945, 'learning_rate': 7.925000000000001e-06, 'epoch': 0.625}
2025-06-08 10:01:31.307 | {'loss': 1.5281, 'grad_norm': 18.428560256958008, 'learning_rate': 7.841666666666668e-06, 'epoch': 0.65}
2025-06-08 10:02:01.724 | {'loss': 1.5732, 'grad_norm': 13.1309175491333, 'learning_rate': 7.758333333333335e-06, 'epoch': 0.675}
2025-06-08 10:02:23.073 | {'loss': 1.7059, 'grad_norm': 15.43209457397461, 'learning_rate': 7.675e-06, 'epoch': 0.7}
2025-06-08 10:02:44.339 | {'loss': 1.7038, 'grad_norm': 18.573436737060547, 'learning_rate': 7.591666666666667e-06, 'epoch': 0.725}
2025-06-08 10:03:16.186 | {'loss': 1.5265, 'grad_norm': 19.553335189819336, 'learning_rate': 7.508333333333334e-06, 'epoch': 0.75}
2025-06-08 10:03:37.908 | {'loss': 1.8121, 'grad_norm': 17.744712829589844, 'learning_rate': 7.425000000000001e-06, 'epoch': 0.775}
2025-06-08 10:03:59.820 | {'loss': 1.9678, 'grad_norm': 17.022144317626953, 'learning_rate': 7.341666666666667e-06, 'epoch': 0.8}
2025-06-08 10:04:30.376 | {'loss': 1.9598, 'grad_norm': 12.18612289428711, 'learning_rate': 7.258333333333334e-06, 'epoch': 0.825}
2025-06-08 10:04:51.948 | {'loss': 1.274, 'grad_norm': 16.331830978393555, 'learning_rate': 7.175000000000001e-06, 'epoch': 0.85}
2025-06-08 10:05:13.221 | {'loss': 1.4732, 'grad_norm': 19.991437911987305, 'learning_rate': 7.091666666666667e-06, 'epoch': 0.875}
2025-06-08 10:05:35.053 | {'loss': 1.6125, 'grad_norm': 20.871063232421875, 'learning_rate': 7.008333333333334e-06, 'epoch': 0.9}
2025-06-08 10:06:07.197 | {'loss': 1.5596, 'grad_norm': 17.863910675048828, 'learning_rate': 6.925000000000001e-06, 'epoch': 0.925}
2025-06-08 10:06:29.480 | {'loss': 1.3418, 'grad_norm': 14.076650619506836, 'learning_rate': 6.8416666666666675e-06, 'epoch': 0.95}
2025-06-08 10:06:53.363 | {'loss': 1.5541, 'grad_norm': 18.551475524902344, 'learning_rate': 6.7583333333333336e-06, 'epoch': 0.975}
2025-06-08 10:07:31.709 | {'loss': 1.4753, 'grad_norm': 16.722965240478516, 'learning_rate': 6.6750000000000005e-06, 'epoch': 1.0}
2025-06-08 10:07:58.903 | {'loss': 1.2233, 'grad_norm': 16.573190689086914, 'learning_rate': 6.591666666666667e-06, 'epoch': 1.025}
2025-06-08 10:08:26.104 | {'loss': 1.2483, 'grad_norm': 17.19977569580078, 'learning_rate': 6.508333333333334e-06, 'epoch': 1.05}
2025-06-08 10:09:07.401 | {'loss': 1.2612, 'grad_norm': 12.175027847290039, 'learning_rate': 6.425e-06, 'epoch': 1.075}
2025-06-08 10:09:36.275 | {'loss': 1.2884, 'grad_norm': 13.825338363647461, 'learning_rate': 6.341666666666667e-06, 'epoch': 1.1}
2025-06-08 10:10:03.116 | {'loss': 1.3664, 'grad_norm': 14.256525039672852, 'learning_rate': 6.258333333333334e-06, 'epoch': 1.125}
2025-06-08 10:10:31.211 | {'loss': 1.1046, 'grad_norm': 14.504459381103516, 'learning_rate': 6.175000000000001e-06, 'epoch': 1.15}
2025-06-08 10:11:11.196 | {'loss': 1.3907, 'grad_norm': 13.653984069824219, 'learning_rate': 6.091666666666667e-06, 'epoch': 1.175}
2025-06-08 10:11:39.681 | {'loss': 1.167, 'grad_norm': 15.068249702453613, 'learning_rate': 6.008333333333334e-06, 'epoch': 1.2}
2025-06-08 10:12:10.313 | {'loss': 1.3432, 'grad_norm': 17.13170623779297, 'learning_rate': 5.925000000000001e-06, 'epoch': 1.225}
2025-06-08 10:12:53.505 | {'loss': 1.2768, 'grad_norm': 11.224323272705078, 'learning_rate': 5.841666666666667e-06, 'epoch': 1.25}
2025-06-08 10:13:22.353 | {'loss': 0.8643, 'grad_norm': 5.760007858276367, 'learning_rate': 5.758333333333334e-06, 'epoch': 1.275}
2025-06-08 10:13:50.553 | {'loss': 1.5649, 'grad_norm': 16.592069625854492, 'learning_rate': 5.675000000000001e-06, 'epoch': 1.3}
2025-06-08 10:14:30.836 | {'loss': 1.3038, 'grad_norm': 9.718681335449219, 'learning_rate': 5.591666666666668e-06, 'epoch': 1.325}
2025-06-08 10:14:57.685 | {'loss': 1.1894, 'grad_norm': 14.032121658325195, 'learning_rate': 5.508333333333334e-06, 'epoch': 1.35}
2025-06-08 10:15:26.228 | {'loss': 1.1525, 'grad_norm': 14.832327842712402, 'learning_rate': 5.4250000000000006e-06, 'epoch': 1.375}
2025-06-08 10:16:08.921 | {'loss': 1.5208, 'grad_norm': 16.791664123535156, 'learning_rate': 5.3416666666666675e-06, 'epoch': 1.4}
2025-06-08 10:16:36.257 | {'loss': 1.293, 'grad_norm': 12.555994987487793, 'learning_rate': 5.258333333333334e-06, 'epoch': 1.425}
2025-06-08 10:17:04.673 | {'loss': 1.2862, 'grad_norm': 13.599864959716797, 'learning_rate': 5.1750000000000004e-06, 'epoch': 1.45}
2025-06-08 10:17:46.742 | {'loss': 1.3193, 'grad_norm': 14.879424095153809, 'learning_rate': 5.091666666666667e-06, 'epoch': 1.475}
2025-06-08 10:18:15.449 | {'loss': 1.4873, 'grad_norm': 12.290756225585938, 'learning_rate': 5.008333333333334e-06, 'epoch': 1.5}
2025-06-08 10:18:43.649 | {'loss': 1.2101, 'grad_norm': 20.377315521240234, 'learning_rate': 4.925e-06, 'epoch': 1.525}
2025-06-08 10:19:12.249 | {'loss': 1.312, 'grad_norm': 21.316617965698242, 'learning_rate': 4.841666666666667e-06, 'epoch': 1.55}
2025-06-08 10:19:54.208 | {'loss': 1.359, 'grad_norm': 14.718611717224121, 'learning_rate': 4.758333333333334e-06, 'epoch': 1.575}
2025-06-08 10:20:22.230 | {'loss': 1.3179, 'grad_norm': 16.86043930053711, 'learning_rate': 4.675000000000001e-06, 'epoch': 1.6}
2025-06-08 10:20:50.156 | {'loss': 1.4711, 'grad_norm': 17.177995681762695, 'learning_rate': 4.591666666666667e-06, 'epoch': 1.625}
2025-06-08 10:21:18.932 | {'loss': 1.1791, 'grad_norm': 12.253060340881348, 'learning_rate': 4.508333333333333e-06, 'epoch': 1.65}
2025-06-08 10:22:00.178 | {'loss': 1.3039, 'grad_norm': 18.377243041992188, 'learning_rate': 4.425e-06, 'epoch': 1.675}
2025-06-08 10:22:30.120 | {'loss': 1.3881, 'grad_norm': 15.716959953308105, 'learning_rate': 4.341666666666667e-06, 'epoch': 1.7}
2025-06-08 10:22:59.559 | {'loss': 1.4305, 'grad_norm': 10.244131088256836, 'learning_rate': 4.258333333333334e-06, 'epoch': 1.725}
2025-06-08 10:23:27.835 | {'loss': 1.5374, 'grad_norm': 18.348766326904297, 'learning_rate': 4.175e-06, 'epoch': 1.75}
2025-06-08 10:24:10.708 | {'loss': 1.4526, 'grad_norm': 16.4710750579834, 'learning_rate': 4.091666666666667e-06, 'epoch': 1.775}
2025-06-08 10:24:47.453 | {'loss': 1.2894, 'grad_norm': 12.528138160705566, 'learning_rate': 4.008333333333334e-06, 'epoch': 1.8}
2025-06-08 10:25:04.251 | {'loss': 1.5498, 'grad_norm': 18.720661163330078, 'learning_rate': 3.9250000000000005e-06, 'epoch': 1.825}
2025-06-08 10:25:22.756 | {'loss': 1.559, 'grad_norm': 12.175692558288574, 'learning_rate': 3.841666666666667e-06, 'epoch': 1.85}
2025-06-08 10:25:49.455 | {'loss': 1.522, 'grad_norm': 19.224328994750977, 'learning_rate': 3.758333333333334e-06, 'epoch': 1.875}
2025-06-08 10:26:08.662 | {'loss': 1.4824, 'grad_norm': 17.157400131225586, 'learning_rate': 3.6750000000000004e-06, 'epoch': 1.9}
2025-06-08 10:26:27.851 | {'loss': 1.7024, 'grad_norm': 14.360757827758789, 'learning_rate': 3.5916666666666673e-06, 'epoch': 1.925}
2025-06-08 10:26:48.725 | {'loss': 1.313, 'grad_norm': 12.562527656555176, 'learning_rate': 3.5083333333333338e-06, 'epoch': 1.95}
2025-06-08 10:27:17.649 | {'loss': 1.5006, 'grad_norm': 15.652344703674316, 'learning_rate': 3.4250000000000007e-06, 'epoch': 1.975}
2025-06-08 10:27:37.703 | {'loss': 1.2462, 'grad_norm': 17.196067810058594, 'learning_rate': 3.341666666666667e-06, 'epoch': 2.0}
2025-06-08 10:27:58.561 | {'loss': 1.3838, 'grad_norm': 14.126571655273438, 'learning_rate': 3.258333333333333e-06, 'epoch': 2.025}
2025-06-08 10:28:27.319 | {'loss': 1.2925, 'grad_norm': 18.575668334960938, 'learning_rate': 3.175e-06, 'epoch': 2.05}
2025-06-08 10:28:47.430 | {'loss': 1.4621, 'grad_norm': 17.2625732421875, 'learning_rate': 3.0916666666666666e-06, 'epoch': 2.075}
2025-06-08 10:29:07.905 | {'loss': 0.9856, 'grad_norm': 12.919270515441895, 'learning_rate': 3.0083333333333335e-06, 'epoch': 2.1}
2025-06-08 10:29:28.012 | {'loss': 1.0658, 'grad_norm': 11.426936149597168, 'learning_rate': 2.925e-06, 'epoch': 2.125}
2025-06-08 10:29:57.325 | {'loss': 1.3852, 'grad_norm': 14.28493595123291, 'learning_rate': 2.841666666666667e-06, 'epoch': 2.15}
2025-06-08 10:30:18.258 | {'loss': 1.0816, 'grad_norm': 15.129097938537598, 'learning_rate': 2.7583333333333333e-06, 'epoch': 2.175}
2025-06-08 10:30:39.651 | {'loss': 1.0558, 'grad_norm': 19.086502075195312, 'learning_rate': 2.6750000000000002e-06, 'epoch': 2.2}
2025-06-08 10:31:00.720 | {'loss': 1.2456, 'grad_norm': 13.513921737670898, 'learning_rate': 2.5916666666666667e-06, 'epoch': 2.225}
2025-06-08 10:31:21.177 | {'loss': 1.4494, 'grad_norm': 13.202851295471191, 'learning_rate': 2.5083333333333336e-06, 'epoch': 2.25}
2025-06-08 10:31:51.150 | {'loss': 1.1277, 'grad_norm': 10.331503868103027, 'learning_rate': 2.425e-06, 'epoch': 2.275}
2025-06-08 10:32:12.319 | {'loss': 0.9622, 'grad_norm': 12.37425422668457, 'learning_rate': 2.341666666666667e-06, 'epoch': 2.3}
2025-06-08 10:32:33.651 | {'loss': 1.1883, 'grad_norm': 18.385459899902344, 'learning_rate': 2.2583333333333335e-06, 'epoch': 2.325}
2025-06-08 10:32:55.892 | {'loss': 1.0482, 'grad_norm': 10.174714088439941, 'learning_rate': 2.1750000000000004e-06, 'epoch': 2.35}
2025-06-08 10:33:28.785 | {'loss': 0.9869, 'grad_norm': 7.807900905609131, 'learning_rate': 2.091666666666667e-06, 'epoch': 2.375}
2025-06-08 10:33:53.610 | {'loss': 1.0536, 'grad_norm': 9.68017292022705, 'learning_rate': 2.0083333333333337e-06, 'epoch': 2.4}
2025-06-08 10:34:20.622 | {'loss': 1.2915, 'grad_norm': 16.68303680419922, 'learning_rate': 1.925e-06, 'epoch': 2.425}
2025-06-08 10:34:57.077 | {'loss': 1.0267, 'grad_norm': 15.34804630279541, 'learning_rate': 1.8416666666666669e-06, 'epoch': 2.45}
2025-06-08 10:35:24.173 | {'loss': 1.0239, 'grad_norm': 13.370282173156738, 'learning_rate': 1.7583333333333336e-06, 'epoch': 2.475}
2025-06-08 10:35:49.760 | {'loss': 0.963, 'grad_norm': 13.586676597595215, 'learning_rate': 1.6750000000000003e-06, 'epoch': 2.5}
2025-06-08 10:36:16.299 | {'loss': 1.1307, 'grad_norm': 10.769627571105957, 'learning_rate': 1.591666666666667e-06, 'epoch': 2.525}
2025-06-08 10:36:54.983 | {'loss': 1.2492, 'grad_norm': 16.746110916137695, 'learning_rate': 1.5083333333333336e-06, 'epoch': 2.55}
2025-06-08 10:37:20.648 | {'loss': 1.2267, 'grad_norm': 15.180411338806152, 'learning_rate': 1.425e-06, 'epoch': 2.575}
2025-06-08 10:37:49.941 | {'loss': 1.1717, 'grad_norm': 15.863021850585938, 'learning_rate': 1.3416666666666666e-06, 'epoch': 2.6}
2025-06-08 10:38:30.798 | {'loss': 1.4208, 'grad_norm': 16.508127212524414, 'learning_rate': 1.2583333333333333e-06, 'epoch': 2.625}
2025-06-08 10:38:57.402 | {'loss': 0.9011, 'grad_norm': 14.697049140930176, 'learning_rate': 1.175e-06, 'epoch': 2.65}
2025-06-08 10:39:24.215 | {'loss': 1.0942, 'grad_norm': 11.944782257080078, 'learning_rate': 1.0916666666666667e-06, 'epoch': 2.675}
2025-06-08 10:40:05.649 | {'loss': 1.3103, 'grad_norm': 17.099390029907227, 'learning_rate': 1.0083333333333333e-06, 'epoch': 2.7}
2025-06-08 10:40:34.922 | {'loss': 1.2241, 'grad_norm': 12.353341102600098, 'learning_rate': 9.25e-07, 'epoch': 2.725}
2025-06-08 10:41:02.565 | {'loss': 1.1759, 'grad_norm': 16.655654907226562, 'learning_rate': 8.416666666666667e-07, 'epoch': 2.75}
2025-06-08 10:41:30.759 | {'loss': 1.1178, 'grad_norm': 17.513864517211914, 'learning_rate': 7.583333333333334e-07, 'epoch': 2.775}
2025-06-08 10:42:12.388 | {'loss': 1.352, 'grad_norm': 19.384634017944336, 'learning_rate': 6.750000000000001e-07, 'epoch': 2.8}
2025-06-08 10:42:41.060 | {'loss': 1.2151, 'grad_norm': 16.512941360473633, 'learning_rate': 5.916666666666667e-07, 'epoch': 2.825}
2025-06-08 10:43:09.925 | {'loss': 1.1622, 'grad_norm': 14.222563743591309, 'learning_rate': 5.083333333333334e-07, 'epoch': 2.85}
2025-06-08 10:43:51.420 | {'loss': 1.0896, 'grad_norm': 9.124100685119629, 'learning_rate': 4.2500000000000006e-07, 'epoch': 2.875}
2025-06-08 10:44:20.803 | {'loss': 1.2412, 'grad_norm': 15.318603515625, 'learning_rate': 3.416666666666667e-07, 'epoch': 2.9}
2025-06-08 10:44:53.280 | {'loss': 1.2881, 'grad_norm': 18.080202102661133, 'learning_rate': 2.5833333333333333e-07, 'epoch': 2.925}
2025-06-08 10:45:35.573 | {'loss': 1.4403, 'grad_norm': 17.765443801879883, 'learning_rate': 1.7500000000000002e-07, 'epoch': 2.95}
2025-06-08 10:45:52.081 | {'loss': 1.1712, 'grad_norm': 16.92896842956543, 'learning_rate': 9.166666666666668e-08, 'epoch': 2.975}
2025-06-08 10:46:02.797 | {'loss': 1.2518, 'grad_norm': 16.255756378173828, 'learning_rate': 8.333333333333335e-09, 'epoch': 3.0}
2025-06-08 10:46:02.797 | {'train_runtime': 3288.7872, 'train_samples_per_second': 0.73, 'train_steps_per_second': 0.365, 'train_loss': 1.3737970956166585, 'epoch': 3.0}
2025-06-08 10:46:16.450 | {'eval_loss': 2.14542293548584, 'eval_runtime': 13.6477, 'eval_samples_per_second': 14.655, 'eval_steps_per_second': 1.832, 'epoch': 3.0}
2025-06-08 10:46:23.775 | INFO :      Sent reply
2025-06-08 10:58:32.771 | INFO :      
2025-06-08 10:58:32.771 | INFO :      Received: evaluate message 035bc374-7d0a-4a87-8561-ab9f7816c1a2
2025-06-08 10:59:00.055 | {'eval_loss': 2.091006278991699, 'eval_runtime': 17.7557, 'eval_samples_per_second': 11.264, 'eval_steps_per_second': 1.408, 'epoch': 3.0}
2025-06-08 10:59:00.079 | INFO :      Sent reply
2025-06-08 10:59:17.183 | INFO :      
2025-06-08 10:59:17.183 | INFO :      Received: train message 88a14a0c-0de4-48fd-845b-3bf7f84c5ebc
2025-06-08 11:00:06.310 | {'loss': 1.3737, 'grad_norm': 14.925872802734375, 'learning_rate': 9.925e-06, 'epoch': 0.025}
2025-06-08 11:00:32.634 | {'loss': 1.4827, 'grad_norm': 18.24297523498535, 'learning_rate': 9.841666666666668e-06, 'epoch': 0.05}
2025-06-08 11:00:57.231 | {'loss': 1.1298, 'grad_norm': 9.451935768127441, 'learning_rate': 9.758333333333334e-06, 'epoch': 0.075}
2025-06-08 11:01:34.409 | {'loss': 1.1861, 'grad_norm': 7.065126895904541, 'learning_rate': 9.675000000000001e-06, 'epoch': 0.1}
2025-06-08 11:01:59.992 | {'loss': 1.4326, 'grad_norm': 21.62043571472168, 'learning_rate': 9.591666666666667e-06, 'epoch': 0.125}
2025-06-08 11:02:28.331 | {'loss': 1.3063, 'grad_norm': 14.486286163330078, 'learning_rate': 9.508333333333333e-06, 'epoch': 0.15}
2025-06-08 11:03:08.937 | {'loss': 1.4114, 'grad_norm': 22.005874633789062, 'learning_rate': 9.425e-06, 'epoch': 0.175}
2025-06-08 11:03:35.590 | {'loss': 1.447, 'grad_norm': 19.575258255004883, 'learning_rate': 9.341666666666667e-06, 'epoch': 0.2}
2025-06-08 11:04:02.104 | {'loss': 1.5135, 'grad_norm': 19.836040496826172, 'learning_rate': 9.258333333333334e-06, 'epoch': 0.225}
2025-06-08 11:04:41.370 | {'loss': 1.3973, 'grad_norm': 21.67152976989746, 'learning_rate': 9.175000000000001e-06, 'epoch': 0.25}
2025-06-08 11:05:07.819 | ERROR :     Client raised an exception.
2025-06-08 11:05:07.819 | Traceback (most recent call last):
2025-06-08 11:05:07.819 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/app.py", line 571, in start_client_internal
2025-06-08 11:05:07.819 |     reply_message = client_app(message=message, context=context)
2025-06-08 11:05:07.819 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/client_app.py", line 144, in __call__
2025-06-08 11:05:07.819 |     return self._call(message, context)
2025-06-08 11:05:07.819 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/client_app.py", line 128, in ffn
2025-06-08 11:05:07.819 |     out_message = handle_legacy_message_from_msgtype(
2025-06-08 11:05:07.819 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/message_handler/message_handler.py", line 128, in handle_legacy_message_from_msgtype
2025-06-08 11:05:07.819 |     fit_res = maybe_call_fit(
2025-06-08 11:05:07.819 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/client.py", line 224, in maybe_call_fit
2025-06-08 11:05:07.819 |     return client.fit(fit_ins)
2025-06-08 11:05:07.819 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/numpy_client.py", line 227, in _fit
2025-06-08 11:05:07.819 |     results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
2025-06-08 11:05:07.819 |   File "/app/client.py", line 78, in fit
2025-06-08 11:05:07.819 |     trainer.train()
2025-06-08 11:05:07.819 |   File "/usr/local/lib/python3.10/site-packages/transformers/trainer.py", line 2240, in train
2025-06-08 11:05:07.819 |     return inner_training_loop(
2025-06-08 11:05:07.819 |   File "/usr/local/lib/python3.10/site-packages/transformers/trainer.py", line 2557, in _inner_training_loop
2025-06-08 11:05:07.819 |     if (
2025-06-08 11:05:07.819 | RuntimeError: CUDA error: unknown error
2025-06-08 11:05:07.819 | CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
2025-06-08 11:05:07.819 | For debugging consider passing CUDA_LAUNCH_BLOCKING=1
2025-06-08 11:05:07.819 | Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
2025-06-08 11:05:07.819 | 
2025-06-08 11:05:07.954 | Traceback (most recent call last):
2025-06-08 11:05:07.954 |   File "/app/client.py", line 105, in <module>
2025-06-08 11:05:07.959 |     fl.client.start_numpy_client(server_address=server_ip, client=FlowerClient())
2025-06-08 11:05:07.959 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/app.py", line 731, in start_numpy_client
2025-06-08 11:05:07.961 |     start_client(
2025-06-08 11:05:07.961 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/app.py", line 201, in start_client
2025-06-08 11:05:07.961 |     start_client_internal(
2025-06-08 11:05:07.961 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/app.py", line 578, in start_client_internal
2025-06-08 11:05:07.961 |     raise ex
2025-06-08 11:05:07.961 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/app.py", line 571, in start_client_internal
2025-06-08 11:05:07.961 |     reply_message = client_app(message=message, context=context)
2025-06-08 11:05:07.961 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/client_app.py", line 144, in __call__
2025-06-08 11:05:07.961 |     return self._call(message, context)
2025-06-08 11:05:07.961 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/client_app.py", line 128, in ffn
2025-06-08 11:05:07.961 |     out_message = handle_legacy_message_from_msgtype(
2025-06-08 11:05:07.961 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/message_handler/message_handler.py", line 128, in handle_legacy_message_from_msgtype
2025-06-08 11:05:07.961 |     fit_res = maybe_call_fit(
2025-06-08 11:05:07.961 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/client.py", line 224, in maybe_call_fit
2025-06-08 11:05:07.962 |     return client.fit(fit_ins)
2025-06-08 11:05:07.962 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/numpy_client.py", line 227, in _fit
2025-06-08 11:05:07.962 |     results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
2025-06-08 11:05:07.962 |   File "/app/client.py", line 78, in fit
2025-06-08 11:05:07.962 |     trainer.train()
2025-06-08 11:05:07.962 |   File "/usr/local/lib/python3.10/site-packages/transformers/trainer.py", line 2240, in train
2025-06-08 11:05:07.971 |     return inner_training_loop(
2025-06-08 11:05:07.971 |   File "/usr/local/lib/python3.10/site-packages/transformers/trainer.py", line 2557, in _inner_training_loop
2025-06-08 11:05:07.974 |     if (
2025-06-08 11:05:07.974 | RuntimeError: CUDA error: unknown error
2025-06-08 11:05:07.974 | CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
2025-06-08 11:05:07.974 | For debugging consider passing CUDA_LAUNCH_BLOCKING=1
2025-06-08 11:05:07.974 | Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
2025-06-08 11:05:07.974 | 
2025-06-08 11:31:06.032 | Generating train split:   0%|          | 0/61373 [00:00<?, ? examples/s]
2025-06-08 11:31:06.032 | Generating train split:   2%|         | 999/61373 [00:00<00:07, 8141.04 examples/s]
2025-06-08 11:31:06.032 | Generating train split:   3%|         | 1949/61373 [00:00<00:07, 7714.19 examples/s]
2025-06-08 11:31:06.032 | Generating train split:   6%|         | 3962/61373 [00:00<00:04, 11749.27 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  10%|         | 6069/61373 [00:00<00:04, 12435.60 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  15%|        | 9287/61373 [00:00<00:03, 15965.72 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  19%|        | 11368/61373 [00:00<00:03, 13505.72 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  21%|       | 13169/61373 [00:01<00:04, 10698.21 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  25%|       | 15138/61373 [00:01<00:04, 10325.72 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  28%|       | 17129/61373 [00:01<00:04, 10607.48 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  31%|       | 19086/61373 [00:01<00:03, 10740.07 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  35%|      | 21243/61373 [00:01<00:03, 11781.82 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  38%|      | 23358/61373 [00:02<00:03, 11173.64 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  41%|      | 25295/61373 [00:02<00:02, 12456.15 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  44%|     | 27259/61373 [00:02<00:02, 13593.19 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  48%|     | 29326/61373 [00:02<00:02, 13837.81 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  51%|    | 31479/61373 [00:02<00:02, 12732.10 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  54%|    | 33426/61373 [00:02<00:02, 12251.81 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  58%|    | 35444/61373 [00:02<00:02, 11446.37 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  61%|    | 37442/61373 [00:03<00:02, 11405.20 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  64%|   | 39433/61373 [00:03<00:01, 11134.09 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  68%|   | 41577/61373 [00:03<00:01, 11123.42 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  71%|   | 43692/61373 [00:03<00:01, 10773.52 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  75%|  | 45755/61373 [00:03<00:01, 10202.80 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  78%|  | 47705/61373 [00:04<00:01, 9416.22 examples/s] 
2025-06-08 11:31:06.032 | Generating train split:  81%|  | 49773/61373 [00:04<00:01, 10073.69 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  84%| | 51792/61373 [00:04<00:01, 9507.75 examples/s] 
2025-06-08 11:31:06.032 | Generating train split:  88%| | 53862/61373 [00:04<00:00, 9314.34 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  91%| | 55664/61373 [00:05<00:00, 10314.25 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  94%|| 57650/61373 [00:05<00:00, 10433.60 examples/s]
2025-06-08 11:31:06.032 | Generating train split:  97%|| 59628/61373 [00:05<00:00, 11268.25 examples/s]
2025-06-08 11:31:06.032 | Generating train split: 100%|| 61373/61373 [00:05<00:00, 12141.97 examples/s]
2025-06-08 11:31:06.032 | Generating train split: 100%|| 61373/61373 [00:05<00:00, 11255.24 examples/s]
2025-06-08 11:31:06.032 | Map:   0%|          | 0/1000 [00:00<?, ? examples/s]
2025-06-08 11:31:06.032 | Map: 100%|| 1000/1000 [00:31<00:00, 31.35 examples/s]
2025-06-08 11:31:06.032 | Map: 100%|| 1000/1000 [00:31<00:00, 31.34 examples/s]
2025-06-08 11:31:06.032 | Map:   0%|          | 0/1000 [00:00<?, ? examples/s]
2025-06-08 11:31:06.032 | Map:   9%|         | 94/1000 [00:00<00:00, 909.31 examples/s]
2025-06-08 11:31:06.032 | Map:  19%|        | 193/1000 [00:00<00:00, 950.41 examples/s]
2025-06-08 11:31:06.032 | Map:  32%|      | 318/1000 [00:00<00:00, 1080.45 examples/s]
2025-06-08 11:31:06.032 | Map:  47%|     | 468/1000 [00:00<00:00, 1240.35 examples/s]
2025-06-08 11:31:06.032 | Map:  62%|   | 617/1000 [00:00<00:00, 1328.02 examples/s]
2025-06-08 11:31:06.032 | Map:  76%|  | 758/1000 [00:00<00:00, 1353.65 examples/s]
2025-06-08 11:31:06.032 | Map:  91%| | 910/1000 [00:00<00:00, 1406.00 examples/s]
2025-06-08 11:31:06.032 | Map: 100%|| 1000/1000 [00:00<00:00, 1187.10 examples/s]