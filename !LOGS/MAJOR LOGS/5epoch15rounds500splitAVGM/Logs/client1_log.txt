2025-05-25 18:00:16.687 | Repo card metadata block was not found. Setting CardData to empty.
2025-05-25 18:02:49.672 | 
2025-05-25 18:03:05.490 | 
2025-05-25 18:03:05.904 | 
2025-05-25 18:03:06.210 | /app/client.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-05-25 18:03:06.210 |   trainer = Trainer(
2025-05-25 18:03:06.704 | WARNING :   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
2025-05-25 18:03:06.704 | 	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
2025-05-25 18:03:06.704 | 	flwr.client.start_client(
2025-05-25 18:03:06.704 | 		server_address='<IP>:<PORT>',
2025-05-25 18:03:06.704 | 		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
2025-05-25 18:03:06.704 | 	)
2025-05-25 18:03:06.704 | 	Using `start_numpy_client()` is deprecated.
2025-05-25 18:03:06.704 | 
2025-05-25 18:03:06.704 |             This is a deprecated feature. It will be removed
2025-05-25 18:03:06.704 |             entirely in future versions of Flower.
2025-05-25 18:03:06.704 |         
2025-05-25 18:03:06.704 | WARNING :   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
2025-05-25 18:03:06.704 | 	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:
2025-05-25 18:03:06.704 | 
2025-05-25 18:03:06.704 | 		$ flower-supernode --insecure --superlink='<IP>:<PORT>'
2025-05-25 18:03:06.704 | 
2025-05-25 18:03:06.704 | 	To view all available options, run:
2025-05-25 18:03:06.704 | 
2025-05-25 18:03:06.704 | 		$ flower-supernode --help
2025-05-25 18:03:06.704 | 
2025-05-25 18:03:06.704 | 	Using `start_client()` is deprecated.
2025-05-25 18:03:06.704 | 
2025-05-25 18:03:06.704 |             This is a deprecated feature. It will be removed
2025-05-25 18:03:06.704 |             entirely in future versions of Flower.
2025-05-25 18:03:06.704 |         
2025-05-25 18:03:06.923 | Traceback (most recent call last):
2025-05-25 18:03:06.923 |   File "/app/client.py", line 111, in <module>
2025-05-25 18:03:06.923 |     fl.client.start_numpy_client(server_address=server_ip, client=FlowerClient())
2025-05-25 18:03:06.923 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/app.py", line 731, in start_numpy_client
2025-05-25 18:03:06.924 |     start_client(
2025-05-25 18:03:06.924 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/app.py", line 201, in start_client
2025-05-25 18:03:06.924 |     start_client_internal(
2025-05-25 18:03:06.924 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/app.py", line 438, in start_client_internal
2025-05-25 18:03:06.924 |     message = receive()
2025-05-25 18:03:06.924 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/grpc_client/connection.py", line 142, in receive
2025-05-25 18:03:06.924 |     proto = next(server_message_iterator)
2025-05-25 18:03:06.924 |   File "/usr/local/lib/python3.10/site-packages/grpc/_channel.py", line 543, in __next__
2025-05-25 18:03:06.924 |     return self._next()
2025-05-25 18:03:06.924 |   File "/usr/local/lib/python3.10/site-packages/grpc/_channel.py", line 952, in _next
2025-05-25 18:03:06.925 |     raise self
2025-05-25 18:03:06.925 | grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
2025-05-25 18:03:06.925 | 	status = StatusCode.UNAVAILABLE
2025-05-25 18:03:06.925 | 	details = "failed to connect to all addresses; last error: UNKNOWN: ipv4:172.18.0.2:8080: Failed to connect to remote host: connect: Connection refused (111)"
2025-05-25 18:03:06.925 | 	debug_error_string = "UNKNOWN:Error received from peer  {created_time:"2025-05-25T15:03:06.719301724+00:00", grpc_status:14, grpc_message:"failed to connect to all addresses; last error: UNKNOWN: ipv4:172.18.0.2:8080: Failed to connect to remote host: connect: Connection refused (111)"}"
2025-05-25 18:03:06.925 | >
2025-05-25 18:34:00.164 | Repo card metadata block was not found. Setting CardData to empty.
2025-05-25 18:34:03.645 | /app/client.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-05-25 18:34:03.645 |   trainer = Trainer(
2025-05-25 18:34:04.254 | WARNING :   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
2025-05-25 18:34:04.254 | 	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
2025-05-25 18:34:04.254 | 	flwr.client.start_client(
2025-05-25 18:34:04.254 | 		server_address='<IP>:<PORT>',
2025-05-25 18:34:04.254 | 		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
2025-05-25 18:34:04.254 | 	)
2025-05-25 18:34:04.254 | 	Using `start_numpy_client()` is deprecated.
2025-05-25 18:34:04.254 | 
2025-05-25 18:34:04.254 |             This is a deprecated feature. It will be removed
2025-05-25 18:34:04.254 |             entirely in future versions of Flower.
2025-05-25 18:34:04.254 |         
2025-05-25 18:34:04.254 | WARNING :   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
2025-05-25 18:34:04.254 | 	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:
2025-05-25 18:34:04.254 | 
2025-05-25 18:34:04.254 | 		$ flower-supernode --insecure --superlink='<IP>:<PORT>'
2025-05-25 18:34:04.254 | 
2025-05-25 18:34:04.254 | 	To view all available options, run:
2025-05-25 18:34:04.254 | 
2025-05-25 18:34:04.254 | 		$ flower-supernode --help
2025-05-25 18:34:04.254 | 
2025-05-25 18:34:04.254 | 	Using `start_client()` is deprecated.
2025-05-25 18:34:04.254 | 
2025-05-25 18:34:04.254 |             This is a deprecated feature. It will be removed
2025-05-25 18:34:04.254 |             entirely in future versions of Flower.
2025-05-25 18:34:04.254 |         
2025-05-25 18:34:04.291 | INFO :      
2025-05-25 18:34:04.291 | INFO :      Received: get_parameters message d4bb21d2-ed6f-47fc-be21-8b09512dcf5e
2025-05-25 18:34:07.961 | INFO :      Sent reply
2025-05-25 18:40:15.240 | INFO :      
2025-05-25 18:40:15.240 | INFO :      Received: train message bc58ca2a-1c5c-4d18-b5df-f75fee74c467
2025-05-25 18:40:53.482 | {'loss': 6.4124, 'grad_norm': 15.962553024291992, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 18:41:22.174 | {'loss': 4.8953, 'grad_norm': 21.92350196838379, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 18:41:54.606 | {'loss': 4.5591, 'grad_norm': 21.427597045898438, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 18:42:26.238 | {'loss': 4.4322, 'grad_norm': 16.027103424072266, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 18:42:48.094 | {'loss': 3.7482, 'grad_norm': 15.55219841003418, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 18:43:19.858 | {'loss': 3.7887, 'grad_norm': 15.273616790771484, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 18:43:51.638 | {'loss': 3.7321, 'grad_norm': 15.062935829162598, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 18:44:23.364 | {'loss': 4.0004, 'grad_norm': 13.52077865600586, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 18:44:45.668 | {'loss': 3.9551, 'grad_norm': 15.356768608093262, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 18:45:17.179 | {'loss': 3.693, 'grad_norm': 14.574679374694824, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 18:45:49.182 | {'loss': 3.303, 'grad_norm': 11.233160972595215, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 18:46:21.344 | {'loss': 3.3995, 'grad_norm': 35.338775634765625, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 18:46:43.906 | {'loss': 3.374, 'grad_norm': 12.050407409667969, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 18:47:16.110 | {'loss': 3.3723, 'grad_norm': 14.337498664855957, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 18:47:47.947 | {'loss': 3.4305, 'grad_norm': 18.12967872619629, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 18:48:09.834 | {'loss': 3.6285, 'grad_norm': 13.920215606689453, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 18:48:42.446 | {'loss': 3.0151, 'grad_norm': 10.816327095031738, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 18:49:13.702 | {'loss': 3.3748, 'grad_norm': 24.006044387817383, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 18:49:35.592 | {'loss': 3.3911, 'grad_norm': 19.545991897583008, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 18:50:07.319 | {'loss': 3.4323, 'grad_norm': 12.978036880493164, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 18:50:38.092 | {'loss': 2.7669, 'grad_norm': 15.876821517944336, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 18:51:09.580 | {'loss': 2.7198, 'grad_norm': 13.604827880859375, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 18:51:31.374 | {'loss': 2.2551, 'grad_norm': 11.72856330871582, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 18:52:02.874 | {'loss': 2.2206, 'grad_norm': 12.886499404907227, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 18:52:25.127 | {'loss': 2.4789, 'grad_norm': 13.530438423156738, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 18:52:56.691 | {'loss': 1.9843, 'grad_norm': 13.951533317565918, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 18:53:18.858 | {'loss': 2.4278, 'grad_norm': 13.163044929504395, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 18:53:50.754 | {'loss': 2.5268, 'grad_norm': 12.478824615478516, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 18:54:13.241 | {'loss': 2.3229, 'grad_norm': 13.597607612609863, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 18:54:44.872 | {'loss': 2.413, 'grad_norm': 14.400456428527832, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 18:55:16.752 | {'loss': 2.6039, 'grad_norm': 16.178619384765625, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 18:55:47.919 | {'loss': 1.9883, 'grad_norm': 15.191866874694824, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 18:56:19.660 | {'loss': 2.1717, 'grad_norm': 15.02625846862793, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 18:56:41.182 | {'loss': 2.592, 'grad_norm': 10.913809776306152, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 18:57:12.801 | {'loss': 2.5934, 'grad_norm': 14.475648880004883, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 18:57:45.198 | {'loss': 2.5782, 'grad_norm': 15.94132137298584, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 18:58:17.154 | {'loss': 2.1784, 'grad_norm': 12.366684913635254, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 18:58:39.098 | {'loss': 2.1679, 'grad_norm': 12.323044776916504, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 18:59:11.263 | {'loss': 2.5103, 'grad_norm': 12.890032768249512, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 18:59:43.225 | {'loss': 2.4318, 'grad_norm': 12.68185806274414, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 19:00:15.001 | {'loss': 1.6816, 'grad_norm': 11.16161823272705, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 19:00:46.734 | {'loss': 1.7944, 'grad_norm': 8.790255546569824, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 19:01:09.159 | {'loss': 1.7392, 'grad_norm': 12.292445182800293, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 19:01:40.569 | {'loss': 1.7343, 'grad_norm': 12.615763664245605, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 19:02:11.962 | {'loss': 1.7485, 'grad_norm': 12.103742599487305, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 19:02:43.376 | {'loss': 1.6042, 'grad_norm': 13.767919540405273, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 19:03:05.529 | {'loss': 1.6212, 'grad_norm': 13.294604301452637, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 19:03:37.781 | {'loss': 1.659, 'grad_norm': 12.045374870300293, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 19:04:01.134 | {'loss': 1.9187, 'grad_norm': 12.515647888183594, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 19:04:22.037 | {'loss': 1.4866, 'grad_norm': 12.889114379882812, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 19:04:37.287 | {'loss': 1.6401, 'grad_norm': 11.916647911071777, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 19:04:52.045 | {'loss': 1.6808, 'grad_norm': 14.542020797729492, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 19:05:08.001 | {'loss': 1.7597, 'grad_norm': 14.518033027648926, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 19:05:29.174 | {'loss': 1.3517, 'grad_norm': 8.686637878417969, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 19:05:44.346 | {'loss': 1.777, 'grad_norm': 12.80284595489502, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 19:05:59.186 | {'loss': 1.7715, 'grad_norm': 12.056626319885254, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 19:06:20.328 | {'loss': 1.7836, 'grad_norm': 13.379602432250977, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 19:06:35.638 | {'loss': 1.6895, 'grad_norm': 14.795389175415039, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 19:06:57.094 | {'loss': 1.3887, 'grad_norm': 14.334752082824707, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 19:07:12.036 | {'loss': 1.636, 'grad_norm': 9.817361831665039, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 19:07:27.186 | {'loss': 1.2553, 'grad_norm': 11.391338348388672, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 19:07:48.728 | {'loss': 1.1469, 'grad_norm': 5.608512878417969, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 19:08:03.983 | {'loss': 1.187, 'grad_norm': 10.666352272033691, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 19:08:18.695 | {'loss': 1.2584, 'grad_norm': 11.31948184967041, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 19:08:40.422 | {'loss': 1.1838, 'grad_norm': 11.21663761138916, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 19:08:54.850 | {'loss': 1.1599, 'grad_norm': 10.853983879089355, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 19:09:10.006 | {'loss': 1.1265, 'grad_norm': 13.2786865234375, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 19:09:24.603 | {'loss': 1.2478, 'grad_norm': 11.4475679397583, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 19:09:46.312 | {'loss': 1.0664, 'grad_norm': 10.526346206665039, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 19:10:01.516 | {'loss': 1.1828, 'grad_norm': 12.159737586975098, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 19:10:16.357 | {'loss': 1.234, 'grad_norm': 11.127951622009277, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 19:10:31.394 | {'loss': 1.0989, 'grad_norm': 12.139036178588867, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 19:10:46.102 | {'loss': 1.2756, 'grad_norm': 11.82764720916748, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 19:11:07.488 | {'loss': 1.1708, 'grad_norm': 10.335149765014648, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 19:11:22.160 | {'loss': 1.1171, 'grad_norm': 8.51020622253418, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 19:11:37.293 | {'loss': 1.2677, 'grad_norm': 9.683106422424316, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 19:11:51.971 | {'loss': 1.0566, 'grad_norm': 11.510059356689453, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 19:12:13.783 | {'loss': 1.2473, 'grad_norm': 10.271734237670898, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 19:12:29.096 | {'loss': 1.0685, 'grad_norm': 11.913439750671387, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 19:12:44.016 | {'loss': 1.1155, 'grad_norm': 5.21012020111084, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 19:12:58.812 | {'loss': 0.7783, 'grad_norm': 9.573774337768555, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 19:13:20.126 | {'loss': 0.8481, 'grad_norm': 8.58003044128418, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 19:13:35.325 | {'loss': 0.8052, 'grad_norm': 10.704076766967773, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 19:13:49.989 | {'loss': 0.8531, 'grad_norm': 9.939563751220703, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 19:14:04.977 | {'loss': 0.7119, 'grad_norm': 9.393742561340332, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 19:14:25.933 | {'loss': 0.9231, 'grad_norm': 8.620806694030762, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 19:14:41.343 | {'loss': 0.8007, 'grad_norm': 9.179242134094238, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 19:14:56.361 | {'loss': 0.8048, 'grad_norm': 9.062230110168457, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 19:15:12.040 | {'loss': 0.8494, 'grad_norm': 12.294646263122559, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 19:15:26.966 | {'loss': 0.8796, 'grad_norm': 7.397285461425781, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 19:15:48.692 | {'loss': 0.8425, 'grad_norm': 8.05286979675293, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 19:16:03.576 | {'loss': 0.8869, 'grad_norm': 9.358908653259277, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 19:16:18.526 | {'loss': 0.7602, 'grad_norm': 7.539438724517822, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-25 19:16:34.073 | {'loss': 1.0353, 'grad_norm': 8.609282493591309, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-25 19:16:55.469 | {'loss': 0.8566, 'grad_norm': 10.210787773132324, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-25 19:17:11.313 | {'loss': 0.8867, 'grad_norm': 7.07397985458374, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-25 19:17:25.741 | {'loss': 0.8093, 'grad_norm': 8.359152793884277, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-25 19:17:40.800 | {'loss': 0.823, 'grad_norm': 9.466012954711914, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-25 19:17:55.564 | {'loss': 0.8364, 'grad_norm': 10.278393745422363, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-25 19:18:17.295 | {'loss': 0.901, 'grad_norm': 10.15361213684082, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-25 19:18:17.295 | {'train_runtime': 2279.9095, 'train_samples_per_second': 0.877, 'train_steps_per_second': 0.439, 'train_loss': 1.9869472723007202, 'epoch': 5.0}
2025-05-25 19:18:23.184 | INFO :      Sent reply
2025-05-25 19:24:52.251 | INFO :      
2025-05-25 19:24:52.251 | INFO :      Received: evaluate message c2d2c93d-2086-417f-a22e-4ce173aa25f0
2025-05-25 19:25:06.205 | {'eval_loss': 2.7394747734069824, 'eval_runtime': 10.4845, 'eval_samples_per_second': 9.538, 'eval_steps_per_second': 1.24, 'epoch': 5.0}
2025-05-25 19:25:06.209 | INFO :      Sent reply
2025-05-25 19:25:15.771 | INFO :      
2025-05-25 19:25:15.771 | INFO :      Received: train message dc695c9e-4340-4dc9-91d3-1acb6241c5f4
2025-05-25 19:25:47.348 | {'loss': 2.0774, 'grad_norm': 16.177993774414062, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 19:26:02.381 | {'loss': 1.9734, 'grad_norm': 16.694171905517578, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 19:26:18.264 | {'loss': 2.2357, 'grad_norm': 8.985589027404785, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 19:26:40.132 | {'loss': 2.1255, 'grad_norm': 13.935519218444824, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 19:26:55.295 | {'loss': 1.9386, 'grad_norm': 12.83346939086914, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 19:27:10.628 | {'loss': 2.1357, 'grad_norm': 13.387615203857422, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 19:27:25.602 | {'loss': 2.0842, 'grad_norm': 17.02745246887207, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 19:27:47.479 | {'loss': 2.1985, 'grad_norm': 12.475728988647461, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 19:28:02.424 | {'loss': 2.2711, 'grad_norm': 12.953014373779297, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 19:28:18.072 | {'loss': 2.0618, 'grad_norm': 14.912273406982422, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 19:28:33.181 | {'loss': 1.8034, 'grad_norm': 12.234100341796875, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 19:28:55.163 | {'loss': 2.0748, 'grad_norm': 10.667817115783691, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 19:29:10.352 | {'loss': 1.9687, 'grad_norm': 9.816699981689453, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 19:29:25.333 | {'loss': 2.0484, 'grad_norm': 16.42482566833496, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 19:29:40.560 | {'loss': 2.1407, 'grad_norm': 16.122098922729492, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 19:30:01.983 | {'loss': 2.2403, 'grad_norm': 11.712825775146484, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 19:30:17.579 | {'loss': 1.8517, 'grad_norm': 8.041970252990723, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 19:30:32.557 | {'loss': 2.1346, 'grad_norm': 16.007080078125, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 19:30:47.870 | {'loss': 2.088, 'grad_norm': 16.84478187561035, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 19:31:02.608 | {'loss': 2.1651, 'grad_norm': 12.249007225036621, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 19:31:24.274 | {'loss': 1.4618, 'grad_norm': 14.194360733032227, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 19:31:39.353 | {'loss': 1.4431, 'grad_norm': 12.969592094421387, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 19:31:54.579 | {'loss': 1.2151, 'grad_norm': 10.30630874633789, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 19:32:09.857 | {'loss': 1.2126, 'grad_norm': 16.64406394958496, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 19:32:31.656 | {'loss': 1.44, 'grad_norm': 10.038628578186035, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 19:32:46.680 | {'loss': 1.1357, 'grad_norm': 12.428105354309082, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 19:33:01.450 | {'loss': 1.387, 'grad_norm': 11.645495414733887, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 19:33:16.590 | {'loss': 1.4552, 'grad_norm': 10.50403118133545, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 19:33:37.601 | {'loss': 1.2691, 'grad_norm': 11.56194019317627, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 19:33:53.203 | {'loss': 1.3976, 'grad_norm': 14.10766315460205, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 19:34:08.290 | {'loss': 1.4098, 'grad_norm': 11.353178977966309, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 19:34:23.944 | {'loss': 1.1007, 'grad_norm': 13.92936897277832, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 19:34:45.237 | {'loss': 1.2624, 'grad_norm': 12.850004196166992, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 19:34:59.990 | {'loss': 1.4937, 'grad_norm': 10.513724327087402, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 19:35:15.163 | {'loss': 1.505, 'grad_norm': 13.173678398132324, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 19:35:29.947 | {'loss': 1.4565, 'grad_norm': 11.301244735717773, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 19:35:52.012 | {'loss': 1.159, 'grad_norm': 11.385185241699219, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 19:36:07.185 | {'loss': 1.195, 'grad_norm': 12.726673126220703, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 19:36:22.530 | {'loss': 1.3288, 'grad_norm': 13.355155944824219, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 19:36:37.112 | {'loss': 1.3972, 'grad_norm': 11.988511085510254, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 19:36:58.993 | {'loss': 0.8358, 'grad_norm': 12.513526916503906, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 19:37:14.116 | {'loss': 0.9257, 'grad_norm': 8.396872520446777, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 19:37:29.211 | {'loss': 0.8843, 'grad_norm': 10.782024383544922, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 19:37:44.827 | {'loss': 0.8231, 'grad_norm': 10.776472091674805, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 19:38:06.632 | {'loss': 0.9497, 'grad_norm': 10.713140487670898, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 19:38:21.638 | {'loss': 0.8361, 'grad_norm': 9.943273544311523, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 19:38:36.304 | {'loss': 0.8833, 'grad_norm': 11.594277381896973, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 19:38:51.718 | {'loss': 0.8379, 'grad_norm': 12.638278007507324, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 19:39:07.190 | {'loss': 0.9817, 'grad_norm': 9.15926456451416, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 19:39:22.044 | {'loss': 0.7377, 'grad_norm': 7.931380271911621, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 19:39:43.543 | {'loss': 0.8814, 'grad_norm': 10.232209205627441, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 19:39:58.942 | {'loss': 0.8336, 'grad_norm': 10.835878372192383, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 19:40:14.468 | {'loss': 0.9756, 'grad_norm': 11.77283000946045, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 19:40:29.576 | {'loss': 0.7155, 'grad_norm': 7.97450065612793, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 19:40:44.817 | {'loss': 0.9522, 'grad_norm': 12.192680358886719, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 19:41:05.940 | {'loss': 0.9821, 'grad_norm': 12.451231002807617, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 19:41:21.085 | {'loss': 0.9012, 'grad_norm': 10.782825469970703, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 19:41:36.046 | {'loss': 0.9093, 'grad_norm': 12.29129695892334, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 19:41:51.587 | {'loss': 0.732, 'grad_norm': 12.240432739257812, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 19:42:13.576 | {'loss': 0.9166, 'grad_norm': 7.415658473968506, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 19:42:28.317 | {'loss': 0.5559, 'grad_norm': 8.843809127807617, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 19:42:43.159 | {'loss': 0.5447, 'grad_norm': 4.038475513458252, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 19:42:58.056 | {'loss': 0.5631, 'grad_norm': 9.781774520874023, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 19:43:12.967 | {'loss': 0.6126, 'grad_norm': 9.889453887939453, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 19:43:34.179 | {'loss': 0.6175, 'grad_norm': 8.24903678894043, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 19:43:49.893 | {'loss': 0.6069, 'grad_norm': 8.71208381652832, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 19:44:04.845 | {'loss': 0.5746, 'grad_norm': 9.474421501159668, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 19:44:19.962 | {'loss': 0.579, 'grad_norm': 9.845317840576172, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 19:44:40.960 | {'loss': 0.5205, 'grad_norm': 9.089887619018555, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 19:44:56.249 | {'loss': 0.5632, 'grad_norm': 8.809213638305664, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 19:45:11.262 | {'loss': 0.6188, 'grad_norm': 9.109550476074219, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 19:45:26.763 | {'loss': 0.5247, 'grad_norm': 8.816950798034668, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 19:45:42.117 | {'loss': 0.6583, 'grad_norm': 10.06973934173584, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 19:46:04.537 | {'loss': 0.6046, 'grad_norm': 15.115147590637207, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 19:46:19.942 | {'loss': 0.5492, 'grad_norm': 6.778736114501953, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 19:46:35.091 | {'loss': 0.5666, 'grad_norm': 8.30932331085205, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 19:46:50.257 | {'loss': 0.494, 'grad_norm': 8.520796775817871, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 19:47:11.727 | {'loss': 0.5838, 'grad_norm': 8.633538246154785, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 19:47:27.418 | {'loss': 0.5177, 'grad_norm': 9.513060569763184, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 19:47:42.695 | {'loss': 0.565, 'grad_norm': 3.8464841842651367, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 19:47:58.191 | {'loss': 0.3355, 'grad_norm': 6.000731945037842, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 19:48:12.965 | {'loss': 0.393, 'grad_norm': 8.27973747253418, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 19:48:34.611 | {'loss': 0.3698, 'grad_norm': 6.974469184875488, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 19:48:49.814 | {'loss': 0.4002, 'grad_norm': 7.451693058013916, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 19:49:04.943 | {'loss': 0.3408, 'grad_norm': 6.769774436950684, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 19:49:20.218 | {'loss': 0.4169, 'grad_norm': 5.468594551086426, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 19:49:35.537 | {'loss': 0.3495, 'grad_norm': 6.569921970367432, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 19:49:56.944 | {'loss': 0.3559, 'grad_norm': 8.133098602294922, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 19:50:11.701 | {'loss': 0.3964, 'grad_norm': 8.540297508239746, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 19:50:26.981 | {'loss': 0.3932, 'grad_norm': 3.6240499019622803, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 19:50:42.123 | {'loss': 0.3992, 'grad_norm': 4.474835395812988, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 19:51:03.652 | {'loss': 0.4102, 'grad_norm': 8.14889144897461, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 19:51:18.764 | {'loss': 0.3399, 'grad_norm': 4.98388671875, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-25 19:51:34.357 | {'loss': 0.4207, 'grad_norm': 6.395969390869141, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-25 19:51:49.083 | {'loss': 0.3661, 'grad_norm': 8.339043617248535, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-25 19:52:09.981 | {'loss': 0.3782, 'grad_norm': 5.052157402038574, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-25 19:52:25.221 | {'loss': 0.3809, 'grad_norm': 6.896146297454834, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-25 19:52:40.115 | {'loss': 0.3374, 'grad_norm': 6.639687538146973, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-25 19:52:55.309 | {'loss': 0.3469, 'grad_norm': 6.672736167907715, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-25 19:53:07.017 | {'loss': 0.3492, 'grad_norm': 7.2906599044799805, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-25 19:53:07.017 | {'train_runtime': 1667.4904, 'train_samples_per_second': 1.199, 'train_steps_per_second': 0.6, 'train_loss': 1.0473837611675263, 'epoch': 5.0}
2025-05-25 19:53:16.502 | INFO :      Sent reply
2025-05-25 19:59:18.053 | INFO :      
2025-05-25 19:59:18.053 | INFO :      Received: evaluate message c41a7cfa-d8c9-48e5-a4d3-eba3f2a5c07f
2025-05-25 19:59:42.325 | {'eval_loss': 2.8087573051452637, 'eval_runtime': 14.2552, 'eval_samples_per_second': 7.015, 'eval_steps_per_second': 0.912, 'epoch': 5.0}
2025-05-25 19:59:42.335 | INFO :      Sent reply
2025-05-25 19:59:53.317 | INFO :      
2025-05-25 19:59:53.317 | INFO :      Received: train message e0ba34b8-c1b7-4ea2-b3bb-89784c3eebb5
2025-05-25 20:00:34.378 | {'loss': 1.2754, 'grad_norm': 14.604202270507812, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 20:00:51.133 | {'loss': 1.2449, 'grad_norm': 13.577676773071289, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 20:01:09.105 | {'loss': 1.5309, 'grad_norm': 8.635247230529785, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 20:01:33.204 | {'loss': 1.4602, 'grad_norm': 13.442045211791992, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 20:01:48.723 | {'loss': 1.3214, 'grad_norm': 11.233161926269531, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 20:02:04.804 | {'loss': 1.5069, 'grad_norm': 13.213113784790039, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 20:02:29.645 | {'loss': 1.3947, 'grad_norm': 14.291687965393066, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 20:02:46.809 | {'loss': 1.6094, 'grad_norm': 10.455378532409668, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 20:03:03.568 | {'loss': 1.5049, 'grad_norm': 13.294787406921387, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 20:03:26.357 | {'loss': 1.4217, 'grad_norm': 14.262503623962402, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 20:03:41.991 | {'loss': 1.2476, 'grad_norm': 13.357481002807617, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 20:04:00.497 | {'loss': 1.4507, 'grad_norm': 9.50858211517334, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 20:04:17.719 | {'loss': 1.3746, 'grad_norm': 8.87116813659668, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 20:04:41.409 | {'loss': 1.4198, 'grad_norm': 14.089316368103027, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 20:04:58.061 | {'loss': 1.5874, 'grad_norm': 13.411100387573242, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 20:05:14.758 | {'loss': 1.6185, 'grad_norm': 11.711913108825684, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 20:05:40.322 | {'loss': 1.2945, 'grad_norm': 5.200077056884766, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 20:05:58.889 | {'loss': 1.4856, 'grad_norm': 16.880308151245117, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 20:06:16.655 | {'loss': 1.4664, 'grad_norm': 16.089168548583984, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 20:06:42.776 | {'loss': 1.5156, 'grad_norm': 12.971561431884766, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 20:07:00.841 | {'loss': 0.8736, 'grad_norm': 12.972734451293945, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 20:07:18.585 | {'loss': 0.8938, 'grad_norm': 10.542572975158691, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 20:07:44.767 | {'loss': 0.7826, 'grad_norm': 8.36751937866211, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 20:08:02.693 | {'loss': 0.8103, 'grad_norm': 15.942802429199219, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 20:08:19.134 | {'loss': 0.9799, 'grad_norm': 10.877045631408691, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 20:08:44.114 | {'loss': 0.7612, 'grad_norm': 12.070686340332031, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 20:09:02.394 | {'loss': 0.9135, 'grad_norm': 12.931686401367188, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 20:09:20.184 | {'loss': 0.9559, 'grad_norm': 10.46629524230957, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 20:09:38.182 | {'loss': 0.852, 'grad_norm': 10.54260540008545, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 20:10:04.659 | {'loss': 0.8847, 'grad_norm': 11.70458698272705, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 20:10:21.773 | {'loss': 0.91, 'grad_norm': 11.505908012390137, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 20:10:39.612 | {'loss': 0.7521, 'grad_norm': 14.623148918151855, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 20:11:04.720 | {'loss': 0.8539, 'grad_norm': 12.52807903289795, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 20:11:21.975 | {'loss': 0.9469, 'grad_norm': 11.124568939208984, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 20:11:47.302 | {'loss': 0.9839, 'grad_norm': 12.323512077331543, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 20:12:04.807 | {'loss': 0.9, 'grad_norm': 10.198955535888672, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 20:12:22.564 | {'loss': 0.7996, 'grad_norm': 12.307113647460938, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 20:12:49.082 | {'loss': 0.8103, 'grad_norm': 13.070623397827148, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 20:13:06.959 | {'loss': 0.8596, 'grad_norm': 12.119501113891602, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 20:13:24.088 | {'loss': 0.9159, 'grad_norm': 12.238629341125488, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 20:13:41.864 | {'loss': 0.5191, 'grad_norm': 10.571524620056152, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 20:14:04.880 | {'loss': 0.5756, 'grad_norm': 8.9846830368042, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 20:14:21.005 | {'loss': 0.5727, 'grad_norm': 10.529609680175781, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 20:14:37.884 | {'loss': 0.5197, 'grad_norm': 8.414834976196289, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 20:15:02.454 | {'loss': 0.6025, 'grad_norm': 9.094680786132812, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 20:15:18.290 | {'loss': 0.5413, 'grad_norm': 9.132380485534668, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 20:15:37.603 | {'loss': 0.5764, 'grad_norm': 12.475898742675781, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 20:16:01.538 | {'loss': 0.5127, 'grad_norm': 11.588595390319824, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 20:16:17.335 | {'loss': 0.6159, 'grad_norm': 7.332332611083984, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 20:16:33.436 | {'loss': 0.4579, 'grad_norm': 6.41212272644043, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 20:16:49.402 | {'loss': 0.5385, 'grad_norm': 9.815816879272461, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 20:17:14.857 | {'loss': 0.5077, 'grad_norm': 12.271538734436035, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 20:17:32.333 | {'loss': 0.6036, 'grad_norm': 11.865939140319824, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 20:17:48.229 | {'loss': 0.4349, 'grad_norm': 9.155038833618164, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 20:18:07.073 | {'loss': 0.6035, 'grad_norm': 10.535606384277344, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 20:18:24.868 | {'loss': 0.6076, 'grad_norm': 9.24937629699707, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 20:18:52.347 | {'loss': 0.5519, 'grad_norm': 9.271965980529785, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 20:19:09.140 | {'loss': 0.59, 'grad_norm': 12.2876558303833, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 20:19:25.692 | {'loss': 0.4646, 'grad_norm': 8.329212188720703, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 20:19:42.247 | {'loss': 0.5727, 'grad_norm': 6.875269412994385, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 20:20:06.099 | {'loss': 0.3417, 'grad_norm': 6.503680229187012, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 20:20:24.229 | {'loss': 0.3273, 'grad_norm': 3.335381507873535, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 20:20:41.976 | {'loss': 0.3447, 'grad_norm': 7.189955711364746, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 20:20:59.082 | {'loss': 0.3702, 'grad_norm': 7.155824661254883, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 20:21:22.138 | {'loss': 0.3646, 'grad_norm': 6.06365442276001, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 20:21:38.817 | {'loss': 0.3492, 'grad_norm': 8.002132415771484, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 20:21:56.011 | {'loss': 0.3487, 'grad_norm': 8.191573143005371, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 20:22:14.200 | {'loss': 0.3375, 'grad_norm': 5.957983493804932, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 20:22:36.655 | {'loss': 0.3148, 'grad_norm': 9.583941459655762, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 20:22:52.442 | {'loss': 0.3421, 'grad_norm': 7.411461353302002, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 20:23:08.718 | {'loss': 0.401, 'grad_norm': 9.356969833374023, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 20:23:25.299 | {'loss': 0.3234, 'grad_norm': 9.232800483703613, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 20:23:42.547 | {'loss': 0.3816, 'grad_norm': 6.4403839111328125, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 20:24:06.947 | {'loss': 0.3637, 'grad_norm': 8.940075874328613, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 20:24:22.584 | {'loss': 0.3197, 'grad_norm': 8.123228073120117, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 20:24:38.909 | {'loss': 0.3305, 'grad_norm': 6.621922969818115, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 20:25:01.715 | {'loss': 0.2899, 'grad_norm': 6.360307216644287, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 20:25:19.399 | {'loss': 0.3439, 'grad_norm': 6.246244430541992, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 20:25:36.738 | {'loss': 0.3019, 'grad_norm': 7.636544227600098, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 20:25:52.471 | {'loss': 0.329, 'grad_norm': 3.5523860454559326, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 20:26:08.250 | {'loss': 0.1886, 'grad_norm': 4.844237804412842, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 20:26:30.900 | {'loss': 0.2298, 'grad_norm': 4.745090007781982, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 20:26:47.833 | {'loss': 0.2272, 'grad_norm': 4.92226505279541, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 20:27:04.876 | {'loss': 0.227, 'grad_norm': 5.434191703796387, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 20:27:28.390 | {'loss': 0.2094, 'grad_norm': 5.854735851287842, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 20:27:44.462 | {'loss': 0.2482, 'grad_norm': 5.202080249786377, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 20:28:00.135 | {'loss': 0.21, 'grad_norm': 4.2208709716796875, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 20:28:16.414 | {'loss': 0.1913, 'grad_norm': 5.760140895843506, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 20:28:41.507 | {'loss': 0.2362, 'grad_norm': 6.31020450592041, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 20:28:58.796 | {'loss': 0.2187, 'grad_norm': 2.8053343296051025, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 20:29:15.306 | {'loss': 0.2361, 'grad_norm': 4.246999740600586, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 20:29:38.411 | {'loss': 0.2323, 'grad_norm': 6.060808181762695, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 20:29:54.446 | {'loss': 0.1974, 'grad_norm': 4.701040744781494, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-25 20:30:11.984 | {'loss': 0.2344, 'grad_norm': 4.994945526123047, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-25 20:30:29.515 | {'loss': 0.2049, 'grad_norm': 5.8023362159729, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-25 20:30:52.611 | {'loss': 0.2048, 'grad_norm': 3.6387746334075928, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-25 20:31:08.597 | {'loss': 0.2217, 'grad_norm': 4.788296699523926, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-25 20:31:24.540 | {'loss': 0.1805, 'grad_norm': 4.287354946136475, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-25 20:31:40.432 | {'loss': 0.1873, 'grad_norm': 5.675141334533691, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-25 20:32:02.987 | {'loss': 0.1882, 'grad_norm': 5.399672508239746, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-25 20:32:02.987 | {'train_runtime': 1922.3992, 'train_samples_per_second': 1.04, 'train_steps_per_second': 0.52, 'train_loss': 0.6823891725540161, 'epoch': 5.0}
2025-05-25 20:32:11.594 | INFO :      Sent reply
2025-05-25 20:38:16.276 | INFO :      
2025-05-25 20:38:16.276 | INFO :      Received: evaluate message cd3fd6a3-bac5-42d2-8b14-373a84565ec0
2025-05-25 20:38:31.656 | {'eval_loss': 2.9159328937530518, 'eval_runtime': 3.8826, 'eval_samples_per_second': 25.756, 'eval_steps_per_second': 3.348, 'epoch': 5.0}
2025-05-25 20:38:31.657 | INFO :      Sent reply
2025-05-25 20:38:43.569 | INFO :      
2025-05-25 20:38:43.569 | INFO :      Received: train message 7f53d197-d5d8-4ef3-979d-c04b74c48941
2025-05-25 20:39:05.491 | {'loss': 0.7508, 'grad_norm': 13.380372047424316, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 20:39:20.898 | {'loss': 0.7977, 'grad_norm': 11.713452339172363, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 20:39:42.613 | {'loss': 1.0297, 'grad_norm': 8.256271362304688, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 20:39:57.692 | {'loss': 0.9834, 'grad_norm': 12.956709861755371, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 20:40:13.086 | {'loss': 0.9032, 'grad_norm': 8.047979354858398, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 20:40:28.408 | {'loss': 1.0715, 'grad_norm': 12.74329662322998, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 20:40:50.310 | {'loss': 0.9301, 'grad_norm': 13.500480651855469, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 20:41:05.468 | {'loss': 1.1109, 'grad_norm': 11.734135627746582, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 20:41:21.026 | {'loss': 1.0501, 'grad_norm': 11.780940055847168, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 20:41:36.103 | {'loss': 0.9791, 'grad_norm': 13.723360061645508, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 20:41:51.676 | {'loss': 0.8515, 'grad_norm': 11.572541236877441, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 20:42:06.931 | {'loss': 0.9994, 'grad_norm': 14.08012866973877, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 20:42:29.610 | {'loss': 0.9846, 'grad_norm': 18.043121337890625, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 20:42:44.690 | {'loss': 0.9897, 'grad_norm': 12.923996925354004, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 20:42:59.904 | {'loss': 1.1531, 'grad_norm': 13.149005889892578, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 20:43:15.327 | {'loss': 1.1407, 'grad_norm': 10.509739875793457, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 20:43:37.118 | {'loss': 0.9016, 'grad_norm': 6.512522220611572, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 20:43:52.473 | {'loss': 1.0119, 'grad_norm': 14.114702224731445, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 20:44:07.586 | {'loss': 1.0187, 'grad_norm': 16.851119995117188, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 20:44:23.055 | {'loss': 1.0733, 'grad_norm': 11.6103515625, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 20:44:45.096 | {'loss': 0.5838, 'grad_norm': 12.125286102294922, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 20:45:00.197 | {'loss': 0.6012, 'grad_norm': 9.04940414428711, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 20:45:15.563 | {'loss': 0.5208, 'grad_norm': 8.265901565551758, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 20:45:30.651 | {'loss': 0.5372, 'grad_norm': 12.189852714538574, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 20:45:46.132 | {'loss': 0.7006, 'grad_norm': 11.20244026184082, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 20:46:07.631 | {'loss': 0.5352, 'grad_norm': 12.952190399169922, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 20:46:23.209 | {'loss': 0.6042, 'grad_norm': 12.220940589904785, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 20:46:38.226 | {'loss': 0.6392, 'grad_norm': 10.333744049072266, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 20:46:54.029 | {'loss': 0.5825, 'grad_norm': 9.366189956665039, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 20:47:09.388 | {'loss': 0.6151, 'grad_norm': 11.509382247924805, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 20:47:31.684 | {'loss': 0.6036, 'grad_norm': 8.570245742797852, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 20:47:46.852 | {'loss': 0.5462, 'grad_norm': 14.484514236450195, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 20:48:02.226 | {'loss': 0.603, 'grad_norm': 13.216836929321289, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 20:48:17.660 | {'loss': 0.6502, 'grad_norm': 10.273093223571777, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 20:48:32.710 | {'loss': 0.6579, 'grad_norm': 11.448748588562012, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 20:48:54.638 | {'loss': 0.6016, 'grad_norm': 9.224461555480957, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 20:49:09.862 | {'loss': 0.5343, 'grad_norm': 8.804377555847168, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 20:49:25.617 | {'loss': 0.5332, 'grad_norm': 14.595823287963867, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 20:49:41.295 | {'loss': 0.596, 'grad_norm': 11.60710334777832, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 20:49:57.177 | {'loss': 0.6199, 'grad_norm': 12.101576805114746, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 20:50:19.543 | {'loss': 0.3368, 'grad_norm': 9.863800048828125, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 20:50:34.846 | {'loss': 0.4007, 'grad_norm': 6.9727654457092285, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 20:50:50.763 | {'loss': 0.3835, 'grad_norm': 13.294472694396973, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 20:51:05.562 | {'loss': 0.3381, 'grad_norm': 8.101639747619629, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 20:51:20.766 | {'loss': 0.4425, 'grad_norm': 8.407662391662598, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 20:51:36.204 | {'loss': 0.3891, 'grad_norm': 6.891060829162598, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 20:51:58.034 | {'loss': 0.4047, 'grad_norm': 8.492668151855469, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 20:52:13.806 | {'loss': 0.3577, 'grad_norm': 8.672324180603027, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 20:52:28.598 | {'loss': 0.3634, 'grad_norm': 7.7036895751953125, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 20:52:43.291 | {'loss': 0.3079, 'grad_norm': 5.668966293334961, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 20:52:58.380 | {'loss': 0.3948, 'grad_norm': 9.406676292419434, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 20:53:19.924 | {'loss': 0.3574, 'grad_norm': 10.224981307983398, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 20:53:34.742 | {'loss': 0.4023, 'grad_norm': 8.897013664245605, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 20:53:50.242 | {'loss': 0.297, 'grad_norm': 6.950115203857422, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 20:54:05.239 | {'loss': 0.4003, 'grad_norm': 10.084936141967773, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 20:54:27.394 | {'loss': 0.4352, 'grad_norm': 9.04686450958252, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 20:54:42.479 | {'loss': 0.3823, 'grad_norm': 7.7714996337890625, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 20:54:57.939 | {'loss': 0.3847, 'grad_norm': 9.636855125427246, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 20:55:19.864 | {'loss': 0.3115, 'grad_norm': 7.628750801086426, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 20:55:34.746 | {'loss': 0.3813, 'grad_norm': 7.143357276916504, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 20:55:49.766 | {'loss': 0.2298, 'grad_norm': 8.02377700805664, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 20:56:04.628 | {'loss': 0.2268, 'grad_norm': 2.501140832901001, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 20:56:26.633 | {'loss': 0.2313, 'grad_norm': 6.223671913146973, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 20:56:41.523 | {'loss': 0.269, 'grad_norm': 7.272737503051758, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 20:56:56.999 | {'loss': 0.2521, 'grad_norm': 5.1165666580200195, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 20:57:12.133 | {'loss': 0.2536, 'grad_norm': 5.620851516723633, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 20:57:33.962 | {'loss': 0.2429, 'grad_norm': 7.226167678833008, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 20:57:49.232 | {'loss': 0.2295, 'grad_norm': 6.251255989074707, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 20:58:04.082 | {'loss': 0.2135, 'grad_norm': 8.749801635742188, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 20:58:19.094 | {'loss': 0.2496, 'grad_norm': 8.253946304321289, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 20:58:40.367 | {'loss': 0.2416, 'grad_norm': 6.9567718505859375, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 20:58:55.664 | {'loss': 0.2413, 'grad_norm': 6.178097724914551, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 20:59:10.782 | {'loss': 0.2753, 'grad_norm': 5.4632134437561035, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 20:59:26.504 | {'loss': 0.2508, 'grad_norm': 8.697785377502441, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 20:59:48.481 | {'loss': 0.2508, 'grad_norm': 5.467337131500244, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 21:00:03.540 | {'loss': 0.2459, 'grad_norm': 5.5283002853393555, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 21:00:18.587 | {'loss': 0.2077, 'grad_norm': 4.533967971801758, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 21:00:33.681 | {'loss': 0.2282, 'grad_norm': 6.273426055908203, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 21:00:48.799 | {'loss': 0.2191, 'grad_norm': 7.6558637619018555, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 21:01:10.339 | {'loss': 0.2417, 'grad_norm': 2.2664878368377686, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 21:01:25.664 | {'loss': 0.1295, 'grad_norm': 3.5880517959594727, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 21:01:40.628 | {'loss': 0.1688, 'grad_norm': 3.744774341583252, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 21:01:56.035 | {'loss': 0.164, 'grad_norm': 6.434539794921875, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 21:02:11.150 | {'loss': 0.1537, 'grad_norm': 4.992335319519043, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 21:02:33.284 | {'loss': 0.1568, 'grad_norm': 4.196489334106445, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 21:02:48.762 | {'loss': 0.1518, 'grad_norm': 3.4201865196228027, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 21:03:03.915 | {'loss': 0.1384, 'grad_norm': 3.5999720096588135, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 21:03:18.902 | {'loss': 0.1443, 'grad_norm': 4.426767349243164, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 21:03:40.351 | {'loss': 0.1899, 'grad_norm': 4.989196300506592, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 21:03:55.734 | {'loss': 0.1565, 'grad_norm': 2.200549602508545, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 21:04:10.677 | {'loss': 0.1622, 'grad_norm': 3.8264248371124268, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 21:04:26.071 | {'loss': 0.1572, 'grad_norm': 5.3419013023376465, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 21:04:41.054 | {'loss': 0.1445, 'grad_norm': 3.3254380226135254, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-25 21:05:03.066 | {'loss': 0.162, 'grad_norm': 4.598419666290283, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-25 21:05:18.307 | {'loss': 0.1281, 'grad_norm': 3.681838035583496, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-25 21:05:33.981 | {'loss': 0.1345, 'grad_norm': 3.0310661792755127, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-25 21:05:49.142 | {'loss': 0.1528, 'grad_norm': 4.757216930389404, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-25 21:06:10.795 | {'loss': 0.1204, 'grad_norm': 6.661420822143555, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-25 21:06:26.150 | {'loss': 0.1247, 'grad_norm': 4.500652313232422, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-25 21:06:41.239 | {'loss': 0.1562, 'grad_norm': 7.121574401855469, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-25 21:06:41.239 | {'train_runtime': 1675.7414, 'train_samples_per_second': 1.194, 'train_steps_per_second': 0.597, 'train_loss': 0.4686507295370102, 'epoch': 5.0}
2025-05-25 21:06:53.664 | INFO :      Sent reply
2025-05-25 21:13:09.067 | INFO :      
2025-05-25 21:13:09.067 | INFO :      Received: evaluate message 241c5875-594e-451c-aefa-f88449a20a9d
2025-05-25 21:13:26.069 | {'eval_loss': 3.0126726627349854, 'eval_runtime': 13.2389, 'eval_samples_per_second': 7.553, 'eval_steps_per_second': 0.982, 'epoch': 5.0}
2025-05-25 21:13:26.090 | INFO :      Sent reply
2025-05-25 21:13:37.160 | INFO :      
2025-05-25 21:13:37.160 | INFO :      Received: train message c601691c-1afc-4b4f-8624-807760b0d201
2025-05-25 21:14:03.529 | {'loss': 0.4029, 'grad_norm': 10.395234107971191, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 21:14:18.724 | {'loss': 0.4777, 'grad_norm': 8.974191665649414, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 21:14:40.678 | {'loss': 0.6912, 'grad_norm': 7.091381072998047, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 21:14:56.216 | {'loss': 0.619, 'grad_norm': 12.095108985900879, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 21:15:11.794 | {'loss': 0.6073, 'grad_norm': 8.437834739685059, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 21:15:27.863 | {'loss': 0.6824, 'grad_norm': 10.549041748046875, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 21:15:43.961 | {'loss': 0.6169, 'grad_norm': 10.023873329162598, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 21:16:06.414 | {'loss': 0.7904, 'grad_norm': 12.153583526611328, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 21:16:21.601 | {'loss': 0.68, 'grad_norm': 10.297151565551758, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 21:16:37.099 | {'loss': 0.6845, 'grad_norm': 11.482105255126953, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 21:16:52.224 | {'loss': 0.5804, 'grad_norm': 10.208134651184082, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 21:17:14.047 | {'loss': 0.6952, 'grad_norm': 7.700003147125244, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 21:17:29.606 | {'loss': 0.7091, 'grad_norm': 7.895874500274658, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 21:17:45.014 | {'loss': 0.6792, 'grad_norm': 10.400043487548828, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 21:18:00.451 | {'loss': 0.8447, 'grad_norm': 13.020770072937012, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 21:18:15.679 | {'loss': 0.8248, 'grad_norm': 9.699563980102539, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 21:18:37.493 | {'loss': 0.6276, 'grad_norm': 4.08690071105957, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 21:18:52.361 | {'loss': 0.7165, 'grad_norm': 13.846329689025879, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 21:19:07.693 | {'loss': 0.7481, 'grad_norm': 14.810161590576172, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 21:19:22.681 | {'loss': 0.7426, 'grad_norm': 11.039419174194336, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 21:19:44.580 | {'loss': 0.4409, 'grad_norm': 12.552334785461426, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 21:20:00.151 | {'loss': 0.4459, 'grad_norm': 11.856545448303223, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 21:20:15.579 | {'loss': 0.4092, 'grad_norm': 6.242441654205322, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 21:20:31.272 | {'loss': 0.372, 'grad_norm': 9.370102882385254, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 21:20:46.751 | {'loss': 0.4947, 'grad_norm': 7.020033836364746, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 21:21:08.651 | {'loss': 0.4035, 'grad_norm': 11.29643440246582, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 21:21:23.777 | {'loss': 0.4661, 'grad_norm': 10.788888931274414, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 21:21:39.345 | {'loss': 0.4492, 'grad_norm': 9.121294021606445, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 21:21:54.463 | {'loss': 0.4327, 'grad_norm': 8.895649909973145, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 21:22:16.469 | {'loss': 0.4569, 'grad_norm': 9.971941947937012, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 21:22:32.075 | {'loss': 0.4379, 'grad_norm': 9.435968399047852, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 21:22:47.593 | {'loss': 0.4282, 'grad_norm': 17.003469467163086, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 21:23:03.150 | {'loss': 0.4695, 'grad_norm': 13.67432975769043, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 21:23:18.469 | {'loss': 0.4901, 'grad_norm': 11.169984817504883, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 21:23:40.449 | {'loss': 0.5082, 'grad_norm': 10.42882251739502, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 21:23:55.487 | {'loss': 0.4586, 'grad_norm': 7.127087593078613, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 21:24:10.955 | {'loss': 0.4109, 'grad_norm': 7.875021934509277, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 21:24:26.198 | {'loss': 0.3854, 'grad_norm': 10.607060432434082, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 21:24:47.909 | {'loss': 0.4355, 'grad_norm': 10.86868667602539, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 21:25:03.285 | {'loss': 0.4703, 'grad_norm': 13.974578857421875, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 21:25:18.476 | {'loss': 0.2604, 'grad_norm': 7.523486614227295, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 21:25:34.243 | {'loss': 0.3124, 'grad_norm': 6.3283538818359375, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 21:25:49.812 | {'loss': 0.2816, 'grad_norm': 8.199577331542969, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 21:26:11.921 | {'loss': 0.263, 'grad_norm': 7.232173919677734, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 21:26:27.260 | {'loss': 0.3191, 'grad_norm': 7.239428520202637, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 21:26:42.284 | {'loss': 0.3117, 'grad_norm': 7.400418758392334, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 21:26:57.789 | {'loss': 0.3044, 'grad_norm': 7.539473056793213, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 21:27:12.842 | {'loss': 0.286, 'grad_norm': 8.485517501831055, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 21:27:34.921 | {'loss': 0.3421, 'grad_norm': 7.2418904304504395, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 21:27:50.303 | {'loss': 0.2392, 'grad_norm': 5.275221824645996, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 21:28:06.148 | {'loss': 0.281, 'grad_norm': 9.373929023742676, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 21:28:21.474 | {'loss': 0.2619, 'grad_norm': 8.630916595458984, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 21:28:43.179 | {'loss': 0.3064, 'grad_norm': 8.782713890075684, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 21:28:58.523 | {'loss': 0.2307, 'grad_norm': 6.69434118270874, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 21:29:14.025 | {'loss': 0.3124, 'grad_norm': 8.223363876342773, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 21:29:28.870 | {'loss': 0.2999, 'grad_norm': 7.874664783477783, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 21:29:44.095 | {'loss': 0.3063, 'grad_norm': 7.9554266929626465, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 21:30:06.381 | {'loss': 0.3174, 'grad_norm': 9.218881607055664, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 21:30:21.817 | {'loss': 0.2609, 'grad_norm': 8.84870433807373, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 21:30:37.348 | {'loss': 0.2769, 'grad_norm': 5.447281837463379, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 21:30:52.803 | {'loss': 0.1804, 'grad_norm': 5.415576934814453, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 21:31:14.256 | {'loss': 0.1713, 'grad_norm': 1.8010444641113281, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 21:31:29.661 | {'loss': 0.1921, 'grad_norm': 6.042173862457275, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 21:31:45.010 | {'loss': 0.2065, 'grad_norm': 6.5901198387146, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 21:32:00.552 | {'loss': 0.2051, 'grad_norm': 4.276482582092285, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 21:32:16.090 | {'loss': 0.2052, 'grad_norm': 7.617783546447754, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 21:32:38.424 | {'loss': 0.2067, 'grad_norm': 6.61588716506958, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 21:32:53.458 | {'loss': 0.1741, 'grad_norm': 6.347014904022217, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 21:33:08.670 | {'loss': 0.1929, 'grad_norm': 8.666236877441406, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 21:33:23.899 | {'loss': 0.1721, 'grad_norm': 6.86323881149292, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 21:33:45.723 | {'loss': 0.1869, 'grad_norm': 6.286262035369873, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 21:34:00.878 | {'loss': 0.1881, 'grad_norm': 6.050632476806641, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 21:34:16.274 | {'loss': 0.1868, 'grad_norm': 4.673821449279785, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 21:34:32.152 | {'loss': 0.183, 'grad_norm': 5.549155235290527, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 21:34:47.879 | {'loss': 0.1897, 'grad_norm': 4.249332427978516, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 21:35:09.978 | {'loss': 0.1886, 'grad_norm': 5.815733432769775, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 21:35:25.220 | {'loss': 0.1713, 'grad_norm': 4.020524501800537, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 21:35:40.601 | {'loss': 0.2031, 'grad_norm': 5.0580339431762695, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 21:35:55.735 | {'loss': 0.1664, 'grad_norm': 4.736070156097412, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 21:36:17.771 | {'loss': 0.177, 'grad_norm': 2.4662997722625732, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 21:36:33.141 | {'loss': 0.1074, 'grad_norm': 3.059891700744629, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 21:36:48.522 | {'loss': 0.1246, 'grad_norm': 4.138638973236084, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 21:37:04.052 | {'loss': 0.143, 'grad_norm': 6.13968563079834, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 21:37:26.297 | {'loss': 0.1213, 'grad_norm': 4.708374977111816, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 21:37:42.134 | {'loss': 0.1203, 'grad_norm': 4.047516822814941, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 21:37:57.524 | {'loss': 0.1153, 'grad_norm': 2.5890250205993652, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 21:38:12.903 | {'loss': 0.1208, 'grad_norm': 3.2155160903930664, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 21:38:27.997 | {'loss': 0.1148, 'grad_norm': 3.26084566116333, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 21:38:49.992 | {'loss': 0.1374, 'grad_norm': 4.085197448730469, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 21:39:05.460 | {'loss': 0.1162, 'grad_norm': 2.2168989181518555, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 21:39:20.627 | {'loss': 0.118, 'grad_norm': 2.715147018432617, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 21:39:36.096 | {'loss': 0.1239, 'grad_norm': 3.8931517601013184, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 21:39:57.430 | {'loss': 0.1016, 'grad_norm': 1.8749881982803345, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-25 21:40:13.041 | {'loss': 0.1276, 'grad_norm': 3.9195404052734375, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-25 21:40:28.293 | {'loss': 0.1098, 'grad_norm': 4.1109161376953125, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-25 21:40:43.916 | {'loss': 0.1149, 'grad_norm': 4.746236801147461, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-25 21:41:05.516 | {'loss': 0.1216, 'grad_norm': 3.298518419265747, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-25 21:41:21.019 | {'loss': 0.1063, 'grad_norm': 3.2438721656799316, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-25 21:41:36.040 | {'loss': 0.1138, 'grad_norm': 3.7856829166412354, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-25 21:41:51.204 | {'loss': 0.1346, 'grad_norm': 5.715847969055176, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-25 21:41:51.204 | {'train_runtime': 1689.9388, 'train_samples_per_second': 1.183, 'train_steps_per_second': 0.592, 'train_loss': 0.34200020265579223, 'epoch': 5.0}
2025-05-25 21:42:02.896 | INFO :      Sent reply
2025-05-25 21:48:13.184 | INFO :      
2025-05-25 21:48:13.184 | INFO :      Received: evaluate message b2ee912b-2046-43e4-b59d-53d98f54a6fb
2025-05-25 21:48:26.303 | {'eval_loss': 3.141977310180664, 'eval_runtime': 9.2676, 'eval_samples_per_second': 10.79, 'eval_steps_per_second': 1.403, 'epoch': 5.0}
2025-05-25 21:48:26.305 | INFO :      Sent reply
2025-05-25 21:48:36.873 | INFO :      
2025-05-25 21:48:36.873 | INFO :      Received: train message a070ce52-d9d1-43cd-8945-c9e88fd5b00e
2025-05-25 21:49:01.203 | {'loss': 0.2597, 'grad_norm': 8.242647171020508, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 21:49:16.217 | {'loss': 0.312, 'grad_norm': 7.7668867111206055, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 21:49:31.735 | {'loss': 0.4252, 'grad_norm': 5.8982391357421875, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 21:49:53.419 | {'loss': 0.4149, 'grad_norm': 8.037374496459961, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 21:50:09.074 | {'loss': 0.4391, 'grad_norm': 6.345093250274658, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 21:50:24.300 | {'loss': 0.4815, 'grad_norm': 8.614516258239746, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 21:50:39.425 | {'loss': 0.4233, 'grad_norm': 8.481901168823242, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 21:51:01.059 | {'loss': 0.5503, 'grad_norm': 9.947555541992188, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 21:51:15.955 | {'loss': 0.4372, 'grad_norm': 7.766077518463135, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 21:51:30.626 | {'loss': 0.4573, 'grad_norm': 12.145476341247559, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 21:51:45.853 | {'loss': 0.4263, 'grad_norm': 7.901696681976318, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 21:52:07.756 | {'loss': 0.5402, 'grad_norm': 8.938833236694336, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 21:52:22.743 | {'loss': 0.5205, 'grad_norm': 5.922926425933838, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 21:52:37.970 | {'loss': 0.4945, 'grad_norm': 6.92473030090332, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 21:52:53.247 | {'loss': 0.6245, 'grad_norm': 10.750919342041016, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 21:53:08.204 | {'loss': 0.5682, 'grad_norm': 9.138078689575195, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 21:53:29.640 | {'loss': 0.4606, 'grad_norm': 5.446059226989746, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 21:53:44.858 | {'loss': 0.5141, 'grad_norm': 12.322260856628418, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 21:54:00.100 | {'loss': 0.5263, 'grad_norm': 13.305357933044434, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 21:54:15.032 | {'loss': 0.5502, 'grad_norm': 9.417343139648438, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 21:54:30.110 | {'loss': 0.3295, 'grad_norm': 11.123199462890625, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 21:54:52.153 | {'loss': 0.3594, 'grad_norm': 6.486940860748291, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 21:55:07.555 | {'loss': 0.37, 'grad_norm': 5.132450580596924, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 21:55:22.813 | {'loss': 0.3396, 'grad_norm': 8.603839874267578, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 21:55:37.922 | {'loss': 0.3967, 'grad_norm': 7.880776405334473, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 21:55:59.370 | {'loss': 0.3217, 'grad_norm': 12.65709400177002, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 21:56:14.585 | {'loss': 0.3573, 'grad_norm': 9.736766815185547, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 21:56:29.513 | {'loss': 0.3942, 'grad_norm': 8.391319274902344, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 21:56:44.823 | {'loss': 0.3255, 'grad_norm': 7.230815410614014, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 21:57:00.170 | {'loss': 0.3567, 'grad_norm': 9.818487167358398, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 21:57:22.466 | {'loss': 0.346, 'grad_norm': 9.604711532592773, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 21:57:37.589 | {'loss': 0.3482, 'grad_norm': 13.45683765411377, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 21:57:53.003 | {'loss': 0.3845, 'grad_norm': 10.443902015686035, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 21:58:08.282 | {'loss': 0.3759, 'grad_norm': 10.576130867004395, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 21:58:23.479 | {'loss': 0.3901, 'grad_norm': 10.75615119934082, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 21:58:45.216 | {'loss': 0.3484, 'grad_norm': 9.01113224029541, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 21:59:00.420 | {'loss': 0.3361, 'grad_norm': 8.34799575805664, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 21:59:15.799 | {'loss': 0.3249, 'grad_norm': 9.320350646972656, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 21:59:31.112 | {'loss': 0.3315, 'grad_norm': 7.774972915649414, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 21:59:53.529 | {'loss': 0.3555, 'grad_norm': 9.888773918151855, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 22:00:09.097 | {'loss': 0.2086, 'grad_norm': 7.68426513671875, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 22:00:24.153 | {'loss': 0.2258, 'grad_norm': 5.325965881347656, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 22:00:39.243 | {'loss': 0.2443, 'grad_norm': 9.645934104919434, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 22:00:54.388 | {'loss': 0.2371, 'grad_norm': 5.438337326049805, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 22:01:16.417 | {'loss': 0.29, 'grad_norm': 7.669131755828857, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 22:01:31.101 | {'loss': 0.2426, 'grad_norm': 7.370408058166504, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 22:01:46.216 | {'loss': 0.2472, 'grad_norm': 12.502297401428223, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 22:02:01.357 | {'loss': 0.2435, 'grad_norm': 6.674106597900391, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 22:02:23.496 | {'loss': 0.2561, 'grad_norm': 7.402662754058838, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 22:02:38.613 | {'loss': 0.2279, 'grad_norm': 4.1956353187561035, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 22:02:53.875 | {'loss': 0.254, 'grad_norm': 9.21053409576416, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 22:03:08.831 | {'loss': 0.2188, 'grad_norm': 9.333969116210938, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 22:03:24.171 | {'loss': 0.2356, 'grad_norm': 6.957070350646973, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 22:03:45.775 | {'loss': 0.2031, 'grad_norm': 5.866717338562012, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 22:04:00.869 | {'loss': 0.238, 'grad_norm': 8.082216262817383, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 22:04:16.223 | {'loss': 0.2799, 'grad_norm': 7.409631729125977, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 22:04:31.811 | {'loss': 0.2597, 'grad_norm': 5.871089458465576, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 22:04:53.674 | {'loss': 0.2308, 'grad_norm': 5.838196277618408, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 22:05:09.006 | {'loss': 0.2112, 'grad_norm': 5.9468302726745605, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 22:05:24.706 | {'loss': 0.2526, 'grad_norm': 6.135531425476074, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 22:05:39.664 | {'loss': 0.1434, 'grad_norm': 6.201378345489502, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 22:05:54.681 | {'loss': 0.1494, 'grad_norm': 1.8485631942749023, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 22:06:09.534 | {'loss': 0.1678, 'grad_norm': 4.615616321563721, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 22:06:31.416 | {'loss': 0.1462, 'grad_norm': 4.839489459991455, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 22:06:46.760 | {'loss': 0.1609, 'grad_norm': 5.270794868469238, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 22:07:02.481 | {'loss': 0.1785, 'grad_norm': 6.232041835784912, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 22:07:18.256 | {'loss': 0.172, 'grad_norm': 6.356043338775635, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 22:07:39.543 | {'loss': 0.1776, 'grad_norm': 5.722204208374023, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 22:07:55.141 | {'loss': 0.1611, 'grad_norm': 7.7709245681762695, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 22:08:09.791 | {'loss': 0.1526, 'grad_norm': 4.963068962097168, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 22:08:24.925 | {'loss': 0.1653, 'grad_norm': 4.890246868133545, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 22:08:39.747 | {'loss': 0.1683, 'grad_norm': 5.308585166931152, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 22:09:01.457 | {'loss': 0.1572, 'grad_norm': 4.55110502243042, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 22:09:16.769 | {'loss': 0.149, 'grad_norm': 7.080491065979004, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 22:09:32.251 | {'loss': 0.1349, 'grad_norm': 4.3075642585754395, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 22:09:47.736 | {'loss': 0.1549, 'grad_norm': 5.9979634284973145, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 22:10:02.955 | {'loss': 0.1659, 'grad_norm': 4.067922592163086, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 22:10:24.768 | {'loss': 0.1585, 'grad_norm': 3.557039260864258, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 22:10:39.752 | {'loss': 0.1492, 'grad_norm': 5.726000785827637, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 22:10:54.962 | {'loss': 0.1566, 'grad_norm': 1.993281602859497, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 22:11:09.877 | {'loss': 0.0858, 'grad_norm': 4.656773090362549, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 22:11:25.129 | {'loss': 0.1064, 'grad_norm': 3.5201215744018555, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 22:11:46.926 | {'loss': 0.1007, 'grad_norm': 4.187785625457764, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 22:12:02.173 | {'loss': 0.112, 'grad_norm': 3.878983974456787, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 22:12:17.884 | {'loss': 0.1054, 'grad_norm': 3.2680156230926514, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 22:12:33.267 | {'loss': 0.111, 'grad_norm': 2.9716784954071045, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 22:12:55.014 | {'loss': 0.0993, 'grad_norm': 3.650426149368286, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 22:13:09.795 | {'loss': 0.1028, 'grad_norm': 3.124321937561035, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 22:13:25.271 | {'loss': 0.1175, 'grad_norm': 5.121904373168945, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 22:13:40.019 | {'loss': 0.1072, 'grad_norm': 2.049469470977783, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 22:13:55.071 | {'loss': 0.1176, 'grad_norm': 3.790473699569702, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 22:14:10.271 | {'loss': 0.1162, 'grad_norm': 4.390856742858887, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 22:14:32.343 | {'loss': 0.0913, 'grad_norm': 1.8673537969589233, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-25 22:14:47.697 | {'loss': 0.1135, 'grad_norm': 4.087824821472168, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-25 22:15:02.909 | {'loss': 0.0974, 'grad_norm': 2.3616185188293457, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-25 22:15:18.232 | {'loss': 0.0963, 'grad_norm': 2.230665683746338, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-25 22:15:33.362 | {'loss': 0.1005, 'grad_norm': 2.9809823036193848, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-25 22:15:48.334 | {'loss': 0.0891, 'grad_norm': 2.191225528717041, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-25 22:16:09.442 | {'loss': 0.106, 'grad_norm': 8.775802612304688, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-25 22:16:25.121 | {'loss': 0.1052, 'grad_norm': 4.772136211395264, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-25 22:16:25.121 | {'train_runtime': 1665.6749, 'train_samples_per_second': 1.201, 'train_steps_per_second': 0.6, 'train_loss': 0.26574372678995134, 'epoch': 5.0}
2025-05-25 22:16:30.979 | INFO :      Sent reply
2025-05-25 22:22:48.641 | INFO :      
2025-05-25 22:22:48.641 | INFO :      Received: evaluate message 550a5749-e6e7-495e-943d-312669befec9
2025-05-25 22:23:07.754 | {'eval_loss': 3.23720645904541, 'eval_runtime': 15.665, 'eval_samples_per_second': 6.384, 'eval_steps_per_second': 0.83, 'epoch': 5.0}
2025-05-25 22:23:07.767 | INFO :      Sent reply
2025-05-25 22:23:17.923 | INFO :      
2025-05-25 22:23:17.923 | INFO :      Received: train message b5393a76-d6ee-45a8-b289-f8b0406aa076
2025-05-25 22:23:48.244 | {'loss': 0.1634, 'grad_norm': 5.296627998352051, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 22:24:03.579 | {'loss': 0.1958, 'grad_norm': 5.593902111053467, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 22:24:18.836 | {'loss': 0.3216, 'grad_norm': 4.979966163635254, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 22:24:34.171 | {'loss': 0.3244, 'grad_norm': 6.61522102355957, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 22:24:49.644 | {'loss': 0.3156, 'grad_norm': 4.5725836753845215, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 22:25:05.186 | {'loss': 0.347, 'grad_norm': 7.457548141479492, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 22:25:20.812 | {'loss': 0.3157, 'grad_norm': 7.782265663146973, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 22:25:42.218 | {'loss': 0.3682, 'grad_norm': 8.716635704040527, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 22:25:57.464 | {'loss': 0.3307, 'grad_norm': 7.0796403884887695, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 22:26:12.637 | {'loss': 0.333, 'grad_norm': 10.834986686706543, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 22:26:27.992 | {'loss': 0.3197, 'grad_norm': 8.362189292907715, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 22:26:42.969 | {'loss': 0.3592, 'grad_norm': 6.489159107208252, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 22:26:58.241 | {'loss': 0.3631, 'grad_norm': 5.452975273132324, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 22:27:13.233 | {'loss': 0.3922, 'grad_norm': 10.687166213989258, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 22:27:34.848 | {'loss': 0.494, 'grad_norm': 10.108256340026855, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 22:27:50.038 | {'loss': 0.4227, 'grad_norm': 6.252963066101074, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 22:28:05.248 | {'loss': 0.3419, 'grad_norm': 5.0147600173950195, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 22:28:20.620 | {'loss': 0.3837, 'grad_norm': 12.92385482788086, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 22:28:35.945 | {'loss': 0.4044, 'grad_norm': 13.309793472290039, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 22:28:58.109 | {'loss': 0.4134, 'grad_norm': 8.162643432617188, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 22:29:13.135 | {'loss': 0.3154, 'grad_norm': 10.239605903625488, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 22:29:28.488 | {'loss': 0.292, 'grad_norm': 7.22630500793457, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 22:29:44.022 | {'loss': 0.313, 'grad_norm': 6.257381916046143, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 22:30:00.124 | {'loss': 0.2607, 'grad_norm': 9.342804908752441, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 22:30:21.437 | {'loss': 0.3558, 'grad_norm': 8.763294219970703, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 22:30:36.967 | {'loss': 0.2863, 'grad_norm': 10.694816589355469, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 22:30:52.026 | {'loss': 0.3234, 'grad_norm': 9.465058326721191, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 22:31:13.695 | {'loss': 0.2839, 'grad_norm': 8.124629974365234, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 22:31:29.401 | {'loss': 0.3199, 'grad_norm': 6.5162882804870605, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 22:31:44.911 | {'loss': 0.3201, 'grad_norm': 9.514307022094727, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 22:32:06.933 | {'loss': 0.3172, 'grad_norm': 9.462567329406738, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 22:32:22.368 | {'loss': 0.2863, 'grad_norm': 11.314509391784668, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 22:32:37.867 | {'loss': 0.2717, 'grad_norm': 9.776368141174316, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 22:32:59.747 | {'loss': 0.325, 'grad_norm': 7.681879997253418, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 22:33:14.682 | {'loss': 0.342, 'grad_norm': 9.699231147766113, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 22:33:30.141 | {'loss': 0.3104, 'grad_norm': 6.818448543548584, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 22:33:51.832 | {'loss': 0.2819, 'grad_norm': 7.785204887390137, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 22:34:06.805 | {'loss': 0.2731, 'grad_norm': 9.31141471862793, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 22:34:21.997 | {'loss': 0.3038, 'grad_norm': 10.17535400390625, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 22:34:37.473 | {'loss': 0.3258, 'grad_norm': 9.327117919921875, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 22:34:59.637 | {'loss': 0.2106, 'grad_norm': 7.925976753234863, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 22:35:14.742 | {'loss': 0.2106, 'grad_norm': 4.5905046463012695, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 22:35:30.163 | {'loss': 0.1898, 'grad_norm': 6.7092366218566895, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 22:35:45.168 | {'loss': 0.1765, 'grad_norm': 5.6487202644348145, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 22:36:00.517 | {'loss': 0.2532, 'grad_norm': 6.5258660316467285, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 22:36:22.332 | {'loss': 0.2434, 'grad_norm': 5.522864818572998, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 22:36:37.625 | {'loss': 0.243, 'grad_norm': 6.968977928161621, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 22:36:53.010 | {'loss': 0.2475, 'grad_norm': 14.150092124938965, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 22:37:15.249 | {'loss': 0.2215, 'grad_norm': 5.958489418029785, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 22:37:31.528 | {'loss': 0.1932, 'grad_norm': 2.934940814971924, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 22:37:46.993 | {'loss': 0.2034, 'grad_norm': 7.265561103820801, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 22:38:02.810 | {'loss': 0.1853, 'grad_norm': 10.08346939086914, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 22:38:18.445 | {'loss': 0.1826, 'grad_norm': 4.6065673828125, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 22:38:39.955 | {'loss': 0.1774, 'grad_norm': 3.2536869049072266, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 22:38:55.294 | {'loss': 0.2184, 'grad_norm': 7.586646556854248, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 22:39:10.505 | {'loss': 0.2372, 'grad_norm': 7.276091575622559, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 22:39:26.079 | {'loss': 0.2068, 'grad_norm': 6.085978031158447, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 22:39:47.568 | {'loss': 0.2023, 'grad_norm': 6.239464282989502, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 22:40:03.331 | {'loss': 0.1881, 'grad_norm': 5.5831475257873535, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 22:40:18.589 | {'loss': 0.2088, 'grad_norm': 5.999130725860596, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 22:40:34.246 | {'loss': 0.1378, 'grad_norm': 3.331146478652954, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 22:40:55.966 | {'loss': 0.1185, 'grad_norm': 1.4963335990905762, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 22:41:11.263 | {'loss': 0.1337, 'grad_norm': 5.706467151641846, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 22:41:26.418 | {'loss': 0.1579, 'grad_norm': 3.749246120452881, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 22:41:41.753 | {'loss': 0.1365, 'grad_norm': 3.601238489151001, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 22:41:57.405 | {'loss': 0.1405, 'grad_norm': 5.016132831573486, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 22:42:18.853 | {'loss': 0.1413, 'grad_norm': 5.282509803771973, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 22:42:34.592 | {'loss': 0.1372, 'grad_norm': 5.221503734588623, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 22:42:50.079 | {'loss': 0.1314, 'grad_norm': 6.170139312744141, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 22:43:12.281 | {'loss': 0.1312, 'grad_norm': 4.590770244598389, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 22:43:27.792 | {'loss': 0.1385, 'grad_norm': 5.808992385864258, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 22:43:43.186 | {'loss': 0.1615, 'grad_norm': 10.28671932220459, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 22:43:58.769 | {'loss': 0.1482, 'grad_norm': 4.562801361083984, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 22:44:14.094 | {'loss': 0.1313, 'grad_norm': 5.305761337280273, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 22:44:36.019 | {'loss': 0.1417, 'grad_norm': 4.485848426818848, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 22:44:51.580 | {'loss': 0.1297, 'grad_norm': 4.0528764724731445, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 22:45:06.598 | {'loss': 0.1474, 'grad_norm': 4.331335067749023, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 22:45:21.845 | {'loss': 0.1404, 'grad_norm': 4.90084171295166, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 22:45:37.657 | {'loss': 0.1367, 'grad_norm': 5.092239856719971, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 22:46:00.345 | {'loss': 0.1438, 'grad_norm': 2.159571886062622, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 22:46:15.484 | {'loss': 0.0767, 'grad_norm': 2.9908368587493896, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 22:46:30.582 | {'loss': 0.1074, 'grad_norm': 5.993854999542236, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 22:46:45.652 | {'loss': 0.1071, 'grad_norm': 3.572286367416382, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 22:47:01.032 | {'loss': 0.1138, 'grad_norm': 3.054184913635254, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 22:47:22.548 | {'loss': 0.1017, 'grad_norm': 3.9964234828948975, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 22:47:37.850 | {'loss': 0.0979, 'grad_norm': 3.6719486713409424, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 22:47:53.269 | {'loss': 0.0871, 'grad_norm': 3.4146015644073486, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 22:48:09.031 | {'loss': 0.0882, 'grad_norm': 2.435366630554199, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 22:48:31.271 | {'loss': 0.1258, 'grad_norm': 3.333278179168701, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 22:48:46.525 | {'loss': 0.0903, 'grad_norm': 2.4852547645568848, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 22:49:02.096 | {'loss': 0.0935, 'grad_norm': 1.258061408996582, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 22:49:17.442 | {'loss': 0.1018, 'grad_norm': 5.412498950958252, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 22:49:32.826 | {'loss': 0.0825, 'grad_norm': 2.5268983840942383, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-25 22:49:54.601 | {'loss': 0.1058, 'grad_norm': 3.515972137451172, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-25 22:50:09.841 | {'loss': 0.0913, 'grad_norm': 2.278639316558838, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-25 22:50:25.310 | {'loss': 0.089, 'grad_norm': 2.0361509323120117, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-25 22:50:40.446 | {'loss': 0.093, 'grad_norm': 3.265378713607788, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-25 22:51:02.651 | {'loss': 0.0837, 'grad_norm': 1.5876996517181396, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-25 22:51:17.816 | {'loss': 0.0913, 'grad_norm': 4.924502849578857, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-25 22:51:32.832 | {'loss': 0.1008, 'grad_norm': 4.4151506423950195, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-25 22:51:32.832 | {'train_runtime': 1691.0786, 'train_samples_per_second': 1.183, 'train_steps_per_second': 0.591, 'train_loss': 0.2193096400499344, 'epoch': 5.0}
2025-05-25 22:51:42.329 | INFO :      Sent reply
2025-05-25 22:57:51.662 | INFO :      
2025-05-25 22:57:51.662 | INFO :      Received: evaluate message 3bcd4082-031c-4709-acf2-80c1fef62f97
2025-05-25 22:58:03.953 | {'eval_loss': 3.326603412628174, 'eval_runtime': 9.5425, 'eval_samples_per_second': 10.479, 'eval_steps_per_second': 1.362, 'epoch': 5.0}
2025-05-25 22:58:03.954 | INFO :      Sent reply
2025-05-25 22:58:13.837 | INFO :      
2025-05-25 22:58:13.837 | INFO :      Received: train message 852be496-4cdd-4fea-9e7f-2ef72394dd85
2025-05-25 22:58:50.687 | {'loss': 0.1259, 'grad_norm': 4.225061893463135, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 22:59:13.125 | {'loss': 0.1743, 'grad_norm': 8.509647369384766, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 22:59:28.851 | {'loss': 0.2499, 'grad_norm': 6.1327338218688965, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 22:59:44.785 | {'loss': 0.2294, 'grad_norm': 6.655887603759766, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 23:00:07.066 | {'loss': 0.2543, 'grad_norm': 3.874995231628418, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 23:00:15.747 | {'loss': 0.2619, 'grad_norm': 5.854572296142578, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 23:00:38.000 | {'loss': 0.2716, 'grad_norm': 7.315432071685791, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 23:00:53.162 | {'loss': 0.2975, 'grad_norm': 6.088634967803955, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 23:01:08.401 | {'loss': 0.2517, 'grad_norm': 6.250545024871826, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 23:01:23.638 | {'loss': 0.2889, 'grad_norm': 8.71157169342041, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 23:01:39.186 | {'loss': 0.2524, 'grad_norm': 6.526175498962402, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 23:02:01.952 | {'loss': 0.3071, 'grad_norm': 8.435466766357422, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 23:02:17.335 | {'loss': 0.3054, 'grad_norm': 3.694969415664673, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 23:02:33.070 | {'loss': 0.3223, 'grad_norm': 7.209251403808594, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 23:02:48.541 | {'loss': 0.4044, 'grad_norm': 8.295769691467285, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 23:03:10.580 | {'loss': 0.3376, 'grad_norm': 6.347081184387207, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 23:03:25.803 | {'loss': 0.2719, 'grad_norm': 4.2786478996276855, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 23:03:41.002 | {'loss': 0.3027, 'grad_norm': 10.10761833190918, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 23:03:56.276 | {'loss': 0.3192, 'grad_norm': 9.135575294494629, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 23:04:18.588 | {'loss': 0.3322, 'grad_norm': 7.476381301879883, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 23:04:34.374 | {'loss': 0.2572, 'grad_norm': 11.540504455566406, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 23:04:50.092 | {'loss': 0.2895, 'grad_norm': 4.689356327056885, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 23:05:11.895 | {'loss': 0.2858, 'grad_norm': 6.529997825622559, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 23:05:27.130 | {'loss': 0.2484, 'grad_norm': 8.503927230834961, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 23:05:42.289 | {'loss': 0.3508, 'grad_norm': 7.855540752410889, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 23:06:03.889 | {'loss': 0.2773, 'grad_norm': 9.806528091430664, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 23:06:19.195 | {'loss': 0.3324, 'grad_norm': 10.498274803161621, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 23:06:34.402 | {'loss': 0.2758, 'grad_norm': 7.056614875793457, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 23:06:49.960 | {'loss': 0.2445, 'grad_norm': 7.659090042114258, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 23:07:12.447 | {'loss': 0.2785, 'grad_norm': 8.30178451538086, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 23:07:27.869 | {'loss': 0.2802, 'grad_norm': 10.480022430419922, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 23:07:49.827 | {'loss': 0.2275, 'grad_norm': 9.523002624511719, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 23:08:05.041 | {'loss': 0.2929, 'grad_norm': 7.955532073974609, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 23:08:20.089 | {'loss': 0.2344, 'grad_norm': 7.715770721435547, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 23:08:35.602 | {'loss': 0.2757, 'grad_norm': 9.397086143493652, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 23:08:57.483 | {'loss': 0.2535, 'grad_norm': 6.83249044418335, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 23:09:12.715 | {'loss': 0.2633, 'grad_norm': 5.490673065185547, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 23:09:28.232 | {'loss': 0.2677, 'grad_norm': 10.224188804626465, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 23:09:50.602 | {'loss': 0.2798, 'grad_norm': 8.337708473205566, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 23:10:06.242 | {'loss': 0.276, 'grad_norm': 7.789005756378174, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 23:10:21.492 | {'loss': 0.1776, 'grad_norm': 6.61985445022583, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 23:10:36.687 | {'loss': 0.1703, 'grad_norm': 3.8632423877716064, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 23:10:58.227 | {'loss': 0.2055, 'grad_norm': 6.964034557342529, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 23:11:13.804 | {'loss': 0.1853, 'grad_norm': 5.244894027709961, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 23:11:29.148 | {'loss': 0.2134, 'grad_norm': 6.874311447143555, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 23:11:44.549 | {'loss': 0.1647, 'grad_norm': 6.910312652587891, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 23:12:07.439 | {'loss': 0.2029, 'grad_norm': 6.991196155548096, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 23:12:23.184 | {'loss': 0.166, 'grad_norm': 4.485702037811279, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 23:12:38.845 | {'loss': 0.1978, 'grad_norm': 3.768087387084961, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 23:13:00.483 | {'loss': 0.1691, 'grad_norm': 2.968410015106201, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 23:13:15.845 | {'loss': 0.1935, 'grad_norm': 8.302668571472168, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 23:13:31.049 | {'loss': 0.1874, 'grad_norm': 7.461816310882568, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 23:13:46.531 | {'loss': 0.1948, 'grad_norm': 6.561600685119629, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 23:14:08.448 | {'loss': 0.1513, 'grad_norm': 4.409432888031006, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 23:14:23.766 | {'loss': 0.1908, 'grad_norm': 5.218496799468994, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 23:14:39.737 | {'loss': 0.1943, 'grad_norm': 6.017823219299316, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 23:14:55.409 | {'loss': 0.1606, 'grad_norm': 4.793613910675049, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 23:15:17.555 | {'loss': 0.1912, 'grad_norm': 4.785031795501709, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 23:15:32.875 | {'loss': 0.1751, 'grad_norm': 3.7324726581573486, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 23:15:48.110 | {'loss': 0.2026, 'grad_norm': 5.028772830963135, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 23:16:03.461 | {'loss': 0.1218, 'grad_norm': 3.685966968536377, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 23:16:19.060 | {'loss': 0.1165, 'grad_norm': 1.9972118139266968, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 23:16:34.075 | {'loss': 0.1308, 'grad_norm': 5.131117820739746, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 23:16:56.505 | {'loss': 0.121, 'grad_norm': 3.35154390335083, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 23:17:12.140 | {'loss': 0.1478, 'grad_norm': 6.7715067863464355, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 23:17:27.894 | {'loss': 0.1509, 'grad_norm': 4.313629627227783, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 23:17:43.322 | {'loss': 0.1421, 'grad_norm': 6.792481899261475, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 23:18:05.482 | {'loss': 0.1297, 'grad_norm': 3.133401870727539, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 23:18:21.188 | {'loss': 0.1353, 'grad_norm': 6.6404290199279785, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 23:18:36.350 | {'loss': 0.1343, 'grad_norm': 5.6338701248168945, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 23:18:51.844 | {'loss': 0.1364, 'grad_norm': 3.291289806365967, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 23:19:14.763 | {'loss': 0.1302, 'grad_norm': 4.0605268478393555, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 23:19:29.843 | {'loss': 0.1326, 'grad_norm': 4.99509859085083, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 23:19:45.102 | {'loss': 0.1172, 'grad_norm': 6.002798080444336, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 23:20:00.094 | {'loss': 0.1158, 'grad_norm': 2.673144578933716, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 23:20:15.550 | {'loss': 0.1312, 'grad_norm': 5.279611110687256, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 23:20:37.154 | {'loss': 0.1222, 'grad_norm': 2.731783390045166, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 23:20:52.355 | {'loss': 0.1133, 'grad_norm': 2.950892686843872, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 23:21:07.748 | {'loss': 0.1163, 'grad_norm': 4.037292003631592, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 23:21:30.304 | {'loss': 0.1228, 'grad_norm': 2.3019421100616455, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 23:21:46.170 | {'loss': 0.0733, 'grad_norm': 4.498379707336426, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 23:22:01.579 | {'loss': 0.0842, 'grad_norm': 1.5575906038284302, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 23:22:17.243 | {'loss': 0.0962, 'grad_norm': 3.6637604236602783, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 23:22:32.509 | {'loss': 0.0976, 'grad_norm': 1.9509865045547485, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 23:22:54.546 | {'loss': 0.0979, 'grad_norm': 2.3846137523651123, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 23:23:09.915 | {'loss': 0.0899, 'grad_norm': 2.2246711254119873, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 23:23:25.118 | {'loss': 0.0885, 'grad_norm': 2.5015151500701904, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 23:23:40.650 | {'loss': 0.0852, 'grad_norm': 2.541947841644287, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 23:24:02.652 | {'loss': 0.1001, 'grad_norm': 3.0061240196228027, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 23:24:18.230 | {'loss': 0.0877, 'grad_norm': 1.7270361185073853, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 23:24:34.324 | {'loss': 0.094, 'grad_norm': 3.169787883758545, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 23:24:50.256 | {'loss': 0.0915, 'grad_norm': 4.8923139572143555, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 23:25:05.815 | {'loss': 0.0801, 'grad_norm': 1.6475588083267212, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-25 23:25:27.637 | {'loss': 0.0909, 'grad_norm': 3.41365385055542, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-25 23:25:43.105 | {'loss': 0.0913, 'grad_norm': 2.5913262367248535, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-25 23:25:58.754 | {'loss': 0.0831, 'grad_norm': 1.7416067123413086, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-25 23:26:13.863 | {'loss': 0.0854, 'grad_norm': 3.0850260257720947, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-25 23:26:35.370 | {'loss': 0.0752, 'grad_norm': 1.669419527053833, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-25 23:26:51.081 | {'loss': 0.0891, 'grad_norm': 4.222702503204346, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-25 23:27:01.563 | {'loss': 0.0982, 'grad_norm': 5.771292209625244, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-25 23:27:01.563 | {'train_runtime': 1719.3333, 'train_samples_per_second': 1.163, 'train_steps_per_second': 0.582, 'train_loss': 0.1909374269247055, 'epoch': 5.0}
2025-05-25 23:27:08.866 | INFO :      Sent reply
2025-05-25 23:33:13.499 | INFO :      
2025-05-25 23:33:13.499 | INFO :      Received: evaluate message 697450ee-5636-4e52-9ffe-425324caffbc
2025-05-25 23:33:29.350 | {'eval_loss': 3.421067714691162, 'eval_runtime': 15.062, 'eval_samples_per_second': 6.639, 'eval_steps_per_second': 0.863, 'epoch': 5.0}
2025-05-25 23:33:29.351 | INFO :      Sent reply
2025-05-25 23:33:41.511 | INFO :      
2025-05-25 23:33:41.511 | INFO :      Received: train message bc5d52bb-c7cb-4bd5-a232-5567ac79640b
2025-05-25 23:34:13.257 | {'loss': 0.0988, 'grad_norm': 2.0523486137390137, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 23:34:35.109 | {'loss': 0.1354, 'grad_norm': 5.00162410736084, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 23:34:50.836 | {'loss': 0.1812, 'grad_norm': 5.489222049713135, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 23:35:06.387 | {'loss': 0.1726, 'grad_norm': 4.486795902252197, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 23:35:22.045 | {'loss': 0.1966, 'grad_norm': 5.9310784339904785, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 23:35:37.274 | {'loss': 0.2138, 'grad_norm': 5.493709087371826, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 23:35:59.186 | {'loss': 0.2024, 'grad_norm': 8.00833511352539, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 23:36:14.497 | {'loss': 0.2347, 'grad_norm': 4.973787784576416, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 23:36:29.615 | {'loss': 0.2114, 'grad_norm': 5.491031646728516, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 23:36:44.918 | {'loss': 0.2373, 'grad_norm': 7.43217134475708, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 23:37:00.134 | {'loss': 0.2171, 'grad_norm': 7.158513069152832, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 23:37:22.306 | {'loss': 0.2639, 'grad_norm': 6.39490270614624, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 23:37:37.820 | {'loss': 0.2391, 'grad_norm': 4.117897987365723, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 23:37:53.489 | {'loss': 0.2392, 'grad_norm': 4.541566848754883, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 23:38:08.575 | {'loss': 0.3237, 'grad_norm': 9.026602745056152, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 23:38:23.948 | {'loss': 0.2552, 'grad_norm': 5.004930019378662, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 23:38:45.606 | {'loss': 0.2586, 'grad_norm': 2.976181983947754, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 23:39:00.944 | {'loss': 0.2454, 'grad_norm': 8.283207893371582, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 23:39:16.336 | {'loss': 0.2519, 'grad_norm': 8.869548797607422, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 23:39:31.573 | {'loss': 0.2774, 'grad_norm': 7.209772109985352, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 23:39:46.993 | {'loss': 0.2476, 'grad_norm': 11.033327102661133, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 23:40:09.283 | {'loss': 0.2014, 'grad_norm': 9.517378807067871, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 23:40:24.961 | {'loss': 0.2477, 'grad_norm': 4.449483394622803, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 23:40:40.226 | {'loss': 0.2454, 'grad_norm': 8.172467231750488, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 23:40:55.406 | {'loss': 0.3172, 'grad_norm': 5.943309783935547, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 23:41:17.359 | {'loss': 0.2432, 'grad_norm': 8.882283210754395, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 23:41:32.384 | {'loss': 0.2835, 'grad_norm': 9.437829971313477, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 23:41:48.125 | {'loss': 0.2327, 'grad_norm': 5.4588541984558105, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 23:42:03.686 | {'loss': 0.2628, 'grad_norm': 8.367389678955078, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 23:42:25.330 | {'loss': 0.2673, 'grad_norm': 9.29454517364502, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 23:42:40.839 | {'loss': 0.2569, 'grad_norm': 7.018933296203613, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 23:42:56.432 | {'loss': 0.2141, 'grad_norm': 8.06109619140625, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 23:43:11.709 | {'loss': 0.2447, 'grad_norm': 8.52304458618164, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 23:43:26.969 | {'loss': 0.2672, 'grad_norm': 7.031817436218262, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 23:43:48.962 | {'loss': 0.2778, 'grad_norm': 8.115304946899414, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 23:44:04.273 | {'loss': 0.2478, 'grad_norm': 7.5645222663879395, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 23:44:19.992 | {'loss': 0.2544, 'grad_norm': 10.108518600463867, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 23:44:35.292 | {'loss': 0.2169, 'grad_norm': 8.688323020935059, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 23:44:50.960 | {'loss': 0.2259, 'grad_norm': 9.340168952941895, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 23:45:13.510 | {'loss': 0.2493, 'grad_norm': 7.844566345214844, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 23:45:29.377 | {'loss': 0.1681, 'grad_norm': 4.190213680267334, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 23:45:45.201 | {'loss': 0.1827, 'grad_norm': 5.807199478149414, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 23:46:00.631 | {'loss': 0.1865, 'grad_norm': 4.500066757202148, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 23:46:16.153 | {'loss': 0.1434, 'grad_norm': 6.747025966644287, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 23:46:37.646 | {'loss': 0.2224, 'grad_norm': 4.782276153564453, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 23:46:53.268 | {'loss': 0.1865, 'grad_norm': 5.565217018127441, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 23:47:08.273 | {'loss': 0.191, 'grad_norm': 7.435821056365967, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 23:47:23.646 | {'loss': 0.1469, 'grad_norm': 4.438750743865967, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 23:47:46.103 | {'loss': 0.1777, 'grad_norm': 4.062576770782471, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 23:48:01.743 | {'loss': 0.154, 'grad_norm': 3.8305368423461914, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 23:48:17.564 | {'loss': 0.1688, 'grad_norm': 6.694766521453857, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 23:48:32.477 | {'loss': 0.1627, 'grad_norm': 6.337182521820068, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 23:48:47.895 | {'loss': 0.1832, 'grad_norm': 8.188739776611328, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 23:49:09.057 | {'loss': 0.1425, 'grad_norm': 4.857086181640625, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 23:49:24.290 | {'loss': 0.1805, 'grad_norm': 8.023245811462402, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 23:49:39.419 | {'loss': 0.1772, 'grad_norm': 7.114301681518555, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 23:49:55.142 | {'loss': 0.1605, 'grad_norm': 6.961852550506592, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 23:50:17.468 | {'loss': 0.1606, 'grad_norm': 5.997636795043945, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 23:50:33.319 | {'loss': 0.1616, 'grad_norm': 5.050100803375244, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 23:50:48.665 | {'loss': 0.1593, 'grad_norm': 4.483290195465088, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 23:51:03.598 | {'loss': 0.1064, 'grad_norm': 4.420637130737305, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 23:51:25.851 | {'loss': 0.1098, 'grad_norm': 2.2690770626068115, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 23:51:40.811 | {'loss': 0.116, 'grad_norm': 4.4176249504089355, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 23:51:56.058 | {'loss': 0.1119, 'grad_norm': 4.792508125305176, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 23:52:11.256 | {'loss': 0.1324, 'grad_norm': 3.896721601486206, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 23:52:33.201 | {'loss': 0.133, 'grad_norm': 3.579857349395752, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 23:52:48.593 | {'loss': 0.1127, 'grad_norm': 4.918395519256592, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 23:53:04.269 | {'loss': 0.1166, 'grad_norm': 5.178957462310791, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 23:53:19.562 | {'loss': 0.1108, 'grad_norm': 4.9013261795043945, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 23:53:34.565 | {'loss': 0.1122, 'grad_norm': 3.2470998764038086, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 23:53:49.649 | {'loss': 0.1143, 'grad_norm': 3.241273880004883, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 23:54:11.136 | {'loss': 0.1252, 'grad_norm': 7.819048881530762, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 23:54:26.493 | {'loss': 0.1195, 'grad_norm': 3.1600899696350098, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 23:54:41.678 | {'loss': 0.1236, 'grad_norm': 6.050027370452881, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 23:54:57.180 | {'loss': 0.1171, 'grad_norm': 3.6422924995422363, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 23:55:19.697 | {'loss': 0.1169, 'grad_norm': 5.0712432861328125, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 23:55:35.446 | {'loss': 0.1283, 'grad_norm': 3.1981544494628906, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 23:55:51.162 | {'loss': 0.12, 'grad_norm': 3.612677574157715, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 23:56:06.398 | {'loss': 0.1106, 'grad_norm': 2.6620101928710938, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 23:56:21.876 | {'loss': 0.1236, 'grad_norm': 4.020793437957764, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 23:56:43.868 | {'loss': 0.065, 'grad_norm': 2.0225672721862793, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 23:56:59.001 | {'loss': 0.081, 'grad_norm': 2.1968352794647217, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 23:57:14.312 | {'loss': 0.0948, 'grad_norm': 3.1723718643188477, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 23:57:29.439 | {'loss': 0.0809, 'grad_norm': 1.9872173070907593, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 23:57:51.831 | {'loss': 0.0851, 'grad_norm': 3.528662919998169, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 23:58:07.663 | {'loss': 0.0819, 'grad_norm': 2.0167036056518555, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 23:58:23.419 | {'loss': 0.0808, 'grad_norm': 1.8233401775360107, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 23:58:38.862 | {'loss': 0.0774, 'grad_norm': 2.6269195079803467, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 23:58:54.235 | {'loss': 0.0967, 'grad_norm': 1.9541406631469727, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 23:59:09.454 | {'loss': 0.0903, 'grad_norm': 3.6855874061584473, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 23:59:31.388 | {'loss': 0.0823, 'grad_norm': 2.9639248847961426, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 23:59:47.108 | {'loss': 0.0921, 'grad_norm': 2.290127992630005, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-26 00:00:02.189 | {'loss': 0.0757, 'grad_norm': 1.3641616106033325, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-26 00:00:18.655 | {'loss': 0.0841, 'grad_norm': 1.5514203310012817, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-26 00:00:40.812 | {'loss': 0.0845, 'grad_norm': 1.8317201137542725, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-26 00:00:56.599 | {'loss': 0.0751, 'grad_norm': 1.492514729499817, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-26 00:01:12.216 | {'loss': 0.0896, 'grad_norm': 3.856529951095581, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-26 00:01:27.735 | {'loss': 0.0781, 'grad_norm': 2.313652992248535, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-26 00:01:43.071 | {'loss': 0.0859, 'grad_norm': 3.3264381885528564, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-26 00:02:04.559 | {'loss': 0.0897, 'grad_norm': 5.445253849029541, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-26 00:02:04.559 | {'train_runtime': 1699.6844, 'train_samples_per_second': 1.177, 'train_steps_per_second': 0.588, 'train_loss': 0.16907321226596833, 'epoch': 5.0}
2025-05-26 00:02:09.961 | INFO :      Sent reply
2025-05-26 00:08:34.227 | INFO :      
2025-05-26 00:08:34.227 | INFO :      Received: evaluate message 0723c4e6-7d08-4f41-8e72-53b64640c659
2025-05-26 00:08:54.443 | {'eval_loss': 3.492521286010742, 'eval_runtime': 11.5882, 'eval_samples_per_second': 8.629, 'eval_steps_per_second': 1.122, 'epoch': 5.0}
2025-05-26 00:08:54.448 | INFO :      Sent reply
2025-05-26 00:09:08.086 | INFO :      
2025-05-26 00:09:08.086 | INFO :      Received: train message ff222038-84ca-42df-b8bf-f51878af8036
2025-05-26 00:09:38.398 | {'loss': 0.0907, 'grad_norm': 1.9369533061981201, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-26 00:09:53.639 | {'loss': 0.1081, 'grad_norm': 3.5530357360839844, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-26 00:10:15.418 | {'loss': 0.1632, 'grad_norm': 4.9683051109313965, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-26 00:10:30.771 | {'loss': 0.1747, 'grad_norm': 5.689957141876221, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-26 00:10:46.054 | {'loss': 0.1757, 'grad_norm': 3.613438844680786, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-26 00:11:01.689 | {'loss': 0.1905, 'grad_norm': 4.7304205894470215, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-26 00:11:16.883 | {'loss': 0.1865, 'grad_norm': 5.507757663726807, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-26 00:11:38.860 | {'loss': 0.2132, 'grad_norm': 5.658079624176025, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-26 00:11:54.130 | {'loss': 0.1763, 'grad_norm': 5.556722640991211, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-26 00:12:09.242 | {'loss': 0.1809, 'grad_norm': 6.5448832511901855, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-26 00:12:24.694 | {'loss': 0.1884, 'grad_norm': 5.113792419433594, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-26 00:12:39.796 | {'loss': 0.22, 'grad_norm': 4.741762638092041, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-26 00:13:01.522 | {'loss': 0.2266, 'grad_norm': 5.993758678436279, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-26 00:13:16.586 | {'loss': 0.2348, 'grad_norm': 4.711713790893555, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-26 00:13:32.215 | {'loss': 0.2534, 'grad_norm': 8.72340202331543, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-26 00:13:47.406 | {'loss': 0.2409, 'grad_norm': 7.764150619506836, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-26 00:14:03.146 | {'loss': 0.2168, 'grad_norm': 2.763737201690674, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-26 00:14:18.806 | {'loss': 0.2336, 'grad_norm': 8.841673851013184, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-26 00:14:40.505 | {'loss': 0.2087, 'grad_norm': 9.037991523742676, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-26 00:14:55.662 | {'loss': 0.2174, 'grad_norm': 5.209321022033691, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-26 00:15:10.885 | {'loss': 0.176, 'grad_norm': 10.625127792358398, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-26 00:15:26.168 | {'loss': 0.2105, 'grad_norm': 5.904119968414307, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-26 00:15:40.911 | {'loss': 0.2556, 'grad_norm': 8.063220977783203, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-26 00:16:02.411 | {'loss': 0.1823, 'grad_norm': 7.259786128997803, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-26 00:16:17.726 | {'loss': 0.2637, 'grad_norm': 5.46955680847168, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-26 00:16:32.798 | {'loss': 0.2312, 'grad_norm': 7.071024417877197, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-26 00:16:47.847 | {'loss': 0.2318, 'grad_norm': 9.06020450592041, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-26 00:17:03.266 | {'loss': 0.1778, 'grad_norm': 5.737059593200684, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-26 00:17:18.282 | {'loss': 0.2294, 'grad_norm': 5.276327133178711, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-26 00:17:39.707 | {'loss': 0.2226, 'grad_norm': 10.10853099822998, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-26 00:17:54.841 | {'loss': 0.2212, 'grad_norm': 6.300893783569336, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-26 00:18:10.055 | {'loss': 0.2081, 'grad_norm': 10.201565742492676, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-26 00:18:25.563 | {'loss': 0.2338, 'grad_norm': 9.729883193969727, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-26 00:18:46.607 | {'loss': 0.2526, 'grad_norm': 11.957706451416016, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-26 00:19:01.737 | {'loss': 0.223, 'grad_norm': 6.922260284423828, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-26 00:19:16.646 | {'loss': 0.2116, 'grad_norm': 4.5701727867126465, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-26 00:19:32.187 | {'loss': 0.2182, 'grad_norm': 4.36959171295166, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-26 00:19:47.345 | {'loss': 0.1894, 'grad_norm': 7.061163425445557, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-26 00:20:09.042 | {'loss': 0.1994, 'grad_norm': 6.866081237792969, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-26 00:20:24.030 | {'loss': 0.2468, 'grad_norm': 6.1003546714782715, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-26 00:20:39.028 | {'loss': 0.1616, 'grad_norm': 4.847840309143066, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-26 00:20:54.179 | {'loss': 0.1459, 'grad_norm': 3.5054824352264404, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-26 00:21:09.469 | {'loss': 0.1509, 'grad_norm': 5.586312770843506, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-26 00:21:31.390 | {'loss': 0.1409, 'grad_norm': 5.745387077331543, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-26 00:21:46.618 | {'loss': 0.2077, 'grad_norm': 9.664434432983398, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-26 00:22:02.170 | {'loss': 0.17, 'grad_norm': 5.7503743171691895, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-26 00:22:17.114 | {'loss': 0.2077, 'grad_norm': 16.546873092651367, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-26 00:22:32.465 | {'loss': 0.1559, 'grad_norm': 5.7523627281188965, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-26 00:22:54.161 | {'loss': 0.1602, 'grad_norm': 5.1515679359436035, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-26 00:23:09.353 | {'loss': 0.1616, 'grad_norm': 6.521677494049072, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-26 00:23:24.589 | {'loss': 0.1483, 'grad_norm': 5.1304473876953125, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-26 00:23:40.479 | {'loss': 0.1618, 'grad_norm': 6.676943778991699, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-26 00:24:02.019 | {'loss': 0.1491, 'grad_norm': 6.7491960525512695, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-26 00:24:17.547 | {'loss': 0.1325, 'grad_norm': 4.798628807067871, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-26 00:24:33.227 | {'loss': 0.1406, 'grad_norm': 6.4663519859313965, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-26 00:24:47.896 | {'loss': 0.1668, 'grad_norm': 4.326387405395508, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-26 00:25:09.491 | {'loss': 0.1683, 'grad_norm': 5.734415054321289, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-26 00:25:24.538 | {'loss': 0.1591, 'grad_norm': 5.124875545501709, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-26 00:25:39.855 | {'loss': 0.1563, 'grad_norm': 4.838158130645752, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-26 00:25:55.188 | {'loss': 0.1574, 'grad_norm': 3.9730446338653564, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-26 00:26:16.803 | {'loss': 0.1134, 'grad_norm': 2.9662954807281494, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-26 00:26:32.138 | {'loss': 0.0924, 'grad_norm': 2.031097888946533, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-26 00:26:46.943 | {'loss': 0.108, 'grad_norm': 4.156938552856445, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-26 00:27:02.657 | {'loss': 0.1151, 'grad_norm': 4.277902603149414, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-26 00:27:24.051 | {'loss': 0.1028, 'grad_norm': 2.250661849975586, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-26 00:27:39.448 | {'loss': 0.1295, 'grad_norm': 5.477045059204102, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-26 00:27:54.683 | {'loss': 0.1114, 'grad_norm': 4.377880096435547, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-26 00:28:09.711 | {'loss': 0.1176, 'grad_norm': 3.6778180599212646, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-26 00:28:31.610 | {'loss': 0.1076, 'grad_norm': 4.824430465698242, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-26 00:28:46.941 | {'loss': 0.116, 'grad_norm': 2.6261448860168457, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-26 00:29:02.376 | {'loss': 0.1179, 'grad_norm': 3.745558500289917, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-26 00:29:17.684 | {'loss': 0.1196, 'grad_norm': 2.57539963722229, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-26 00:29:39.310 | {'loss': 0.1047, 'grad_norm': 2.975557565689087, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-26 00:29:54.458 | {'loss': 0.1164, 'grad_norm': 5.514632225036621, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-26 00:30:09.882 | {'loss': 0.1117, 'grad_norm': 3.0869295597076416, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-26 00:30:31.989 | {'loss': 0.1032, 'grad_norm': 3.756497383117676, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-26 00:30:47.917 | {'loss': 0.1052, 'grad_norm': 4.013056755065918, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-26 00:31:03.246 | {'loss': 0.1194, 'grad_norm': 3.626868724822998, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-26 00:31:24.890 | {'loss': 0.1261, 'grad_norm': 3.9482972621917725, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-26 00:31:40.052 | {'loss': 0.1035, 'grad_norm': 1.746956706047058, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-26 00:32:01.930 | {'loss': 0.0678, 'grad_norm': 1.9813159704208374, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-26 00:32:17.088 | {'loss': 0.089, 'grad_norm': 2.983736753463745, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-26 00:32:32.830 | {'loss': 0.0805, 'grad_norm': 4.444429397583008, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-26 00:32:54.768 | {'loss': 0.0857, 'grad_norm': 2.2733049392700195, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-26 00:33:10.489 | {'loss': 0.0813, 'grad_norm': 2.4245431423187256, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-26 00:33:26.016 | {'loss': 0.085, 'grad_norm': 1.8325966596603394, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-26 00:33:47.501 | {'loss': 0.0746, 'grad_norm': 1.626827359199524, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-26 00:34:02.980 | {'loss': 0.0787, 'grad_norm': 1.777675986289978, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-26 00:34:18.165 | {'loss': 0.0961, 'grad_norm': 1.954580307006836, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-26 00:34:39.698 | {'loss': 0.0788, 'grad_norm': 1.2352967262268066, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-26 00:34:55.084 | {'loss': 0.0791, 'grad_norm': 2.0186102390289307, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-26 00:35:10.500 | {'loss': 0.0861, 'grad_norm': 4.747941017150879, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-26 00:35:32.601 | {'loss': 0.0759, 'grad_norm': 1.7342655658721924, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-26 00:35:47.579 | {'loss': 0.0842, 'grad_norm': 2.104586362838745, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-26 00:36:02.885 | {'loss': 0.079, 'grad_norm': 0.9804255962371826, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-26 00:36:24.490 | {'loss': 0.0735, 'grad_norm': 1.468213677406311, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-26 00:36:39.639 | {'loss': 0.0805, 'grad_norm': 2.939347267150879, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-26 00:36:54.806 | {'loss': 0.0707, 'grad_norm': 1.6392426490783691, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-26 00:37:10.174 | {'loss': 0.0834, 'grad_norm': 5.419816017150879, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-26 00:37:25.004 | {'loss': 0.0832, 'grad_norm': 2.035677194595337, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-26 00:37:25.004 | {'train_runtime': 1692.6714, 'train_samples_per_second': 1.182, 'train_steps_per_second': 0.591, 'train_loss': 0.15343280464410783, 'epoch': 5.0}
2025-05-26 00:37:31.941 | INFO :      Sent reply
2025-05-26 00:43:52.862 | INFO :      
2025-05-26 00:43:52.862 | INFO :      Received: evaluate message 4a04e8f9-16a1-4b31-9886-e9eeb91ea2ff
2025-05-26 00:44:02.361 | {'eval_loss': 3.5605809688568115, 'eval_runtime': 3.4993, 'eval_samples_per_second': 28.577, 'eval_steps_per_second': 3.715, 'epoch': 5.0}
2025-05-26 00:44:02.362 | INFO :      Sent reply
2025-05-26 00:44:12.088 | INFO :      
2025-05-26 00:44:12.088 | INFO :      Received: train message 8741eec3-47c0-47c5-960a-c053179b02f6
2025-05-26 00:44:51.466 | {'loss': 0.0835, 'grad_norm': 1.486588954925537, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-26 00:45:07.259 | {'loss': 0.109, 'grad_norm': 4.569185733795166, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-26 00:45:22.587 | {'loss': 0.1359, 'grad_norm': 3.7376179695129395, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-26 00:45:44.847 | {'loss': 0.1694, 'grad_norm': 3.8938920497894287, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-26 00:46:00.575 | {'loss': 0.1558, 'grad_norm': 3.250427722930908, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-26 00:46:15.825 | {'loss': 0.1675, 'grad_norm': 3.9703783988952637, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-26 00:46:30.869 | {'loss': 0.1601, 'grad_norm': 5.492616176605225, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-26 00:46:46.070 | {'loss': 0.1809, 'grad_norm': 5.58095121383667, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-26 00:47:07.732 | {'loss': 0.1536, 'grad_norm': 2.4662692546844482, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-26 00:47:22.751 | {'loss': 0.193, 'grad_norm': 7.369478225708008, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-26 00:47:38.004 | {'loss': 0.1693, 'grad_norm': 4.584400653839111, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-26 00:47:53.086 | {'loss': 0.176, 'grad_norm': 4.422897815704346, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-26 00:48:08.511 | {'loss': 0.1973, 'grad_norm': 3.4643659591674805, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-26 00:48:30.701 | {'loss': 0.2014, 'grad_norm': 4.6014275550842285, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-26 00:48:46.163 | {'loss': 0.2531, 'grad_norm': 8.371173858642578, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-26 00:49:01.541 | {'loss': 0.2059, 'grad_norm': 5.005345344543457, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-26 00:49:16.734 | {'loss': 0.1867, 'grad_norm': 2.2124905586242676, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-26 00:49:38.064 | {'loss': 0.1964, 'grad_norm': 10.435376167297363, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-26 00:49:53.082 | {'loss': 0.198, 'grad_norm': 7.975613117218018, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-26 00:50:08.359 | {'loss': 0.2153, 'grad_norm': 4.958076000213623, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-26 00:50:23.437 | {'loss': 0.2202, 'grad_norm': 11.677445411682129, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-26 00:50:38.794 | {'loss': 0.214, 'grad_norm': 5.013073921203613, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-26 00:51:00.640 | {'loss': 0.2105, 'grad_norm': 4.8954758644104, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-26 00:51:15.933 | {'loss': 0.1762, 'grad_norm': 7.005375385284424, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-26 00:51:31.232 | {'loss': 0.2374, 'grad_norm': 5.943019866943359, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-26 00:51:46.570 | {'loss': 0.1858, 'grad_norm': 7.3987884521484375, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-26 00:52:01.982 | {'loss': 0.225, 'grad_norm': 9.639525413513184, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-26 00:52:23.815 | {'loss': 0.2173, 'grad_norm': 6.900008201599121, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-26 00:52:39.186 | {'loss': 0.1988, 'grad_norm': 5.256438732147217, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-26 00:52:54.379 | {'loss': 0.2211, 'grad_norm': 11.09615707397461, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-26 00:53:09.687 | {'loss': 0.2172, 'grad_norm': 9.327388763427734, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-26 00:53:24.692 | {'loss': 0.1651, 'grad_norm': 5.421176910400391, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-26 00:53:39.916 | {'loss': 0.2083, 'grad_norm': 6.805118083953857, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-26 00:54:01.851 | {'loss': 0.1777, 'grad_norm': 5.392916679382324, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-26 00:54:17.044 | {'loss': 0.2248, 'grad_norm': 8.261367797851562, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-26 00:54:32.275 | {'loss': 0.2087, 'grad_norm': 5.586009979248047, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-26 00:54:47.173 | {'loss': 0.1946, 'grad_norm': 6.3005547523498535, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-26 00:55:09.126 | {'loss': 0.1925, 'grad_norm': 7.299716472625732, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-26 00:55:24.341 | {'loss': 0.2492, 'grad_norm': 7.462735176086426, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-26 00:55:40.107 | {'loss': 0.233, 'grad_norm': 9.190566062927246, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-26 00:55:55.313 | {'loss': 0.1488, 'grad_norm': 5.153168678283691, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-26 00:56:17.361 | {'loss': 0.1144, 'grad_norm': 3.4482908248901367, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-26 00:56:32.552 | {'loss': 0.1489, 'grad_norm': 5.421855449676514, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-26 00:56:47.924 | {'loss': 0.1291, 'grad_norm': 4.911648750305176, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-26 00:57:03.262 | {'loss': 0.1742, 'grad_norm': 6.734434604644775, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-26 00:57:18.053 | {'loss': 0.1589, 'grad_norm': 4.039028167724609, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-26 00:57:33.084 | {'loss': 0.1509, 'grad_norm': 6.987247943878174, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-26 00:57:54.400 | {'loss': 0.1538, 'grad_norm': 5.523092746734619, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-26 00:58:09.723 | {'loss': 0.1734, 'grad_norm': 5.292768478393555, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-26 00:58:24.707 | {'loss': 0.1435, 'grad_norm': 4.521132946014404, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-26 00:58:40.260 | {'loss': 0.14, 'grad_norm': 3.846116065979004, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-26 00:58:55.591 | {'loss': 0.151, 'grad_norm': 4.326113224029541, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-26 00:59:16.967 | {'loss': 0.1336, 'grad_norm': 2.3995471000671387, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-26 00:59:32.060 | {'loss': 0.1184, 'grad_norm': 3.275743246078491, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-26 00:59:47.053 | {'loss': 0.1451, 'grad_norm': 5.5947418212890625, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-26 01:00:02.235 | {'loss': 0.1597, 'grad_norm': 5.5830183029174805, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-26 01:00:24.053 | {'loss': 0.1429, 'grad_norm': 4.594004154205322, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-26 01:00:39.699 | {'loss': 0.1404, 'grad_norm': 4.459107398986816, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-26 01:00:55.299 | {'loss': 0.1438, 'grad_norm': 4.494245529174805, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-26 01:01:10.804 | {'loss': 0.151, 'grad_norm': 3.0995867252349854, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-26 01:01:26.110 | {'loss': 0.0977, 'grad_norm': 2.494246482849121, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-26 01:01:47.724 | {'loss': 0.0882, 'grad_norm': 0.929652214050293, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-26 01:02:02.770 | {'loss': 0.0921, 'grad_norm': 2.776322841644287, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-26 01:02:17.715 | {'loss': 0.1056, 'grad_norm': 3.1832985877990723, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-26 01:02:33.077 | {'loss': 0.1035, 'grad_norm': 3.6325292587280273, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-26 01:02:55.494 | {'loss': 0.127, 'grad_norm': 4.015695095062256, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-26 01:03:10.644 | {'loss': 0.1103, 'grad_norm': 4.394143581390381, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-26 01:03:25.715 | {'loss': 0.104, 'grad_norm': 3.976552724838257, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-26 01:03:40.780 | {'loss': 0.0983, 'grad_norm': 4.786581993103027, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-26 01:03:55.891 | {'loss': 0.1024, 'grad_norm': 2.6947152614593506, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-26 01:04:17.268 | {'loss': 0.1076, 'grad_norm': 5.243471145629883, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-26 01:04:32.524 | {'loss': 0.121, 'grad_norm': 3.1088693141937256, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-26 01:04:47.765 | {'loss': 0.1053, 'grad_norm': 2.032914400100708, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-26 01:05:03.607 | {'loss': 0.106, 'grad_norm': 5.533203601837158, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-26 01:05:19.057 | {'loss': 0.1184, 'grad_norm': 2.271542549133301, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-26 01:05:40.956 | {'loss': 0.1032, 'grad_norm': 2.9746086597442627, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-26 01:05:55.924 | {'loss': 0.1184, 'grad_norm': 3.9154860973358154, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-26 01:06:11.237 | {'loss': 0.0948, 'grad_norm': 2.6985363960266113, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-26 01:06:25.953 | {'loss': 0.1023, 'grad_norm': 3.4875035285949707, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-26 01:06:40.883 | {'loss': 0.1028, 'grad_norm': 1.64411199092865, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-26 01:07:02.658 | {'loss': 0.0755, 'grad_norm': 1.459165334701538, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-26 01:07:18.002 | {'loss': 0.0808, 'grad_norm': 1.8610564470291138, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-26 01:07:33.512 | {'loss': 0.0881, 'grad_norm': 2.9136741161346436, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-26 01:07:48.727 | {'loss': 0.078, 'grad_norm': 3.9258177280426025, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-26 01:08:10.293 | {'loss': 0.0758, 'grad_norm': 2.0514135360717773, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-26 01:08:25.316 | {'loss': 0.0779, 'grad_norm': 3.616746187210083, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-26 01:08:40.619 | {'loss': 0.0785, 'grad_norm': 1.504254937171936, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-26 01:08:55.717 | {'loss': 0.0768, 'grad_norm': 1.5700868368148804, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-26 01:09:11.064 | {'loss': 0.0873, 'grad_norm': 2.585878610610962, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-26 01:09:33.037 | {'loss': 0.0703, 'grad_norm': 1.2581603527069092, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-26 01:09:48.655 | {'loss': 0.0772, 'grad_norm': 1.0644798278808594, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-26 01:10:04.196 | {'loss': 0.0784, 'grad_norm': 3.1452698707580566, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-26 01:10:19.507 | {'loss': 0.0733, 'grad_norm': 1.1703864336013794, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-26 01:10:34.753 | {'loss': 0.0715, 'grad_norm': 1.9709041118621826, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-26 01:10:49.790 | {'loss': 0.0705, 'grad_norm': 1.1977081298828125, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-26 01:11:11.690 | {'loss': 0.0753, 'grad_norm': 1.0350751876831055, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-26 01:11:26.750 | {'loss': 0.0754, 'grad_norm': 1.8874914646148682, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-26 01:11:42.109 | {'loss': 0.0637, 'grad_norm': 1.0743438005447388, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-26 01:11:57.831 | {'loss': 0.0742, 'grad_norm': 3.0789084434509277, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-26 01:12:12.511 | {'loss': 0.0863, 'grad_norm': 3.355208396911621, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-26 01:12:12.511 | {'train_runtime': 1675.1982, 'train_samples_per_second': 1.194, 'train_steps_per_second': 0.597, 'train_loss': 0.14251064443588257, 'epoch': 5.0}
2025-05-26 01:12:20.875 | INFO :      Sent reply
2025-05-26 01:18:33.261 | INFO :      
2025-05-26 01:18:33.261 | INFO :      Received: evaluate message a05abee8-98f8-4efa-9bee-0ba7dd4ff365
2025-05-26 01:18:50.465 | {'eval_loss': 3.654120445251465, 'eval_runtime': 13.2613, 'eval_samples_per_second': 7.541, 'eval_steps_per_second': 0.98, 'epoch': 5.0}
2025-05-26 01:18:50.467 | INFO :      Sent reply
2025-05-26 01:19:02.162 | INFO :      
2025-05-26 01:19:02.162 | INFO :      Received: train message 69c17dd4-364d-46da-8558-28530e4fd0e1
2025-05-26 01:19:25.785 | {'loss': 0.081, 'grad_norm': 1.2810057401657104, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-26 01:19:41.542 | {'loss': 0.1042, 'grad_norm': 2.221240520477295, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-26 01:20:04.438 | {'loss': 0.1266, 'grad_norm': 2.2744786739349365, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-26 01:20:20.011 | {'loss': 0.1466, 'grad_norm': 3.8436357975006104, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-26 01:20:35.283 | {'loss': 0.1556, 'grad_norm': 3.377673387527466, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-26 01:20:50.420 | {'loss': 0.141, 'grad_norm': 4.605184078216553, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-26 01:21:05.561 | {'loss': 0.1551, 'grad_norm': 3.6704022884368896, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-26 01:21:27.349 | {'loss': 0.1583, 'grad_norm': 5.864328384399414, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-26 01:21:42.246 | {'loss': 0.1285, 'grad_norm': 4.924289226531982, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-26 01:21:57.247 | {'loss': 0.1635, 'grad_norm': 3.9847452640533447, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-26 01:22:12.664 | {'loss': 0.1748, 'grad_norm': 2.690744400024414, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-26 01:22:27.893 | {'loss': 0.1604, 'grad_norm': 4.712395191192627, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-26 01:22:49.907 | {'loss': 0.1726, 'grad_norm': 2.6167023181915283, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-26 01:23:05.058 | {'loss': 0.1911, 'grad_norm': 3.1290643215179443, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-26 01:23:20.222 | {'loss': 0.2369, 'grad_norm': 6.005516529083252, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-26 01:23:35.414 | {'loss': 0.1924, 'grad_norm': 4.182438373565674, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-26 01:23:56.991 | {'loss': 0.1722, 'grad_norm': 2.7348461151123047, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-26 01:24:12.227 | {'loss': 0.1628, 'grad_norm': 6.430224895477295, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-26 01:24:27.347 | {'loss': 0.164, 'grad_norm': 5.804760456085205, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-26 01:24:42.928 | {'loss': 0.1741, 'grad_norm': 5.1921706199646, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-26 01:24:58.393 | {'loss': 0.1823, 'grad_norm': 8.036863327026367, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-26 01:25:20.208 | {'loss': 0.2269, 'grad_norm': 6.4811224937438965, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-26 01:25:35.275 | {'loss': 0.2034, 'grad_norm': 5.194362640380859, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-26 01:25:50.374 | {'loss': 0.2083, 'grad_norm': 7.888051986694336, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-26 01:26:05.574 | {'loss': 0.205, 'grad_norm': 4.855015277862549, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-26 01:26:20.802 | {'loss': 0.158, 'grad_norm': 7.476113319396973, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-26 01:26:36.312 | {'loss': 0.2022, 'grad_norm': 7.993338108062744, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-26 01:26:57.749 | {'loss': 0.1596, 'grad_norm': 7.636391639709473, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-26 01:27:13.736 | {'loss': 0.1872, 'grad_norm': 5.347856044769287, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-26 01:27:28.753 | {'loss': 0.1904, 'grad_norm': 7.717362880706787, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-26 01:27:43.985 | {'loss': 0.1705, 'grad_norm': 5.021096706390381, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-26 01:28:05.511 | {'loss': 0.182, 'grad_norm': 7.201371192932129, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-26 01:28:20.342 | {'loss': 0.1901, 'grad_norm': 7.954607963562012, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-26 01:28:35.322 | {'loss': 0.1677, 'grad_norm': 6.0227179527282715, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-26 01:28:50.285 | {'loss': 0.1893, 'grad_norm': 4.964161396026611, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-26 01:29:11.986 | {'loss': 0.2058, 'grad_norm': 5.197997570037842, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-26 01:29:27.201 | {'loss': 0.1904, 'grad_norm': 11.860197067260742, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-26 01:29:42.745 | {'loss': 0.1679, 'grad_norm': 6.610182285308838, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-26 01:29:57.920 | {'loss': 0.2217, 'grad_norm': 7.399792194366455, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-26 01:30:19.434 | {'loss': 0.1959, 'grad_norm': 7.973104953765869, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-26 01:30:34.589 | {'loss': 0.1584, 'grad_norm': 5.47389030456543, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-26 01:30:49.742 | {'loss': 0.1135, 'grad_norm': 3.029655694961548, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-26 01:31:04.862 | {'loss': 0.152, 'grad_norm': 7.529514312744141, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-26 01:31:19.981 | {'loss': 0.1398, 'grad_norm': 5.005418300628662, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-26 01:31:41.548 | {'loss': 0.1525, 'grad_norm': 3.5873637199401855, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-26 01:31:56.706 | {'loss': 0.145, 'grad_norm': 3.409156560897827, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-26 01:32:12.173 | {'loss': 0.1396, 'grad_norm': 8.035770416259766, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-26 01:32:27.539 | {'loss': 0.1729, 'grad_norm': 7.5906982421875, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-26 01:32:42.810 | {'loss': 0.1731, 'grad_norm': 3.190063238143921, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-26 01:33:04.368 | {'loss': 0.1278, 'grad_norm': 2.477775812149048, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-26 01:33:19.481 | {'loss': 0.1647, 'grad_norm': 9.645877838134766, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-26 01:33:34.689 | {'loss': 0.1436, 'grad_norm': 4.951173782348633, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-26 01:33:49.838 | {'loss': 0.1405, 'grad_norm': 3.8000075817108154, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-26 01:34:11.822 | {'loss': 0.1343, 'grad_norm': 3.6787662506103516, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-26 01:34:26.667 | {'loss': 0.1228, 'grad_norm': 5.295008659362793, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-26 01:34:42.083 | {'loss': 0.148, 'grad_norm': 4.261226177215576, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-26 01:34:57.352 | {'loss': 0.1274, 'grad_norm': 3.384126663208008, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-26 01:35:19.439 | {'loss': 0.1677, 'grad_norm': 7.009820938110352, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-26 01:35:34.453 | {'loss': 0.1263, 'grad_norm': 3.9028384685516357, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-26 01:35:49.424 | {'loss': 0.1296, 'grad_norm': 2.8376266956329346, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-26 01:36:04.527 | {'loss': 0.0981, 'grad_norm': 3.673645257949829, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-26 01:36:19.681 | {'loss': 0.1255, 'grad_norm': 2.1906912326812744, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-26 01:36:41.554 | {'loss': 0.0997, 'grad_norm': 3.8137714862823486, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-26 01:36:57.021 | {'loss': 0.1085, 'grad_norm': 4.404426574707031, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-26 01:37:12.502 | {'loss': 0.1, 'grad_norm': 3.0902352333068848, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-26 01:37:27.686 | {'loss': 0.1072, 'grad_norm': 3.665008306503296, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-26 01:37:42.923 | {'loss': 0.094, 'grad_norm': 3.56872820854187, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-26 01:38:04.566 | {'loss': 0.0928, 'grad_norm': 3.8160150051116943, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-26 01:38:19.665 | {'loss': 0.0955, 'grad_norm': 4.2419843673706055, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-26 01:38:34.617 | {'loss': 0.0978, 'grad_norm': 4.33665657043457, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-26 01:38:49.566 | {'loss': 0.1076, 'grad_norm': 2.6135547161102295, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-26 01:39:04.796 | {'loss': 0.1134, 'grad_norm': 5.04066276550293, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-26 01:39:26.918 | {'loss': 0.1118, 'grad_norm': 3.9760618209838867, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-26 01:39:42.346 | {'loss': 0.1055, 'grad_norm': 5.881198406219482, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-26 01:39:57.427 | {'loss': 0.1127, 'grad_norm': 1.6364140510559082, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-26 01:40:12.626 | {'loss': 0.1072, 'grad_norm': 4.131466865539551, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-26 01:40:34.141 | {'loss': 0.0984, 'grad_norm': 3.770726442337036, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-26 01:40:49.380 | {'loss': 0.0983, 'grad_norm': 4.151097774505615, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-26 01:41:04.436 | {'loss': 0.0901, 'grad_norm': 1.4263579845428467, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-26 01:41:19.568 | {'loss': 0.1068, 'grad_norm': 1.5074833631515503, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-26 01:41:34.682 | {'loss': 0.0693, 'grad_norm': 1.5754073858261108, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-26 01:41:56.463 | {'loss': 0.0709, 'grad_norm': 1.7022429704666138, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-26 01:42:12.070 | {'loss': 0.0846, 'grad_norm': 2.7596404552459717, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-26 01:42:27.513 | {'loss': 0.0741, 'grad_norm': 1.2323296070098877, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-26 01:42:42.604 | {'loss': 0.0704, 'grad_norm': 3.363161325454712, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-26 01:43:03.949 | {'loss': 0.0778, 'grad_norm': 1.6890946626663208, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-26 01:43:18.946 | {'loss': 0.077, 'grad_norm': 1.6204547882080078, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-26 01:43:33.984 | {'loss': 0.0669, 'grad_norm': 1.488006591796875, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-26 01:43:49.167 | {'loss': 0.0865, 'grad_norm': 7.8765153884887695, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-26 01:44:04.351 | {'loss': 0.0718, 'grad_norm': 0.8724374771118164, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-26 01:44:26.441 | {'loss': 0.0841, 'grad_norm': 3.133723735809326, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-26 01:44:42.229 | {'loss': 0.0675, 'grad_norm': 1.166500449180603, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-26 01:44:57.301 | {'loss': 0.0689, 'grad_norm': 1.1834391355514526, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-26 01:45:12.268 | {'loss': 0.0805, 'grad_norm': 2.9484708309173584, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-26 01:45:27.284 | {'loss': 0.0764, 'grad_norm': 0.8248672485351562, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-26 01:45:49.387 | {'loss': 0.0763, 'grad_norm': 1.2754334211349487, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-26 01:46:04.324 | {'loss': 0.0801, 'grad_norm': 2.5917909145355225, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-26 01:46:19.646 | {'loss': 0.069, 'grad_norm': 1.031092882156372, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-26 01:46:34.994 | {'loss': 0.0723, 'grad_norm': 1.970620036125183, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-26 01:46:50.520 | {'loss': 0.084, 'grad_norm': 2.4914374351501465, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-26 01:46:50.520 | {'train_runtime': 1665.6865, 'train_samples_per_second': 1.201, 'train_steps_per_second': 0.6, 'train_loss': 0.13425148904323578, 'epoch': 5.0}
2025-05-26 01:47:01.033 | INFO :      Sent reply
2025-05-26 01:53:07.908 | INFO :      
2025-05-26 01:53:07.908 | INFO :      Received: evaluate message ff2ee85e-ec04-468c-b5e1-3833dc18872a
2025-05-26 01:53:19.471 | {'eval_loss': 3.6932692527770996, 'eval_runtime': 8.6385, 'eval_samples_per_second': 11.576, 'eval_steps_per_second': 1.505, 'epoch': 5.0}
2025-05-26 01:53:19.485 | INFO :      Sent reply
2025-05-26 01:53:27.446 | INFO :      
2025-05-26 01:53:27.446 | INFO :      Received: train message 2516c7b8-468d-49fa-928f-7faa8984622f
2025-05-26 01:54:05.454 | {'loss': 0.0769, 'grad_norm': 1.6927093267440796, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-26 01:54:20.604 | {'loss': 0.0968, 'grad_norm': 3.7697227001190186, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-26 01:54:35.646 | {'loss': 0.1157, 'grad_norm': 3.7119576930999756, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-26 01:54:57.660 | {'loss': 0.1327, 'grad_norm': 3.8175346851348877, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-26 01:55:13.271 | {'loss': 0.1361, 'grad_norm': 2.2210733890533447, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-26 01:55:28.588 | {'loss': 0.1411, 'grad_norm': 4.243382453918457, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-26 01:55:43.891 | {'loss': 0.1343, 'grad_norm': 4.1284260749816895, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-26 01:55:59.033 | {'loss': 0.168, 'grad_norm': 4.145773887634277, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-26 01:56:20.821 | {'loss': 0.1387, 'grad_norm': 3.870159864425659, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-26 01:56:35.959 | {'loss': 0.1525, 'grad_norm': 3.8780417442321777, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-26 01:56:51.174 | {'loss': 0.1495, 'grad_norm': 3.693979263305664, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-26 01:57:06.262 | {'loss': 0.1495, 'grad_norm': 4.268777847290039, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-26 01:57:21.633 | {'loss': 0.1542, 'grad_norm': 2.082686424255371, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-26 01:57:43.304 | {'loss': 0.1618, 'grad_norm': 4.181257247924805, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-26 01:57:58.601 | {'loss': 0.1782, 'grad_norm': 4.808961391448975, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-26 01:58:13.766 | {'loss': 0.1502, 'grad_norm': 4.6726508140563965, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-26 01:58:28.910 | {'loss': 0.1524, 'grad_norm': 2.2211086750030518, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-26 01:58:44.227 | {'loss': 0.1526, 'grad_norm': 5.108731746673584, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-26 01:58:59.374 | {'loss': 0.1642, 'grad_norm': 6.5552897453308105, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-26 01:59:21.280 | {'loss': 0.1638, 'grad_norm': 3.613464593887329, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-26 01:59:36.434 | {'loss': 0.1805, 'grad_norm': 7.248935699462891, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-26 01:59:51.809 | {'loss': 0.2056, 'grad_norm': 8.515109062194824, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-26 02:00:07.010 | {'loss': 0.2314, 'grad_norm': 5.142733573913574, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-26 02:00:28.966 | {'loss': 0.1613, 'grad_norm': 5.5437116622924805, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-26 02:00:45.016 | {'loss': 0.2031, 'grad_norm': 4.415035724639893, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-26 02:01:00.138 | {'loss': 0.1653, 'grad_norm': 8.87292194366455, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-26 02:01:15.466 | {'loss': 0.2138, 'grad_norm': 7.584484100341797, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-26 02:01:37.180 | {'loss': 0.1644, 'grad_norm': 6.968911647796631, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-26 02:01:52.267 | {'loss': 0.21, 'grad_norm': 5.907064914703369, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-26 02:02:07.280 | {'loss': 0.1874, 'grad_norm': 9.636536598205566, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-26 02:02:22.680 | {'loss': 0.1676, 'grad_norm': 7.5836639404296875, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-26 02:02:38.142 | {'loss': 0.1418, 'grad_norm': 4.295910358428955, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-26 02:03:00.319 | {'loss': 0.1773, 'grad_norm': 7.846146583557129, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-26 02:03:15.605 | {'loss': 0.1695, 'grad_norm': 9.24307632446289, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-26 02:03:30.731 | {'loss': 0.1972, 'grad_norm': 10.95439624786377, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-26 02:03:45.860 | {'loss': 0.1768, 'grad_norm': 3.8613638877868652, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-26 02:04:07.397 | {'loss': 0.1923, 'grad_norm': 9.82337760925293, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-26 02:04:22.983 | {'loss': 0.1528, 'grad_norm': 8.505121231079102, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-26 02:04:37.770 | {'loss': 0.182, 'grad_norm': 5.252148151397705, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-26 02:04:52.793 | {'loss': 0.1851, 'grad_norm': 7.276920318603516, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-26 02:05:14.934 | {'loss': 0.1266, 'grad_norm': 6.9737372398376465, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-26 02:05:30.593 | {'loss': 0.1115, 'grad_norm': 2.2937779426574707, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-26 02:05:46.351 | {'loss': 0.1211, 'grad_norm': 5.896548271179199, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-26 02:06:01.814 | {'loss': 0.1308, 'grad_norm': 3.008650302886963, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-26 02:06:17.286 | {'loss': 0.1556, 'grad_norm': 6.136209011077881, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-26 02:06:39.191 | {'loss': 0.1767, 'grad_norm': 5.526279449462891, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-26 02:06:54.475 | {'loss': 0.1704, 'grad_norm': 5.508452415466309, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-26 02:07:09.525 | {'loss': 0.1455, 'grad_norm': 4.4376630783081055, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-26 02:07:24.679 | {'loss': 0.1717, 'grad_norm': 4.932777404785156, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-26 02:07:46.666 | {'loss': 0.1104, 'grad_norm': 1.827612042427063, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-26 02:08:01.999 | {'loss': 0.1272, 'grad_norm': 3.9725961685180664, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-26 02:08:17.431 | {'loss': 0.1413, 'grad_norm': 4.11058235168457, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-26 02:08:32.431 | {'loss': 0.1532, 'grad_norm': 5.661693096160889, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-26 02:08:47.514 | {'loss': 0.1054, 'grad_norm': 1.8262133598327637, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-26 02:09:08.923 | {'loss': 0.1358, 'grad_norm': 4.798343181610107, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-26 02:09:24.033 | {'loss': 0.1398, 'grad_norm': 6.046995639801025, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-26 02:09:39.085 | {'loss': 0.1304, 'grad_norm': 4.901490688323975, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-26 02:09:54.379 | {'loss': 0.1247, 'grad_norm': 5.615095615386963, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-26 02:10:09.868 | {'loss': 0.1248, 'grad_norm': 3.1608948707580566, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-26 02:10:32.265 | {'loss': 0.1258, 'grad_norm': 2.48363995552063, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-26 02:10:47.691 | {'loss': 0.0863, 'grad_norm': 1.8194016218185425, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-26 02:11:02.937 | {'loss': 0.0837, 'grad_norm': 1.0105754137039185, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-26 02:11:17.872 | {'loss': 0.0859, 'grad_norm': 4.519077777862549, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-26 02:11:32.775 | {'loss': 0.1167, 'grad_norm': 3.896690607070923, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-26 02:11:54.424 | {'loss': 0.0913, 'grad_norm': 2.5365936756134033, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-26 02:12:09.817 | {'loss': 0.1005, 'grad_norm': 1.9552634954452515, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-26 02:12:25.350 | {'loss': 0.0921, 'grad_norm': 1.517410159111023, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-26 02:12:40.946 | {'loss': 0.1075, 'grad_norm': 2.131277084350586, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-26 02:12:56.411 | {'loss': 0.0933, 'grad_norm': 5.587141036987305, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-26 02:13:17.700 | {'loss': 0.0955, 'grad_norm': 2.3847951889038086, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-26 02:13:32.748 | {'loss': 0.1074, 'grad_norm': 4.768151760101318, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-26 02:13:47.982 | {'loss': 0.1165, 'grad_norm': 4.769874095916748, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-26 02:14:02.721 | {'loss': 0.122, 'grad_norm': 3.2117974758148193, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-26 02:14:24.116 | {'loss': 0.1062, 'grad_norm': 2.2818706035614014, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-26 02:14:39.145 | {'loss': 0.0964, 'grad_norm': 2.4995486736297607, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-26 02:14:54.386 | {'loss': 0.1027, 'grad_norm': 5.611443996429443, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-26 02:15:09.563 | {'loss': 0.0982, 'grad_norm': 1.8990683555603027, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-26 02:15:31.453 | {'loss': 0.0898, 'grad_norm': 3.6623215675354004, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-26 02:15:46.925 | {'loss': 0.0964, 'grad_norm': 2.24717116355896, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-26 02:16:02.229 | {'loss': 0.0976, 'grad_norm': 3.0381431579589844, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-26 02:16:17.401 | {'loss': 0.0599, 'grad_norm': 1.1617494821548462, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-26 02:16:38.877 | {'loss': 0.0832, 'grad_norm': 2.0268423557281494, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-26 02:16:54.071 | {'loss': 0.0809, 'grad_norm': 1.7133022546768188, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-26 02:17:09.244 | {'loss': 0.0751, 'grad_norm': 3.7908096313476562, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-26 02:17:24.422 | {'loss': 0.0721, 'grad_norm': 1.5124342441558838, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-26 02:17:46.061 | {'loss': 0.0779, 'grad_norm': 3.3706932067871094, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-26 02:18:01.417 | {'loss': 0.0716, 'grad_norm': 1.5630258321762085, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-26 02:18:17.297 | {'loss': 0.0679, 'grad_norm': 1.5284100770950317, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-26 02:18:32.459 | {'loss': 0.0811, 'grad_norm': 1.7574330568313599, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-26 02:18:54.005 | {'loss': 0.0742, 'grad_norm': 0.9910662174224854, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-26 02:19:09.264 | {'loss': 0.0719, 'grad_norm': 1.0406330823898315, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-26 02:19:24.111 | {'loss': 0.0744, 'grad_norm': 1.2839511632919312, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-26 02:19:38.989 | {'loss': 0.0632, 'grad_norm': 2.1321663856506348, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-26 02:20:00.365 | {'loss': 0.0793, 'grad_norm': 1.926339030265808, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-26 02:20:15.451 | {'loss': 0.0754, 'grad_norm': 1.5005439519882202, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-26 02:20:30.531 | {'loss': 0.0706, 'grad_norm': 1.7262769937515259, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-26 02:20:45.914 | {'loss': 0.077, 'grad_norm': 2.120323419570923, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-26 02:21:07.861 | {'loss': 0.0654, 'grad_norm': 1.0549509525299072, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-26 02:21:19.848 | {'loss': 0.0693, 'grad_norm': 2.3231074810028076, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-26 02:21:25.847 | {'loss': 0.0746, 'grad_norm': 1.9098105430603027, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-26 02:21:25.847 | {'train_runtime': 1673.9106, 'train_samples_per_second': 1.195, 'train_steps_per_second': 0.597, 'train_loss': 0.12714205330610276, 'epoch': 5.0}
2025-05-26 02:21:29.169 | INFO :      Sent reply
2025-05-26 02:27:35.640 | INFO :      
2025-05-26 02:27:35.640 | INFO :      Received: evaluate message f839a507-1f98-41fb-a9a4-931773335157
2025-05-26 02:27:49.598 | {'eval_loss': 3.742849111557007, 'eval_runtime': 13.1793, 'eval_samples_per_second': 7.588, 'eval_steps_per_second': 0.986, 'epoch': 5.0}
2025-05-26 02:27:49.608 | INFO :      Sent reply
2025-05-26 02:27:59.196 | INFO :      
2025-05-26 02:27:59.197 | INFO :      Received: train message b495ea87-040c-4fe5-8b16-1770afc8338e
2025-05-26 02:28:28.751 | {'loss': 0.0691, 'grad_norm': 1.3628261089324951, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-26 02:28:44.060 | {'loss': 0.09, 'grad_norm': 2.2133123874664307, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-26 02:28:59.370 | {'loss': 0.0973, 'grad_norm': 2.6850600242614746, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-26 02:29:21.567 | {'loss': 0.1084, 'grad_norm': 3.8449881076812744, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-26 02:29:37.098 | {'loss': 0.1222, 'grad_norm': 1.547799825668335, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-26 02:29:52.644 | {'loss': 0.1327, 'grad_norm': 3.3074076175689697, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-26 02:30:07.920 | {'loss': 0.1177, 'grad_norm': 4.841132640838623, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-26 02:30:23.230 | {'loss': 0.1372, 'grad_norm': 4.802280426025391, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-26 02:30:45.238 | {'loss': 0.1226, 'grad_norm': 2.9515275955200195, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-26 02:31:00.621 | {'loss': 0.1467, 'grad_norm': 5.035301208496094, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-26 02:31:15.931 | {'loss': 0.1334, 'grad_norm': 3.815005302429199, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-26 02:31:31.066 | {'loss': 0.1389, 'grad_norm': 2.7776038646698, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-26 02:31:46.760 | {'loss': 0.1422, 'grad_norm': 2.2091169357299805, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-26 02:32:09.250 | {'loss': 0.1574, 'grad_norm': 6.78835916519165, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-26 02:32:24.858 | {'loss': 0.1825, 'grad_norm': 3.673460006713867, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-26 02:32:40.378 | {'loss': 0.1449, 'grad_norm': 4.618359565734863, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-26 02:32:55.950 | {'loss': 0.1786, 'grad_norm': 1.6084835529327393, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-26 02:33:11.335 | {'loss': 0.1563, 'grad_norm': 7.032976150512695, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-26 02:33:26.701 | {'loss': 0.1488, 'grad_norm': 6.719786167144775, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-26 02:33:48.975 | {'loss': 0.1554, 'grad_norm': 3.6963586807250977, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-26 02:34:04.141 | {'loss': 0.1548, 'grad_norm': 5.814230918884277, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-26 02:34:19.774 | {'loss': 0.14, 'grad_norm': 3.864311456680298, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-26 02:34:42.172 | {'loss': 0.1902, 'grad_norm': 6.776305675506592, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-26 02:34:57.484 | {'loss': 0.1475, 'grad_norm': 5.579270839691162, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-26 02:35:12.660 | {'loss': 0.1657, 'grad_norm': 5.8188157081604, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-26 02:35:27.904 | {'loss': 0.1314, 'grad_norm': 4.550936222076416, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-26 02:35:43.158 | {'loss': 0.1607, 'grad_norm': 4.436218738555908, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-26 02:36:04.723 | {'loss': 0.1949, 'grad_norm': 5.973996639251709, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-26 02:36:19.889 | {'loss': 0.2172, 'grad_norm': 6.147247314453125, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-26 02:36:34.909 | {'loss': 0.1598, 'grad_norm': 7.249889850616455, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-26 02:36:50.484 | {'loss': 0.1699, 'grad_norm': 6.537126541137695, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-26 02:37:06.118 | {'loss': 0.1164, 'grad_norm': 5.5010480880737305, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-26 02:37:21.630 | {'loss': 0.1611, 'grad_norm': 6.002348899841309, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-26 02:37:43.356 | {'loss': 0.1346, 'grad_norm': 6.3111162185668945, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-26 02:37:58.525 | {'loss': 0.1711, 'grad_norm': 7.152550220489502, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-26 02:38:13.753 | {'loss': 0.1806, 'grad_norm': 4.45681619644165, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-26 02:38:28.946 | {'loss': 0.1633, 'grad_norm': 3.4368796348571777, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-26 02:38:44.408 | {'loss': 0.159, 'grad_norm': 8.427249908447266, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-26 02:38:59.989 | {'loss': 0.1754, 'grad_norm': 6.17905330657959, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-26 02:39:22.008 | {'loss': 0.1801, 'grad_norm': 5.332282543182373, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-26 02:39:37.460 | {'loss': 0.1297, 'grad_norm': 4.631688594818115, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-26 02:39:53.159 | {'loss': 0.1304, 'grad_norm': 4.216159343719482, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-26 02:40:08.659 | {'loss': 0.1226, 'grad_norm': 6.107961654663086, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-26 02:40:24.083 | {'loss': 0.1227, 'grad_norm': 5.187812805175781, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-26 02:40:39.511 | {'loss': 0.1648, 'grad_norm': 3.5073089599609375, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-26 02:41:01.529 | {'loss': 0.1241, 'grad_norm': 5.0502190589904785, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-26 02:41:16.809 | {'loss': 0.1426, 'grad_norm': 8.257308006286621, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-26 02:41:31.989 | {'loss': 0.1218, 'grad_norm': 4.78066873550415, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-26 02:41:47.202 | {'loss': 0.1354, 'grad_norm': 2.2579379081726074, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-26 02:42:02.443 | {'loss': 0.1203, 'grad_norm': 2.001910448074341, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-26 02:42:23.997 | {'loss': 0.1245, 'grad_norm': 4.537980556488037, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-26 02:42:39.588 | {'loss': 0.1267, 'grad_norm': 4.678330421447754, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-26 02:42:55.158 | {'loss': 0.138, 'grad_norm': 4.868966579437256, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-26 02:43:10.329 | {'loss': 0.1224, 'grad_norm': 3.249854803085327, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-26 02:43:25.438 | {'loss': 0.1147, 'grad_norm': 5.835562229156494, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-26 02:43:46.932 | {'loss': 0.1397, 'grad_norm': 5.845620155334473, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-26 02:44:02.018 | {'loss': 0.1187, 'grad_norm': 5.842188835144043, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-26 02:44:17.199 | {'loss': 0.1378, 'grad_norm': 5.586988925933838, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-26 02:44:32.302 | {'loss': 0.1335, 'grad_norm': 5.823968410491943, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-26 02:44:54.157 | {'loss': 0.1075, 'grad_norm': 3.868013620376587, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-26 02:45:09.823 | {'loss': 0.0822, 'grad_norm': 1.193542242050171, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-26 02:45:25.099 | {'loss': 0.0813, 'grad_norm': 0.8945184350013733, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-26 02:45:40.183 | {'loss': 0.0921, 'grad_norm': 2.3446202278137207, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-26 02:45:55.349 | {'loss': 0.0909, 'grad_norm': 6.2291646003723145, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-26 02:46:17.149 | {'loss': 0.1008, 'grad_norm': 1.9643778800964355, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-26 02:46:32.305 | {'loss': 0.1256, 'grad_norm': 3.2858593463897705, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-26 02:46:47.525 | {'loss': 0.1192, 'grad_norm': 6.214417934417725, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-26 02:47:02.654 | {'loss': 0.0837, 'grad_norm': 3.6032981872558594, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-26 02:47:18.220 | {'loss': 0.0968, 'grad_norm': 3.1329991817474365, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-26 02:47:40.593 | {'loss': 0.0945, 'grad_norm': 2.210240364074707, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-26 02:47:56.264 | {'loss': 0.1019, 'grad_norm': 1.9593623876571655, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-26 02:48:11.569 | {'loss': 0.1021, 'grad_norm': 2.3135905265808105, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-26 02:48:26.843 | {'loss': 0.0854, 'grad_norm': 1.726149082183838, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-26 02:48:48.462 | {'loss': 0.0986, 'grad_norm': 5.319235324859619, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-26 02:49:03.835 | {'loss': 0.0791, 'grad_norm': 2.0830078125, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-26 02:49:19.124 | {'loss': 0.0989, 'grad_norm': 3.457521438598633, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-26 02:49:34.350 | {'loss': 0.0876, 'grad_norm': 1.6237282752990723, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-26 02:49:56.305 | {'loss': 0.0856, 'grad_norm': 1.5896532535552979, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-26 02:50:11.422 | {'loss': 0.0989, 'grad_norm': 4.878435134887695, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-26 02:50:26.731 | {'loss': 0.0799, 'grad_norm': 1.0113681554794312, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-26 02:50:41.837 | {'loss': 0.0557, 'grad_norm': 1.5900700092315674, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-26 02:51:03.360 | {'loss': 0.0683, 'grad_norm': 2.190789222717285, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-26 02:51:18.668 | {'loss': 0.0861, 'grad_norm': 4.8652663230896, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-26 02:51:33.458 | {'loss': 0.0689, 'grad_norm': 2.0834603309631348, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-26 02:51:48.360 | {'loss': 0.0685, 'grad_norm': 1.483999252319336, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-26 02:52:09.794 | {'loss': 0.0703, 'grad_norm': 1.6891210079193115, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-26 02:52:25.383 | {'loss': 0.0745, 'grad_norm': 1.3475587368011475, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-26 02:52:40.727 | {'loss': 0.0717, 'grad_norm': 1.238690972328186, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-26 02:52:56.175 | {'loss': 0.0852, 'grad_norm': 4.303847789764404, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-26 02:53:11.216 | {'loss': 0.0692, 'grad_norm': 1.3307759761810303, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-26 02:53:32.986 | {'loss': 0.0707, 'grad_norm': 1.129353404045105, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-26 02:53:48.216 | {'loss': 0.0772, 'grad_norm': 1.3849711418151855, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-26 02:54:03.416 | {'loss': 0.0647, 'grad_norm': 1.0618278980255127, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-26 02:54:18.619 | {'loss': 0.0707, 'grad_norm': 1.5325801372528076, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-26 02:54:40.052 | {'loss': 0.0783, 'grad_norm': 1.289270043373108, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-26 02:54:55.499 | {'loss': 0.0671, 'grad_norm': 1.1219536066055298, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-26 02:55:10.897 | {'loss': 0.071, 'grad_norm': 3.422048330307007, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-26 02:55:26.435 | {'loss': 0.0663, 'grad_norm': 1.0275815725326538, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-26 02:55:41.752 | {'loss': 0.0714, 'grad_norm': 4.26541805267334, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-26 02:56:03.534 | {'loss': 0.0714, 'grad_norm': 1.928573727607727, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-26 02:56:03.534 | {'train_runtime': 1681.5616, 'train_samples_per_second': 1.189, 'train_steps_per_second': 0.595, 'train_loss': 0.11846610373258591, 'epoch': 5.0}
2025-05-26 02:56:08.223 | INFO :      Sent reply
2025-05-26 03:02:23.827 | INFO :      
2025-05-26 03:02:23.827 | INFO :      Received: evaluate message 11c47986-0286-4f92-91dd-275157a1e6f0
2025-05-26 03:02:40.519 | {'eval_loss': 3.8045730590820312, 'eval_runtime': 12.9676, 'eval_samples_per_second': 7.712, 'eval_steps_per_second': 1.002, 'epoch': 5.0}
2025-05-26 03:02:40.520 | INFO :      Sent reply
2025-05-26 03:02:52.103 | INFO :      
2025-05-26 03:02:52.103 | INFO :      Received: train message 748a129c-c868-4085-b52e-4fac5a7a8e0c
2025-05-26 03:03:21.169 | {'loss': 0.0687, 'grad_norm': 1.7186390161514282, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-26 03:03:36.432 | {'loss': 0.0967, 'grad_norm': 3.813239097595215, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-26 03:03:58.445 | {'loss': 0.0991, 'grad_norm': 2.401648759841919, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-26 03:04:13.691 | {'loss': 0.1159, 'grad_norm': 1.5397260189056396, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-26 03:04:29.197 | {'loss': 0.1363, 'grad_norm': 2.231174945831299, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-26 03:04:44.709 | {'loss': 0.114, 'grad_norm': 2.508014440536499, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-26 03:05:06.464 | {'loss': 0.1249, 'grad_norm': 2.319833993911743, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-26 03:05:21.677 | {'loss': 0.1284, 'grad_norm': 3.427663803100586, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-26 03:05:36.893 | {'loss': 0.1095, 'grad_norm': 2.8955740928649902, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-26 03:05:52.124 | {'loss': 0.1228, 'grad_norm': 3.9555771350860596, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-26 03:06:13.811 | {'loss': 0.1157, 'grad_norm': 3.067411184310913, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-26 03:06:28.867 | {'loss': 0.139, 'grad_norm': 3.399505138397217, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-26 03:06:44.192 | {'loss': 0.1602, 'grad_norm': 3.024120330810547, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-26 03:06:59.777 | {'loss': 0.146, 'grad_norm': 3.6009931564331055, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-26 03:07:21.832 | {'loss': 0.1696, 'grad_norm': 5.382586479187012, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-26 03:07:37.102 | {'loss': 0.1518, 'grad_norm': 5.042129039764404, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-26 03:07:51.988 | {'loss': 0.1596, 'grad_norm': 3.250007152557373, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-26 03:08:06.924 | {'loss': 0.1602, 'grad_norm': 6.073686599731445, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-26 03:08:22.029 | {'loss': 0.162, 'grad_norm': 5.44860315322876, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-26 03:08:43.644 | {'loss': 0.142, 'grad_norm': 3.784878730773926, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-26 03:08:59.161 | {'loss': 0.1446, 'grad_norm': 7.828007698059082, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-26 03:09:14.522 | {'loss': 0.1782, 'grad_norm': 5.036292552947998, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-26 03:09:30.049 | {'loss': 0.1668, 'grad_norm': 3.782210111618042, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-26 03:09:51.766 | {'loss': 0.151, 'grad_norm': 6.498531818389893, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-26 03:10:06.965 | {'loss': 0.1888, 'grad_norm': 2.2714030742645264, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-26 03:10:22.132 | {'loss': 0.2261, 'grad_norm': 7.572725772857666, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-26 03:10:37.330 | {'loss': 0.1728, 'grad_norm': 7.20145320892334, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-26 03:10:52.591 | {'loss': 0.1658, 'grad_norm': 4.580139636993408, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-26 03:11:14.311 | {'loss': 0.1796, 'grad_norm': 6.057222366333008, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-26 03:11:29.811 | {'loss': 0.148, 'grad_norm': 7.340038299560547, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-26 03:11:45.354 | {'loss': 0.1447, 'grad_norm': 7.460474491119385, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-26 03:12:00.825 | {'loss': 0.1406, 'grad_norm': 7.451712131500244, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-26 03:12:22.672 | {'loss': 0.1776, 'grad_norm': 4.888335704803467, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-26 03:12:37.582 | {'loss': 0.1587, 'grad_norm': 8.128423690795898, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-26 03:12:52.703 | {'loss': 0.1529, 'grad_norm': 3.831857442855835, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-26 03:13:07.868 | {'loss': 0.1447, 'grad_norm': 4.885432720184326, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-26 03:13:29.684 | {'loss': 0.1667, 'grad_norm': 5.47655725479126, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-26 03:13:44.698 | {'loss': 0.1537, 'grad_norm': 5.965604782104492, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-26 03:14:00.091 | {'loss': 0.1546, 'grad_norm': 3.8216233253479004, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-26 03:14:15.674 | {'loss': 0.1659, 'grad_norm': 4.627928256988525, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-26 03:14:37.761 | {'loss': 0.1223, 'grad_norm': 7.133045673370361, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-26 03:14:53.048 | {'loss': 0.1122, 'grad_norm': 2.5163373947143555, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-26 03:15:08.241 | {'loss': 0.1097, 'grad_norm': 4.218088150024414, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-26 03:15:23.425 | {'loss': 0.1083, 'grad_norm': 2.979365825653076, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-26 03:15:38.735 | {'loss': 0.1187, 'grad_norm': 2.1017236709594727, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-26 03:16:00.017 | {'loss': 0.1291, 'grad_norm': 4.195322036743164, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-26 03:16:15.378 | {'loss': 0.1456, 'grad_norm': 10.144619941711426, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-26 03:16:31.278 | {'loss': 0.1431, 'grad_norm': 3.6130058765411377, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-26 03:16:46.381 | {'loss': 0.1149, 'grad_norm': 3.5478909015655518, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-26 03:17:08.772 | {'loss': 0.1387, 'grad_norm': 2.060617208480835, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-26 03:17:23.787 | {'loss': 0.1187, 'grad_norm': 3.5866689682006836, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-26 03:17:38.857 | {'loss': 0.1281, 'grad_norm': 7.006126403808594, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-26 03:17:54.308 | {'loss': 0.1016, 'grad_norm': 2.5712201595306396, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-26 03:18:15.652 | {'loss': 0.1065, 'grad_norm': 1.6121035814285278, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-26 03:18:30.955 | {'loss': 0.1291, 'grad_norm': 5.825483322143555, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-26 03:18:46.061 | {'loss': 0.1454, 'grad_norm': 4.064906120300293, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-26 03:19:01.596 | {'loss': 0.1128, 'grad_norm': 3.6421432495117188, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-26 03:19:23.861 | {'loss': 0.101, 'grad_norm': 3.5604586601257324, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-26 03:19:39.677 | {'loss': 0.1146, 'grad_norm': 5.234315395355225, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-26 03:19:54.844 | {'loss': 0.1173, 'grad_norm': 2.9279401302337646, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-26 03:20:10.098 | {'loss': 0.0867, 'grad_norm': 4.32735538482666, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-26 03:20:25.382 | {'loss': 0.0768, 'grad_norm': 0.9759197235107422, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-26 03:20:47.263 | {'loss': 0.0819, 'grad_norm': 2.2752511501312256, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-26 03:21:02.672 | {'loss': 0.0917, 'grad_norm': 3.3886053562164307, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-26 03:21:18.003 | {'loss': 0.0934, 'grad_norm': 2.00557279586792, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-26 03:21:33.792 | {'loss': 0.0902, 'grad_norm': 3.92231822013855, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-26 03:21:49.392 | {'loss': 0.0896, 'grad_norm': 3.441551685333252, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-26 03:22:11.533 | {'loss': 0.0905, 'grad_norm': 3.5874931812286377, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-26 03:22:27.154 | {'loss': 0.0963, 'grad_norm': 3.7272815704345703, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-26 03:22:42.477 | {'loss': 0.0864, 'grad_norm': 1.6197552680969238, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-26 03:22:57.942 | {'loss': 0.1017, 'grad_norm': 2.2406938076019287, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-26 03:23:19.868 | {'loss': 0.1037, 'grad_norm': 3.914874315261841, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-26 03:23:35.065 | {'loss': 0.1089, 'grad_norm': 3.8497314453125, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-26 03:23:50.228 | {'loss': 0.0926, 'grad_norm': 2.872708559036255, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-26 03:24:05.327 | {'loss': 0.1118, 'grad_norm': 2.251478672027588, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-26 03:24:20.613 | {'loss': 0.0811, 'grad_norm': 1.8747034072875977, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-26 03:24:36.526 | {'loss': 0.0854, 'grad_norm': 1.7682520151138306, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-26 03:24:58.435 | {'loss': 0.0992, 'grad_norm': 1.3591015338897705, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-26 03:25:13.640 | {'loss': 0.0879, 'grad_norm': 2.633864641189575, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-26 03:25:28.604 | {'loss': 0.0954, 'grad_norm': 1.3389126062393188, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-26 03:25:43.809 | {'loss': 0.0573, 'grad_norm': 1.1542162895202637, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-26 03:26:05.208 | {'loss': 0.0749, 'grad_norm': 2.3356235027313232, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-26 03:26:20.309 | {'loss': 0.0731, 'grad_norm': 1.704592227935791, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-26 03:26:35.839 | {'loss': 0.0726, 'grad_norm': 1.1649106740951538, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-26 03:26:51.220 | {'loss': 0.0808, 'grad_norm': 1.4645304679870605, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-26 03:27:06.758 | {'loss': 0.0682, 'grad_norm': 0.9155901670455933, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-26 03:27:22.066 | {'loss': 0.0712, 'grad_norm': 2.392089605331421, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-26 03:27:44.231 | {'loss': 0.0663, 'grad_norm': 1.1706911325454712, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-26 03:27:59.175 | {'loss': 0.0753, 'grad_norm': 3.743201494216919, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-26 03:28:14.260 | {'loss': 0.068, 'grad_norm': 1.4694666862487793, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-26 03:28:29.763 | {'loss': 0.0753, 'grad_norm': 4.646877288818359, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-26 03:28:51.214 | {'loss': 0.0676, 'grad_norm': 1.3525065183639526, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-26 03:29:06.981 | {'loss': 0.0625, 'grad_norm': 1.0683207511901855, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-26 03:29:22.678 | {'loss': 0.0715, 'grad_norm': 1.5697901248931885, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-26 03:29:37.836 | {'loss': 0.0789, 'grad_norm': 1.2155992984771729, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-26 03:29:59.413 | {'loss': 0.07, 'grad_norm': 1.1944267749786377, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-26 03:30:14.628 | {'loss': 0.0658, 'grad_norm': 1.5088289976119995, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-26 03:30:29.779 | {'loss': 0.0695, 'grad_norm': 0.9122409820556641, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-26 03:30:42.127 | {'loss': 0.0691, 'grad_norm': 2.0652387142181396, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-26 03:30:47.284 | {'loss': 0.0781, 'grad_norm': 1.8654050827026367, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-26 03:30:47.284 | {'train_runtime': 1668.4272, 'train_samples_per_second': 1.199, 'train_steps_per_second': 0.599, 'train_loss': 0.11588855677843093, 'epoch': 5.0}
2025-05-26 03:30:51.977 | INFO :      Sent reply
2025-05-26 03:36:56.291 | INFO :      
2025-05-26 03:36:56.291 | INFO :      Received: evaluate message 51df4de0-9c28-4b04-88ff-84f4393b6e64
2025-05-26 03:37:08.066 | {'eval_loss': 3.836500644683838, 'eval_runtime': 10.6349, 'eval_samples_per_second': 9.403, 'eval_steps_per_second': 1.222, 'epoch': 5.0}
2025-05-26 03:37:08.080 | INFO :      Sent reply
2025-05-26 03:37:10.164 | INFO :      
2025-05-26 03:37:10.164 | INFO :      Received: reconnect message 179472c0-9db7-46f4-9fdd-bf353e2e08b0
2025-05-26 03:37:10.232 | INFO :      Disconnect and shut down
