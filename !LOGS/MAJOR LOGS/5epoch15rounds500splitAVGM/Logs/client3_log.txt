2025-05-25 18:00:13.666 | Repo card metadata block was not found. Setting CardData to empty.
2025-05-25 18:02:57.608 | 
2025-05-25 18:03:11.246 | 
2025-05-25 18:03:11.653 | 
2025-05-25 18:03:11.760 | /app/client.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-05-25 18:03:11.760 |   trainer = Trainer(
2025-05-25 18:03:12.185 | WARNING :   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
2025-05-25 18:03:12.185 | 	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
2025-05-25 18:03:12.185 | 	flwr.client.start_client(
2025-05-25 18:03:12.185 | 		server_address='<IP>:<PORT>',
2025-05-25 18:03:12.185 | 		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
2025-05-25 18:03:12.185 | 	)
2025-05-25 18:03:12.185 | 	Using `start_numpy_client()` is deprecated.
2025-05-25 18:03:12.185 | 
2025-05-25 18:03:12.185 |             This is a deprecated feature. It will be removed
2025-05-25 18:03:12.185 |             entirely in future versions of Flower.
2025-05-25 18:03:12.185 |         
2025-05-25 18:03:12.185 | WARNING :   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
2025-05-25 18:03:12.185 | 	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:
2025-05-25 18:03:12.185 | 
2025-05-25 18:03:12.185 | 		$ flower-supernode --insecure --superlink='<IP>:<PORT>'
2025-05-25 18:03:12.185 | 
2025-05-25 18:03:12.185 | 	To view all available options, run:
2025-05-25 18:03:12.185 | 
2025-05-25 18:03:12.185 | 		$ flower-supernode --help
2025-05-25 18:03:12.185 | 
2025-05-25 18:03:12.185 | 	Using `start_client()` is deprecated.
2025-05-25 18:03:12.185 | 
2025-05-25 18:03:12.185 |             This is a deprecated feature. It will be removed
2025-05-25 18:03:12.185 |             entirely in future versions of Flower.
2025-05-25 18:03:12.185 |         
2025-05-25 18:03:12.201 | Exception in thread Thread-4 (_run):
2025-05-25 18:03:12.201 | Traceback (most recent call last):
2025-05-25 18:03:12.201 |   File "/usr/local/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
2025-05-25 18:03:12.201 | Traceback (most recent call last):
2025-05-25 18:03:12.201 |   File "/app/client.py", line 111, in <module>
2025-05-25 18:03:12.203 |         fl.client.start_numpy_client(server_address=server_ip, client=FlowerClient())self.run()
2025-05-25 18:03:12.203 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/app.py", line 731, in start_numpy_client
2025-05-25 18:03:12.203 | 
2025-05-25 18:03:12.203 |       File "/usr/local/lib/python3.10/threading.py", line 953, in run
2025-05-25 18:03:12.203 | start_client(
2025-05-25 18:03:12.203 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/app.py", line 201, in start_client
2025-05-25 18:03:12.203 |     start_client_internal(
2025-05-25 18:03:12.203 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/app.py", line 438, in start_client_internal
2025-05-25 18:03:12.204 |         self._target(*self._args, **self._kwargs)
2025-05-25 18:03:12.204 |   File "src/python/grpcio/grpc/_cython/_cygrpc/thread.pyx.pxi", line 53, in grpc._cython.cygrpc._run_with_context._run
2025-05-25 18:03:12.204 | message = receive()
2025-05-25 18:03:12.204 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/grpc_client/connection.py", line 142, in receive
2025-05-25 18:03:12.204 |     proto = next(server_message_iterator)  File "/usr/local/lib/python3.10/site-packages/grpc/_channel.py", line 1942, in _poll_connectivity
2025-05-25 18:03:12.204 | 
2025-05-25 18:03:12.205 |       File "/usr/local/lib/python3.10/site-packages/grpc/_channel.py", line 543, in __next__
2025-05-25 18:03:12.205 | event = channel.watch_connectivity_state(    
2025-05-25 18:03:12.205 | return self._next()
2025-05-25 18:03:12.205 |   File "src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi", line 561, in grpc._cython.cygrpc.Channel.watch_connectivity_state
2025-05-25 18:03:12.205 |   File "/usr/local/lib/python3.10/site-packages/grpc/_channel.py", line 952, in _next
2025-05-25 18:03:12.206 |     raise self
2025-05-25 18:03:12.206 | grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
2025-05-25 18:03:12.206 | 	status = StatusCode.UNAVAILABLE
2025-05-25 18:03:12.206 | 	details = "failed to connect to all addresses; last error: UNKNOWN: ipv4:172.18.0.2:8080: Failed to connect to remote host: connect: Connection refused (111)"
2025-05-25 18:03:12.206 | 	debug_error_string = "UNKNOWN:Error received from peer  {grpc_message:"failed to connect to all addresses; last error: UNKNOWN: ipv4:172.18.0.2:8080: Failed to connect to remote host: connect: Connection refused (111)", grpc_status:14, created_time:"2025-05-25T15:03:12.197872064+00:00"}"
2025-05-25 18:03:12.206 | >
2025-05-25 18:03:12.206 |   File "src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi", line 427, in grpc._cython.cygrpc._watch_connectivity_state
2025-05-25 18:03:12.206 |   File "src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi", line 435, in grpc._cython.cygrpc._watch_connectivity_state
2025-05-25 18:03:12.206 | ValueError: Cannot monitor channel state: Channel closed!
2025-05-25 18:34:00.544 | Repo card metadata block was not found. Setting CardData to empty.
2025-05-25 18:34:03.645 | /app/client.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-05-25 18:34:03.645 |   trainer = Trainer(
2025-05-25 18:34:04.281 | WARNING :   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
2025-05-25 18:34:04.281 | 	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
2025-05-25 18:34:04.281 | 	flwr.client.start_client(
2025-05-25 18:34:04.281 | 		server_address='<IP>:<PORT>',
2025-05-25 18:34:04.281 | 		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
2025-05-25 18:34:04.281 | 	)
2025-05-25 18:34:04.281 | 	Using `start_numpy_client()` is deprecated.
2025-05-25 18:34:04.281 | 
2025-05-25 18:34:04.281 |             This is a deprecated feature. It will be removed
2025-05-25 18:34:04.281 |             entirely in future versions of Flower.
2025-05-25 18:34:04.281 |         
2025-05-25 18:34:04.281 | WARNING :   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
2025-05-25 18:34:04.281 | 	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:
2025-05-25 18:34:04.281 | 
2025-05-25 18:34:04.281 | 		$ flower-supernode --insecure --superlink='<IP>:<PORT>'
2025-05-25 18:34:04.281 | 
2025-05-25 18:34:04.281 | 	To view all available options, run:
2025-05-25 18:34:04.281 | 
2025-05-25 18:34:04.281 | 		$ flower-supernode --help
2025-05-25 18:34:04.281 | 
2025-05-25 18:34:04.281 | 	Using `start_client()` is deprecated.
2025-05-25 18:34:04.281 | 
2025-05-25 18:34:04.281 |             This is a deprecated feature. It will be removed
2025-05-25 18:34:04.281 |             entirely in future versions of Flower.
2025-05-25 18:34:04.281 |         
2025-05-25 18:40:15.040 | INFO :      
2025-05-25 18:40:15.040 | INFO :      Received: train message 63f558fc-0039-4cfb-ad86-d4cf98ad1268
2025-05-25 18:40:59.110 | {'loss': 6.6842, 'grad_norm': 20.29840850830078, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 18:41:29.396 | {'loss': 5.3099, 'grad_norm': 30.205474853515625, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 18:42:01.751 | {'loss': 4.6098, 'grad_norm': 20.450220108032227, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 18:42:33.300 | {'loss': 3.8702, 'grad_norm': 13.716910362243652, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 18:42:55.760 | {'loss': 3.874, 'grad_norm': 23.674964904785156, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 18:43:27.470 | {'loss': 3.693, 'grad_norm': 14.531303405761719, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 18:43:59.405 | {'loss': 3.231, 'grad_norm': 18.21224021911621, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 18:44:31.673 | {'loss': 3.765, 'grad_norm': 17.960763931274414, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 18:45:02.902 | {'loss': 3.6385, 'grad_norm': 12.58031940460205, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 18:45:24.062 | {'loss': 3.5844, 'grad_norm': 18.193405151367188, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 18:45:56.412 | {'loss': 3.5089, 'grad_norm': 17.04205322265625, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 18:46:29.410 | {'loss': 3.2981, 'grad_norm': 11.033360481262207, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 18:47:01.706 | {'loss': 3.9569, 'grad_norm': 15.054044723510742, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 18:47:23.221 | {'loss': 3.6721, 'grad_norm': 18.72520637512207, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 18:47:55.539 | {'loss': 3.5981, 'grad_norm': 18.164512634277344, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 18:48:28.454 | {'loss': 3.3515, 'grad_norm': 19.46755027770996, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 18:48:59.258 | {'loss': 2.9319, 'grad_norm': 14.422900199890137, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 18:49:30.465 | {'loss': 3.144, 'grad_norm': 14.698613166809082, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 18:49:52.939 | {'loss': 3.7261, 'grad_norm': 17.105756759643555, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 18:50:24.167 | {'loss': 3.907, 'grad_norm': 15.281865119934082, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 18:50:55.396 | {'loss': 2.1458, 'grad_norm': 11.815241813659668, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 18:51:27.639 | {'loss': 2.6177, 'grad_norm': 10.27154541015625, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 18:51:59.334 | {'loss': 2.6266, 'grad_norm': 14.306354522705078, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 18:52:21.823 | {'loss': 2.1437, 'grad_norm': 11.840514183044434, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 18:52:53.874 | {'loss': 2.3333, 'grad_norm': 14.357190132141113, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 18:53:25.685 | {'loss': 2.6225, 'grad_norm': 14.332388877868652, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 18:53:58.058 | {'loss': 2.451, 'grad_norm': 10.077720642089844, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 18:54:29.963 | {'loss': 2.3199, 'grad_norm': 16.586212158203125, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 18:55:01.658 | {'loss': 2.7086, 'grad_norm': 15.889789581298828, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 18:55:23.967 | {'loss': 2.2268, 'grad_norm': 15.49234390258789, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 18:55:55.248 | {'loss': 2.3014, 'grad_norm': 11.750406265258789, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 18:56:27.228 | {'loss': 2.216, 'grad_norm': 12.491593360900879, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 18:56:58.933 | {'loss': 2.2663, 'grad_norm': 13.234822273254395, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 18:57:30.391 | {'loss': 2.3244, 'grad_norm': 16.18136978149414, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 18:58:02.295 | {'loss': 2.2952, 'grad_norm': 14.047759056091309, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 18:58:24.816 | {'loss': 2.4729, 'grad_norm': 13.371926307678223, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 18:58:57.173 | {'loss': 2.2595, 'grad_norm': 12.789712905883789, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 18:59:29.021 | {'loss': 2.0593, 'grad_norm': 11.193404197692871, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 18:59:51.366 | {'loss': 2.6494, 'grad_norm': 16.516040802001953, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 19:00:23.576 | {'loss': 2.0658, 'grad_norm': 10.402728080749512, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 19:00:54.889 | {'loss': 1.7887, 'grad_norm': 12.540556907653809, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 19:01:26.672 | {'loss': 1.7158, 'grad_norm': 11.267985343933105, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 19:01:57.978 | {'loss': 1.7394, 'grad_norm': 14.37732982635498, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 19:02:19.628 | {'loss': 1.7443, 'grad_norm': 17.51996612548828, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 19:02:50.978 | {'loss': 1.6744, 'grad_norm': 12.4634428024292, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 19:03:23.792 | {'loss': 1.7472, 'grad_norm': 15.439462661743164, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 19:03:58.115 | {'loss': 1.9272, 'grad_norm': 13.22314453125, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 19:04:12.853 | {'loss': 1.4609, 'grad_norm': 10.63664722442627, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 19:04:34.436 | {'loss': 1.5069, 'grad_norm': 8.703747749328613, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 19:04:49.164 | {'loss': 1.7149, 'grad_norm': 11.214737892150879, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 19:05:04.890 | {'loss': 1.6179, 'grad_norm': 10.803484916687012, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 19:05:19.812 | {'loss': 1.6133, 'grad_norm': 13.025331497192383, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 19:05:41.956 | {'loss': 1.4378, 'grad_norm': 14.17599868774414, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 19:05:56.735 | {'loss': 1.3918, 'grad_norm': 8.42761516571045, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 19:06:18.005 | {'loss': 1.5861, 'grad_norm': 10.947497367858887, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 19:06:40.284 | {'loss': 1.7198, 'grad_norm': 12.200870513916016, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 19:06:55.241 | {'loss': 1.5583, 'grad_norm': 12.208788871765137, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 19:07:16.570 | {'loss': 1.7419, 'grad_norm': 15.320508003234863, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 19:07:32.041 | {'loss': 1.8629, 'grad_norm': 13.33621597290039, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 19:07:47.078 | {'loss': 1.4228, 'grad_norm': 11.722286224365234, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 19:08:08.710 | {'loss': 1.0088, 'grad_norm': 6.765652179718018, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 19:08:23.611 | {'loss': 1.1395, 'grad_norm': 10.844922065734863, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 19:08:45.237 | {'loss': 1.0732, 'grad_norm': 12.523466110229492, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 19:09:00.248 | {'loss': 1.3543, 'grad_norm': 13.83288860321045, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 19:09:14.978 | {'loss': 1.0468, 'grad_norm': 10.685210227966309, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 19:09:36.648 | {'loss': 1.0392, 'grad_norm': 10.20777416229248, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 19:09:51.548 | {'loss': 1.4085, 'grad_norm': 11.208740234375, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 19:10:06.967 | {'loss': 1.0519, 'grad_norm': 7.563182830810547, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 19:10:28.159 | {'loss': 1.0959, 'grad_norm': 9.31790542602539, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 19:10:43.088 | {'loss': 1.304, 'grad_norm': 11.16594409942627, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 19:10:57.953 | {'loss': 1.2203, 'grad_norm': 11.771652221679688, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 19:11:12.941 | {'loss': 1.046, 'grad_norm': 8.691311836242676, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 19:11:27.807 | {'loss': 1.2699, 'grad_norm': 11.252249717712402, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 19:11:48.980 | {'loss': 1.1743, 'grad_norm': 10.436208724975586, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 19:12:04.322 | {'loss': 1.3532, 'grad_norm': 10.007270812988281, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 19:12:19.610 | {'loss': 0.8493, 'grad_norm': 9.32396411895752, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 19:12:34.683 | {'loss': 1.2576, 'grad_norm': 10.908315658569336, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 19:12:55.422 | {'loss': 1.03, 'grad_norm': 12.767242431640625, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 19:13:10.647 | {'loss': 1.2077, 'grad_norm': 8.3564453125, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 19:13:25.711 | {'loss': 1.1579, 'grad_norm': 12.142053604125977, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 19:13:40.669 | {'loss': 0.8291, 'grad_norm': 8.618999481201172, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 19:14:01.871 | {'loss': 0.7106, 'grad_norm': 6.788532733917236, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 19:14:16.800 | {'loss': 0.5882, 'grad_norm': 6.090273857116699, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 19:14:31.874 | {'loss': 0.681, 'grad_norm': 3.375802755355835, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 19:14:46.980 | {'loss': 0.7983, 'grad_norm': 10.915446281433105, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 19:15:09.021 | {'loss': 1.0045, 'grad_norm': 9.49146842956543, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 19:15:24.016 | {'loss': 0.8321, 'grad_norm': 10.357935905456543, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 19:15:39.313 | {'loss': 0.8907, 'grad_norm': 9.061677932739258, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 19:15:54.211 | {'loss': 0.8161, 'grad_norm': 7.977959632873535, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 19:16:15.553 | {'loss': 0.9169, 'grad_norm': 10.01161003112793, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 19:16:30.908 | {'loss': 0.8641, 'grad_norm': 8.175679206848145, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 19:16:45.872 | {'loss': 0.7653, 'grad_norm': 10.11463451385498, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 19:17:01.193 | {'loss': 0.8551, 'grad_norm': 8.07523250579834, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-25 19:17:16.591 | {'loss': 0.8397, 'grad_norm': 11.388160705566406, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-25 19:17:37.691 | {'loss': 0.9287, 'grad_norm': 10.086623191833496, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-25 19:17:52.477 | {'loss': 0.9931, 'grad_norm': 7.876195907592773, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-25 19:18:07.729 | {'loss': 0.802, 'grad_norm': 8.519219398498535, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-25 19:18:22.485 | {'loss': 0.7066, 'grad_norm': 9.258222579956055, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-25 19:18:34.562 | {'loss': 0.8396, 'grad_norm': 11.772438049316406, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-25 19:18:48.255 | {'loss': 0.7883, 'grad_norm': 9.899375915527344, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-25 19:18:48.255 | {'train_runtime': 2310.878, 'train_samples_per_second': 0.865, 'train_steps_per_second': 0.433, 'train_loss': 1.969713927745819, 'epoch': 5.0}
2025-05-25 19:18:53.088 | INFO :      Sent reply
2025-05-25 19:24:52.419 | INFO :      
2025-05-25 19:24:52.419 | INFO :      Received: evaluate message 95c04422-c845-49c6-835a-68c25a7bdb08
2025-05-25 19:25:05.064 | {'eval_loss': 2.535473585128784, 'eval_runtime': 3.7348, 'eval_samples_per_second': 26.775, 'eval_steps_per_second': 3.481, 'epoch': 5.0}
2025-05-25 19:25:05.066 | INFO :      Sent reply
2025-05-25 19:25:15.170 | INFO :      
2025-05-25 19:25:15.170 | INFO :      Received: train message 18621cd5-9a5b-4648-97bd-c9680ddfd172
2025-05-25 19:25:37.610 | {'loss': 2.0193, 'grad_norm': 11.899413108825684, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 19:25:52.678 | {'loss': 2.0889, 'grad_norm': 16.24452781677246, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 19:26:14.801 | {'loss': 2.1076, 'grad_norm': 13.79481315612793, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 19:26:30.035 | {'loss': 1.7087, 'grad_norm': 11.019062995910645, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 19:26:45.714 | {'loss': 1.8953, 'grad_norm': 19.735267639160156, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 19:27:00.649 | {'loss': 1.9998, 'grad_norm': 9.457873344421387, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 19:27:22.266 | {'loss': 1.7404, 'grad_norm': 13.861355781555176, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 19:27:37.439 | {'loss': 2.112, 'grad_norm': 19.023075103759766, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 19:27:52.438 | {'loss': 1.9938, 'grad_norm': 7.34532356262207, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 19:28:07.650 | {'loss': 2.0936, 'grad_norm': 16.97707176208496, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 19:28:22.902 | {'loss': 2.1044, 'grad_norm': 16.048738479614258, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 19:28:38.268 | {'loss': 1.9139, 'grad_norm': 7.494357585906982, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 19:28:53.375 | {'loss': 2.3961, 'grad_norm': 13.612509727478027, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 19:29:14.949 | {'loss': 2.2578, 'grad_norm': 13.935319900512695, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 19:29:30.039 | {'loss': 2.2214, 'grad_norm': 13.168548583984375, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 19:29:45.277 | {'loss': 2.0111, 'grad_norm': 17.460615158081055, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 19:30:00.344 | {'loss': 1.7928, 'grad_norm': 15.968974113464355, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 19:30:22.361 | {'loss': 1.9805, 'grad_norm': 14.772531509399414, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 19:30:37.571 | {'loss': 2.4314, 'grad_norm': 18.3740291595459, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 19:30:52.699 | {'loss': 2.5196, 'grad_norm': 10.594980239868164, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 19:31:07.714 | {'loss': 1.011, 'grad_norm': 10.10655403137207, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 19:31:29.178 | {'loss': 1.4516, 'grad_norm': 8.012322425842285, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 19:31:44.393 | {'loss': 1.3774, 'grad_norm': 13.776941299438477, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 19:31:59.462 | {'loss': 1.1567, 'grad_norm': 13.960569381713867, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 19:32:14.958 | {'loss': 1.3371, 'grad_norm': 11.982698440551758, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 19:32:36.256 | {'loss': 1.5473, 'grad_norm': 16.299423217773438, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 19:32:51.487 | {'loss': 1.4258, 'grad_norm': 8.071117401123047, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 19:33:06.181 | {'loss': 1.385, 'grad_norm': 12.786275863647461, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 19:33:21.287 | {'loss': 1.5761, 'grad_norm': 15.5595121383667, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 19:33:35.954 | {'loss': 1.1783, 'grad_norm': 9.31192398071289, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 19:33:57.808 | {'loss': 1.2813, 'grad_norm': 10.142029762268066, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 19:34:13.642 | {'loss': 1.2214, 'grad_norm': 12.055404663085938, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 19:34:28.402 | {'loss': 1.3412, 'grad_norm': 12.584567070007324, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 19:34:43.415 | {'loss': 1.2448, 'grad_norm': 15.397074699401855, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 19:34:58.174 | {'loss': 1.3865, 'grad_norm': 11.17849349975586, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 19:35:19.597 | {'loss': 1.5247, 'grad_norm': 11.550924301147461, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 19:35:34.332 | {'loss': 1.2779, 'grad_norm': 8.202607154846191, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 19:35:49.880 | {'loss': 1.0877, 'grad_norm': 9.474103927612305, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 19:36:05.246 | {'loss': 1.612, 'grad_norm': 13.825875282287598, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 19:36:26.808 | {'loss': 1.2069, 'grad_norm': 10.62703800201416, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 19:36:41.701 | {'loss': 0.9774, 'grad_norm': 12.112163543701172, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 19:36:56.953 | {'loss': 0.8898, 'grad_norm': 11.716050148010254, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 19:37:11.910 | {'loss': 0.9475, 'grad_norm': 11.143936157226562, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 19:37:27.032 | {'loss': 0.9765, 'grad_norm': 16.713376998901367, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 19:37:49.148 | {'loss': 0.8526, 'grad_norm': 10.324931144714355, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 19:38:04.150 | {'loss': 0.9072, 'grad_norm': 10.373908996582031, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 19:38:19.573 | {'loss': 0.9528, 'grad_norm': 13.343950271606445, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 19:38:34.309 | {'loss': 0.6618, 'grad_norm': 8.1128568649292, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 19:38:49.572 | {'loss': 0.7779, 'grad_norm': 7.050309658050537, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 19:39:11.244 | {'loss': 0.94, 'grad_norm': 8.149904251098633, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 19:39:26.252 | {'loss': 0.9027, 'grad_norm': 9.633296012878418, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 19:39:41.112 | {'loss': 0.8044, 'grad_norm': 11.463621139526367, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 19:39:56.721 | {'loss': 0.8054, 'grad_norm': 13.04687213897705, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 19:40:12.212 | {'loss': 0.7414, 'grad_norm': 8.640748023986816, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 19:40:33.732 | {'loss': 0.8834, 'grad_norm': 9.914986610412598, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 19:40:48.975 | {'loss': 0.9739, 'grad_norm': 11.180058479309082, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 19:41:03.720 | {'loss': 0.8118, 'grad_norm': 10.677892684936523, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 19:41:18.734 | {'loss': 0.9271, 'grad_norm': 11.128329277038574, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 19:41:33.680 | {'loss': 1.0272, 'grad_norm': 12.700847625732422, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 19:41:49.245 | {'loss': 0.8012, 'grad_norm': 9.633702278137207, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 19:42:11.084 | {'loss': 0.462, 'grad_norm': 6.531428813934326, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 19:42:26.033 | {'loss': 0.5169, 'grad_norm': 8.926791191101074, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 19:42:40.698 | {'loss': 0.5189, 'grad_norm': 7.7320451736450195, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 19:42:55.901 | {'loss': 0.6514, 'grad_norm': 10.9722318649292, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 19:43:17.321 | {'loss': 0.5305, 'grad_norm': 11.248433113098145, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 19:43:32.035 | {'loss': 0.5167, 'grad_norm': 7.731569766998291, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 19:43:47.614 | {'loss': 0.6751, 'grad_norm': 9.404867172241211, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 19:44:02.573 | {'loss': 0.49, 'grad_norm': 4.8246612548828125, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 19:44:23.981 | {'loss': 0.5263, 'grad_norm': 7.051711082458496, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 19:44:38.680 | {'loss': 0.6504, 'grad_norm': 9.261419296264648, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 19:44:53.826 | {'loss': 0.648, 'grad_norm': 10.479116439819336, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 19:45:08.791 | {'loss': 0.512, 'grad_norm': 6.363954544067383, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 19:45:24.217 | {'loss': 0.6483, 'grad_norm': 7.93606424331665, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 19:45:46.482 | {'loss': 0.6121, 'grad_norm': 11.113256454467773, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 19:46:02.050 | {'loss': 0.675, 'grad_norm': 8.2469482421875, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 19:46:17.395 | {'loss': 0.4151, 'grad_norm': 6.965770721435547, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 19:46:32.551 | {'loss': 0.5707, 'grad_norm': 7.400421619415283, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 19:46:47.734 | {'loss': 0.5361, 'grad_norm': 10.840605735778809, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 19:47:09.093 | {'loss': 0.5994, 'grad_norm': 7.832704544067383, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 19:47:24.818 | {'loss': 0.5491, 'grad_norm': 6.991907596588135, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 19:47:40.111 | {'loss': 0.3789, 'grad_norm': 6.350588798522949, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 19:47:55.610 | {'loss': 0.3414, 'grad_norm': 11.69853687286377, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 19:48:10.450 | {'loss': 0.2685, 'grad_norm': 4.763794422149658, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 19:48:32.025 | {'loss': 0.2964, 'grad_norm': 3.014108657836914, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 19:48:47.102 | {'loss': 0.3501, 'grad_norm': 7.209674835205078, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 19:49:02.458 | {'loss': 0.4582, 'grad_norm': 5.245282173156738, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 19:49:17.696 | {'loss': 0.3766, 'grad_norm': 8.599149703979492, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 19:49:33.111 | {'loss': 0.4112, 'grad_norm': 6.322656154632568, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 19:49:54.473 | {'loss': 0.3722, 'grad_norm': 6.164742469787598, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 19:50:09.185 | {'loss': 0.4189, 'grad_norm': 7.868407726287842, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 19:50:24.246 | {'loss': 0.3834, 'grad_norm': 7.921298980712891, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 19:50:39.604 | {'loss': 0.3502, 'grad_norm': 8.045209884643555, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 19:50:54.668 | {'loss': 0.378, 'grad_norm': 6.519673824310303, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-25 19:51:15.904 | {'loss': 0.4006, 'grad_norm': 6.879230499267578, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-25 19:51:31.725 | {'loss': 0.4419, 'grad_norm': 6.793517589569092, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-25 19:51:46.110 | {'loss': 0.4629, 'grad_norm': 5.5413007736206055, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-25 19:52:01.049 | {'loss': 0.3806, 'grad_norm': 6.144436359405518, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-25 19:52:15.627 | {'loss': 0.3033, 'grad_norm': 7.376646518707275, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-25 19:52:37.331 | {'loss': 0.3416, 'grad_norm': 5.2487311363220215, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-25 19:52:52.522 | {'loss': 0.28, 'grad_norm': 7.87880802154541, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-25 19:52:52.522 | {'train_runtime': 1655.0467, 'train_samples_per_second': 1.208, 'train_steps_per_second': 0.604, 'train_loss': 1.0427957434654236, 'epoch': 5.0}
2025-05-25 19:52:58.840 | INFO :      Sent reply
2025-05-25 19:59:17.443 | INFO :      
2025-05-25 19:59:17.443 | INFO :      Received: evaluate message eb8d887f-124e-40e0-90fa-19eef39a8767
2025-05-25 19:59:40.119 | {'eval_loss': 2.6168341636657715, 'eval_runtime': 14.6341, 'eval_samples_per_second': 6.833, 'eval_steps_per_second': 0.888, 'epoch': 5.0}
2025-05-25 19:59:40.121 | INFO :      Sent reply
2025-05-25 19:59:52.824 | INFO :      
2025-05-25 19:59:52.824 | INFO :      Received: train message 261ba4de-dfcf-40e9-b5f8-96a06493929b
2025-05-25 20:00:13.740 | {'loss': 1.2247, 'grad_norm': 11.63692569732666, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 20:00:39.622 | {'loss': 1.3613, 'grad_norm': 12.674687385559082, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 20:00:56.348 | {'loss': 1.4126, 'grad_norm': 12.24608039855957, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 20:01:14.435 | {'loss': 1.1506, 'grad_norm': 9.318992614746094, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 20:01:31.263 | {'loss': 1.3365, 'grad_norm': 15.51679801940918, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 20:01:53.581 | {'loss': 1.4138, 'grad_norm': 8.225647926330566, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 20:02:09.665 | {'loss': 1.2281, 'grad_norm': 15.534144401550293, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 20:02:27.182 | {'loss': 1.4726, 'grad_norm': 19.802846908569336, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 20:02:44.270 | {'loss': 1.3969, 'grad_norm': 5.1653900146484375, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 20:03:08.111 | {'loss': 1.491, 'grad_norm': 16.692180633544922, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 20:03:23.906 | {'loss': 1.5166, 'grad_norm': 14.604582786560059, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 20:03:39.613 | {'loss': 1.3451, 'grad_norm': 5.8762054443359375, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 20:03:57.821 | {'loss': 1.6722, 'grad_norm': 13.283586502075195, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 20:04:22.998 | {'loss': 1.6211, 'grad_norm': 13.95007610321045, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 20:04:38.973 | {'loss': 1.5714, 'grad_norm': 13.161266326904297, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 20:04:55.538 | {'loss': 1.3966, 'grad_norm': 16.588539123535156, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 20:05:11.503 | {'loss': 1.2546, 'grad_norm': 14.663265228271484, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 20:05:37.128 | {'loss': 1.4442, 'grad_norm': 16.578685760498047, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 20:05:56.046 | {'loss': 1.7747, 'grad_norm': 17.722116470336914, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 20:06:13.633 | {'loss': 1.7668, 'grad_norm': 8.787912368774414, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 20:06:32.157 | {'loss': 0.6176, 'grad_norm': 7.9873738288879395, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 20:06:57.724 | {'loss': 0.919, 'grad_norm': 7.854447364807129, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 20:07:15.412 | {'loss': 0.8504, 'grad_norm': 11.838930130004883, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 20:07:33.329 | {'loss': 0.7909, 'grad_norm': 12.955363273620605, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 20:07:59.949 | {'loss': 0.8714, 'grad_norm': 12.39106559753418, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 20:08:15.706 | {'loss': 1.0304, 'grad_norm': 13.84745979309082, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 20:08:33.354 | {'loss': 0.8958, 'grad_norm': 6.773410797119141, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 20:08:59.162 | {'loss': 0.9348, 'grad_norm': 14.093873023986816, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 20:09:17.159 | {'loss': 0.9792, 'grad_norm': 14.30271053314209, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 20:09:34.760 | {'loss': 0.7508, 'grad_norm': 10.814035415649414, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 20:09:53.289 | {'loss': 0.821, 'grad_norm': 10.805628776550293, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 20:10:18.625 | {'loss': 0.8873, 'grad_norm': 13.802242279052734, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 20:10:36.440 | {'loss': 0.9032, 'grad_norm': 11.903521537780762, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 20:10:53.836 | {'loss': 0.7924, 'grad_norm': 10.968023300170898, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 20:11:11.508 | {'loss': 0.9001, 'grad_norm': 11.065479278564453, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 20:11:36.668 | {'loss': 1.003, 'grad_norm': 11.124978065490723, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 20:11:53.421 | {'loss': 0.8191, 'grad_norm': 11.193649291992188, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 20:12:10.956 | {'loss': 0.7494, 'grad_norm': 14.12325668334961, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 20:12:37.123 | {'loss': 1.093, 'grad_norm': 12.380425453186035, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 20:12:55.138 | {'loss': 0.8132, 'grad_norm': 9.670572280883789, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 20:13:12.810 | {'loss': 0.6011, 'grad_norm': 9.868756294250488, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 20:13:38.419 | {'loss': 0.5006, 'grad_norm': 8.639612197875977, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 20:13:54.022 | {'loss': 0.5684, 'grad_norm': 10.792717933654785, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 20:14:10.839 | {'loss': 0.5863, 'grad_norm': 15.38278865814209, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 20:14:26.562 | {'loss': 0.5101, 'grad_norm': 11.451762199401855, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 20:14:51.466 | {'loss': 0.5481, 'grad_norm': 9.398171424865723, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 20:15:07.877 | {'loss': 0.5872, 'grad_norm': 12.552472114562988, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 20:15:24.787 | {'loss': 0.4124, 'grad_norm': 5.747267246246338, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 20:15:51.016 | {'loss': 0.4836, 'grad_norm': 6.7654829025268555, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 20:16:06.993 | {'loss': 0.639, 'grad_norm': 7.910451412200928, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 20:16:22.898 | {'loss': 0.5787, 'grad_norm': 9.56367301940918, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 20:16:38.918 | {'loss': 0.4704, 'grad_norm': 9.85338020324707, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 20:17:03.542 | {'loss': 0.4753, 'grad_norm': 11.549813270568848, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 20:17:21.076 | {'loss': 0.4902, 'grad_norm': 6.898962497711182, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 20:17:37.895 | {'loss': 0.5572, 'grad_norm': 11.243816375732422, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 20:17:54.572 | {'loss': 0.6275, 'grad_norm': 10.16295337677002, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 20:18:21.787 | {'loss': 0.5094, 'grad_norm': 9.211236000061035, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 20:18:39.315 | {'loss': 0.5341, 'grad_norm': 10.377632141113281, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 20:19:06.150 | {'loss': 0.6623, 'grad_norm': 9.395742416381836, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 20:19:22.748 | {'loss': 0.4964, 'grad_norm': 8.274030685424805, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 20:19:39.525 | {'loss': 0.2899, 'grad_norm': 5.670770645141602, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 20:19:55.601 | {'loss': 0.2945, 'grad_norm': 8.529890060424805, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 20:20:21.130 | {'loss': 0.3207, 'grad_norm': 5.885371208190918, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 20:20:39.052 | {'loss': 0.3356, 'grad_norm': 7.670082092285156, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 20:20:56.086 | {'loss': 0.3042, 'grad_norm': 8.478124618530273, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 20:21:19.409 | {'loss': 0.3108, 'grad_norm': 6.899840354919434, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 20:21:35.840 | {'loss': 0.4114, 'grad_norm': 8.311368942260742, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 20:21:53.025 | {'loss': 0.2909, 'grad_norm': 5.465944290161133, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 20:22:11.025 | {'loss': 0.3197, 'grad_norm': 7.330483913421631, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 20:22:34.218 | {'loss': 0.3643, 'grad_norm': 6.644550800323486, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 20:22:50.085 | {'loss': 0.4153, 'grad_norm': 8.23410701751709, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 20:23:06.445 | {'loss': 0.3144, 'grad_norm': 4.514091491699219, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 20:23:30.228 | {'loss': 0.3785, 'grad_norm': 5.81663703918457, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 20:23:47.738 | {'loss': 0.3829, 'grad_norm': 8.54582405090332, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 20:24:04.681 | {'loss': 0.4025, 'grad_norm': 7.262068271636963, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 20:24:20.460 | {'loss': 0.2406, 'grad_norm': 4.848332405090332, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 20:24:43.582 | {'loss': 0.3259, 'grad_norm': 6.577402591705322, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 20:24:59.278 | {'loss': 0.3102, 'grad_norm': 8.252567291259766, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 20:25:16.718 | {'loss': 0.3427, 'grad_norm': 7.323132038116455, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 20:25:34.500 | {'loss': 0.3378, 'grad_norm': 4.961420059204102, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 20:25:56.907 | {'loss': 0.2087, 'grad_norm': 4.8674774169921875, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 20:26:13.146 | {'loss': 0.2016, 'grad_norm': 14.526420593261719, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 20:26:28.746 | {'loss': 0.167, 'grad_norm': 3.1769354343414307, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 20:26:52.888 | {'loss': 0.1709, 'grad_norm': 2.4218437671661377, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 20:27:09.983 | {'loss': 0.1973, 'grad_norm': 6.509115695953369, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 20:27:26.352 | {'loss': 0.2524, 'grad_norm': 4.059240818023682, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 20:27:42.410 | {'loss': 0.2183, 'grad_norm': 7.0406012535095215, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 20:28:05.129 | {'loss': 0.2361, 'grad_norm': 5.962102890014648, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 20:28:21.702 | {'loss': 0.2096, 'grad_norm': 4.942932605743408, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 20:28:39.276 | {'loss': 0.2281, 'grad_norm': 5.706839084625244, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 20:29:04.150 | {'loss': 0.2251, 'grad_norm': 5.992135524749756, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 20:29:20.137 | {'loss': 0.2051, 'grad_norm': 6.952417850494385, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 20:29:36.278 | {'loss': 0.2203, 'grad_norm': 4.887986183166504, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-25 20:29:52.373 | {'loss': 0.2141, 'grad_norm': 7.141269683837891, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-25 20:30:17.103 | {'loss': 0.229, 'grad_norm': 4.130849838256836, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-25 20:30:34.744 | {'loss': 0.2578, 'grad_norm': 3.4919004440307617, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-25 20:30:50.887 | {'loss': 0.2346, 'grad_norm': 5.711293697357178, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-25 20:31:13.714 | {'loss': 0.1752, 'grad_norm': 5.016475677490234, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-25 20:31:29.617 | {'loss': 0.1901, 'grad_norm': 4.30354642868042, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-25 20:31:45.426 | {'loss': 0.1508, 'grad_norm': 3.6555063724517822, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-25 20:31:45.427 | {'train_runtime': 1910.2998, 'train_samples_per_second': 1.047, 'train_steps_per_second': 0.523, 'train_loss': 0.6799659309387207, 'epoch': 5.0}
2025-05-25 20:32:00.883 | INFO :      Sent reply
2025-05-25 20:38:16.874 | INFO :      
2025-05-25 20:38:16.874 | INFO :      Received: evaluate message 92560e34-bf02-4372-9166-30f620babb6b
2025-05-25 20:38:32.742 | {'eval_loss': 2.7406179904937744, 'eval_runtime': 9.698, 'eval_samples_per_second': 10.311, 'eval_steps_per_second': 1.34, 'epoch': 5.0}
2025-05-25 20:38:32.744 | INFO :      Sent reply
2025-05-25 20:38:44.623 | INFO :      
2025-05-25 20:38:44.623 | INFO :      Received: train message 5903683b-784e-4b59-bd72-6b33ecb1fd6c
2025-05-25 20:39:15.727 | {'loss': 0.7484, 'grad_norm': 8.374185562133789, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 20:39:30.752 | {'loss': 0.8925, 'grad_norm': 26.217954635620117, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 20:39:52.621 | {'loss': 0.9508, 'grad_norm': 10.986310958862305, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 20:40:07.662 | {'loss': 0.7924, 'grad_norm': 8.528940200805664, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 20:40:23.289 | {'loss': 0.8996, 'grad_norm': 15.075627326965332, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 20:40:45.374 | {'loss': 0.9928, 'grad_norm': 8.140155792236328, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 20:41:00.588 | {'loss': 0.8547, 'grad_norm': 15.46185302734375, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 20:41:15.953 | {'loss': 1.0225, 'grad_norm': 17.38525390625, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 20:41:31.185 | {'loss': 0.9318, 'grad_norm': 4.5934672355651855, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 20:41:46.736 | {'loss': 1.0075, 'grad_norm': 13.84846305847168, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 20:42:08.556 | {'loss': 1.0305, 'grad_norm': 14.359124183654785, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 20:42:24.393 | {'loss': 0.9205, 'grad_norm': 5.766534805297852, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 20:42:39.690 | {'loss': 1.112, 'grad_norm': 13.045758247375488, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 20:42:54.850 | {'loss': 1.1419, 'grad_norm': 14.509288787841797, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 20:43:10.003 | {'loss': 1.0924, 'grad_norm': 12.55113410949707, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 20:43:31.974 | {'loss': 0.9567, 'grad_norm': 14.589916229248047, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 20:43:47.236 | {'loss': 0.8479, 'grad_norm': 13.623246192932129, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 20:44:02.386 | {'loss': 1.0119, 'grad_norm': 15.674150466918945, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 20:44:17.802 | {'loss': 1.2751, 'grad_norm': 16.44061851501465, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 20:44:33.015 | {'loss': 1.2277, 'grad_norm': 7.9800543785095215, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 20:44:48.452 | {'loss': 0.4315, 'grad_norm': 12.996804237365723, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 20:45:09.877 | {'loss': 0.5822, 'grad_norm': 6.241995811462402, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 20:45:25.326 | {'loss': 0.5737, 'grad_norm': 13.78482437133789, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 20:45:40.475 | {'loss': 0.532, 'grad_norm': 11.611656188964844, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 20:45:55.819 | {'loss': 0.5735, 'grad_norm': 12.01202392578125, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 20:46:11.294 | {'loss': 0.7577, 'grad_norm': 14.786367416381836, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 20:46:32.943 | {'loss': 0.6438, 'grad_norm': 6.607337951660156, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 20:46:48.665 | {'loss': 0.6052, 'grad_norm': 13.813791275024414, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 20:47:03.920 | {'loss': 0.6664, 'grad_norm': 14.240033149719238, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 20:47:19.646 | {'loss': 0.532, 'grad_norm': 7.697667121887207, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 20:47:34.794 | {'loss': 0.6134, 'grad_norm': 11.07794189453125, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 20:47:56.943 | {'loss': 0.5356, 'grad_norm': 10.267436027526855, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 20:48:12.231 | {'loss': 0.6222, 'grad_norm': 11.261794090270996, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 20:48:27.617 | {'loss': 0.5558, 'grad_norm': 10.20438003540039, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 20:48:42.816 | {'loss': 0.5848, 'grad_norm': 10.042865753173828, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 20:49:04.717 | {'loss': 0.6641, 'grad_norm': 10.495086669921875, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 20:49:20.405 | {'loss': 0.5671, 'grad_norm': 6.800368785858154, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 20:49:35.975 | {'loss': 0.4832, 'grad_norm': 7.552757263183594, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 20:49:51.742 | {'loss': 0.7538, 'grad_norm': 13.479958534240723, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 20:50:07.283 | {'loss': 0.5471, 'grad_norm': 8.563376426696777, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 20:50:22.924 | {'loss': 0.4216, 'grad_norm': 10.003339767456055, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 20:50:45.429 | {'loss': 0.338, 'grad_norm': 9.090795516967773, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 20:51:00.566 | {'loss': 0.4084, 'grad_norm': 8.460464477539062, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 20:51:15.841 | {'loss': 0.421, 'grad_norm': 12.381929397583008, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 20:51:31.464 | {'loss': 0.3445, 'grad_norm': 7.836376190185547, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 20:51:53.108 | {'loss': 0.3783, 'grad_norm': 9.256671905517578, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 20:52:08.382 | {'loss': 0.3853, 'grad_norm': 9.403131484985352, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 20:52:24.028 | {'loss': 0.2893, 'grad_norm': 5.405806064605713, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 20:52:38.688 | {'loss': 0.3769, 'grad_norm': 5.863893985748291, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 20:53:00.334 | {'loss': 0.4374, 'grad_norm': 5.99196195602417, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 20:53:15.081 | {'loss': 0.4083, 'grad_norm': 10.58320426940918, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 20:53:30.003 | {'loss': 0.3203, 'grad_norm': 7.879678726196289, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 20:53:45.422 | {'loss': 0.309, 'grad_norm': 9.215420722961426, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 20:54:06.788 | {'loss': 0.3595, 'grad_norm': 5.392794609069824, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 20:54:22.343 | {'loss': 0.3851, 'grad_norm': 9.008387565612793, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 20:54:37.524 | {'loss': 0.4261, 'grad_norm': 9.847879409790039, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 20:54:52.899 | {'loss': 0.3552, 'grad_norm': 9.816767692565918, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 20:55:08.369 | {'loss': 0.3635, 'grad_norm': 8.637984275817871, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 20:55:29.624 | {'loss': 0.4961, 'grad_norm': 9.968945503234863, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 20:55:44.259 | {'loss': 0.3363, 'grad_norm': 6.867362022399902, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 20:55:59.440 | {'loss': 0.1983, 'grad_norm': 5.24782133102417, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 20:56:14.299 | {'loss': 0.2015, 'grad_norm': 6.721271991729736, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 20:56:29.901 | {'loss': 0.229, 'grad_norm': 9.239616394042969, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 20:56:51.582 | {'loss': 0.2345, 'grad_norm': 7.795457363128662, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 20:57:06.753 | {'loss': 0.216, 'grad_norm': 5.450169086456299, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 20:57:22.059 | {'loss': 0.2254, 'grad_norm': 5.805490970611572, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 20:57:37.501 | {'loss': 0.2674, 'grad_norm': 7.59702730178833, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 20:57:58.829 | {'loss': 0.2185, 'grad_norm': 6.212044715881348, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 20:58:13.700 | {'loss': 0.2372, 'grad_norm': 5.26966667175293, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 20:58:28.884 | {'loss': 0.2609, 'grad_norm': 6.283969402313232, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 20:58:43.766 | {'loss': 0.3155, 'grad_norm': 6.516951084136963, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 20:59:05.495 | {'loss': 0.2252, 'grad_norm': 5.1674957275390625, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 20:59:20.925 | {'loss': 0.2434, 'grad_norm': 3.978562355041504, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 20:59:36.459 | {'loss': 0.3026, 'grad_norm': 6.635056495666504, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 20:59:51.903 | {'loss': 0.2579, 'grad_norm': 5.375588893890381, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 21:00:13.219 | {'loss': 0.1748, 'grad_norm': 4.867511749267578, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 21:00:28.540 | {'loss': 0.2313, 'grad_norm': 5.3250908851623535, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 21:00:43.459 | {'loss': 0.2155, 'grad_norm': 5.8811821937561035, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 21:00:58.821 | {'loss': 0.2346, 'grad_norm': 5.066662788391113, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 21:01:20.439 | {'loss': 0.2238, 'grad_norm': 4.511116027832031, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 21:01:35.529 | {'loss': 0.1427, 'grad_norm': 3.985224723815918, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 21:01:50.780 | {'loss': 0.1345, 'grad_norm': 5.342280387878418, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 21:02:06.153 | {'loss': 0.1323, 'grad_norm': 3.4850685596466064, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 21:02:28.243 | {'loss': 0.1334, 'grad_norm': 2.218194007873535, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 21:02:43.620 | {'loss': 0.1486, 'grad_norm': 4.9182538986206055, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 21:02:58.935 | {'loss': 0.184, 'grad_norm': 3.890676259994507, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 21:03:13.798 | {'loss': 0.1522, 'grad_norm': 6.100178241729736, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 21:03:29.092 | {'loss': 0.1557, 'grad_norm': 3.8485889434814453, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 21:03:50.665 | {'loss': 0.1334, 'grad_norm': 3.4799792766571045, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 21:04:05.720 | {'loss': 0.1467, 'grad_norm': 4.2299370765686035, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 21:04:20.936 | {'loss': 0.147, 'grad_norm': 3.6711790561676025, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 21:04:36.090 | {'loss': 0.1522, 'grad_norm': 6.50813627243042, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 21:04:58.021 | {'loss': 0.1555, 'grad_norm': 2.934800624847412, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-25 21:05:13.317 | {'loss': 0.1493, 'grad_norm': 7.060387134552002, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-25 21:05:28.972 | {'loss': 0.1569, 'grad_norm': 4.980377197265625, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-25 21:05:44.080 | {'loss': 0.1798, 'grad_norm': 3.246778726577759, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-25 21:06:05.911 | {'loss': 0.1745, 'grad_norm': 4.171320915222168, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-25 21:06:20.879 | {'loss': 0.1344, 'grad_norm': 3.6769332885742188, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-25 21:06:36.096 | {'loss': 0.1282, 'grad_norm': 3.429110288619995, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-25 21:06:51.370 | {'loss': 0.121, 'grad_norm': 3.742112398147583, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-25 21:06:51.371 | {'train_runtime': 1683.6922, 'train_samples_per_second': 1.188, 'train_steps_per_second': 0.594, 'train_loss': 0.4677039581537247, 'epoch': 5.0}
2025-05-25 21:07:02.475 | INFO :      Sent reply
2025-05-25 21:13:11.152 | INFO :      
2025-05-25 21:13:11.152 | INFO :      Received: evaluate message 52f6d8fd-1f37-4788-b024-82c123d65edd
2025-05-25 21:13:27.368 | {'eval_loss': 2.8519692420959473, 'eval_runtime': 9.3557, 'eval_samples_per_second': 10.689, 'eval_steps_per_second': 1.39, 'epoch': 5.0}
2025-05-25 21:13:27.378 | INFO :      Sent reply
2025-05-25 21:13:36.533 | INFO :      
2025-05-25 21:13:36.533 | INFO :      Received: train message 8a097c29-b824-452a-a561-d8fdd89a957f
2025-05-25 21:14:08.704 | {'loss': 0.4262, 'grad_norm': 6.749914169311523, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 21:14:30.841 | {'loss': 0.5584, 'grad_norm': 10.721700668334961, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 21:14:45.934 | {'loss': 0.6047, 'grad_norm': 10.40808391571045, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 21:15:01.764 | {'loss': 0.5101, 'grad_norm': 7.0561041831970215, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 21:15:17.452 | {'loss': 0.6208, 'grad_norm': 12.714171409606934, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 21:15:40.853 | {'loss': 0.6721, 'grad_norm': 5.953378677368164, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 21:15:56.627 | {'loss': 0.6287, 'grad_norm': 13.2477388381958, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 21:16:11.927 | {'loss': 0.6848, 'grad_norm': 16.2735538482666, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 21:16:33.931 | {'loss': 0.6308, 'grad_norm': 4.638618469238281, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 21:16:49.089 | {'loss': 0.7171, 'grad_norm': 14.89277172088623, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 21:17:04.551 | {'loss': 0.7061, 'grad_norm': 13.471258163452148, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 21:17:19.435 | {'loss': 0.6781, 'grad_norm': 4.6405816078186035, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 21:17:35.488 | {'loss': 0.8005, 'grad_norm': 11.51294994354248, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 21:17:57.147 | {'loss': 0.8044, 'grad_norm': 12.940126419067383, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 21:18:12.549 | {'loss': 0.779, 'grad_norm': 11.612993240356445, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 21:18:28.028 | {'loss': 0.6624, 'grad_norm': 14.051843643188477, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 21:18:42.865 | {'loss': 0.6187, 'grad_norm': 12.313908576965332, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 21:18:57.976 | {'loss': 0.7123, 'grad_norm': 14.269318580627441, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 21:19:19.447 | {'loss': 0.8708, 'grad_norm': 13.585780143737793, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 21:19:34.902 | {'loss': 0.8458, 'grad_norm': 6.477047920227051, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 21:19:50.035 | {'loss': 0.303, 'grad_norm': 7.686037063598633, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 21:20:05.691 | {'loss': 0.4181, 'grad_norm': 5.874484539031982, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 21:20:21.065 | {'loss': 0.4238, 'grad_norm': 11.020748138427734, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 21:20:43.427 | {'loss': 0.3881, 'grad_norm': 10.959973335266113, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 21:20:58.803 | {'loss': 0.455, 'grad_norm': 12.223723411560059, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 21:21:14.072 | {'loss': 0.5371, 'grad_norm': 11.855189323425293, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 21:21:29.501 | {'loss': 0.4751, 'grad_norm': 6.29410457611084, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 21:21:51.249 | {'loss': 0.4398, 'grad_norm': 11.723645210266113, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 21:22:06.763 | {'loss': 0.4733, 'grad_norm': 13.381534576416016, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 21:22:21.914 | {'loss': 0.3839, 'grad_norm': 7.234394550323486, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 21:22:37.642 | {'loss': 0.4337, 'grad_norm': 7.994179725646973, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 21:22:53.039 | {'loss': 0.4051, 'grad_norm': 10.246818542480469, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 21:23:15.133 | {'loss': 0.4303, 'grad_norm': 11.59349250793457, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 21:23:30.533 | {'loss': 0.4326, 'grad_norm': 10.40674114227295, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 21:23:45.711 | {'loss': 0.4666, 'grad_norm': 10.714971542358398, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 21:24:01.001 | {'loss': 0.4948, 'grad_norm': 11.12027359008789, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 21:24:16.105 | {'loss': 0.4367, 'grad_norm': 6.99176025390625, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 21:24:37.892 | {'loss': 0.3533, 'grad_norm': 9.269238471984863, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 21:24:52.980 | {'loss': 0.5389, 'grad_norm': 9.947687149047852, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 21:25:08.395 | {'loss': 0.394, 'grad_norm': 8.389127731323242, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 21:25:23.675 | {'loss': 0.3048, 'grad_norm': 8.035978317260742, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 21:25:46.449 | {'loss': 0.2709, 'grad_norm': 5.987053394317627, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 21:26:02.084 | {'loss': 0.303, 'grad_norm': 9.316372871398926, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 21:26:17.537 | {'loss': 0.3567, 'grad_norm': 13.405367851257324, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 21:26:32.653 | {'loss': 0.2783, 'grad_norm': 7.900206089019775, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 21:26:47.737 | {'loss': 0.2891, 'grad_norm': 10.300435066223145, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 21:27:09.574 | {'loss': 0.3214, 'grad_norm': 9.944003105163574, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 21:27:24.628 | {'loss': 0.2323, 'grad_norm': 4.73088264465332, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 21:27:40.284 | {'loss': 0.2438, 'grad_norm': 4.9915571212768555, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 21:27:55.686 | {'loss': 0.3226, 'grad_norm': 6.530329704284668, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 21:28:18.011 | {'loss': 0.3071, 'grad_norm': 7.17778205871582, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 21:28:33.708 | {'loss': 0.2437, 'grad_norm': 9.543686866760254, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 21:28:48.687 | {'loss': 0.2457, 'grad_norm': 10.699952125549316, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 21:29:04.302 | {'loss': 0.2669, 'grad_norm': 6.104480743408203, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 21:29:25.754 | {'loss': 0.2728, 'grad_norm': 8.860651969909668, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 21:29:40.959 | {'loss': 0.3103, 'grad_norm': 9.31041145324707, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 21:29:56.540 | {'loss': 0.2798, 'grad_norm': 7.93222713470459, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 21:30:12.214 | {'loss': 0.2701, 'grad_norm': 7.63287353515625, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 21:30:34.427 | {'loss': 0.3871, 'grad_norm': 8.919721603393555, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 21:30:49.711 | {'loss': 0.2633, 'grad_norm': 6.2032976150512695, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 21:31:05.066 | {'loss': 0.1768, 'grad_norm': 5.64354944229126, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 21:31:19.916 | {'loss': 0.1713, 'grad_norm': 5.951045989990234, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 21:31:35.321 | {'loss': 0.182, 'grad_norm': 6.51003885269165, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 21:31:50.399 | {'loss': 0.1818, 'grad_norm': 5.840435028076172, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 21:32:12.799 | {'loss': 0.1708, 'grad_norm': 4.668184757232666, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 21:32:28.083 | {'loss': 0.1661, 'grad_norm': 6.2991251945495605, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 21:32:43.820 | {'loss': 0.2305, 'grad_norm': 6.342964172363281, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 21:32:58.766 | {'loss': 0.1891, 'grad_norm': 5.148128509521484, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 21:33:20.757 | {'loss': 0.2035, 'grad_norm': 5.319882869720459, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 21:33:36.064 | {'loss': 0.2007, 'grad_norm': 5.436556339263916, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 21:33:50.999 | {'loss': 0.2276, 'grad_norm': 5.824322700500488, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 21:34:06.253 | {'loss': 0.1655, 'grad_norm': 4.005163669586182, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 21:34:21.702 | {'loss': 0.1881, 'grad_norm': 4.237560272216797, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 21:34:37.562 | {'loss': 0.2312, 'grad_norm': 8.263808250427246, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 21:34:52.932 | {'loss': 0.2027, 'grad_norm': 4.81687593460083, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 21:35:14.937 | {'loss': 0.1526, 'grad_norm': 2.904627561569214, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 21:35:30.268 | {'loss': 0.1707, 'grad_norm': 4.429009437561035, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 21:35:45.472 | {'loss': 0.1844, 'grad_norm': 7.718590259552002, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 21:36:00.706 | {'loss': 0.1803, 'grad_norm': 4.677075386047363, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 21:36:16.014 | {'loss': 0.1902, 'grad_norm': 4.038958549499512, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 21:36:37.925 | {'loss': 0.1097, 'grad_norm': 3.621473789215088, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 21:36:53.278 | {'loss': 0.117, 'grad_norm': 4.009033203125, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 21:37:08.854 | {'loss': 0.1131, 'grad_norm': 2.8659489154815674, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 21:37:24.437 | {'loss': 0.1228, 'grad_norm': 1.5162140130996704, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 21:37:47.017 | {'loss': 0.1167, 'grad_norm': 4.193592071533203, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 21:38:02.290 | {'loss': 0.1311, 'grad_norm': 3.190126657485962, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 21:38:17.504 | {'loss': 0.1237, 'grad_norm': 5.094934463500977, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 21:38:32.776 | {'loss': 0.1332, 'grad_norm': 3.9580705165863037, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 21:38:48.168 | {'loss': 0.1135, 'grad_norm': 3.219623327255249, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 21:39:03.555 | {'loss': 0.1232, 'grad_norm': 3.3262648582458496, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 21:39:25.178 | {'loss': 0.122, 'grad_norm': 3.687027931213379, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 21:39:40.499 | {'loss': 0.1226, 'grad_norm': 5.252934455871582, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 21:39:55.446 | {'loss': 0.1247, 'grad_norm': 2.138849973678589, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-25 21:40:10.851 | {'loss': 0.1224, 'grad_norm': 4.117625713348389, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-25 21:40:32.908 | {'loss': 0.125, 'grad_norm': 3.448273181915283, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-25 21:40:48.302 | {'loss': 0.1279, 'grad_norm': 2.527925729751587, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-25 21:41:03.464 | {'loss': 0.1444, 'grad_norm': 3.9817147254943848, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-25 21:41:18.643 | {'loss': 0.111, 'grad_norm': 2.9658939838409424, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-25 21:41:40.411 | {'loss': 0.1033, 'grad_norm': 2.8059818744659424, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-25 21:41:55.264 | {'loss': 0.0965, 'grad_norm': 3.1707751750946045, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-25 21:41:55.264 | {'train_runtime': 1694.0274, 'train_samples_per_second': 1.181, 'train_steps_per_second': 0.59, 'train_loss': 0.3415399594306946, 'epoch': 5.0}
2025-05-25 21:42:04.526 | INFO :      Sent reply
2025-05-25 21:48:12.034 | INFO :      
2025-05-25 21:48:12.034 | INFO :      Received: evaluate message 9820c538-caf3-4936-970a-49d3a9c4db8c
2025-05-25 21:48:25.099 | {'eval_loss': 2.973820209503174, 'eval_runtime': 10.4214, 'eval_samples_per_second': 9.596, 'eval_steps_per_second': 1.247, 'epoch': 5.0}
2025-05-25 21:48:25.116 | INFO :      Sent reply
2025-05-25 21:48:35.735 | INFO :      
2025-05-25 21:48:35.736 | INFO :      Received: train message 2c711343-a93b-402a-a806-ee18a0b23098
2025-05-25 21:48:55.959 | {'loss': 0.2586, 'grad_norm': 5.121274948120117, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 21:49:11.403 | {'loss': 0.3648, 'grad_norm': 17.67926788330078, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 21:49:26.233 | {'loss': 0.4155, 'grad_norm': 7.339339256286621, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 21:49:48.392 | {'loss': 0.3546, 'grad_norm': 6.843008995056152, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 21:50:03.738 | {'loss': 0.4115, 'grad_norm': 11.950374603271484, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 21:50:19.328 | {'loss': 0.5205, 'grad_norm': 5.8414387702941895, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 21:50:34.307 | {'loss': 0.4252, 'grad_norm': 12.460345268249512, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 21:50:55.928 | {'loss': 0.489, 'grad_norm': 14.446380615234375, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 21:51:11.159 | {'loss': 0.4196, 'grad_norm': 3.2636358737945557, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 21:51:25.851 | {'loss': 0.4961, 'grad_norm': 11.018088340759277, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 21:51:40.996 | {'loss': 0.5064, 'grad_norm': 11.624455451965332, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 21:52:02.478 | {'loss': 0.4341, 'grad_norm': 4.106800556182861, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 21:52:18.107 | {'loss': 0.5583, 'grad_norm': 10.388516426086426, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 21:52:33.093 | {'loss': 0.5379, 'grad_norm': 10.630854606628418, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 21:52:55.071 | {'loss': 0.5564, 'grad_norm': 12.505346298217773, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 21:53:10.163 | {'loss': 0.4712, 'grad_norm': 11.968122482299805, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 21:53:25.270 | {'loss': 0.4485, 'grad_norm': 13.110652923583984, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 21:53:40.423 | {'loss': 0.5064, 'grad_norm': 12.530685424804688, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 21:54:02.122 | {'loss': 0.6159, 'grad_norm': 12.850412368774414, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 21:54:17.235 | {'loss': 0.5905, 'grad_norm': 6.363534927368164, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 21:54:32.313 | {'loss': 0.2615, 'grad_norm': 6.224853515625, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 21:54:47.800 | {'loss': 0.3677, 'grad_norm': 8.62647533416748, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 21:55:09.806 | {'loss': 0.3305, 'grad_norm': 10.19165325164795, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 21:55:24.966 | {'loss': 0.3287, 'grad_norm': 10.225310325622559, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 21:55:40.129 | {'loss': 0.3639, 'grad_norm': 10.07332992553711, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 21:55:55.179 | {'loss': 0.446, 'grad_norm': 10.763679504394531, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 21:56:10.217 | {'loss': 0.3712, 'grad_norm': 8.732902526855469, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 21:56:31.630 | {'loss': 0.3407, 'grad_norm': 9.76470947265625, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 21:56:46.969 | {'loss': 0.3482, 'grad_norm': 11.164403915405273, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 21:57:02.354 | {'loss': 0.2965, 'grad_norm': 6.102956771850586, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 21:57:17.920 | {'loss': 0.3888, 'grad_norm': 9.845056533813477, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 21:57:33.270 | {'loss': 0.3008, 'grad_norm': 9.115116119384766, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 21:57:55.158 | {'loss': 0.3694, 'grad_norm': 12.946778297424316, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 21:58:10.507 | {'loss': 0.3708, 'grad_norm': 10.30150032043457, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 21:58:25.626 | {'loss': 0.3746, 'grad_norm': 10.514674186706543, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 21:58:40.801 | {'loss': 0.3866, 'grad_norm': 9.761385917663574, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 21:59:02.571 | {'loss': 0.3482, 'grad_norm': 8.168743133544922, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 21:59:17.987 | {'loss': 0.2942, 'grad_norm': 6.507997035980225, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 21:59:33.408 | {'loss': 0.4308, 'grad_norm': 11.076987266540527, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 21:59:49.040 | {'loss': 0.3323, 'grad_norm': 7.5305328369140625, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 22:00:04.775 | {'loss': 0.2433, 'grad_norm': 10.037712097167969, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 22:00:26.218 | {'loss': 0.2498, 'grad_norm': 7.567551136016846, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 22:00:41.452 | {'loss': 0.2472, 'grad_norm': 7.7851715087890625, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 22:00:56.581 | {'loss': 0.2934, 'grad_norm': 13.204887390136719, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 22:01:11.710 | {'loss': 0.2221, 'grad_norm': 6.477290630340576, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 22:01:33.102 | {'loss': 0.2568, 'grad_norm': 7.5761566162109375, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 22:01:48.322 | {'loss': 0.281, 'grad_norm': 8.891853332519531, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 22:02:03.475 | {'loss': 0.2251, 'grad_norm': 3.273026704788208, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 22:02:18.967 | {'loss': 0.2318, 'grad_norm': 5.260710716247559, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 22:02:34.141 | {'loss': 0.3031, 'grad_norm': 4.9757399559021, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 22:02:55.977 | {'loss': 0.2289, 'grad_norm': 5.937971115112305, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 22:03:11.128 | {'loss': 0.2182, 'grad_norm': 9.207576751708984, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 22:03:26.367 | {'loss': 0.2127, 'grad_norm': 10.73118782043457, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 22:03:41.490 | {'loss': 0.2308, 'grad_norm': 5.147143363952637, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 22:04:03.059 | {'loss': 0.2305, 'grad_norm': 8.414896965026855, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 22:04:18.469 | {'loss': 0.2696, 'grad_norm': 9.969877243041992, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 22:04:34.032 | {'loss': 0.2171, 'grad_norm': 6.698562145233154, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 22:04:49.309 | {'loss': 0.2115, 'grad_norm': 7.540609359741211, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 22:05:11.605 | {'loss': 0.3017, 'grad_norm': 7.618291854858398, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 22:05:27.424 | {'loss': 0.2142, 'grad_norm': 5.677737236022949, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 22:05:42.230 | {'loss': 0.1473, 'grad_norm': 3.653688430786133, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 22:05:57.145 | {'loss': 0.1366, 'grad_norm': 4.49377965927124, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 22:06:12.150 | {'loss': 0.1544, 'grad_norm': 4.475475311279297, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 22:06:33.784 | {'loss': 0.1637, 'grad_norm': 5.918240547180176, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 22:06:49.144 | {'loss': 0.1647, 'grad_norm': 5.622046947479248, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 22:07:04.893 | {'loss': 0.158, 'grad_norm': 4.571774005889893, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 22:07:20.583 | {'loss': 0.1749, 'grad_norm': 6.385345458984375, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 22:07:35.487 | {'loss': 0.1464, 'grad_norm': 4.178905487060547, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 22:07:57.343 | {'loss': 0.167, 'grad_norm': 4.6804728507995605, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 22:08:12.215 | {'loss': 0.1503, 'grad_norm': 4.435722827911377, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 22:08:27.251 | {'loss': 0.2033, 'grad_norm': 6.876832008361816, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 22:08:42.359 | {'loss': 0.1507, 'grad_norm': 4.029955863952637, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 22:09:04.003 | {'loss': 0.1682, 'grad_norm': 4.010560035705566, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 22:09:19.531 | {'loss': 0.1897, 'grad_norm': 5.147141933441162, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 22:09:34.749 | {'loss': 0.1733, 'grad_norm': 4.73011589050293, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 22:09:50.316 | {'loss': 0.1351, 'grad_norm': 4.259960174560547, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 22:10:11.836 | {'loss': 0.1621, 'grad_norm': 5.599586486816406, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 22:10:27.221 | {'loss': 0.1553, 'grad_norm': 3.843193769454956, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 22:10:42.442 | {'loss': 0.1535, 'grad_norm': 2.3627207279205322, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 22:10:57.555 | {'loss': 0.1577, 'grad_norm': 2.2915167808532715, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 22:11:19.264 | {'loss': 0.0934, 'grad_norm': 3.1170217990875244, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 22:11:34.359 | {'loss': 0.108, 'grad_norm': 3.8622255325317383, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 22:11:49.765 | {'loss': 0.1088, 'grad_norm': 2.9999570846557617, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 22:12:05.002 | {'loss': 0.101, 'grad_norm': 2.3464343547821045, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 22:12:20.705 | {'loss': 0.1068, 'grad_norm': 3.419205665588379, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 22:12:42.656 | {'loss': 0.1173, 'grad_norm': 2.6378495693206787, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 22:12:57.843 | {'loss': 0.1062, 'grad_norm': 6.223183631896973, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 22:13:12.860 | {'loss': 0.1019, 'grad_norm': 2.56685471534729, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 22:13:28.315 | {'loss': 0.1023, 'grad_norm': 3.4091172218322754, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 22:13:49.498 | {'loss': 0.099, 'grad_norm': 2.614471435546875, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 22:14:04.469 | {'loss': 0.1041, 'grad_norm': 4.209368705749512, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 22:14:19.834 | {'loss': 0.1154, 'grad_norm': 5.8094401359558105, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 22:14:35.038 | {'loss': 0.0965, 'grad_norm': 2.850389003753662, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-25 22:14:50.463 | {'loss': 0.114, 'grad_norm': 5.983330249786377, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-25 22:15:05.576 | {'loss': 0.1143, 'grad_norm': 4.391816139221191, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-25 22:15:20.925 | {'loss': 0.1125, 'grad_norm': 2.1593379974365234, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-25 22:15:42.375 | {'loss': 0.1228, 'grad_norm': 3.211735963821411, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-25 22:15:57.473 | {'loss': 0.0917, 'grad_norm': 2.3765225410461426, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-25 22:16:12.295 | {'loss': 0.0921, 'grad_norm': 2.8355438709259033, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-25 22:16:27.708 | {'loss': 0.0964, 'grad_norm': 3.573742628097534, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-25 22:16:27.708 | {'train_runtime': 1670.278, 'train_samples_per_second': 1.197, 'train_steps_per_second': 0.599, 'train_loss': 0.2663826305270195, 'epoch': 5.0}
2025-05-25 22:16:37.709 | INFO :      Sent reply
2025-05-25 22:22:49.776 | INFO :      
2025-05-25 22:22:49.776 | INFO :      Received: evaluate message 91b958d6-eba5-4dad-b7d7-5351ba190124
2025-05-25 22:23:06.772 | {'eval_loss': 3.067519187927246, 'eval_runtime': 9.9257, 'eval_samples_per_second': 10.075, 'eval_steps_per_second': 1.31, 'epoch': 5.0}
2025-05-25 22:23:06.773 | INFO :      Sent reply
2025-05-25 22:23:16.662 | INFO :      
2025-05-25 22:23:16.662 | INFO :      Received: train message 136963cf-8925-4182-a8d3-e1341122bf64
2025-05-25 22:23:38.960 | {'loss': 0.1663, 'grad_norm': 5.11134147644043, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 22:24:01.012 | {'loss': 0.2389, 'grad_norm': 8.19604206085205, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 22:24:16.098 | {'loss': 0.2909, 'grad_norm': 6.0695037841796875, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 22:24:31.680 | {'loss': 0.2778, 'grad_norm': 6.996474742889404, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 22:24:47.124 | {'loss': 0.314, 'grad_norm': 8.043644905090332, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 22:25:02.788 | {'loss': 0.3568, 'grad_norm': 5.238731384277344, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 22:25:25.040 | {'loss': 0.3235, 'grad_norm': 9.47681999206543, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 22:25:40.033 | {'loss': 0.3725, 'grad_norm': 12.131753921508789, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 22:25:55.317 | {'loss': 0.3173, 'grad_norm': 3.0143702030181885, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 22:26:10.532 | {'loss': 0.3774, 'grad_norm': 9.701017379760742, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 22:26:25.950 | {'loss': 0.3594, 'grad_norm': 10.022834777832031, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 22:26:47.780 | {'loss': 0.341, 'grad_norm': 2.8868000507354736, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 22:27:02.906 | {'loss': 0.4271, 'grad_norm': 8.554805755615234, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 22:27:18.122 | {'loss': 0.4117, 'grad_norm': 9.362197875976562, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 22:27:39.744 | {'loss': 0.4472, 'grad_norm': 9.935446739196777, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 22:27:55.172 | {'loss': 0.3686, 'grad_norm': 12.312012672424316, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 22:28:10.356 | {'loss': 0.3508, 'grad_norm': 10.472776412963867, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 22:28:25.837 | {'loss': 0.3837, 'grad_norm': 10.918966293334961, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 22:28:47.662 | {'loss': 0.4496, 'grad_norm': 10.90581226348877, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 22:29:03.321 | {'loss': 0.4069, 'grad_norm': 5.077646732330322, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 22:29:18.243 | {'loss': 0.2131, 'grad_norm': 5.802306652069092, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 22:29:33.774 | {'loss': 0.3317, 'grad_norm': 16.822975158691406, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 22:29:49.326 | {'loss': 0.3161, 'grad_norm': 13.00585651397705, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 22:30:11.352 | {'loss': 0.28, 'grad_norm': 10.034529685974121, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 22:30:26.679 | {'loss': 0.3133, 'grad_norm': 8.757464408874512, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 22:30:41.759 | {'loss': 0.398, 'grad_norm': 8.943046569824219, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 22:30:56.995 | {'loss': 0.3761, 'grad_norm': 11.252348899841309, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 22:31:12.013 | {'loss': 0.2926, 'grad_norm': 11.168627738952637, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 22:31:34.002 | {'loss': 0.2831, 'grad_norm': 10.922710418701172, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 22:31:49.166 | {'loss': 0.2816, 'grad_norm': 5.055026531219482, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 22:32:04.509 | {'loss': 0.2987, 'grad_norm': 7.716438293457031, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 22:32:20.066 | {'loss': 0.2721, 'grad_norm': 8.507737159729004, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 22:32:35.551 | {'loss': 0.3112, 'grad_norm': 9.256353378295898, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 22:32:57.380 | {'loss': 0.2982, 'grad_norm': 9.97745418548584, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 22:33:12.201 | {'loss': 0.3298, 'grad_norm': 8.614777565002441, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 22:33:27.536 | {'loss': 0.3319, 'grad_norm': 8.489884376525879, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 22:33:48.961 | {'loss': 0.2912, 'grad_norm': 5.653265953063965, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 22:34:04.136 | {'loss': 0.2504, 'grad_norm': 5.374453544616699, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 22:34:19.117 | {'loss': 0.3512, 'grad_norm': 7.364628791809082, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 22:34:34.821 | {'loss': 0.2677, 'grad_norm': 6.455596923828125, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 22:34:50.110 | {'loss': 0.2303, 'grad_norm': 6.177743434906006, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 22:35:12.053 | {'loss': 0.2051, 'grad_norm': 5.575840473175049, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 22:35:27.396 | {'loss': 0.2231, 'grad_norm': 8.102538108825684, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 22:35:42.433 | {'loss': 0.2463, 'grad_norm': 14.261401176452637, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 22:35:57.784 | {'loss': 0.2204, 'grad_norm': 6.564382076263428, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 22:36:12.913 | {'loss': 0.1963, 'grad_norm': 5.905519485473633, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 22:36:34.821 | {'loss': 0.232, 'grad_norm': 9.827392578125, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 22:36:49.919 | {'loss': 0.2026, 'grad_norm': 2.386038303375244, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 22:37:05.622 | {'loss': 0.2034, 'grad_norm': 5.919643402099609, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 22:37:21.207 | {'loss': 0.2361, 'grad_norm': 5.449352264404297, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 22:37:37.157 | {'loss': 0.212, 'grad_norm': 7.391364574432373, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 22:37:59.651 | {'loss': 0.178, 'grad_norm': 5.6664628982543945, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 22:38:14.906 | {'loss': 0.1634, 'grad_norm': 7.766798496246338, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 22:38:30.361 | {'loss': 0.2087, 'grad_norm': 6.5981903076171875, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 22:38:45.513 | {'loss': 0.2174, 'grad_norm': 7.298498153686523, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 22:39:00.932 | {'loss': 0.228, 'grad_norm': 8.36398983001709, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 22:39:22.813 | {'loss': 0.2028, 'grad_norm': 6.8173933029174805, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 22:39:37.884 | {'loss': 0.1955, 'grad_norm': 9.229121208190918, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 22:39:53.410 | {'loss': 0.2756, 'grad_norm': 7.44622278213501, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 22:40:09.025 | {'loss': 0.1997, 'grad_norm': 4.581223011016846, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 22:40:31.159 | {'loss': 0.1218, 'grad_norm': 3.8343052864074707, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 22:40:46.027 | {'loss': 0.1258, 'grad_norm': 8.474615097045898, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 22:41:01.871 | {'loss': 0.1401, 'grad_norm': 8.666425704956055, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 22:41:16.606 | {'loss': 0.1326, 'grad_norm': 5.124749660491943, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 22:41:31.883 | {'loss': 0.1332, 'grad_norm': 4.413046836853027, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 22:41:54.253 | {'loss': 0.1285, 'grad_norm': 3.6964588165283203, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 22:42:09.065 | {'loss': 0.1634, 'grad_norm': 5.87703800201416, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 22:42:24.499 | {'loss': 0.1326, 'grad_norm': 2.7626302242279053, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 22:42:40.055 | {'loss': 0.1517, 'grad_norm': 3.869605302810669, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 22:43:02.555 | {'loss': 0.1637, 'grad_norm': 5.210529327392578, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 22:43:17.673 | {'loss': 0.1789, 'grad_norm': 4.806942462921143, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 22:43:33.170 | {'loss': 0.1453, 'grad_norm': 3.720865488052368, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 22:43:48.527 | {'loss': 0.1434, 'grad_norm': 4.758774757385254, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 22:44:04.136 | {'loss': 0.1597, 'grad_norm': 5.047486305236816, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 22:44:26.130 | {'loss': 0.1669, 'grad_norm': 4.886326313018799, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 22:44:41.359 | {'loss': 0.12, 'grad_norm': 3.46254825592041, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 22:44:56.894 | {'loss': 0.1445, 'grad_norm': 6.25840425491333, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 22:45:11.813 | {'loss': 0.1362, 'grad_norm': 5.208824157714844, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 22:45:27.342 | {'loss': 0.1461, 'grad_norm': 4.180752754211426, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 22:45:49.780 | {'loss': 0.1425, 'grad_norm': 2.335155487060547, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 22:46:05.815 | {'loss': 0.0991, 'grad_norm': 2.3935673236846924, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 22:46:20.537 | {'loss': 0.0887, 'grad_norm': 4.119751453399658, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 22:46:35.780 | {'loss': 0.0958, 'grad_norm': 3.4873580932617188, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 22:46:50.708 | {'loss': 0.1016, 'grad_norm': 1.4405690431594849, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 22:47:12.439 | {'loss': 0.0997, 'grad_norm': 3.921616792678833, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 22:47:27.692 | {'loss': 0.1039, 'grad_norm': 2.531773567199707, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 22:47:42.735 | {'loss': 0.089, 'grad_norm': 3.0837035179138184, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 22:47:58.376 | {'loss': 0.1055, 'grad_norm': 4.257437705993652, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 22:48:14.072 | {'loss': 0.0912, 'grad_norm': 2.589367628097534, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 22:48:36.168 | {'loss': 0.0954, 'grad_norm': 2.835561752319336, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 22:48:51.487 | {'loss': 0.0977, 'grad_norm': 3.7833054065704346, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 22:49:07.120 | {'loss': 0.1046, 'grad_norm': 3.916599988937378, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 22:49:22.367 | {'loss': 0.0965, 'grad_norm': 2.0824382305145264, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-25 22:49:37.812 | {'loss': 0.0871, 'grad_norm': 2.2146739959716797, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-25 22:49:59.719 | {'loss': 0.1099, 'grad_norm': 3.1016716957092285, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-25 22:50:14.913 | {'loss': 0.0963, 'grad_norm': 1.6033904552459717, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-25 22:50:30.559 | {'loss': 0.1098, 'grad_norm': 2.9451942443847656, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-25 22:50:52.533 | {'loss': 0.091, 'grad_norm': 2.600757122039795, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-25 22:51:08.101 | {'loss': 0.0834, 'grad_norm': 1.6499184370040894, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-25 22:51:23.222 | {'loss': 0.0778, 'grad_norm': 2.575106143951416, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-25 22:51:23.223 | {'train_runtime': 1683.3836, 'train_samples_per_second': 1.188, 'train_steps_per_second': 0.594, 'train_loss': 0.22147003787755967, 'epoch': 5.0}
2025-05-25 22:51:34.699 | INFO :      Sent reply
2025-05-25 22:57:52.657 | INFO :      
2025-05-25 22:57:52.657 | INFO :      Received: evaluate message 44411faf-d860-4725-b534-7755cc0dd4da
2025-05-25 22:58:02.930 | {'eval_loss': 3.1668426990509033, 'eval_runtime': 3.6693, 'eval_samples_per_second': 27.253, 'eval_steps_per_second': 3.543, 'epoch': 5.0}
2025-05-25 22:58:02.934 | INFO :      Sent reply
2025-05-25 22:58:10.263 | INFO :      
2025-05-25 22:58:10.264 | INFO :      Received: train message b020e313-875b-4da8-8e1a-6a687b59ae03
2025-05-25 22:58:39.998 | {'loss': 0.1374, 'grad_norm': 4.386964321136475, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 22:58:55.594 | {'loss': 0.197, 'grad_norm': 7.862128734588623, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 22:59:11.234 | {'loss': 0.2273, 'grad_norm': 5.108699321746826, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 22:59:26.749 | {'loss': 0.2326, 'grad_norm': 6.22843074798584, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 22:59:49.770 | {'loss': 0.2685, 'grad_norm': 7.843670845031738, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 23:00:05.010 | {'loss': 0.2996, 'grad_norm': 4.524066925048828, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 23:00:20.632 | {'loss': 0.2604, 'grad_norm': 7.067529201507568, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 23:00:36.217 | {'loss': 0.3075, 'grad_norm': 8.945674896240234, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 23:00:57.699 | {'loss': 0.2329, 'grad_norm': 4.008421421051025, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 23:01:13.132 | {'loss': 0.3036, 'grad_norm': 8.63769245147705, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 23:01:28.965 | {'loss': 0.2928, 'grad_norm': 9.414413452148438, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 23:01:44.251 | {'loss': 0.2564, 'grad_norm': 2.631511926651001, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 23:02:06.971 | {'loss': 0.3433, 'grad_norm': 7.841973781585693, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 23:02:22.500 | {'loss': 0.3199, 'grad_norm': 8.036654472351074, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 23:02:38.795 | {'loss': 0.358, 'grad_norm': 7.525978088378906, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 23:03:00.624 | {'loss': 0.277, 'grad_norm': 8.546812057495117, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 23:03:15.558 | {'loss': 0.2591, 'grad_norm': 9.136515617370605, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 23:03:30.794 | {'loss': 0.2944, 'grad_norm': 10.734989166259766, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 23:03:46.291 | {'loss': 0.3482, 'grad_norm': 8.568245887756348, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 23:04:08.251 | {'loss': 0.329, 'grad_norm': 6.00908088684082, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 23:04:24.198 | {'loss': 0.2152, 'grad_norm': 8.044204711914062, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 23:04:40.019 | {'loss': 0.275, 'grad_norm': 4.343433380126953, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 23:05:02.146 | {'loss': 0.2817, 'grad_norm': 9.704197883605957, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 23:05:17.423 | {'loss': 0.2447, 'grad_norm': 11.07963752746582, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 23:05:32.346 | {'loss': 0.277, 'grad_norm': 9.355886459350586, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 23:05:47.291 | {'loss': 0.3413, 'grad_norm': 8.082982063293457, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 23:06:08.980 | {'loss': 0.2942, 'grad_norm': 7.1183600425720215, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 23:06:24.261 | {'loss': 0.2615, 'grad_norm': 11.366948127746582, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 23:06:39.537 | {'loss': 0.2663, 'grad_norm': 11.550898551940918, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 23:07:02.232 | {'loss': 0.253, 'grad_norm': 6.922087669372559, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 23:07:17.557 | {'loss': 0.2901, 'grad_norm': 8.87134075164795, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 23:07:32.836 | {'loss': 0.2143, 'grad_norm': 8.398926734924316, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 23:07:48.218 | {'loss': 0.302, 'grad_norm': 9.468415260314941, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 23:08:09.623 | {'loss': 0.2863, 'grad_norm': 7.088812351226807, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 23:08:24.619 | {'loss': 0.285, 'grad_norm': 8.701067924499512, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 23:08:40.064 | {'loss': 0.277, 'grad_norm': 7.869411468505859, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 23:08:55.387 | {'loss': 0.2764, 'grad_norm': 5.1940484046936035, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 23:09:10.455 | {'loss': 0.2329, 'grad_norm': 6.373309135437012, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 23:09:32.755 | {'loss': 0.3036, 'grad_norm': 7.193292140960693, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 23:09:48.168 | {'loss': 0.2324, 'grad_norm': 5.902826309204102, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 23:10:03.832 | {'loss': 0.1927, 'grad_norm': 7.83536434173584, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 23:10:19.135 | {'loss': 0.1713, 'grad_norm': 5.374063491821289, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 23:10:34.233 | {'loss': 0.1998, 'grad_norm': 6.531612873077393, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 23:10:55.782 | {'loss': 0.2378, 'grad_norm': 9.927777290344238, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 23:11:11.186 | {'loss': 0.1679, 'grad_norm': 6.883916854858398, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 23:11:26.393 | {'loss': 0.1858, 'grad_norm': 6.997128486633301, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 23:11:41.766 | {'loss': 0.2158, 'grad_norm': 7.35465669631958, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 23:11:57.275 | {'loss': 0.1697, 'grad_norm': 4.570623874664307, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 23:12:20.331 | {'loss': 0.1619, 'grad_norm': 4.661564826965332, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 23:12:35.881 | {'loss': 0.2517, 'grad_norm': 4.1166768074035645, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 23:12:51.174 | {'loss': 0.1655, 'grad_norm': 4.345484256744385, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 23:13:06.408 | {'loss': 0.1622, 'grad_norm': 5.969158172607422, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 23:13:28.104 | {'loss': 0.1596, 'grad_norm': 9.005258560180664, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 23:13:43.435 | {'loss': 0.1913, 'grad_norm': 4.318140506744385, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 23:13:58.626 | {'loss': 0.1828, 'grad_norm': 6.987645626068115, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 23:14:13.968 | {'loss': 0.202, 'grad_norm': 7.715946197509766, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 23:14:29.481 | {'loss': 0.2082, 'grad_norm': 6.679128170013428, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 23:14:52.170 | {'loss': 0.1762, 'grad_norm': 4.931264877319336, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 23:15:07.934 | {'loss': 0.2378, 'grad_norm': 5.637644290924072, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 23:15:23.205 | {'loss': 0.1826, 'grad_norm': 6.297121047973633, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 23:15:45.160 | {'loss': 0.122, 'grad_norm': 3.4093565940856934, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 23:16:00.490 | {'loss': 0.1179, 'grad_norm': 3.4387104511260986, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 23:16:16.420 | {'loss': 0.1328, 'grad_norm': 3.1623151302337646, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 23:16:31.226 | {'loss': 0.1327, 'grad_norm': 4.710324764251709, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 23:16:47.335 | {'loss': 0.1297, 'grad_norm': 5.642036437988281, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 23:17:09.561 | {'loss': 0.1241, 'grad_norm': 4.1500091552734375, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 23:17:25.418 | {'loss': 0.1478, 'grad_norm': 4.969529628753662, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 23:17:40.712 | {'loss': 0.1189, 'grad_norm': 2.3438096046447754, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 23:17:55.875 | {'loss': 0.1371, 'grad_norm': 3.104309320449829, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 23:18:18.159 | {'loss': 0.1474, 'grad_norm': 2.946678638458252, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 23:18:33.773 | {'loss': 0.1507, 'grad_norm': 2.9604623317718506, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 23:18:49.253 | {'loss': 0.1126, 'grad_norm': 5.004769802093506, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 23:19:04.839 | {'loss': 0.1366, 'grad_norm': 3.619811534881592, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 23:19:27.233 | {'loss': 0.1577, 'grad_norm': 6.132863521575928, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 23:19:42.534 | {'loss': 0.127, 'grad_norm': 4.5044145584106445, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 23:19:57.550 | {'loss': 0.1052, 'grad_norm': 3.473541021347046, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 23:20:13.037 | {'loss': 0.1253, 'grad_norm': 2.1678531169891357, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 23:20:34.686 | {'loss': 0.1322, 'grad_norm': 3.6524579524993896, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 23:20:49.864 | {'loss': 0.1224, 'grad_norm': 1.7146060466766357, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 23:21:05.158 | {'loss': 0.1353, 'grad_norm': 2.2009475231170654, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 23:21:27.680 | {'loss': 0.0915, 'grad_norm': 2.1269686222076416, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 23:21:43.594 | {'loss': 0.0837, 'grad_norm': 2.4294631481170654, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 23:21:59.056 | {'loss': 0.0813, 'grad_norm': 1.7381337881088257, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 23:22:14.641 | {'loss': 0.0982, 'grad_norm': 1.257704257965088, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 23:22:29.937 | {'loss': 0.0939, 'grad_norm': 2.323671817779541, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 23:22:45.387 | {'loss': 0.0964, 'grad_norm': 2.506321907043457, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 23:23:07.181 | {'loss': 0.0872, 'grad_norm': 2.7021005153656006, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 23:23:22.447 | {'loss': 0.0854, 'grad_norm': 2.7793984413146973, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 23:23:37.920 | {'loss': 0.0872, 'grad_norm': 2.3658597469329834, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 23:23:53.437 | {'loss': 0.0862, 'grad_norm': 2.718997001647949, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 23:24:15.624 | {'loss': 0.0926, 'grad_norm': 2.153049945831299, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 23:24:31.677 | {'loss': 0.0909, 'grad_norm': 3.74900484085083, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 23:24:47.503 | {'loss': 0.0935, 'grad_norm': 1.9529041051864624, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-25 23:25:03.151 | {'loss': 0.0903, 'grad_norm': 3.2614285945892334, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-25 23:25:25.208 | {'loss': 0.0983, 'grad_norm': 2.857651472091675, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-25 23:25:40.716 | {'loss': 0.0834, 'grad_norm': 2.245840072631836, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-25 23:25:56.442 | {'loss': 0.1043, 'grad_norm': 2.941906690597534, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-25 23:26:11.440 | {'loss': 0.0823, 'grad_norm': 1.8412007093429565, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-25 23:26:26.435 | {'loss': 0.0771, 'grad_norm': 1.8643866777420044, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-25 23:26:41.689 | {'loss': 0.0809, 'grad_norm': 2.294753074645996, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-25 23:26:41.689 | {'train_runtime': 1709.5697, 'train_samples_per_second': 1.17, 'train_steps_per_second': 0.585, 'train_loss': 0.1917749326825142, 'epoch': 5.0}
2025-05-25 23:26:52.809 | INFO :      Sent reply
2025-05-25 23:33:14.326 | INFO :      
2025-05-25 23:33:14.326 | INFO :      Received: evaluate message ad69b12c-f76c-4b5d-922f-b1f7d46ff025
2025-05-25 23:33:30.904 | {'eval_loss': 3.244565486907959, 'eval_runtime': 10.9147, 'eval_samples_per_second': 9.162, 'eval_steps_per_second': 1.191, 'epoch': 5.0}
2025-05-25 23:33:30.906 | INFO :      Sent reply
2025-05-25 23:33:40.490 | INFO :      
2025-05-25 23:33:40.490 | INFO :      Received: train message f7faf636-a605-43d8-b43f-d4ba1a3a20ec
2025-05-25 23:34:15.487 | {'loss': 0.1119, 'grad_norm': 4.061059474945068, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 23:34:30.678 | {'loss': 0.1901, 'grad_norm': 12.298357963562012, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 23:34:46.308 | {'loss': 0.1869, 'grad_norm': 5.053217887878418, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 23:35:08.755 | {'loss': 0.1996, 'grad_norm': 6.448803424835205, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 23:35:24.240 | {'loss': 0.2145, 'grad_norm': 9.55235767364502, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 23:35:39.624 | {'loss': 0.2477, 'grad_norm': 4.344143390655518, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 23:35:54.907 | {'loss': 0.2078, 'grad_norm': 7.9328413009643555, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 23:36:10.160 | {'loss': 0.2624, 'grad_norm': 8.978545188903809, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 23:36:31.850 | {'loss': 0.193, 'grad_norm': 2.2609026432037354, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 23:36:47.181 | {'loss': 0.2242, 'grad_norm': 7.757925987243652, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 23:37:02.432 | {'loss': 0.2329, 'grad_norm': 7.497243881225586, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 23:37:18.039 | {'loss': 0.1997, 'grad_norm': 3.1052305698394775, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 23:37:40.280 | {'loss': 0.2545, 'grad_norm': 7.352625846862793, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 23:37:55.666 | {'loss': 0.2645, 'grad_norm': 6.336992263793945, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 23:38:10.920 | {'loss': 0.2663, 'grad_norm': 6.926586151123047, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 23:38:26.190 | {'loss': 0.2288, 'grad_norm': 7.586142063140869, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 23:38:41.309 | {'loss': 0.2378, 'grad_norm': 8.12362003326416, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 23:38:56.509 | {'loss': 0.2445, 'grad_norm': 9.682555198669434, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 23:39:18.363 | {'loss': 0.2842, 'grad_norm': 6.773114204406738, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 23:39:33.656 | {'loss': 0.2602, 'grad_norm': 8.842597007751465, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 23:39:49.211 | {'loss': 0.1904, 'grad_norm': 8.360913276672363, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 23:40:04.914 | {'loss': 0.2512, 'grad_norm': 8.625078201293945, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 23:40:27.141 | {'loss': 0.2261, 'grad_norm': 9.791359901428223, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 23:40:42.445 | {'loss': 0.2484, 'grad_norm': 7.451522350311279, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 23:40:57.561 | {'loss': 0.2572, 'grad_norm': 6.144824504852295, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 23:41:12.922 | {'loss': 0.3595, 'grad_norm': 8.850810050964355, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 23:41:27.986 | {'loss': 0.2811, 'grad_norm': 6.7056050300598145, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 23:41:50.083 | {'loss': 0.2418, 'grad_norm': 8.971918106079102, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 23:42:05.611 | {'loss': 0.2374, 'grad_norm': 9.729107856750488, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 23:42:20.792 | {'loss': 0.2032, 'grad_norm': 3.605571746826172, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 23:42:36.241 | {'loss': 0.2559, 'grad_norm': 5.520244121551514, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 23:42:58.702 | {'loss': 0.2057, 'grad_norm': 7.971791744232178, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 23:43:14.189 | {'loss': 0.253, 'grad_norm': 9.700945854187012, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 23:43:29.332 | {'loss': 0.2807, 'grad_norm': 8.975197792053223, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 23:43:44.840 | {'loss': 0.2412, 'grad_norm': 8.722424507141113, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 23:44:06.857 | {'loss': 0.2445, 'grad_norm': 7.710393905639648, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 23:44:22.627 | {'loss': 0.2351, 'grad_norm': 4.610939025878906, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 23:44:38.034 | {'loss': 0.2307, 'grad_norm': 10.870333671569824, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 23:44:53.699 | {'loss': 0.2624, 'grad_norm': 7.8553056716918945, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 23:45:16.403 | {'loss': 0.2012, 'grad_norm': 8.296512603759766, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 23:45:32.175 | {'loss': 0.1877, 'grad_norm': 6.960874557495117, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 23:45:48.073 | {'loss': 0.1789, 'grad_norm': 6.413886070251465, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 23:46:03.486 | {'loss': 0.1889, 'grad_norm': 5.653881549835205, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 23:46:25.292 | {'loss': 0.1939, 'grad_norm': 9.23774242401123, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 23:46:40.513 | {'loss': 0.1626, 'grad_norm': 6.086766242980957, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 23:46:55.944 | {'loss': 0.1713, 'grad_norm': 4.470696926116943, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 23:47:10.829 | {'loss': 0.1905, 'grad_norm': 8.484397888183594, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 23:47:26.151 | {'loss': 0.1504, 'grad_norm': 2.2776315212249756, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 23:47:48.992 | {'loss': 0.1621, 'grad_norm': 4.373167037963867, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 23:48:04.538 | {'loss': 0.1742, 'grad_norm': 4.495360851287842, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 23:48:20.203 | {'loss': 0.1897, 'grad_norm': 4.813896656036377, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 23:48:35.077 | {'loss': 0.1435, 'grad_norm': 6.57094144821167, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 23:48:56.689 | {'loss': 0.1359, 'grad_norm': 6.814428806304932, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 23:49:11.522 | {'loss': 0.1663, 'grad_norm': 7.193603038787842, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 23:49:26.717 | {'loss': 0.1651, 'grad_norm': 5.668449401855469, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 23:49:42.323 | {'loss': 0.1782, 'grad_norm': 7.259552955627441, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 23:49:57.538 | {'loss': 0.1903, 'grad_norm': 7.032206058502197, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 23:50:20.300 | {'loss': 0.146, 'grad_norm': 5.955277442932129, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 23:50:36.088 | {'loss': 0.2196, 'grad_norm': 6.621234893798828, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 23:50:51.041 | {'loss': 0.1695, 'grad_norm': 3.7487192153930664, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 23:51:05.968 | {'loss': 0.1122, 'grad_norm': 2.4321529865264893, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 23:51:21.902 | {'loss': 0.1132, 'grad_norm': 4.424981117248535, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 23:51:43.310 | {'loss': 0.1256, 'grad_norm': 4.799655914306641, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 23:51:58.806 | {'loss': 0.1139, 'grad_norm': 3.075512170791626, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 23:52:14.053 | {'loss': 0.1142, 'grad_norm': 2.754564046859741, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 23:52:29.046 | {'loss': 0.1091, 'grad_norm': 3.436872720718384, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 23:52:51.190 | {'loss': 0.1414, 'grad_norm': 5.2315239906311035, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 23:53:06.902 | {'loss': 0.1164, 'grad_norm': 2.44112491607666, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 23:53:22.056 | {'loss': 0.1219, 'grad_norm': 3.888979196548462, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 23:53:37.048 | {'loss': 0.1334, 'grad_norm': 2.9183318614959717, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 23:53:59.007 | {'loss': 0.1397, 'grad_norm': 4.1725006103515625, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 23:54:13.981 | {'loss': 0.1136, 'grad_norm': 2.511539936065674, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 23:54:29.162 | {'loss': 0.1303, 'grad_norm': 4.137864112854004, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 23:54:44.388 | {'loss': 0.1259, 'grad_norm': 4.525426864624023, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 23:54:59.757 | {'loss': 0.1308, 'grad_norm': 3.5856075286865234, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 23:55:22.300 | {'loss': 0.0953, 'grad_norm': 2.606860876083374, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 23:55:38.102 | {'loss': 0.1302, 'grad_norm': 2.7572388648986816, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 23:55:53.741 | {'loss': 0.1228, 'grad_norm': 3.869732618331909, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 23:56:08.968 | {'loss': 0.1218, 'grad_norm': 1.9246164560317993, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 23:56:31.035 | {'loss': 0.1271, 'grad_norm': 1.7912402153015137, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 23:56:46.515 | {'loss': 0.085, 'grad_norm': 2.0855507850646973, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 23:57:01.685 | {'loss': 0.0808, 'grad_norm': 3.510164737701416, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 23:57:23.680 | {'loss': 0.0933, 'grad_norm': 3.312518835067749, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 23:57:39.078 | {'loss': 0.0794, 'grad_norm': 1.2241010665893555, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 23:57:55.218 | {'loss': 0.0835, 'grad_norm': 2.0530576705932617, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 23:58:17.863 | {'loss': 0.0947, 'grad_norm': 2.730397939682007, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 23:58:33.476 | {'loss': 0.0858, 'grad_norm': 4.0026535987854, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 23:58:48.898 | {'loss': 0.0882, 'grad_norm': 2.3350939750671387, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 23:59:04.081 | {'loss': 0.0772, 'grad_norm': 2.7109997272491455, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 23:59:19.609 | {'loss': 0.0844, 'grad_norm': 2.311577796936035, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 23:59:41.305 | {'loss': 0.0881, 'grad_norm': 2.3224689960479736, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 23:59:56.885 | {'loss': 0.0964, 'grad_norm': 3.457350730895996, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-26 00:00:12.613 | {'loss': 0.0812, 'grad_norm': 1.5748378038406372, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-26 00:00:29.069 | {'loss': 0.0793, 'grad_norm': 2.357384204864502, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-26 00:00:51.191 | {'loss': 0.0851, 'grad_norm': 1.841581106185913, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-26 00:01:06.798 | {'loss': 0.0795, 'grad_norm': 1.6209590435028076, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-26 00:01:22.491 | {'loss': 0.0991, 'grad_norm': 4.134289741516113, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-26 00:01:38.087 | {'loss': 0.0784, 'grad_norm': 3.2642288208007812, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-26 00:01:59.573 | {'loss': 0.07, 'grad_norm': 1.4664617776870728, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-26 00:02:11.161 | {'loss': 0.0734, 'grad_norm': 2.362877368927002, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-26 00:02:11.161 | {'train_runtime': 1708.0503, 'train_samples_per_second': 1.171, 'train_steps_per_second': 0.585, 'train_loss': 0.17004696190357207, 'epoch': 5.0}
2025-05-26 00:02:14.622 | INFO :      Sent reply
2025-05-26 00:08:35.550 | INFO :      
2025-05-26 00:08:35.550 | INFO :      Received: evaluate message 042a3428-cb45-470e-9fd6-f37b29f37416
2025-05-26 00:08:52.805 | {'eval_loss': 3.321021318435669, 'eval_runtime': 11.292, 'eval_samples_per_second': 8.856, 'eval_steps_per_second': 1.151, 'epoch': 5.0}
2025-05-26 00:08:52.807 | INFO :      Sent reply
2025-05-26 00:09:05.806 | INFO :      
2025-05-26 00:09:05.806 | INFO :      Received: train message 0cc2bda4-2a6c-4379-8a31-520392ab430c
2025-05-26 00:09:28.146 | {'loss': 0.095, 'grad_norm': 4.912326335906982, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-26 00:09:43.323 | {'loss': 0.1349, 'grad_norm': 6.2023234367370605, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-26 00:09:58.681 | {'loss': 0.1683, 'grad_norm': 5.756106376647949, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-26 00:10:20.449 | {'loss': 0.1603, 'grad_norm': 3.5641791820526123, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-26 00:10:35.748 | {'loss': 0.1818, 'grad_norm': 7.179062843322754, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-26 00:10:51.245 | {'loss': 0.209, 'grad_norm': 4.092605113983154, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-26 00:11:06.691 | {'loss': 0.2276, 'grad_norm': 6.170072555541992, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-26 00:11:28.784 | {'loss': 0.2239, 'grad_norm': 8.550931930541992, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-26 00:11:43.928 | {'loss': 0.1813, 'grad_norm': 2.812734603881836, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-26 00:11:59.269 | {'loss': 0.2285, 'grad_norm': 7.030174732208252, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-26 00:12:14.446 | {'loss': 0.2002, 'grad_norm': 7.3890790939331055, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-26 00:12:29.966 | {'loss': 0.198, 'grad_norm': 3.186699390411377, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-26 00:12:51.691 | {'loss': 0.216, 'grad_norm': 5.526341438293457, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-26 00:13:06.820 | {'loss': 0.2254, 'grad_norm': 6.610802173614502, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-26 00:13:22.227 | {'loss': 0.2292, 'grad_norm': 6.28640079498291, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-26 00:13:37.577 | {'loss': 0.2212, 'grad_norm': 7.128129005432129, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-26 00:13:59.969 | {'loss': 0.1949, 'grad_norm': 9.042130470275879, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-26 00:14:15.723 | {'loss': 0.1976, 'grad_norm': 6.958190441131592, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-26 00:14:30.993 | {'loss': 0.2377, 'grad_norm': 7.077150344848633, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-26 00:14:46.012 | {'loss': 0.2374, 'grad_norm': 5.636776924133301, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-26 00:15:08.174 | {'loss': 0.1446, 'grad_norm': 7.67930269241333, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-26 00:15:23.411 | {'loss': 0.2287, 'grad_norm': 3.8271644115448, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-26 00:15:38.244 | {'loss': 0.2027, 'grad_norm': 8.323485374450684, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-26 00:15:53.294 | {'loss': 0.1848, 'grad_norm': 5.650628089904785, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-26 00:16:15.274 | {'loss': 0.2294, 'grad_norm': 7.080972671508789, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-26 00:16:30.328 | {'loss': 0.2745, 'grad_norm': 7.9772772789001465, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-26 00:16:45.347 | {'loss': 0.2557, 'grad_norm': 8.182183265686035, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-26 00:17:01.053 | {'loss': 0.2093, 'grad_norm': 10.147919654846191, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-26 00:17:22.576 | {'loss': 0.2125, 'grad_norm': 9.500659942626953, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-26 00:17:37.452 | {'loss': 0.1891, 'grad_norm': 4.763185977935791, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-26 00:17:52.530 | {'loss': 0.2273, 'grad_norm': 5.024058818817139, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-26 00:18:07.693 | {'loss': 0.2238, 'grad_norm': 10.21251392364502, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-26 00:18:23.259 | {'loss': 0.2168, 'grad_norm': 6.6762542724609375, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-26 00:18:44.230 | {'loss': 0.2071, 'grad_norm': 5.116807460784912, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-26 00:18:59.344 | {'loss': 0.2455, 'grad_norm': 8.882451057434082, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-26 00:19:14.373 | {'loss': 0.2151, 'grad_norm': 5.570250511169434, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-26 00:19:29.863 | {'loss': 0.1981, 'grad_norm': 4.7929840087890625, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-26 00:19:52.066 | {'loss': 0.1776, 'grad_norm': 6.289297103881836, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-26 00:20:06.894 | {'loss': 0.259, 'grad_norm': 9.322474479675293, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-26 00:20:21.870 | {'loss': 0.2298, 'grad_norm': 5.060184478759766, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-26 00:20:36.907 | {'loss': 0.1693, 'grad_norm': 7.185190200805664, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-26 00:20:58.717 | {'loss': 0.1497, 'grad_norm': 5.036935329437256, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-26 00:21:13.858 | {'loss': 0.1761, 'grad_norm': 5.5682291984558105, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-26 00:21:29.339 | {'loss': 0.2168, 'grad_norm': 9.174976348876953, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-26 00:21:44.652 | {'loss': 0.1609, 'grad_norm': 5.809304714202881, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-26 00:22:06.569 | {'loss': 0.154, 'grad_norm': 5.683444976806641, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-26 00:22:21.790 | {'loss': 0.1622, 'grad_norm': 6.344383716583252, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-26 00:22:37.128 | {'loss': 0.1269, 'grad_norm': 4.075998306274414, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-26 00:22:52.316 | {'loss': 0.1495, 'grad_norm': 4.426462650299072, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-26 00:23:14.054 | {'loss': 0.1726, 'grad_norm': 3.2102184295654297, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-26 00:23:29.347 | {'loss': 0.1549, 'grad_norm': 3.7667529582977295, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-26 00:23:45.031 | {'loss': 0.1417, 'grad_norm': 4.8766255378723145, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-26 00:24:00.245 | {'loss': 0.1135, 'grad_norm': 4.717464923858643, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-26 00:24:15.678 | {'loss': 0.1516, 'grad_norm': 4.047243595123291, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-26 00:24:37.550 | {'loss': 0.1567, 'grad_norm': 5.125149250030518, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-26 00:24:52.854 | {'loss': 0.1415, 'grad_norm': 5.509352684020996, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-26 00:25:07.592 | {'loss': 0.1571, 'grad_norm': 5.186002731323242, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-26 00:25:22.573 | {'loss': 0.1703, 'grad_norm': 5.486781597137451, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-26 00:25:44.475 | {'loss': 0.2007, 'grad_norm': 5.836949348449707, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-26 00:25:59.535 | {'loss': 0.1412, 'grad_norm': 3.1567068099975586, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-26 00:26:14.868 | {'loss': 0.1038, 'grad_norm': 2.669968366622925, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-26 00:26:30.188 | {'loss': 0.0899, 'grad_norm': 3.163240671157837, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-26 00:26:51.707 | {'loss': 0.1019, 'grad_norm': 3.533193349838257, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-26 00:27:07.356 | {'loss': 0.1038, 'grad_norm': 3.4900307655334473, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-26 00:27:22.067 | {'loss': 0.1068, 'grad_norm': 4.076813697814941, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-26 00:27:37.476 | {'loss': 0.1068, 'grad_norm': 3.229037284851074, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-26 00:27:52.585 | {'loss': 0.1282, 'grad_norm': 4.106245994567871, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-26 00:28:14.110 | {'loss': 0.097, 'grad_norm': 2.401693344116211, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-26 00:28:29.673 | {'loss': 0.1043, 'grad_norm': 3.7925941944122314, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-26 00:28:44.940 | {'loss': 0.1202, 'grad_norm': 5.225271701812744, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-26 00:29:00.225 | {'loss': 0.1295, 'grad_norm': 3.4900777339935303, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-26 00:29:22.245 | {'loss': 0.1053, 'grad_norm': 4.486032009124756, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-26 00:29:36.994 | {'loss': 0.1075, 'grad_norm': 3.035398006439209, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-26 00:29:51.994 | {'loss': 0.1361, 'grad_norm': 5.962711811065674, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-26 00:30:07.498 | {'loss': 0.1256, 'grad_norm': 6.866089820861816, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-26 00:30:29.113 | {'loss': 0.0956, 'grad_norm': 3.1483356952667236, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-26 00:30:45.204 | {'loss': 0.1139, 'grad_norm': 2.659590482711792, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-26 00:31:00.401 | {'loss': 0.1186, 'grad_norm': 3.6011500358581543, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-26 00:31:15.355 | {'loss': 0.1077, 'grad_norm': 4.390418529510498, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-26 00:31:30.465 | {'loss': 0.1132, 'grad_norm': 2.163870334625244, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-26 00:31:52.011 | {'loss': 0.0718, 'grad_norm': 1.8824377059936523, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-26 00:32:07.225 | {'loss': 0.0733, 'grad_norm': 3.5244970321655273, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-26 00:32:22.314 | {'loss': 0.0806, 'grad_norm': 2.5252339839935303, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-26 00:32:37.775 | {'loss': 0.0818, 'grad_norm': 1.7667508125305176, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-26 00:32:52.979 | {'loss': 0.0794, 'grad_norm': 1.6777626276016235, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-26 00:33:15.130 | {'loss': 0.0931, 'grad_norm': 2.26997447013855, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-26 00:33:30.473 | {'loss': 0.0799, 'grad_norm': 4.777464866638184, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-26 00:33:45.242 | {'loss': 0.0913, 'grad_norm': 2.1645991802215576, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-26 00:34:00.752 | {'loss': 0.0721, 'grad_norm': 1.683833360671997, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-26 00:34:15.527 | {'loss': 0.089, 'grad_norm': 1.9079337120056152, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-26 00:34:37.205 | {'loss': 0.1037, 'grad_norm': 2.7542836666107178, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-26 00:34:52.136 | {'loss': 0.0787, 'grad_norm': 2.883603811264038, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-26 00:35:07.590 | {'loss': 0.0836, 'grad_norm': 1.9052737951278687, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-26 00:35:23.142 | {'loss': 0.0862, 'grad_norm': 2.968116283416748, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-26 00:35:38.248 | {'loss': 0.087, 'grad_norm': 3.18727970123291, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-26 00:35:59.773 | {'loss': 0.076, 'grad_norm': 1.4995734691619873, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-26 00:36:14.821 | {'loss': 0.0817, 'grad_norm': 1.4922696352005005, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-26 00:36:30.043 | {'loss': 0.0777, 'grad_norm': 2.436950445175171, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-26 00:36:45.090 | {'loss': 0.0728, 'grad_norm': 1.8335360288619995, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-26 00:37:00.290 | {'loss': 0.0743, 'grad_norm': 1.9500186443328857, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-26 00:37:00.290 | {'train_runtime': 1672.0865, 'train_samples_per_second': 1.196, 'train_steps_per_second': 0.598, 'train_loss': 0.15316402399539947, 'epoch': 5.0}
2025-05-26 00:37:11.471 | INFO :      Sent reply
2025-05-26 00:43:52.534 | INFO :      
2025-05-26 00:43:52.534 | INFO :      Received: evaluate message f926e4f6-197e-4edb-9ddc-28ee2a71304e
2025-05-26 00:44:03.467 | {'eval_loss': 3.3821659088134766, 'eval_runtime': 6.8631, 'eval_samples_per_second': 14.571, 'eval_steps_per_second': 1.894, 'epoch': 5.0}
2025-05-26 00:44:03.486 | INFO :      Sent reply
2025-05-26 00:44:10.367 | INFO :      
2025-05-26 00:44:10.367 | INFO :      Received: train message 674a357b-333d-489b-b244-4e94ed15d4e3
2025-05-26 00:44:39.133 | {'loss': 0.0852, 'grad_norm': 3.1133368015289307, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-26 00:44:54.593 | {'loss': 0.1219, 'grad_norm': 5.257874011993408, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-26 00:45:16.956 | {'loss': 0.1321, 'grad_norm': 6.0569539070129395, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-26 00:45:32.429 | {'loss': 0.1606, 'grad_norm': 3.2431490421295166, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-26 00:45:48.053 | {'loss': 0.1527, 'grad_norm': 3.5243966579437256, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-26 00:46:10.462 | {'loss': 0.1755, 'grad_norm': 4.134454727172852, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-26 00:46:25.760 | {'loss': 0.1757, 'grad_norm': 4.902120590209961, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-26 00:46:41.010 | {'loss': 0.2089, 'grad_norm': 8.913223266601562, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-26 00:47:02.802 | {'loss': 0.148, 'grad_norm': 1.7382549047470093, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-26 00:47:17.924 | {'loss': 0.1938, 'grad_norm': 5.865982532501221, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-26 00:47:33.249 | {'loss': 0.2046, 'grad_norm': 8.406049728393555, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-26 00:47:54.981 | {'loss': 0.1872, 'grad_norm': 2.284022331237793, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-26 00:48:10.644 | {'loss': 0.2108, 'grad_norm': 5.983999729156494, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-26 00:48:26.230 | {'loss': 0.1915, 'grad_norm': 4.208138465881348, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-26 00:48:48.590 | {'loss': 0.2141, 'grad_norm': 5.404561996459961, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-26 00:49:03.993 | {'loss': 0.1952, 'grad_norm': 6.830445289611816, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-26 00:49:19.114 | {'loss': 0.1598, 'grad_norm': 6.781912803649902, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-26 00:49:40.530 | {'loss': 0.1845, 'grad_norm': 9.031198501586914, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-26 00:49:55.572 | {'loss': 0.2147, 'grad_norm': 5.877851963043213, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-26 00:50:10.895 | {'loss': 0.2121, 'grad_norm': 5.3594560623168945, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-26 00:50:26.041 | {'loss': 0.1354, 'grad_norm': 7.009664535522461, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-26 00:50:41.403 | {'loss': 0.195, 'grad_norm': 2.679396152496338, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-26 00:51:03.144 | {'loss': 0.2109, 'grad_norm': 8.085138320922852, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-26 00:51:18.401 | {'loss': 0.1896, 'grad_norm': 6.503287315368652, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-26 00:51:33.761 | {'loss': 0.2121, 'grad_norm': 8.672664642333984, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-26 00:51:49.238 | {'loss': 0.2857, 'grad_norm': 7.620794773101807, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-26 00:52:04.547 | {'loss': 0.2071, 'grad_norm': 5.539910316467285, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-26 00:52:26.334 | {'loss': 0.2101, 'grad_norm': 9.436429977416992, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-26 00:52:41.629 | {'loss': 0.1895, 'grad_norm': 8.19005298614502, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-26 00:52:57.005 | {'loss': 0.1904, 'grad_norm': 4.572598934173584, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-26 00:53:12.181 | {'loss': 0.2213, 'grad_norm': 5.254544258117676, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-26 00:53:27.304 | {'loss': 0.1823, 'grad_norm': 7.394036293029785, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-26 00:53:49.072 | {'loss': 0.1977, 'grad_norm': 8.891230583190918, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-26 00:54:04.605 | {'loss': 0.2295, 'grad_norm': 8.125890731811523, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-26 00:54:19.717 | {'loss': 0.2292, 'grad_norm': 7.6843671798706055, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-26 00:54:34.921 | {'loss': 0.2049, 'grad_norm': 5.820082664489746, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-26 00:54:56.366 | {'loss': 0.2074, 'grad_norm': 3.4313786029815674, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-26 00:55:11.709 | {'loss': 0.1687, 'grad_norm': 3.675773859024048, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-26 00:55:26.958 | {'loss': 0.2189, 'grad_norm': 6.7527594566345215, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-26 00:55:42.527 | {'loss': 0.1625, 'grad_norm': 4.769787788391113, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-26 00:55:57.893 | {'loss': 0.1373, 'grad_norm': 6.411584854125977, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-26 00:56:19.787 | {'loss': 0.1336, 'grad_norm': 5.552327632904053, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-26 00:56:35.414 | {'loss': 0.1758, 'grad_norm': 5.366271495819092, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-26 00:56:50.601 | {'loss': 0.1736, 'grad_norm': 9.052715301513672, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-26 00:57:05.873 | {'loss': 0.1364, 'grad_norm': 6.512379169464111, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-26 00:57:20.719 | {'loss': 0.1278, 'grad_norm': 5.6331868171691895, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-26 00:57:42.384 | {'loss': 0.1613, 'grad_norm': 5.618289947509766, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-26 00:57:57.595 | {'loss': 0.1299, 'grad_norm': 5.195998191833496, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-26 00:58:12.458 | {'loss': 0.1404, 'grad_norm': 2.765352249145508, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-26 00:58:27.575 | {'loss': 0.165, 'grad_norm': 5.563965797424316, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-26 00:58:49.787 | {'loss': 0.1458, 'grad_norm': 4.182633876800537, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-26 00:59:04.763 | {'loss': 0.1398, 'grad_norm': 6.316007614135742, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-26 00:59:19.611 | {'loss': 0.1187, 'grad_norm': 4.45497465133667, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-26 00:59:34.722 | {'loss': 0.1465, 'grad_norm': 3.5326738357543945, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-26 00:59:49.756 | {'loss': 0.1297, 'grad_norm': 4.607917308807373, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-26 01:00:11.809 | {'loss': 0.158, 'grad_norm': 4.497003078460693, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-26 01:00:26.789 | {'loss': 0.1474, 'grad_norm': 4.832700252532959, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-26 01:00:42.441 | {'loss': 0.1467, 'grad_norm': 5.317267894744873, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-26 01:00:58.120 | {'loss': 0.1932, 'grad_norm': 5.21537971496582, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-26 01:01:20.151 | {'loss': 0.121, 'grad_norm': 5.353906154632568, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-26 01:01:35.710 | {'loss': 0.0907, 'grad_norm': 2.2368662357330322, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-26 01:01:50.553 | {'loss': 0.0816, 'grad_norm': 6.854037284851074, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-26 01:02:05.820 | {'loss': 0.1012, 'grad_norm': 3.382091760635376, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-26 01:02:27.341 | {'loss': 0.1081, 'grad_norm': 4.339207649230957, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-26 01:02:42.938 | {'loss': 0.1154, 'grad_norm': 2.630654811859131, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-26 01:02:58.722 | {'loss': 0.108, 'grad_norm': 3.040254831314087, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-26 01:03:13.852 | {'loss': 0.1136, 'grad_norm': 2.6062211990356445, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-26 01:03:35.295 | {'loss': 0.0929, 'grad_norm': 2.314844846725464, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-26 01:03:50.544 | {'loss': 0.1025, 'grad_norm': 2.889946699142456, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-26 01:04:05.543 | {'loss': 0.107, 'grad_norm': 1.8997997045516968, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-26 01:04:20.600 | {'loss': 0.1242, 'grad_norm': 4.957563877105713, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-26 01:04:42.280 | {'loss': 0.0948, 'grad_norm': 2.105349063873291, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-26 01:04:57.895 | {'loss': 0.1057, 'grad_norm': 1.7444475889205933, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-26 01:05:13.679 | {'loss': 0.1248, 'grad_norm': 4.686431884765625, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-26 01:05:29.045 | {'loss': 0.123, 'grad_norm': 3.5980279445648193, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-26 01:05:44.169 | {'loss': 0.0919, 'grad_norm': 1.905418038368225, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-26 01:06:06.007 | {'loss': 0.1076, 'grad_norm': 3.264763355255127, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-26 01:06:20.631 | {'loss': 0.1475, 'grad_norm': 4.869812488555908, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-26 01:06:35.557 | {'loss': 0.121, 'grad_norm': 1.8901957273483276, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-26 01:06:50.544 | {'loss': 0.1103, 'grad_norm': 1.514202356338501, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-26 01:07:05.849 | {'loss': 0.0716, 'grad_norm': 1.998666524887085, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-26 01:07:27.897 | {'loss': 0.0786, 'grad_norm': 2.460320234298706, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-26 01:07:43.349 | {'loss': 0.0769, 'grad_norm': 1.4956293106079102, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-26 01:07:58.311 | {'loss': 0.0741, 'grad_norm': 1.093328833580017, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-26 01:08:13.497 | {'loss': 0.0732, 'grad_norm': 1.53023099899292, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-26 01:08:35.028 | {'loss': 0.0852, 'grad_norm': 1.4645183086395264, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-26 01:08:50.212 | {'loss': 0.0845, 'grad_norm': 3.13569974899292, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-26 01:09:05.657 | {'loss': 0.0848, 'grad_norm': 1.9170173406600952, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-26 01:09:20.726 | {'loss': 0.0728, 'grad_norm': 1.5608688592910767, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-26 01:09:36.259 | {'loss': 0.0719, 'grad_norm': 2.0369038581848145, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-26 01:09:58.665 | {'loss': 0.082, 'grad_norm': 1.8001407384872437, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-26 01:10:14.208 | {'loss': 0.0835, 'grad_norm': 2.8696916103363037, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-26 01:10:29.246 | {'loss': 0.0813, 'grad_norm': 1.4020556211471558, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-26 01:10:44.596 | {'loss': 0.0763, 'grad_norm': 4.088685989379883, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-26 01:10:59.776 | {'loss': 0.0802, 'grad_norm': 2.4339680671691895, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-26 01:11:15.058 | {'loss': 0.0716, 'grad_norm': 1.1522771120071411, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-26 01:11:36.751 | {'loss': 0.0814, 'grad_norm': 1.2635360956192017, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-26 01:11:52.459 | {'loss': 0.077, 'grad_norm': 1.925391435623169, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-26 01:12:08.283 | {'loss': 0.0732, 'grad_norm': 1.197884202003479, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-26 01:12:20.008 | {'loss': 0.0703, 'grad_norm': 2.8029940128326416, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-26 01:12:20.009 | {'train_runtime': 1686.5628, 'train_samples_per_second': 1.186, 'train_steps_per_second': 0.593, 'train_loss': 0.14227238965034486, 'epoch': 5.0}
2025-05-26 01:12:24.361 | INFO :      Sent reply
2025-05-26 01:18:36.926 | INFO :      
2025-05-26 01:18:36.926 | INFO :      Received: evaluate message 1153c298-e0c2-4ce6-abd2-4311754785d0
2025-05-26 01:18:53.265 | {'eval_loss': 3.4674887657165527, 'eval_runtime': 8.9715, 'eval_samples_per_second': 11.146, 'eval_steps_per_second': 1.449, 'epoch': 5.0}
2025-05-26 01:18:53.273 | INFO :      Sent reply
2025-05-26 01:19:00.866 | INFO :      
2025-05-26 01:19:00.867 | INFO :      Received: train message a7539eaa-5cd5-4251-88a2-a9f7dc9838c8
2025-05-26 01:19:14.385 | {'loss': 0.083, 'grad_norm': 4.404941558837891, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-26 01:19:28.668 | {'loss': 0.1204, 'grad_norm': 5.982906818389893, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-26 01:19:51.410 | {'loss': 0.1197, 'grad_norm': 3.443000316619873, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-26 01:20:15.171 | {'loss': 0.1433, 'grad_norm': 5.090416431427002, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-26 01:20:29.994 | {'loss': 0.138, 'grad_norm': 5.211838722229004, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-26 01:20:45.165 | {'loss': 0.174, 'grad_norm': 2.475064992904663, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-26 01:21:00.111 | {'loss': 0.1729, 'grad_norm': 4.494117259979248, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-26 01:21:15.282 | {'loss': 0.1793, 'grad_norm': 7.003894805908203, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-26 01:21:30.494 | {'loss': 0.153, 'grad_norm': 2.5931732654571533, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-26 01:21:51.901 | {'loss': 0.1637, 'grad_norm': 4.46046781539917, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-26 01:22:07.204 | {'loss': 0.1681, 'grad_norm': 5.580794334411621, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-26 01:22:22.522 | {'loss': 0.1532, 'grad_norm': 5.266648769378662, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-26 01:22:37.917 | {'loss': 0.1792, 'grad_norm': 5.393984794616699, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-26 01:22:59.627 | {'loss': 0.1536, 'grad_norm': 4.507907867431641, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-26 01:23:14.780 | {'loss': 0.205, 'grad_norm': 5.15224027633667, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-26 01:23:29.882 | {'loss': 0.1656, 'grad_norm': 5.7923173904418945, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-26 01:23:45.085 | {'loss': 0.1541, 'grad_norm': 6.932291507720947, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-26 01:24:00.176 | {'loss': 0.1717, 'grad_norm': 6.778417110443115, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-26 01:24:15.449 | {'loss': 0.1805, 'grad_norm': 4.800333023071289, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-26 01:24:37.293 | {'loss': 0.1851, 'grad_norm': 2.3965375423431396, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-26 01:24:52.939 | {'loss': 0.1408, 'grad_norm': 6.271727561950684, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-26 01:25:08.453 | {'loss': 0.1788, 'grad_norm': 3.1302261352539062, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-26 01:25:23.707 | {'loss': 0.1804, 'grad_norm': 4.391273498535156, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-26 01:25:45.281 | {'loss': 0.1643, 'grad_norm': 8.427934646606445, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-26 01:26:00.359 | {'loss': 0.1958, 'grad_norm': 7.394399166107178, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-26 01:26:15.758 | {'loss': 0.2728, 'grad_norm': 5.254124164581299, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-26 01:26:30.827 | {'loss': 0.1947, 'grad_norm': 4.195733070373535, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-26 01:26:52.785 | {'loss': 0.1869, 'grad_norm': 6.704330921173096, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-26 01:27:08.480 | {'loss': 0.1703, 'grad_norm': 8.127751350402832, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-26 01:27:23.884 | {'loss': 0.195, 'grad_norm': 4.9517412185668945, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-26 01:27:39.031 | {'loss': 0.2198, 'grad_norm': 5.522848129272461, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-26 01:28:00.704 | {'loss': 0.1595, 'grad_norm': 5.965495586395264, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-26 01:28:15.542 | {'loss': 0.1869, 'grad_norm': 8.08220386505127, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-26 01:28:30.353 | {'loss': 0.195, 'grad_norm': 7.060128688812256, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-26 01:28:45.420 | {'loss': 0.1981, 'grad_norm': 5.668297290802002, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-26 01:29:07.037 | {'loss': 0.1671, 'grad_norm': 5.889402389526367, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-26 01:29:22.309 | {'loss': 0.1592, 'grad_norm': 4.844285488128662, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-26 01:29:37.693 | {'loss': 0.1657, 'grad_norm': 4.0897297859191895, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-26 01:29:52.997 | {'loss': 0.2369, 'grad_norm': 6.163480281829834, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-26 01:30:08.013 | {'loss': 0.1642, 'grad_norm': 6.345234394073486, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-26 01:30:29.482 | {'loss': 0.1351, 'grad_norm': 4.957979679107666, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-26 01:30:44.778 | {'loss': 0.1301, 'grad_norm': 5.376876354217529, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-26 01:30:59.760 | {'loss': 0.1322, 'grad_norm': 5.613699913024902, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-26 01:31:14.964 | {'loss': 0.1685, 'grad_norm': 8.393302917480469, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-26 01:31:36.464 | {'loss': 0.1404, 'grad_norm': 6.18535852432251, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-26 01:31:51.680 | {'loss': 0.1398, 'grad_norm': 6.045765399932861, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-26 01:32:07.061 | {'loss': 0.1443, 'grad_norm': 6.53420352935791, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-26 01:32:22.425 | {'loss': 0.1253, 'grad_norm': 3.6428892612457275, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-26 01:32:37.821 | {'loss': 0.1529, 'grad_norm': 3.4919075965881348, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-26 01:32:59.323 | {'loss': 0.1623, 'grad_norm': 5.592663288116455, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-26 01:33:14.443 | {'loss': 0.1424, 'grad_norm': 3.3445167541503906, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-26 01:33:29.500 | {'loss': 0.1214, 'grad_norm': 4.4000115394592285, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-26 01:33:44.724 | {'loss': 0.1105, 'grad_norm': 4.918828964233398, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-26 01:33:59.777 | {'loss': 0.1259, 'grad_norm': 4.304784297943115, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-26 01:34:21.630 | {'loss': 0.1437, 'grad_norm': 7.3998284339904785, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-26 01:34:36.855 | {'loss': 0.1596, 'grad_norm': 5.8443522453308105, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-26 01:34:52.146 | {'loss': 0.14, 'grad_norm': 4.683897495269775, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-26 01:35:07.579 | {'loss': 0.1408, 'grad_norm': 13.184345245361328, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-26 01:35:29.266 | {'loss': 0.1647, 'grad_norm': 7.051774024963379, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-26 01:35:44.372 | {'loss': 0.1338, 'grad_norm': 2.979569435119629, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-26 01:35:59.359 | {'loss': 0.0889, 'grad_norm': 2.7529239654541016, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-26 01:36:14.553 | {'loss': 0.1036, 'grad_norm': 3.9640767574310303, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-26 01:36:29.658 | {'loss': 0.0909, 'grad_norm': 2.9661123752593994, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-26 01:36:51.758 | {'loss': 0.0934, 'grad_norm': 2.546020269393921, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-26 01:37:07.262 | {'loss': 0.1099, 'grad_norm': 5.246545791625977, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-26 01:37:22.628 | {'loss': 0.1018, 'grad_norm': 1.674202799797058, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-26 01:37:37.813 | {'loss': 0.1008, 'grad_norm': 4.733792304992676, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-26 01:37:59.418 | {'loss': 0.0952, 'grad_norm': 2.183863639831543, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-26 01:38:14.829 | {'loss': 0.0937, 'grad_norm': 3.5345675945281982, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-26 01:38:29.739 | {'loss': 0.102, 'grad_norm': 2.1777358055114746, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-26 01:38:44.886 | {'loss': 0.1179, 'grad_norm': 4.464967250823975, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-26 01:39:06.572 | {'loss': 0.0941, 'grad_norm': 2.7808492183685303, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-26 01:39:21.967 | {'loss': 0.1076, 'grad_norm': 2.7319092750549316, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-26 01:39:37.499 | {'loss': 0.121, 'grad_norm': 2.6292574405670166, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-26 01:39:52.714 | {'loss': 0.101, 'grad_norm': 2.94924259185791, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-26 01:40:07.784 | {'loss': 0.0842, 'grad_norm': 1.6395715475082397, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-26 01:40:29.301 | {'loss': 0.0942, 'grad_norm': 3.416978597640991, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-26 01:40:44.553 | {'loss': 0.1087, 'grad_norm': 2.983527183532715, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-26 01:40:59.584 | {'loss': 0.1203, 'grad_norm': 1.3825368881225586, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-26 01:41:14.738 | {'loss': 0.1084, 'grad_norm': 3.137263298034668, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-26 01:41:29.679 | {'loss': 0.0777, 'grad_norm': 2.2532434463500977, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-26 01:41:51.466 | {'loss': 0.0785, 'grad_norm': 2.413628339767456, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-26 01:42:06.994 | {'loss': 0.0883, 'grad_norm': 1.3218978643417358, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-26 01:42:22.714 | {'loss': 0.0792, 'grad_norm': 1.0054521560668945, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-26 01:42:37.629 | {'loss': 0.073, 'grad_norm': 2.7313454151153564, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-26 01:42:52.838 | {'loss': 0.0746, 'grad_norm': 1.5454155206680298, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-26 01:43:14.001 | {'loss': 0.0775, 'grad_norm': 1.4339380264282227, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-26 01:43:28.919 | {'loss': 0.083, 'grad_norm': 1.6276201009750366, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-26 01:43:44.149 | {'loss': 0.0705, 'grad_norm': 1.6449687480926514, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-26 01:43:59.231 | {'loss': 0.0693, 'grad_norm': 2.098738193511963, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-26 01:44:14.581 | {'loss': 0.0843, 'grad_norm': 5.6644086837768555, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-26 01:44:37.078 | {'loss': 0.0703, 'grad_norm': 3.0284314155578613, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-26 01:44:52.186 | {'loss': 0.0799, 'grad_norm': 1.5736000537872314, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-26 01:45:07.085 | {'loss': 0.0738, 'grad_norm': 5.126657962799072, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-26 01:45:21.920 | {'loss': 0.0734, 'grad_norm': 2.4358575344085693, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-26 01:45:37.227 | {'loss': 0.0654, 'grad_norm': 1.1822530031204224, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-26 01:45:52.572 | {'loss': 0.0804, 'grad_norm': 3.424528121948242, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-26 01:46:14.062 | {'loss': 0.0714, 'grad_norm': 1.736307144165039, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-26 01:46:29.470 | {'loss': 0.0616, 'grad_norm': 1.1613613367080688, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-26 01:46:44.892 | {'loss': 0.0621, 'grad_norm': 2.5618677139282227, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-26 01:46:44.892 | {'train_runtime': 1662.9556, 'train_samples_per_second': 1.203, 'train_steps_per_second': 0.601, 'train_loss': 0.13241129195690154, 'epoch': 5.0}
2025-05-26 01:46:56.055 | INFO :      Sent reply
2025-05-26 01:53:09.066 | INFO :      
2025-05-26 01:53:09.066 | INFO :      Received: evaluate message fe9a8fc4-11d6-44e3-9a55-3c7d895113b3
2025-05-26 01:53:18.361 | {'eval_loss': 3.5080759525299072, 'eval_runtime': 3.3037, 'eval_samples_per_second': 30.269, 'eval_steps_per_second': 3.935, 'epoch': 5.0}
2025-05-26 01:53:18.362 | INFO :      Sent reply
2025-05-26 01:53:26.869 | INFO :      
2025-05-26 01:53:26.869 | INFO :      Received: train message b23d6866-c227-4af0-a869-9d501a0e6846
2025-05-26 01:54:03.048 | {'loss': 0.0745, 'grad_norm': 3.3086180686950684, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-26 01:54:18.335 | {'loss': 0.1182, 'grad_norm': 5.821138381958008, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-26 01:54:39.994 | {'loss': 0.1612, 'grad_norm': 3.0022435188293457, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-26 01:54:55.437 | {'loss': 0.1401, 'grad_norm': 6.067296981811523, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-26 01:55:11.204 | {'loss': 0.1523, 'grad_norm': 3.051905870437622, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-26 01:55:26.625 | {'loss': 0.1435, 'grad_norm': 2.780890941619873, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-26 01:55:48.386 | {'loss': 0.1289, 'grad_norm': 4.060250759124756, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-26 01:56:03.616 | {'loss': 0.1809, 'grad_norm': 6.887624263763428, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-26 01:56:18.898 | {'loss': 0.1416, 'grad_norm': 1.7330493927001953, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-26 01:56:34.132 | {'loss': 0.156, 'grad_norm': 4.353427886962891, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-26 01:56:55.780 | {'loss': 0.1554, 'grad_norm': 4.623486042022705, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-26 01:57:11.161 | {'loss': 0.1463, 'grad_norm': 2.0515763759613037, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-26 01:57:26.391 | {'loss': 0.1527, 'grad_norm': 4.493678092956543, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-26 01:57:41.627 | {'loss': 0.1416, 'grad_norm': 4.286841869354248, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-26 01:58:03.377 | {'loss': 0.1873, 'grad_norm': 4.7262959480285645, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-26 01:58:18.630 | {'loss': 0.1674, 'grad_norm': 5.262488842010498, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-26 01:58:33.801 | {'loss': 0.1605, 'grad_norm': 7.028223037719727, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-26 01:58:49.118 | {'loss': 0.1578, 'grad_norm': 6.592207431793213, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-26 01:59:11.063 | {'loss': 0.1779, 'grad_norm': 5.955843448638916, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-26 01:59:26.334 | {'loss': 0.1768, 'grad_norm': 2.716848373413086, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-26 01:59:41.594 | {'loss': 0.1329, 'grad_norm': 4.039599895477295, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-26 01:59:56.837 | {'loss': 0.1696, 'grad_norm': 7.290054798126221, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-26 02:00:12.112 | {'loss': 0.1579, 'grad_norm': 4.664319038391113, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-26 02:00:34.104 | {'loss': 0.2151, 'grad_norm': 5.941997528076172, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-26 02:00:49.993 | {'loss': 0.1862, 'grad_norm': 5.545909881591797, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-26 02:01:05.144 | {'loss': 0.2349, 'grad_norm': 6.1682000160217285, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-26 02:01:20.301 | {'loss': 0.2162, 'grad_norm': 6.489739418029785, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-26 02:01:35.391 | {'loss': 0.1458, 'grad_norm': 6.245599746704102, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-26 02:01:56.838 | {'loss': 0.1578, 'grad_norm': 7.802134990692139, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-26 02:02:12.129 | {'loss': 0.1923, 'grad_norm': 5.406913757324219, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-26 02:02:27.633 | {'loss': 0.1968, 'grad_norm': 2.810546636581421, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-26 02:02:43.339 | {'loss': 0.1527, 'grad_norm': 6.957586288452148, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-26 02:02:58.766 | {'loss': 0.1739, 'grad_norm': 8.551679611206055, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-26 02:03:20.275 | {'loss': 0.1844, 'grad_norm': 5.636103630065918, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-26 02:03:35.352 | {'loss': 0.1819, 'grad_norm': 6.910271167755127, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-26 02:03:50.452 | {'loss': 0.1419, 'grad_norm': 5.172482013702393, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-26 02:04:05.631 | {'loss': 0.1517, 'grad_norm': 3.475435733795166, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-26 02:04:21.187 | {'loss': 0.1384, 'grad_norm': 4.60032320022583, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-26 02:04:42.345 | {'loss': 0.185, 'grad_norm': 6.362111568450928, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-26 02:04:57.679 | {'loss': 0.1352, 'grad_norm': 5.4832634925842285, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-26 02:05:12.901 | {'loss': 0.1336, 'grad_norm': 5.046418190002441, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-26 02:05:28.463 | {'loss': 0.1279, 'grad_norm': 4.594196319580078, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-26 02:05:44.083 | {'loss': 0.1237, 'grad_norm': 2.7047550678253174, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-26 02:05:59.382 | {'loss': 0.1568, 'grad_norm': 9.148783683776855, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-26 02:06:14.830 | {'loss': 0.1184, 'grad_norm': 7.329431056976318, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-26 02:06:36.583 | {'loss': 0.1411, 'grad_norm': 5.668468952178955, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-26 02:06:51.960 | {'loss': 0.1538, 'grad_norm': 4.978005886077881, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-26 02:07:06.899 | {'loss': 0.1325, 'grad_norm': 2.816899538040161, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-26 02:07:22.019 | {'loss': 0.1354, 'grad_norm': 3.5114858150482178, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-26 02:07:37.521 | {'loss': 0.1455, 'grad_norm': 5.922220230102539, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-26 02:07:59.162 | {'loss': 0.1482, 'grad_norm': 5.621826648712158, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-26 02:08:14.511 | {'loss': 0.1156, 'grad_norm': 1.6646016836166382, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-26 02:08:29.645 | {'loss': 0.1163, 'grad_norm': 8.886609077453613, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-26 02:08:44.783 | {'loss': 0.1411, 'grad_norm': 3.5565803050994873, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-26 02:08:59.716 | {'loss': 0.1177, 'grad_norm': 5.431758403778076, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-26 02:09:21.129 | {'loss': 0.1169, 'grad_norm': 4.332160949707031, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-26 02:09:36.299 | {'loss': 0.1146, 'grad_norm': 4.1442179679870605, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-26 02:09:51.614 | {'loss': 0.1394, 'grad_norm': 8.347111701965332, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-26 02:10:07.002 | {'loss': 0.1514, 'grad_norm': 6.133054256439209, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-26 02:10:22.549 | {'loss': 0.1399, 'grad_norm': 4.6165642738342285, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-26 02:10:37.946 | {'loss': 0.0882, 'grad_norm': 2.2765603065490723, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-26 02:10:53.176 | {'loss': 0.0916, 'grad_norm': 6.223085403442383, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-26 02:11:14.749 | {'loss': 0.0874, 'grad_norm': 3.3864481449127197, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-26 02:11:29.604 | {'loss': 0.088, 'grad_norm': 2.630776882171631, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-26 02:11:44.967 | {'loss': 0.1036, 'grad_norm': 2.9861552715301514, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-26 02:12:00.201 | {'loss': 0.0899, 'grad_norm': 4.517868518829346, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-26 02:12:15.586 | {'loss': 0.106, 'grad_norm': 2.4034693241119385, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-26 02:12:37.721 | {'loss': 0.1039, 'grad_norm': 1.8675142526626587, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-26 02:12:53.328 | {'loss': 0.0953, 'grad_norm': 3.360771417617798, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-26 02:13:08.145 | {'loss': 0.116, 'grad_norm': 1.9564827680587769, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-26 02:13:23.200 | {'loss': 0.1102, 'grad_norm': 3.7955455780029297, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-26 02:13:38.538 | {'loss': 0.0875, 'grad_norm': 2.7034928798675537, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-26 02:13:59.506 | {'loss': 0.1027, 'grad_norm': 3.127732992172241, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-26 02:14:14.413 | {'loss': 0.1191, 'grad_norm': 5.5826005935668945, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-26 02:14:29.375 | {'loss': 0.1143, 'grad_norm': 2.787191867828369, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-26 02:14:44.463 | {'loss': 0.0916, 'grad_norm': 3.101032018661499, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-26 02:14:59.553 | {'loss': 0.1065, 'grad_norm': 2.1544134616851807, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-26 02:15:21.363 | {'loss': 0.1123, 'grad_norm': 7.902712345123291, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-26 02:15:36.699 | {'loss': 0.0916, 'grad_norm': 2.5559580326080322, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-26 02:15:52.194 | {'loss': 0.113, 'grad_norm': 1.9472360610961914, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-26 02:16:07.494 | {'loss': 0.073, 'grad_norm': 2.370572566986084, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-26 02:16:28.993 | {'loss': 0.0811, 'grad_norm': 3.344526529312134, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-26 02:16:44.113 | {'loss': 0.0732, 'grad_norm': 1.842930555343628, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-26 02:16:59.267 | {'loss': 0.077, 'grad_norm': 1.0303902626037598, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-26 02:17:14.383 | {'loss': 0.0763, 'grad_norm': 1.3897675275802612, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-26 02:17:35.876 | {'loss': 0.0708, 'grad_norm': 1.4112807512283325, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-26 02:17:51.134 | {'loss': 0.0772, 'grad_norm': 4.844162464141846, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-26 02:18:06.492 | {'loss': 0.0774, 'grad_norm': 2.9636752605438232, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-26 02:18:22.285 | {'loss': 0.0676, 'grad_norm': 2.654345750808716, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-26 02:18:37.369 | {'loss': 0.0729, 'grad_norm': 1.7241233587265015, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-26 02:18:58.850 | {'loss': 0.0787, 'grad_norm': 1.490060567855835, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-26 02:19:14.063 | {'loss': 0.0661, 'grad_norm': 1.406154990196228, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-26 02:19:28.971 | {'loss': 0.0738, 'grad_norm': 1.8760396242141724, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-26 02:19:43.917 | {'loss': 0.0724, 'grad_norm': 4.041942596435547, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-26 02:20:05.153 | {'loss': 0.0725, 'grad_norm': 1.6018236875534058, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-26 02:20:20.224 | {'loss': 0.0691, 'grad_norm': 1.0846604108810425, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-26 02:20:35.333 | {'loss': 0.0742, 'grad_norm': 1.491976261138916, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-26 02:20:50.789 | {'loss': 0.0744, 'grad_norm': 1.7345948219299316, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-26 02:21:05.942 | {'loss': 0.0703, 'grad_norm': 1.2293152809143066, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-26 02:21:21.982 | {'loss': 0.0633, 'grad_norm': 2.5824997425079346, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-26 02:21:21.982 | {'train_runtime': 1670.0816, 'train_samples_per_second': 1.198, 'train_steps_per_second': 0.599, 'train_loss': 0.12621673935651778, 'epoch': 5.0}
2025-05-26 02:21:26.040 | INFO :      Sent reply
2025-05-26 02:27:36.512 | INFO :      
2025-05-26 02:27:36.512 | INFO :      Received: evaluate message 6ee84c2c-be22-459e-9791-8eb01ce5bc11
2025-05-26 02:27:52.170 | {'eval_loss': 3.5446372032165527, 'eval_runtime': 9.4103, 'eval_samples_per_second': 10.627, 'eval_steps_per_second': 1.381, 'epoch': 5.0}
2025-05-26 02:27:52.185 | INFO :      Sent reply
2025-05-26 02:27:59.881 | INFO :      
2025-05-26 02:27:59.881 | INFO :      Received: train message 14b891b4-fa21-4977-89a4-b18980528f2a
2025-05-26 02:28:26.007 | {'loss': 0.0741, 'grad_norm': 4.81605339050293, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-26 02:28:41.373 | {'loss': 0.1023, 'grad_norm': 4.5986833572387695, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-26 02:28:56.736 | {'loss': 0.1107, 'grad_norm': 4.765218734741211, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-26 02:29:12.223 | {'loss': 0.1063, 'grad_norm': 2.0305662155151367, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-26 02:29:34.563 | {'loss': 0.1192, 'grad_norm': 3.101134777069092, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-26 02:29:49.970 | {'loss': 0.1275, 'grad_norm': 1.6721482276916504, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-26 02:30:05.388 | {'loss': 0.1544, 'grad_norm': 5.9015421867370605, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-26 02:30:20.704 | {'loss': 0.1452, 'grad_norm': 6.535257816314697, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-26 02:30:42.900 | {'loss': 0.1431, 'grad_norm': 2.3474085330963135, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-26 02:30:58.352 | {'loss': 0.1479, 'grad_norm': 4.050506591796875, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-26 02:31:13.802 | {'loss': 0.1376, 'grad_norm': 5.963642120361328, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-26 02:31:35.509 | {'loss': 0.1398, 'grad_norm': 3.929107189178467, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-26 02:31:51.425 | {'loss': 0.1368, 'grad_norm': 4.815831184387207, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-26 02:32:07.286 | {'loss': 0.1395, 'grad_norm': 6.950125217437744, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-26 02:32:23.034 | {'loss': 0.1607, 'grad_norm': 3.406374216079712, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-26 02:32:45.323 | {'loss': 0.145, 'grad_norm': 4.874937057495117, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-26 02:33:00.896 | {'loss': 0.139, 'grad_norm': 5.48492431640625, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-26 02:33:16.340 | {'loss': 0.1411, 'grad_norm': 5.542813777923584, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-26 02:33:38.437 | {'loss': 0.1479, 'grad_norm': 5.510644435882568, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-26 02:33:53.728 | {'loss': 0.155, 'grad_norm': 2.7432124614715576, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-26 02:34:09.205 | {'loss': 0.1396, 'grad_norm': 4.214409351348877, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-26 02:34:31.737 | {'loss': 0.165, 'grad_norm': 3.3335509300231934, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-26 02:34:47.546 | {'loss': 0.1546, 'grad_norm': 6.257025241851807, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-26 02:35:02.664 | {'loss': 0.2015, 'grad_norm': 9.27679443359375, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-26 02:35:17.957 | {'loss': 0.1752, 'grad_norm': 4.647923946380615, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-26 02:35:39.812 | {'loss': 0.1892, 'grad_norm': 5.074464797973633, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-26 02:35:55.031 | {'loss': 0.1782, 'grad_norm': 7.490994930267334, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-26 02:36:10.086 | {'loss': 0.1564, 'grad_norm': 7.1077752113342285, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-26 02:36:25.248 | {'loss': 0.1431, 'grad_norm': 8.133337020874023, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-26 02:36:40.373 | {'loss': 0.1503, 'grad_norm': 3.4356906414031982, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-26 02:37:02.838 | {'loss': 0.1928, 'grad_norm': 6.60080623626709, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-26 02:37:18.457 | {'loss': 0.1437, 'grad_norm': 5.382024765014648, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-26 02:37:33.689 | {'loss': 0.1512, 'grad_norm': 6.576988220214844, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-26 02:37:49.067 | {'loss': 0.1913, 'grad_norm': 5.27951192855835, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-26 02:38:04.222 | {'loss': 0.1884, 'grad_norm': 4.858255863189697, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-26 02:38:26.051 | {'loss': 0.1578, 'grad_norm': 5.200331687927246, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-26 02:38:41.524 | {'loss': 0.1616, 'grad_norm': 3.719926595687866, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-26 02:38:57.247 | {'loss': 0.1414, 'grad_norm': 3.604067087173462, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-26 02:39:12.757 | {'loss': 0.1886, 'grad_norm': 8.30334186553955, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-26 02:39:34.797 | {'loss': 0.1516, 'grad_norm': 2.9193367958068848, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-26 02:39:50.460 | {'loss': 0.1409, 'grad_norm': 5.7409443855285645, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-26 02:40:06.150 | {'loss': 0.1091, 'grad_norm': 5.03102445602417, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-26 02:40:21.549 | {'loss': 0.1115, 'grad_norm': 2.659043073654175, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-26 02:40:36.986 | {'loss': 0.1578, 'grad_norm': 9.14041519165039, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-26 02:40:59.023 | {'loss': 0.1173, 'grad_norm': 3.837324619293213, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-26 02:41:14.316 | {'loss': 0.1271, 'grad_norm': 5.415356636047363, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-26 02:41:29.505 | {'loss': 0.143, 'grad_norm': 6.6618146896362305, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-26 02:41:44.794 | {'loss': 0.1202, 'grad_norm': 2.1078028678894043, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-26 02:42:00.089 | {'loss': 0.1119, 'grad_norm': 1.8286337852478027, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-26 02:42:21.609 | {'loss': 0.1174, 'grad_norm': 1.8443233966827393, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-26 02:42:37.193 | {'loss': 0.1304, 'grad_norm': 4.520511150360107, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-26 02:42:52.648 | {'loss': 0.1097, 'grad_norm': 3.374544382095337, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-26 02:43:07.908 | {'loss': 0.0952, 'grad_norm': 3.183638334274292, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-26 02:43:29.746 | {'loss': 0.1281, 'grad_norm': 3.1946699619293213, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-26 02:43:44.614 | {'loss': 0.1222, 'grad_norm': 4.528589725494385, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-26 02:43:59.650 | {'loss': 0.1353, 'grad_norm': 5.197564125061035, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-26 02:44:14.773 | {'loss': 0.1321, 'grad_norm': 4.1716814041137695, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-26 02:44:29.884 | {'loss': 0.1286, 'grad_norm': 6.486719608306885, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-26 02:44:51.624 | {'loss': 0.138, 'grad_norm': 4.137385368347168, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-26 02:45:07.464 | {'loss': 0.1174, 'grad_norm': 3.0223333835601807, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-26 02:45:22.664 | {'loss': 0.0811, 'grad_norm': 4.238674640655518, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-26 02:45:37.810 | {'loss': 0.0934, 'grad_norm': 3.296884775161743, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-26 02:45:52.961 | {'loss': 0.0895, 'grad_norm': 1.9856528043746948, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-26 02:46:14.645 | {'loss': 0.0873, 'grad_norm': 4.34382438659668, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-26 02:46:29.821 | {'loss': 0.1041, 'grad_norm': 1.9613584280014038, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-26 02:46:45.026 | {'loss': 0.0797, 'grad_norm': 2.5284056663513184, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-26 02:47:00.187 | {'loss': 0.0987, 'grad_norm': 3.979557514190674, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-26 02:47:15.692 | {'loss': 0.0913, 'grad_norm': 2.498602867126465, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-26 02:47:38.046 | {'loss': 0.0961, 'grad_norm': 1.3289381265640259, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-26 02:47:53.741 | {'loss': 0.103, 'grad_norm': 4.99670934677124, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-26 02:48:09.038 | {'loss': 0.1159, 'grad_norm': 3.995105743408203, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-26 02:48:24.201 | {'loss': 0.0906, 'grad_norm': 1.7597801685333252, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-26 02:48:39.268 | {'loss': 0.0915, 'grad_norm': 2.009060859680176, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-26 02:49:01.140 | {'loss': 0.1065, 'grad_norm': 2.7779414653778076, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-26 02:49:16.296 | {'loss': 0.1069, 'grad_norm': 4.168356895446777, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-26 02:49:31.080 | {'loss': 0.0846, 'grad_norm': 1.6231797933578491, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-26 02:49:46.461 | {'loss': 0.0852, 'grad_norm': 1.9320887327194214, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-26 02:50:02.020 | {'loss': 0.0994, 'grad_norm': 4.492270469665527, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-26 02:50:23.710 | {'loss': 0.0949, 'grad_norm': 2.331838607788086, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-26 02:50:38.793 | {'loss': 0.1108, 'grad_norm': 1.141366958618164, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-26 02:50:54.111 | {'loss': 0.0763, 'grad_norm': 2.153010368347168, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-26 02:51:08.880 | {'loss': 0.0723, 'grad_norm': 2.426971673965454, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-26 02:51:24.102 | {'loss': 0.0667, 'grad_norm': 1.423754334449768, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-26 02:51:45.366 | {'loss': 0.0745, 'grad_norm': 1.0411405563354492, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-26 02:52:00.286 | {'loss': 0.0703, 'grad_norm': 4.680718898773193, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-26 02:52:15.578 | {'loss': 0.0724, 'grad_norm': 1.421778917312622, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-26 02:52:31.037 | {'loss': 0.0771, 'grad_norm': 3.5366570949554443, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-26 02:52:53.045 | {'loss': 0.0833, 'grad_norm': 3.5058417320251465, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-26 02:53:08.115 | {'loss': 0.0703, 'grad_norm': 1.2424780130386353, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-26 02:53:23.280 | {'loss': 0.0674, 'grad_norm': 1.4503549337387085, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-26 02:53:38.426 | {'loss': 0.0812, 'grad_norm': 2.3948814868927, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-26 02:53:53.641 | {'loss': 0.0707, 'grad_norm': 1.1281518936157227, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-26 02:54:08.751 | {'loss': 0.0756, 'grad_norm': 1.1759929656982422, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-26 02:54:30.317 | {'loss': 0.0708, 'grad_norm': 1.111160397529602, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-26 02:54:45.429 | {'loss': 0.0702, 'grad_norm': 1.968802809715271, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-26 02:55:00.797 | {'loss': 0.0667, 'grad_norm': 1.1921257972717285, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-26 02:55:16.303 | {'loss': 0.0706, 'grad_norm': 1.2964212894439697, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-26 02:55:31.820 | {'loss': 0.0688, 'grad_norm': 2.0852019786834717, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-26 02:55:53.491 | {'loss': 0.0641, 'grad_norm': 1.5477813482284546, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-26 02:56:08.747 | {'loss': 0.0746, 'grad_norm': 2.1238784790039062, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-26 02:56:08.748 | {'train_runtime': 1683.5382, 'train_samples_per_second': 1.188, 'train_steps_per_second': 0.594, 'train_loss': 0.11842189139127732, 'epoch': 5.0}
2025-05-26 02:56:14.337 | INFO :      Sent reply
2025-05-26 03:02:24.779 | INFO :      
2025-05-26 03:02:24.779 | INFO :      Received: evaluate message 819bce30-3d7a-49d6-a371-9cdaf98af140
2025-05-26 03:02:42.150 | {'eval_loss': 3.629532814025879, 'eval_runtime': 9.3877, 'eval_samples_per_second': 10.652, 'eval_steps_per_second': 1.385, 'epoch': 5.0}
2025-05-26 03:02:42.156 | INFO :      Sent reply
2025-05-26 03:02:47.621 | INFO :      
2025-05-26 03:02:47.621 | INFO :      Received: train message 02eacdb8-670e-4e0e-b265-a9779dffafb4
2025-05-26 03:02:56.638 | {'loss': 0.0718, 'grad_norm': 2.241118907928467, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-26 03:03:10.860 | {'loss': 0.0924, 'grad_norm': 2.714433193206787, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-26 03:03:26.370 | {'loss': 0.104, 'grad_norm': 4.679666519165039, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-26 03:03:48.443 | {'loss': 0.1118, 'grad_norm': 2.9638288021087646, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-26 03:04:03.812 | {'loss': 0.1073, 'grad_norm': 3.520012617111206, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-26 03:04:19.193 | {'loss': 0.1307, 'grad_norm': 5.132044792175293, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-26 03:04:34.667 | {'loss': 0.1202, 'grad_norm': 3.888357400894165, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-26 03:04:56.640 | {'loss': 0.1394, 'grad_norm': 4.0818939208984375, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-26 03:05:11.787 | {'loss': 0.1288, 'grad_norm': 5.559552192687988, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-26 03:05:27.032 | {'loss': 0.1323, 'grad_norm': 5.0832109451293945, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-26 03:05:42.186 | {'loss': 0.1252, 'grad_norm': 4.943079471588135, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-26 03:06:03.927 | {'loss': 0.1326, 'grad_norm': 3.217721700668335, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-26 03:06:19.125 | {'loss': 0.1314, 'grad_norm': 3.740604877471924, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-26 03:06:34.152 | {'loss': 0.1409, 'grad_norm': 4.823295593261719, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-26 03:06:49.633 | {'loss': 0.1497, 'grad_norm': 4.191758155822754, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-26 03:07:11.787 | {'loss': 0.1317, 'grad_norm': 5.6279449462890625, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-26 03:07:27.227 | {'loss': 0.1294, 'grad_norm': 5.851060390472412, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-26 03:07:42.361 | {'loss': 0.1347, 'grad_norm': 4.7262749671936035, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-26 03:07:57.332 | {'loss': 0.1561, 'grad_norm': 4.602737903594971, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-26 03:08:18.766 | {'loss': 0.1425, 'grad_norm': 3.144502639770508, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-26 03:08:34.064 | {'loss': 0.1382, 'grad_norm': 4.45286226272583, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-26 03:08:49.095 | {'loss': 0.1646, 'grad_norm': 3.1262426376342773, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-26 03:09:04.433 | {'loss': 0.2061, 'grad_norm': 6.252014636993408, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-26 03:09:19.952 | {'loss': 0.1574, 'grad_norm': 4.525888442993164, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-26 03:09:41.620 | {'loss': 0.1649, 'grad_norm': 2.936821460723877, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-26 03:09:56.934 | {'loss': 0.1969, 'grad_norm': 4.947319984436035, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-26 03:10:12.015 | {'loss': 0.1803, 'grad_norm': 4.633647918701172, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-26 03:10:27.286 | {'loss': 0.1493, 'grad_norm': 5.4183855056762695, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-26 03:10:42.323 | {'loss': 0.136, 'grad_norm': 6.010954856872559, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-26 03:10:57.650 | {'loss': 0.1393, 'grad_norm': 4.192814350128174, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-26 03:11:19.450 | {'loss': 0.1605, 'grad_norm': 7.189953804016113, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-26 03:11:34.828 | {'loss': 0.1282, 'grad_norm': 6.098254203796387, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-26 03:11:50.401 | {'loss': 0.1596, 'grad_norm': 6.927347660064697, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-26 03:12:05.789 | {'loss': 0.1812, 'grad_norm': 4.726711750030518, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-26 03:12:27.441 | {'loss': 0.1437, 'grad_norm': 4.641035556793213, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-26 03:12:42.394 | {'loss': 0.1427, 'grad_norm': 3.9536828994750977, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-26 03:12:57.553 | {'loss': 0.1363, 'grad_norm': 2.593271255493164, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-26 03:13:12.717 | {'loss': 0.138, 'grad_norm': 6.15730094909668, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-26 03:13:28.040 | {'loss': 0.1774, 'grad_norm': 4.42340087890625, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-26 03:13:49.608 | {'loss': 0.1245, 'grad_norm': 3.4882795810699463, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-26 03:14:05.097 | {'loss': 0.1453, 'grad_norm': 5.644805908203125, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-26 03:14:20.581 | {'loss': 0.0948, 'grad_norm': 2.44474720954895, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-26 03:14:35.857 | {'loss': 0.0989, 'grad_norm': 3.0523226261138916, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-26 03:14:51.190 | {'loss': 0.1359, 'grad_norm': 6.798598289489746, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-26 03:15:12.826 | {'loss': 0.1106, 'grad_norm': 4.040986061096191, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-26 03:15:28.017 | {'loss': 0.0977, 'grad_norm': 1.639400601387024, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-26 03:15:43.253 | {'loss': 0.1326, 'grad_norm': 4.507989883422852, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-26 03:15:58.277 | {'loss': 0.1308, 'grad_norm': 4.611137390136719, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-26 03:16:20.419 | {'loss': 0.1165, 'grad_norm': 2.1366584300994873, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-26 03:16:35.897 | {'loss': 0.1168, 'grad_norm': 1.3150696754455566, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-26 03:16:51.240 | {'loss': 0.1372, 'grad_norm': 3.651426315307617, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-26 03:17:06.929 | {'loss': 0.1024, 'grad_norm': 5.477128028869629, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-26 03:17:21.890 | {'loss': 0.0989, 'grad_norm': 4.015071392059326, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-26 03:17:43.425 | {'loss': 0.1327, 'grad_norm': 2.6145381927490234, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-26 03:17:58.604 | {'loss': 0.0991, 'grad_norm': 5.047120571136475, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-26 03:18:13.536 | {'loss': 0.1241, 'grad_norm': 5.520497798919678, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-26 03:18:28.828 | {'loss': 0.1189, 'grad_norm': 3.3484575748443604, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-26 03:18:50.510 | {'loss': 0.1161, 'grad_norm': 2.951632022857666, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-26 03:19:06.086 | {'loss': 0.1616, 'grad_norm': 4.963071823120117, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-26 03:19:21.612 | {'loss': 0.1201, 'grad_norm': 2.3765807151794434, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-26 03:19:37.384 | {'loss': 0.0799, 'grad_norm': 1.7047001123428345, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-26 03:19:52.556 | {'loss': 0.0813, 'grad_norm': 4.236785888671875, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-26 03:20:07.826 | {'loss': 0.0894, 'grad_norm': 1.6886049509048462, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-26 03:20:29.625 | {'loss': 0.0868, 'grad_norm': 2.828245162963867, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-26 03:20:44.956 | {'loss': 0.0912, 'grad_norm': 3.5770511627197266, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-26 03:21:00.411 | {'loss': 0.0915, 'grad_norm': 3.116732358932495, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-26 03:21:15.775 | {'loss': 0.0949, 'grad_norm': 2.0264902114868164, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-26 03:21:38.260 | {'loss': 0.0858, 'grad_norm': 2.078286647796631, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-26 03:21:53.839 | {'loss': 0.0967, 'grad_norm': 3.3723645210266113, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-26 03:22:09.324 | {'loss': 0.0966, 'grad_norm': 2.5465285778045654, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-26 03:22:24.837 | {'loss': 0.1026, 'grad_norm': 5.722347736358643, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-26 03:22:40.069 | {'loss': 0.1047, 'grad_norm': 3.5278680324554443, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-26 03:22:55.559 | {'loss': 0.0886, 'grad_norm': 2.1452620029449463, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-26 03:23:17.397 | {'loss': 0.1102, 'grad_norm': 1.4307037591934204, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-26 03:23:32.672 | {'loss': 0.0973, 'grad_norm': 2.0786123275756836, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-26 03:23:47.823 | {'loss': 0.0878, 'grad_norm': 0.9668099880218506, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-26 03:24:03.006 | {'loss': 0.102, 'grad_norm': 2.618293285369873, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-26 03:24:18.267 | {'loss': 0.1069, 'grad_norm': 3.053209066390991, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-26 03:24:40.882 | {'loss': 0.105, 'grad_norm': 2.2766897678375244, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-26 03:24:56.225 | {'loss': 0.1052, 'grad_norm': 1.4130520820617676, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-26 03:25:11.456 | {'loss': 0.0812, 'grad_norm': 2.4199306964874268, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-26 03:25:26.328 | {'loss': 0.0698, 'grad_norm': 4.263083457946777, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-26 03:25:47.946 | {'loss': 0.0668, 'grad_norm': 1.9146565198898315, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-26 03:26:02.893 | {'loss': 0.0682, 'grad_norm': 0.9069777727127075, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-26 03:26:17.951 | {'loss': 0.0656, 'grad_norm': 2.3901126384735107, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-26 03:26:33.434 | {'loss': 0.0655, 'grad_norm': 1.3494963645935059, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-26 03:26:49.045 | {'loss': 0.0752, 'grad_norm': 3.81022310256958, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-26 03:27:11.062 | {'loss': 0.0774, 'grad_norm': 1.1321512460708618, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-26 03:27:26.561 | {'loss': 0.0621, 'grad_norm': 1.3216328620910645, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-26 03:27:42.139 | {'loss': 0.0758, 'grad_norm': 1.300304889678955, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-26 03:27:57.062 | {'loss': 0.0755, 'grad_norm': 2.602170467376709, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-26 03:28:12.038 | {'loss': 0.069, 'grad_norm': 4.416471004486084, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-26 03:28:34.062 | {'loss': 0.0759, 'grad_norm': 1.1695691347122192, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-26 03:28:49.096 | {'loss': 0.0666, 'grad_norm': 1.5147556066513062, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-26 03:29:04.659 | {'loss': 0.0715, 'grad_norm': 2.0719895362854004, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-26 03:29:20.509 | {'loss': 0.0651, 'grad_norm': 1.1224571466445923, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-26 03:29:41.976 | {'loss': 0.0717, 'grad_norm': 1.0311592817306519, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-26 03:29:57.073 | {'loss': 0.0667, 'grad_norm': 2.9987683296203613, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-26 03:30:12.256 | {'loss': 0.0616, 'grad_norm': 1.046972393989563, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-26 03:30:27.383 | {'loss': 0.0647, 'grad_norm': 2.4837088584899902, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-26 03:30:27.384 | {'train_runtime': 1658.4955, 'train_samples_per_second': 1.206, 'train_steps_per_second': 0.603, 'train_loss': 0.11329604703187943, 'epoch': 5.0}
2025-05-26 03:30:37.784 | INFO :      Sent reply
2025-05-26 03:36:57.520 | INFO :      
2025-05-26 03:36:57.520 | INFO :      Received: evaluate message 4738611c-5409-44ec-a650-1444de39ecb5
2025-05-26 03:37:10.095 | {'eval_loss': 3.6601531505584717, 'eval_runtime': 6.8752, 'eval_samples_per_second': 14.545, 'eval_steps_per_second': 1.891, 'epoch': 5.0}
2025-05-26 03:37:10.097 | INFO :      Sent reply
2025-05-26 03:37:10.281 | INFO :      
2025-05-26 03:37:10.282 | INFO :      Received: reconnect message 5debaba8-d1b8-4599-b5f0-dd921f348944
2025-05-26 03:37:10.327 | INFO :      Disconnect and shut down
