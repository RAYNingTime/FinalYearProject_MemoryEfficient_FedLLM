2025-05-25 18:00:16.892 | Repo card metadata block was not found. Setting CardData to empty.
2025-05-25 18:02:54.219 | 
2025-05-25 18:03:12.710 | 
2025-05-25 18:03:13.101 | 
2025-05-25 18:03:13.196 | /app/client.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-05-25 18:03:13.196 |   trainer = Trainer(
2025-05-25 18:03:13.620 | WARNING :   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
2025-05-25 18:03:13.620 | 	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
2025-05-25 18:03:13.620 | 	flwr.client.start_client(
2025-05-25 18:03:13.620 | 		server_address='<IP>:<PORT>',
2025-05-25 18:03:13.620 | 		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
2025-05-25 18:03:13.620 | 	)
2025-05-25 18:03:13.620 | 	Using `start_numpy_client()` is deprecated.
2025-05-25 18:03:13.620 | 
2025-05-25 18:03:13.620 |             This is a deprecated feature. It will be removed
2025-05-25 18:03:13.620 |             entirely in future versions of Flower.
2025-05-25 18:03:13.620 |         
2025-05-25 18:03:13.620 | WARNING :   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
2025-05-25 18:03:13.620 | 	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:
2025-05-25 18:03:13.620 | 
2025-05-25 18:03:13.620 | 		$ flower-supernode --insecure --superlink='<IP>:<PORT>'
2025-05-25 18:03:13.620 | 
2025-05-25 18:03:13.620 | 	To view all available options, run:
2025-05-25 18:03:13.620 | 
2025-05-25 18:03:13.620 | 		$ flower-supernode --help
2025-05-25 18:03:13.620 | 
2025-05-25 18:03:13.620 | 	Using `start_client()` is deprecated.
2025-05-25 18:03:13.620 | 
2025-05-25 18:03:13.620 |             This is a deprecated feature. It will be removed
2025-05-25 18:03:13.620 |             entirely in future versions of Flower.
2025-05-25 18:03:13.620 |         
2025-05-25 18:03:13.840 | Traceback (most recent call last):
2025-05-25 18:03:13.840 |   File "/app/client.py", line 111, in <module>
2025-05-25 18:03:13.840 |     fl.client.start_numpy_client(server_address=server_ip, client=FlowerClient())
2025-05-25 18:03:13.840 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/app.py", line 731, in start_numpy_client
2025-05-25 18:03:13.840 |     start_client(
2025-05-25 18:03:13.841 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/app.py", line 201, in start_client
2025-05-25 18:03:13.841 |     start_client_internal(
2025-05-25 18:03:13.841 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/app.py", line 438, in start_client_internal
2025-05-25 18:03:13.841 |     message = receive()
2025-05-25 18:03:13.841 |   File "/usr/local/lib/python3.10/site-packages/flwr/client/grpc_client/connection.py", line 142, in receive
2025-05-25 18:03:13.841 |     proto = next(server_message_iterator)
2025-05-25 18:03:13.841 |   File "/usr/local/lib/python3.10/site-packages/grpc/_channel.py", line 543, in __next__
2025-05-25 18:03:13.842 |     return self._next()
2025-05-25 18:03:13.842 |   File "/usr/local/lib/python3.10/site-packages/grpc/_channel.py", line 969, in _next
2025-05-25 18:03:13.843 |     raise self
2025-05-25 18:03:13.843 | grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
2025-05-25 18:03:13.843 | 	status = StatusCode.UNAVAILABLE
2025-05-25 18:03:13.843 | 	details = "failed to connect to all addresses; last error: UNKNOWN: ipv4:172.18.0.2:8080: Failed to connect to remote host: connect: Connection refused (111)"
2025-05-25 18:03:13.843 | 	debug_error_string = "UNKNOWN:Error received from peer  {created_time:"2025-05-25T15:03:13.63518754+00:00", grpc_status:14, grpc_message:"failed to connect to all addresses; last error: UNKNOWN: ipv4:172.18.0.2:8080: Failed to connect to remote host: connect: Connection refused (111)"}"
2025-05-25 18:03:13.843 | >
2025-05-25 18:34:00.658 | Repo card metadata block was not found. Setting CardData to empty.
2025-05-25 18:34:03.673 | /app/client.py:50: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-05-25 18:34:03.674 |   trainer = Trainer(
2025-05-25 18:34:04.295 | WARNING :   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
2025-05-25 18:34:04.296 | 	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
2025-05-25 18:34:04.296 | 	flwr.client.start_client(
2025-05-25 18:34:04.296 | 		server_address='<IP>:<PORT>',
2025-05-25 18:34:04.296 | 		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
2025-05-25 18:34:04.296 | 	)
2025-05-25 18:34:04.296 | 	Using `start_numpy_client()` is deprecated.
2025-05-25 18:34:04.296 | 
2025-05-25 18:34:04.296 |             This is a deprecated feature. It will be removed
2025-05-25 18:34:04.296 |             entirely in future versions of Flower.
2025-05-25 18:34:04.296 |         
2025-05-25 18:34:04.296 | WARNING :   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
2025-05-25 18:34:04.296 | 	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:
2025-05-25 18:34:04.296 | 
2025-05-25 18:34:04.296 | 		$ flower-supernode --insecure --superlink='<IP>:<PORT>'
2025-05-25 18:34:04.296 | 
2025-05-25 18:34:04.296 | 	To view all available options, run:
2025-05-25 18:34:04.296 | 
2025-05-25 18:34:04.296 | 		$ flower-supernode --help
2025-05-25 18:34:04.296 | 
2025-05-25 18:34:04.296 | 	Using `start_client()` is deprecated.
2025-05-25 18:34:04.296 | 
2025-05-25 18:34:04.296 |             This is a deprecated feature. It will be removed
2025-05-25 18:34:04.296 |             entirely in future versions of Flower.
2025-05-25 18:34:04.296 |         
2025-05-25 18:40:15.121 | INFO :      
2025-05-25 18:40:15.121 | INFO :      Received: train message 17e67e55-b5e2-4737-98ca-a168d8647ffc
2025-05-25 18:41:47.486 | {'loss': 6.3107, 'grad_norm': 19.9084529876709, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 18:42:18.537 | {'loss': 5.6504, 'grad_norm': 23.56344223022461, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 18:42:41.366 | {'loss': 4.5396, 'grad_norm': 17.257553100585938, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 18:43:13.133 | {'loss': 4.4765, 'grad_norm': 18.015647888183594, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 18:43:44.607 | {'loss': 4.1556, 'grad_norm': 15.904080390930176, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 18:44:16.458 | {'loss': 4.1122, 'grad_norm': 14.597829818725586, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 18:44:38.890 | {'loss': 3.7511, 'grad_norm': 22.83309555053711, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 18:45:10.304 | {'loss': 3.6929, 'grad_norm': 19.180761337280273, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 18:45:41.883 | {'loss': 3.8683, 'grad_norm': 20.854698181152344, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 18:46:13.996 | {'loss': 3.3606, 'grad_norm': 17.75510597229004, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 18:46:36.657 | {'loss': 3.4052, 'grad_norm': 14.363876342773438, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 18:47:08.687 | {'loss': 3.4116, 'grad_norm': 17.015949249267578, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 18:47:40.985 | {'loss': 3.0821, 'grad_norm': 26.7432804107666, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 18:48:02.948 | {'loss': 3.5661, 'grad_norm': 12.972537994384766, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 18:48:35.849 | {'loss': 3.2339, 'grad_norm': 11.317896842956543, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 18:49:07.258 | {'loss': 3.1349, 'grad_norm': 13.943373680114746, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 18:49:38.471 | {'loss': 3.1311, 'grad_norm': 17.834518432617188, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 18:50:10.355 | {'loss': 3.3548, 'grad_norm': 13.710429191589355, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 18:50:41.380 | {'loss': 3.3755, 'grad_norm': 15.158411026000977, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 18:51:12.981 | {'loss': 3.3826, 'grad_norm': 14.801797866821289, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 18:51:34.954 | {'loss': 2.4701, 'grad_norm': 13.975554466247559, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 18:52:07.621 | {'loss': 2.3125, 'grad_norm': 12.913405418395996, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 18:52:39.649 | {'loss': 2.5682, 'grad_norm': 12.063685417175293, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 18:53:11.205 | {'loss': 2.6259, 'grad_norm': 14.310478210449219, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 18:53:32.958 | {'loss': 2.2649, 'grad_norm': 16.59467124938965, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 18:54:05.370 | {'loss': 2.5556, 'grad_norm': 12.006244659423828, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 18:54:37.070 | {'loss': 2.1431, 'grad_norm': 15.017123222351074, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 18:55:09.161 | {'loss': 2.2154, 'grad_norm': 12.022259712219238, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 18:55:40.090 | {'loss': 2.3894, 'grad_norm': 13.570435523986816, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 18:56:02.329 | {'loss': 1.9819, 'grad_norm': 12.577890396118164, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 18:56:34.201 | {'loss': 2.2952, 'grad_norm': 17.75880241394043, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 18:57:05.785 | {'loss': 2.6309, 'grad_norm': 14.668537139892578, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 18:57:37.325 | {'loss': 2.016, 'grad_norm': 11.142926216125488, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 18:58:09.300 | {'loss': 2.6145, 'grad_norm': 12.787836074829102, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 18:58:31.916 | {'loss': 2.7114, 'grad_norm': 14.90399169921875, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 18:59:04.374 | {'loss': 2.4325, 'grad_norm': 13.228635787963867, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 18:59:36.308 | {'loss': 2.4617, 'grad_norm': 12.432168006896973, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 19:00:08.214 | {'loss': 2.3114, 'grad_norm': 15.524703025817871, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 19:00:39.953 | {'loss': 2.3036, 'grad_norm': 13.824671745300293, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 19:01:02.173 | {'loss': 2.0684, 'grad_norm': 12.296196937561035, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 19:01:34.032 | {'loss': 1.5889, 'grad_norm': 10.24804401397705, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 19:02:05.454 | {'loss': 1.849, 'grad_norm': 13.954109191894531, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 19:02:37.178 | {'loss': 1.4185, 'grad_norm': 11.523506164550781, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 19:03:08.699 | {'loss': 1.4117, 'grad_norm': 12.770915031433105, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 19:03:40.853 | {'loss': 1.7531, 'grad_norm': 7.243458271026611, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 19:04:02.900 | {'loss': 1.7483, 'grad_norm': 11.220763206481934, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 19:04:17.518 | {'loss': 1.7186, 'grad_norm': 9.657902717590332, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 19:04:32.809 | {'loss': 1.5959, 'grad_norm': 11.570908546447754, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 19:04:54.233 | {'loss': 1.7584, 'grad_norm': 12.116090774536133, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 19:05:09.828 | {'loss': 1.4022, 'grad_norm': 8.137803077697754, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 19:05:24.667 | {'loss': 1.7246, 'grad_norm': 12.310248374938965, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 19:05:46.390 | {'loss': 1.9568, 'grad_norm': 12.88683032989502, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 19:06:01.298 | {'loss': 1.5802, 'grad_norm': 8.662747383117676, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 19:06:22.582 | {'loss': 1.8217, 'grad_norm': 11.759392738342285, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 19:06:38.069 | {'loss': 1.788, 'grad_norm': 10.954479217529297, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 19:06:59.715 | {'loss': 1.4789, 'grad_norm': 8.880319595336914, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 19:07:14.495 | {'loss': 1.4971, 'grad_norm': 10.232020378112793, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 19:07:29.890 | {'loss': 1.6604, 'grad_norm': 10.628826141357422, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 19:07:51.125 | {'loss': 1.9164, 'grad_norm': 11.734664916992188, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 19:08:06.475 | {'loss': 1.5079, 'grad_norm': 11.722803115844727, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 19:08:21.235 | {'loss': 1.1949, 'grad_norm': 11.347787857055664, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 19:08:36.645 | {'loss': 1.0433, 'grad_norm': 9.71430778503418, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 19:08:57.529 | {'loss': 1.1626, 'grad_norm': 11.743321418762207, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 19:09:12.336 | {'loss': 1.2432, 'grad_norm': 13.586669921875, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 19:09:27.281 | {'loss': 1.0836, 'grad_norm': 10.44703197479248, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 19:09:48.724 | {'loss': 1.2832, 'grad_norm': 10.954887390136719, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 19:10:04.003 | {'loss': 1.1779, 'grad_norm': 10.669068336486816, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 19:10:18.683 | {'loss': 1.0316, 'grad_norm': 9.629844665527344, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 19:10:33.774 | {'loss': 1.2456, 'grad_norm': 11.168135643005371, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 19:10:48.488 | {'loss': 1.259, 'grad_norm': 13.329415321350098, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 19:11:09.908 | {'loss': 1.1008, 'grad_norm': 13.757770538330078, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 19:11:24.509 | {'loss': 1.2956, 'grad_norm': 10.514044761657715, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 19:11:39.628 | {'loss': 1.003, 'grad_norm': 10.742892265319824, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 19:11:54.282 | {'loss': 1.2268, 'grad_norm': 6.141383647918701, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 19:12:09.696 | {'loss': 0.9825, 'grad_norm': 14.041055679321289, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 19:12:31.327 | {'loss': 1.0486, 'grad_norm': 13.230013847351074, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 19:12:46.105 | {'loss': 1.4258, 'grad_norm': 8.204543113708496, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 19:13:00.937 | {'loss': 1.2617, 'grad_norm': 12.078484535217285, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 19:13:15.901 | {'loss': 1.0813, 'grad_norm': 9.738253593444824, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 19:13:37.449 | {'loss': 1.1923, 'grad_norm': 9.87489128112793, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 19:13:52.083 | {'loss': 0.8934, 'grad_norm': 6.988663196563721, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 19:14:07.091 | {'loss': 0.7342, 'grad_norm': 7.36298942565918, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 19:14:21.773 | {'loss': 0.7336, 'grad_norm': 8.146652221679688, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 19:14:37.028 | {'loss': 0.7454, 'grad_norm': 8.292798042297363, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 19:14:58.448 | {'loss': 0.8945, 'grad_norm': 11.949474334716797, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 19:15:14.240 | {'loss': 0.9252, 'grad_norm': 8.800840377807617, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 19:15:29.063 | {'loss': 0.8402, 'grad_norm': 10.49602222442627, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 19:15:44.616 | {'loss': 0.675, 'grad_norm': 3.953911781311035, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 19:16:05.711 | {'loss': 0.707, 'grad_norm': 8.855082511901855, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 19:16:20.575 | {'loss': 0.8517, 'grad_norm': 6.941826820373535, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 19:16:35.989 | {'loss': 0.8896, 'grad_norm': 10.02625846862793, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 19:16:50.861 | {'loss': 0.8234, 'grad_norm': 9.692532539367676, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 19:17:06.366 | {'loss': 0.7994, 'grad_norm': 9.69093132019043, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-25 19:17:21.365 | {'loss': 0.81, 'grad_norm': 6.442576885223389, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-25 19:17:42.602 | {'loss': 0.8879, 'grad_norm': 9.431135177612305, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-25 19:17:57.431 | {'loss': 0.9108, 'grad_norm': 11.474678039550781, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-25 19:18:12.710 | {'loss': 0.9115, 'grad_norm': 9.33815860748291, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-25 19:18:26.448 | {'loss': 0.9314, 'grad_norm': 8.9322509765625, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-25 19:18:37.037 | {'loss': 0.8516, 'grad_norm': 8.792049407958984, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-25 19:18:50.492 | {'loss': 0.8151, 'grad_norm': 10.757880210876465, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-25 19:18:50.493 | {'train_runtime': 2313.0734, 'train_samples_per_second': 0.865, 'train_steps_per_second': 0.432, 'train_loss': 1.9751900281906127, 'epoch': 5.0}
2025-05-25 19:18:54.430 | INFO :      Sent reply
2025-05-25 19:24:50.956 | INFO :      
2025-05-25 19:24:50.956 | INFO :      Received: evaluate message c5174966-3f70-4cf7-b1ac-c782edbbb467
2025-05-25 19:24:53.692 | {'eval_loss': 2.716433048248291, 'eval_runtime': 1.6145, 'eval_samples_per_second': 61.938, 'eval_steps_per_second': 8.052, 'epoch': 5.0}
2025-05-25 19:24:53.694 | INFO :      Sent reply
2025-05-25 19:25:13.030 | INFO :      
2025-05-25 19:25:13.030 | INFO :      Received: train message 7b469a2a-4091-4e78-89ef-ce8de24ffbe6
2025-05-25 19:25:50.300 | {'loss': 2.2526, 'grad_norm': 16.547504425048828, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 19:26:12.322 | {'loss': 2.3053, 'grad_norm': 16.419647216796875, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 19:26:27.670 | {'loss': 1.8222, 'grad_norm': 15.382651329040527, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 19:26:43.164 | {'loss': 2.2252, 'grad_norm': 13.535768508911133, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 19:26:58.055 | {'loss': 2.1991, 'grad_norm': 12.469452857971191, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 19:27:19.880 | {'loss': 2.2298, 'grad_norm': 12.593350410461426, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 19:27:34.704 | {'loss': 2.0343, 'grad_norm': 16.84933853149414, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 19:27:50.050 | {'loss': 2.0192, 'grad_norm': 19.069232940673828, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 19:28:04.935 | {'loss': 2.1304, 'grad_norm': 15.318216323852539, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 19:28:20.578 | {'loss': 1.8945, 'grad_norm': 16.04330062866211, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 19:28:42.472 | {'loss': 1.8987, 'grad_norm': 13.350492477416992, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 19:28:57.544 | {'loss': 1.9123, 'grad_norm': 15.028999328613281, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 19:29:12.672 | {'loss': 1.8207, 'grad_norm': 20.42575454711914, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 19:29:27.471 | {'loss': 2.2235, 'grad_norm': 12.623664855957031, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 19:29:42.709 | {'loss': 1.7749, 'grad_norm': 10.027310371398926, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 19:29:57.819 | {'loss': 1.9023, 'grad_norm': 13.502138137817383, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 19:30:19.847 | {'loss': 1.933, 'grad_norm': 14.527918815612793, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 19:30:34.776 | {'loss': 2.1918, 'grad_norm': 16.70479393005371, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 19:30:50.053 | {'loss': 2.2008, 'grad_norm': 16.73903465270996, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 19:31:04.778 | {'loss': 2.0688, 'grad_norm': 14.43316650390625, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 19:31:20.136 | {'loss': 1.3395, 'grad_norm': 13.168352127075195, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 19:31:41.558 | {'loss': 1.1773, 'grad_norm': 11.671407699584961, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 19:31:56.652 | {'loss': 1.373, 'grad_norm': 11.005925178527832, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 19:32:11.973 | {'loss': 1.4383, 'grad_norm': 14.529942512512207, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 19:32:27.452 | {'loss': 1.2468, 'grad_norm': 12.412764549255371, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 19:32:42.268 | {'loss': 1.4017, 'grad_norm': 10.873085021972656, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 19:33:03.392 | {'loss': 1.2637, 'grad_norm': 11.945670127868652, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 19:33:18.516 | {'loss': 1.3103, 'grad_norm': 10.983660697937012, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 19:33:33.180 | {'loss': 1.3726, 'grad_norm': 24.82497787475586, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 19:33:48.516 | {'loss': 1.0648, 'grad_norm': 10.108170509338379, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 19:34:10.808 | {'loss': 1.2518, 'grad_norm': 14.321248054504395, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 19:34:25.736 | {'loss': 1.4712, 'grad_norm': 14.255931854248047, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 19:34:40.543 | {'loss': 1.1338, 'grad_norm': 8.976262092590332, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 19:34:55.495 | {'loss': 1.4684, 'grad_norm': 11.37165355682373, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 19:35:10.424 | {'loss': 1.6238, 'grad_norm': 13.962413787841797, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 19:35:31.645 | {'loss': 1.3848, 'grad_norm': 13.311399459838867, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 19:35:47.057 | {'loss': 1.3813, 'grad_norm': 15.442300796508789, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 19:36:02.500 | {'loss': 1.3495, 'grad_norm': 14.104540824890137, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 19:36:17.950 | {'loss': 1.4143, 'grad_norm': 14.515252113342285, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 19:36:32.467 | {'loss': 1.1704, 'grad_norm': 13.848840713500977, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 19:36:54.084 | {'loss': 0.8232, 'grad_norm': 8.425065040588379, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 19:37:08.963 | {'loss': 0.8978, 'grad_norm': 12.646768569946289, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 19:37:24.263 | {'loss': 0.7343, 'grad_norm': 9.886968612670898, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 19:37:39.655 | {'loss': 0.7179, 'grad_norm': 9.766698837280273, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 19:37:54.987 | {'loss': 0.9427, 'grad_norm': 5.450028419494629, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 19:38:16.830 | {'loss': 0.905, 'grad_norm': 9.678739547729492, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 19:38:31.589 | {'loss': 0.9001, 'grad_norm': 7.327561378479004, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 19:38:46.717 | {'loss': 0.8554, 'grad_norm': 9.565482139587402, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 19:39:01.846 | {'loss': 0.972, 'grad_norm': 11.093005180358887, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 19:39:17.208 | {'loss': 0.7513, 'grad_norm': 6.752371311187744, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 19:39:38.324 | {'loss': 0.9375, 'grad_norm': 10.68917465209961, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 19:39:53.952 | {'loss': 0.9685, 'grad_norm': 10.537948608398438, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 19:40:09.204 | {'loss': 0.8244, 'grad_norm': 8.874079704284668, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 19:40:24.639 | {'loss': 0.9024, 'grad_norm': 11.157556533813477, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 19:40:39.739 | {'loss': 0.9354, 'grad_norm': 9.110107421875, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 19:41:00.983 | {'loss': 0.7832, 'grad_norm': 10.69933032989502, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 19:41:15.967 | {'loss': 0.7965, 'grad_norm': 8.124860763549805, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 19:41:30.956 | {'loss': 0.8712, 'grad_norm': 10.855794906616211, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 19:41:46.539 | {'loss': 1.0614, 'grad_norm': 9.786151885986328, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 19:42:01.578 | {'loss': 0.8772, 'grad_norm': 9.970968246459961, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 19:42:23.336 | {'loss': 0.569, 'grad_norm': 7.636056423187256, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 19:42:38.014 | {'loss': 0.5065, 'grad_norm': 8.012356758117676, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 19:42:53.202 | {'loss': 0.5743, 'grad_norm': 9.736665725708008, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 19:43:07.952 | {'loss': 0.6059, 'grad_norm': 9.123136520385742, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 19:43:29.308 | {'loss': 0.5099, 'grad_norm': 9.350858688354492, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 19:43:44.473 | {'loss': 0.5693, 'grad_norm': 7.71859073638916, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 19:43:59.872 | {'loss': 0.6022, 'grad_norm': 10.362682342529297, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 19:44:14.928 | {'loss': 0.5119, 'grad_norm': 8.293333053588867, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 19:44:36.032 | {'loss': 0.5716, 'grad_norm': 7.647043704986572, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 19:44:51.182 | {'loss': 0.6062, 'grad_norm': 10.928786277770996, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 19:45:06.208 | {'loss': 0.5411, 'grad_norm': 10.23489761352539, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 19:45:21.606 | {'loss': 0.6435, 'grad_norm': 11.25118637084961, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 19:45:36.887 | {'loss': 0.4907, 'grad_norm': 6.138874053955078, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 19:45:59.270 | {'loss': 0.6543, 'grad_norm': 12.076448440551758, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 19:46:14.422 | {'loss': 0.4913, 'grad_norm': 10.430662155151367, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 19:46:29.895 | {'loss': 0.4927, 'grad_norm': 9.589897155761719, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 19:46:45.010 | {'loss': 0.6719, 'grad_norm': 9.448370933532715, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 19:47:00.083 | {'loss': 0.5901, 'grad_norm': 7.951026439666748, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 19:47:15.239 | {'loss': 0.5558, 'grad_norm': 10.037367820739746, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 19:47:37.393 | {'loss': 0.6006, 'grad_norm': 7.146454811096191, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 19:47:52.945 | {'loss': 0.4277, 'grad_norm': 4.942237377166748, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 19:48:07.829 | {'loss': 0.3373, 'grad_norm': 5.831064701080322, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 19:48:23.070 | {'loss': 0.3422, 'grad_norm': 5.422515869140625, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 19:48:44.206 | {'loss': 0.359, 'grad_norm': 7.357567310333252, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 19:48:59.718 | {'loss': 0.4099, 'grad_norm': 5.490965843200684, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 19:49:14.849 | {'loss': 0.4361, 'grad_norm': 8.171148300170898, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 19:49:30.072 | {'loss': 0.3655, 'grad_norm': 7.015175819396973, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 19:49:45.156 | {'loss': 0.3233, 'grad_norm': 3.561582326889038, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 19:50:06.518 | {'loss': 0.3356, 'grad_norm': 7.050743579864502, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 19:50:21.538 | {'loss': 0.3952, 'grad_norm': 4.939502239227295, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 19:50:36.691 | {'loss': 0.4792, 'grad_norm': 7.892755031585693, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 19:50:51.905 | {'loss': 0.3386, 'grad_norm': 5.875866889953613, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 19:51:13.331 | {'loss': 0.3467, 'grad_norm': 8.053812026977539, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-25 19:51:28.840 | {'loss': 0.372, 'grad_norm': 4.8976030349731445, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-25 19:51:43.733 | {'loss': 0.3923, 'grad_norm': 8.548613548278809, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-25 19:51:58.677 | {'loss': 0.4274, 'grad_norm': 8.519241333007812, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-25 19:52:13.282 | {'loss': 0.4373, 'grad_norm': 8.255118370056152, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-25 19:52:34.711 | {'loss': 0.3939, 'grad_norm': 6.19798469543457, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-25 19:52:49.632 | {'loss': 0.3449, 'grad_norm': 5.958765029907227, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-25 19:53:03.824 | {'loss': 0.2962, 'grad_norm': 5.911098480224609, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-25 19:53:03.824 | {'train_runtime': 1666.3768, 'train_samples_per_second': 1.2, 'train_steps_per_second': 0.6, 'train_loss': 1.0405320768356323, 'epoch': 5.0}
2025-05-25 19:53:15.637 | INFO :      Sent reply
2025-05-25 19:59:15.159 | INFO :      
2025-05-25 19:59:15.159 | INFO :      Received: evaluate message bcf77bfa-b2ea-4c21-8b5e-4e193b450afa
2025-05-25 19:59:37.202 | {'eval_loss': 2.82059383392334, 'eval_runtime': 17.596, 'eval_samples_per_second': 5.683, 'eval_steps_per_second': 0.739, 'epoch': 5.0}
2025-05-25 19:59:37.203 | INFO :      Sent reply
2025-05-25 19:59:54.389 | INFO :      
2025-05-25 19:59:54.389 | INFO :      Received: train message c1b176b4-1bc7-407d-8bce-f697ba123d2a
2025-05-25 20:00:37.631 | {'loss': 1.3913, 'grad_norm': 15.90306568145752, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 20:01:02.277 | {'loss': 1.5249, 'grad_norm': 15.11076545715332, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 20:01:19.458 | {'loss': 1.1588, 'grad_norm': 15.932879447937012, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 20:01:36.241 | {'loss': 1.5462, 'grad_norm': 12.288843154907227, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 20:01:58.646 | {'loss': 1.5284, 'grad_norm': 12.263564109802246, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 20:02:15.256 | {'loss': 1.5416, 'grad_norm': 15.384483337402344, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 20:02:33.091 | {'loss': 1.3912, 'grad_norm': 13.68992805480957, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 20:02:57.343 | {'loss': 1.4102, 'grad_norm': 17.703834533691406, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 20:03:13.404 | {'loss': 1.4566, 'grad_norm': 14.747956275939941, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 20:03:29.540 | {'loss': 1.2995, 'grad_norm': 15.773824691772461, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 20:03:45.071 | {'loss': 1.3031, 'grad_norm': 13.580026626586914, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 20:04:11.383 | {'loss': 1.3521, 'grad_norm': 13.478127479553223, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 20:04:28.545 | {'loss': 1.3309, 'grad_norm': 20.95547103881836, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 20:04:44.656 | {'loss': 1.5334, 'grad_norm': 13.096827507019043, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 20:05:01.089 | {'loss': 1.219, 'grad_norm': 9.118670463562012, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 20:05:25.355 | {'loss': 1.3488, 'grad_norm': 12.283048629760742, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 20:05:43.894 | {'loss': 1.3991, 'grad_norm': 13.730624198913574, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 20:06:09.932 | {'loss': 1.5686, 'grad_norm': 15.705078125, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 20:06:28.799 | {'loss': 1.5891, 'grad_norm': 15.301499366760254, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 20:06:46.148 | {'loss': 1.446, 'grad_norm': 12.531896591186523, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 20:07:12.209 | {'loss': 1.0099, 'grad_norm': 13.516273498535156, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 20:07:30.208 | {'loss': 0.7859, 'grad_norm': 8.978924751281738, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 20:07:48.888 | {'loss': 0.827, 'grad_norm': 10.188126564025879, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 20:08:12.879 | {'loss': 0.9519, 'grad_norm': 12.197500228881836, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 20:08:30.621 | {'loss': 0.8308, 'grad_norm': 12.24609088897705, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 20:08:47.679 | {'loss': 0.8703, 'grad_norm': 9.915521621704102, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 20:09:13.862 | {'loss': 0.8022, 'grad_norm': 11.304338455200195, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 20:09:31.585 | {'loss': 0.8657, 'grad_norm': 11.00466537475586, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 20:09:49.912 | {'loss': 0.888, 'grad_norm': 17.14505958557129, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 20:10:08.207 | {'loss': 0.7031, 'grad_norm': 10.509140968322754, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 20:10:33.123 | {'loss': 0.7873, 'grad_norm': 13.839905738830566, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 20:10:50.900 | {'loss': 0.9475, 'grad_norm': 13.546289443969727, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 20:11:08.324 | {'loss': 0.7526, 'grad_norm': 8.374750137329102, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 20:11:33.383 | {'loss': 0.939, 'grad_norm': 13.105548858642578, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 20:11:50.171 | {'loss': 1.0746, 'grad_norm': 13.630375862121582, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 20:12:07.835 | {'loss': 0.8794, 'grad_norm': 12.859764099121094, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 20:12:25.797 | {'loss': 0.9228, 'grad_norm': 13.605371475219727, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 20:12:52.099 | {'loss': 0.9283, 'grad_norm': 13.6214017868042, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 20:13:09.705 | {'loss': 0.9115, 'grad_norm': 12.923980712890625, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 20:13:27.252 | {'loss': 0.7764, 'grad_norm': 9.861930847167969, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 20:13:44.341 | {'loss': 0.4719, 'grad_norm': 6.795005798339844, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 20:14:07.674 | {'loss': 0.5738, 'grad_norm': 10.306612968444824, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 20:14:23.494 | {'loss': 0.4416, 'grad_norm': 8.808174133300781, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 20:14:40.710 | {'loss': 0.4275, 'grad_norm': 9.650506019592285, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 20:14:57.600 | {'loss': 0.6063, 'grad_norm': 3.9024829864501953, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 20:15:21.129 | {'loss': 0.5458, 'grad_norm': 8.359408378601074, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 20:15:40.270 | {'loss': 0.5916, 'grad_norm': 7.546158313751221, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 20:15:56.619 | {'loss': 0.5719, 'grad_norm': 7.333347797393799, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 20:16:12.828 | {'loss': 0.6293, 'grad_norm': 9.336394309997559, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 20:16:35.623 | {'loss': 0.4842, 'grad_norm': 6.842245578765869, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 20:16:51.690 | {'loss': 0.5729, 'grad_norm': 10.147723197937012, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 20:17:09.617 | {'loss': 0.5964, 'grad_norm': 8.931925773620605, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 20:17:27.376 | {'loss': 0.5128, 'grad_norm': 7.7998046875, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 20:17:51.173 | {'loss': 0.6095, 'grad_norm': 9.17927074432373, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 20:18:10.029 | {'loss': 0.5561, 'grad_norm': 7.820378303527832, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 20:18:27.418 | {'loss': 0.5005, 'grad_norm': 9.593687057495117, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 20:18:55.383 | {'loss': 0.5253, 'grad_norm': 7.011043071746826, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 20:19:12.115 | {'loss': 0.5263, 'grad_norm': 10.78055477142334, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 20:19:28.422 | {'loss': 0.6163, 'grad_norm': 8.385100364685059, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 20:19:45.010 | {'loss': 0.5488, 'grad_norm': 9.993197441101074, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 20:20:08.712 | {'loss': 0.34, 'grad_norm': 7.887303352355957, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 20:20:27.250 | {'loss': 0.3118, 'grad_norm': 9.819220542907715, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 20:20:45.214 | {'loss': 0.3585, 'grad_norm': 8.267702102661133, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 20:21:02.045 | {'loss': 0.3791, 'grad_norm': 8.398237228393555, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 20:21:24.766 | {'loss': 0.2968, 'grad_norm': 6.045709133148193, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 20:21:41.709 | {'loss': 0.3316, 'grad_norm': 5.152555465698242, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 20:21:59.004 | {'loss': 0.3463, 'grad_norm': 9.07131290435791, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 20:22:23.715 | {'loss': 0.308, 'grad_norm': 10.241449356079102, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 20:22:39.421 | {'loss': 0.3389, 'grad_norm': 6.386623382568359, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 20:22:55.321 | {'loss': 0.3691, 'grad_norm': 8.47985553741455, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 20:23:11.921 | {'loss': 0.3273, 'grad_norm': 7.942375183105469, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 20:23:36.296 | {'loss': 0.3759, 'grad_norm': 8.390299797058105, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 20:23:53.600 | {'loss': 0.2942, 'grad_norm': 5.132622718811035, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 20:24:09.951 | {'loss': 0.4047, 'grad_norm': 7.557244777679443, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 20:24:32.521 | {'loss': 0.303, 'grad_norm': 7.5617547035217285, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 20:24:48.660 | {'loss': 0.3004, 'grad_norm': 8.60986042022705, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 20:25:05.260 | {'loss': 0.4492, 'grad_norm': 10.125732421875, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 20:25:22.512 | {'loss': 0.3666, 'grad_norm': 8.061766624450684, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 20:25:39.704 | {'loss': 0.3348, 'grad_norm': 7.791404724121094, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 20:26:02.003 | {'loss': 0.3417, 'grad_norm': 6.22357702255249, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 20:26:18.098 | {'loss': 0.2438, 'grad_norm': 3.6403820514678955, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 20:26:34.167 | {'loss': 0.2057, 'grad_norm': 4.26806116104126, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 20:26:50.983 | {'loss': 0.1914, 'grad_norm': 4.458949089050293, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 20:27:15.544 | {'loss': 0.2068, 'grad_norm': 5.274290084838867, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 20:27:31.225 | {'loss': 0.2353, 'grad_norm': 5.68067741394043, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 20:27:47.428 | {'loss': 0.2796, 'grad_norm': 6.857703685760498, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 20:28:02.968 | {'loss': 0.2184, 'grad_norm': 5.340327739715576, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 20:28:26.780 | {'loss': 0.1935, 'grad_norm': 5.0740509033203125, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 20:28:44.751 | {'loss': 0.204, 'grad_norm': 6.013443946838379, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 20:29:01.700 | {'loss': 0.2419, 'grad_norm': 5.42025089263916, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 20:29:25.033 | {'loss': 0.3094, 'grad_norm': 6.432576656341553, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 20:29:41.469 | {'loss': 0.1999, 'grad_norm': 5.330843448638916, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 20:29:57.652 | {'loss': 0.2024, 'grad_norm': 5.9108500480651855, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-25 20:30:22.770 | {'loss': 0.2063, 'grad_norm': 2.931424379348755, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-25 20:30:39.728 | {'loss': 0.2159, 'grad_norm': 6.552939414978027, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-25 20:30:55.663 | {'loss': 0.2339, 'grad_norm': 8.60711669921875, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-25 20:31:11.620 | {'loss': 0.2412, 'grad_norm': 5.263821601867676, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-25 20:31:27.572 | {'loss': 0.2115, 'grad_norm': 4.549327850341797, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-25 20:31:43.201 | {'loss': 0.1908, 'grad_norm': 5.0724406242370605, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-25 20:32:06.002 | {'loss': 0.1704, 'grad_norm': 3.046159029006958, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-25 20:32:06.002 | {'train_runtime': 1925.3556, 'train_samples_per_second': 1.039, 'train_steps_per_second': 0.519, 'train_loss': 0.6798182917833329, 'epoch': 5.0}
2025-05-25 20:32:12.072 | INFO :      Sent reply
2025-05-25 20:38:14.815 | INFO :      
2025-05-25 20:38:14.815 | INFO :      Received: evaluate message 9616722d-5de1-4940-b488-2f1e91c24aa1
2025-05-25 20:38:18.050 | {'eval_loss': 2.946113348007202, 'eval_runtime': 1.5108, 'eval_samples_per_second': 66.188, 'eval_steps_per_second': 8.604, 'epoch': 5.0}
2025-05-25 20:38:18.053 | INFO :      Sent reply
2025-05-25 20:38:45.223 | INFO :      
2025-05-25 20:38:45.223 | INFO :      Received: train message dcba775f-a5f2-44e2-8e71-673b346afc20
2025-05-25 20:39:18.484 | {'loss': 0.8743, 'grad_norm': 13.50635814666748, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 20:39:40.082 | {'loss': 0.9753, 'grad_norm': 12.045461654663086, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 20:39:55.452 | {'loss': 0.7865, 'grad_norm': 15.6845064163208, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 20:40:10.796 | {'loss': 1.0444, 'grad_norm': 11.454404830932617, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 20:40:26.131 | {'loss': 1.0256, 'grad_norm': 10.123587608337402, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 20:40:47.954 | {'loss': 1.0472, 'grad_norm': 14.503278732299805, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 20:41:03.137 | {'loss': 0.9424, 'grad_norm': 12.424585342407227, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 20:41:18.574 | {'loss': 0.9375, 'grad_norm': 19.394794464111328, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 20:41:33.599 | {'loss': 0.9872, 'grad_norm': 12.514222145080566, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 20:41:49.253 | {'loss': 0.9061, 'grad_norm': 15.096944808959961, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 20:42:11.294 | {'loss': 0.9129, 'grad_norm': 11.433770179748535, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 20:42:26.846 | {'loss': 0.9139, 'grad_norm': 13.294791221618652, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 20:42:42.186 | {'loss': 0.9583, 'grad_norm': 17.950122833251953, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 20:42:57.344 | {'loss': 1.0283, 'grad_norm': 12.08086109161377, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 20:43:12.599 | {'loss': 0.8393, 'grad_norm': 9.5001859664917, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 20:43:34.669 | {'loss': 0.9345, 'grad_norm': 12.22778034210205, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 20:43:49.996 | {'loss': 1.0003, 'grad_norm': 13.646484375, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 20:44:05.098 | {'loss': 1.1055, 'grad_norm': 15.919713020324707, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 20:44:20.506 | {'loss': 1.127, 'grad_norm': 14.77226448059082, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 20:44:35.696 | {'loss': 1.0215, 'grad_norm': 13.22110652923584, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 20:44:57.580 | {'loss': 0.6418, 'grad_norm': 11.10458755493164, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 20:45:12.821 | {'loss': 0.498, 'grad_norm': 9.651820182800293, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 20:45:27.978 | {'loss': 0.5603, 'grad_norm': 9.648916244506836, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 20:45:43.472 | {'loss': 0.6116, 'grad_norm': 10.121260643005371, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 20:45:58.579 | {'loss': 0.56, 'grad_norm': 11.288835525512695, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 20:46:20.686 | {'loss': 0.6051, 'grad_norm': 8.71206283569336, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 20:46:35.702 | {'loss': 0.5625, 'grad_norm': 11.143726348876953, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 20:46:51.493 | {'loss': 0.5745, 'grad_norm': 9.044629096984863, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 20:47:06.900 | {'loss': 0.6324, 'grad_norm': 11.4814453125, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 20:47:29.236 | {'loss': 0.4482, 'grad_norm': 9.364623069763184, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 20:47:44.424 | {'loss': 0.5839, 'grad_norm': 12.126641273498535, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 20:47:59.840 | {'loss': 0.673, 'grad_norm': 13.714677810668945, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 20:48:15.246 | {'loss': 0.5292, 'grad_norm': 8.271195411682129, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 20:48:36.819 | {'loss': 0.5996, 'grad_norm': 10.901506423950195, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 20:48:52.396 | {'loss': 0.7509, 'grad_norm': 11.988802909851074, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 20:49:07.611 | {'loss': 0.5804, 'grad_norm': 12.686165809631348, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 20:49:23.322 | {'loss': 0.6394, 'grad_norm': 15.929637908935547, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 20:49:39.001 | {'loss': 0.6243, 'grad_norm': 12.61794662475586, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 20:50:01.743 | {'loss': 0.6572, 'grad_norm': 13.014080047607422, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 20:50:17.335 | {'loss': 0.5457, 'grad_norm': 8.222631454467773, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 20:50:32.758 | {'loss': 0.3063, 'grad_norm': 6.045219421386719, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 20:50:48.589 | {'loss': 0.4022, 'grad_norm': 9.635249137878418, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 20:51:03.474 | {'loss': 0.3153, 'grad_norm': 8.349895477294922, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 20:51:25.362 | {'loss': 0.3153, 'grad_norm': 8.018571853637695, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 20:51:40.479 | {'loss': 0.4274, 'grad_norm': 5.8062028884887695, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 20:51:55.945 | {'loss': 0.3787, 'grad_norm': 7.934596538543701, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 20:52:11.146 | {'loss': 0.4043, 'grad_norm': 6.531073570251465, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 20:52:32.935 | {'loss': 0.4288, 'grad_norm': 6.751138687133789, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 20:52:47.961 | {'loss': 0.4194, 'grad_norm': 8.992253303527832, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 20:53:03.120 | {'loss': 0.3362, 'grad_norm': 7.590878009796143, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 20:53:18.036 | {'loss': 0.4267, 'grad_norm': 8.71153736114502, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 20:53:39.404 | {'loss': 0.4147, 'grad_norm': 10.470926284790039, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 20:53:54.864 | {'loss': 0.3546, 'grad_norm': 6.469926834106445, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 20:54:09.858 | {'loss': 0.458, 'grad_norm': 9.25525188446045, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 20:54:25.399 | {'loss': 0.371, 'grad_norm': 6.608020782470703, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 20:54:47.267 | {'loss': 0.3559, 'grad_norm': 8.806684494018555, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 20:55:02.492 | {'loss': 0.3756, 'grad_norm': 6.284174919128418, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 20:55:17.782 | {'loss': 0.3693, 'grad_norm': 8.411886215209961, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 20:55:32.636 | {'loss': 0.4229, 'grad_norm': 7.737486839294434, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 20:55:47.571 | {'loss': 0.363, 'grad_norm': 7.404868125915527, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 20:56:08.921 | {'loss': 0.2279, 'grad_norm': 10.515632629394531, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 20:56:24.436 | {'loss': 0.2188, 'grad_norm': 11.214353561401367, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 20:56:39.304 | {'loss': 0.2743, 'grad_norm': 6.784422397613525, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 20:56:54.745 | {'loss': 0.2672, 'grad_norm': 6.246006488800049, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 20:57:16.451 | {'loss': 0.2225, 'grad_norm': 5.192678928375244, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 20:57:31.510 | {'loss': 0.2349, 'grad_norm': 5.007685661315918, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 20:57:46.806 | {'loss': 0.2574, 'grad_norm': 8.250142097473145, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 20:58:01.670 | {'loss': 0.2358, 'grad_norm': 8.299246788024902, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 20:58:16.690 | {'loss': 0.2345, 'grad_norm': 6.0030412673950195, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 20:58:38.076 | {'loss': 0.2421, 'grad_norm': 7.113537788391113, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 20:58:53.311 | {'loss': 0.2457, 'grad_norm': 6.6705217361450195, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 20:59:08.418 | {'loss': 0.266, 'grad_norm': 8.83858585357666, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 20:59:23.968 | {'loss': 0.1998, 'grad_norm': 4.8901448249816895, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 20:59:39.219 | {'loss': 0.2637, 'grad_norm': 6.837591648101807, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 21:00:01.035 | {'loss': 0.2392, 'grad_norm': 7.555037975311279, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 21:00:15.897 | {'loss': 0.2096, 'grad_norm': 8.442428588867188, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 21:00:31.188 | {'loss': 0.3364, 'grad_norm': 6.026310443878174, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 21:00:46.089 | {'loss': 0.2293, 'grad_norm': 6.019375801086426, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 21:01:07.902 | {'loss': 0.2231, 'grad_norm': 6.0122480392456055, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 21:01:23.196 | {'loss': 0.2341, 'grad_norm': 4.517914295196533, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 21:01:38.220 | {'loss': 0.187, 'grad_norm': 3.189756393432617, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 21:01:53.575 | {'loss': 0.1457, 'grad_norm': 3.10512113571167, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 21:02:15.404 | {'loss': 0.1388, 'grad_norm': 3.293056011199951, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 21:02:31.020 | {'loss': 0.1618, 'grad_norm': 5.1826252937316895, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 21:02:46.306 | {'loss': 0.1514, 'grad_norm': 4.658134937286377, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 21:03:01.715 | {'loss': 0.1776, 'grad_norm': 4.7982869148254395, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 21:03:23.200 | {'loss': 0.156, 'grad_norm': 3.992763042449951, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 21:03:38.255 | {'loss': 0.1506, 'grad_norm': 3.4586544036865234, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 21:03:53.549 | {'loss': 0.1431, 'grad_norm': 4.830090522766113, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 21:04:08.497 | {'loss': 0.17, 'grad_norm': 3.4049742221832275, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 21:04:23.819 | {'loss': 0.2322, 'grad_norm': 4.506906509399414, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 21:04:45.239 | {'loss': 0.1496, 'grad_norm': 4.277228355407715, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 21:05:00.752 | {'loss': 0.1424, 'grad_norm': 3.88496994972229, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-25 21:05:16.044 | {'loss': 0.1446, 'grad_norm': 4.542281150817871, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-25 21:05:31.701 | {'loss': 0.158, 'grad_norm': 7.211129665374756, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-25 21:05:53.428 | {'loss': 0.1581, 'grad_norm': 6.912064552307129, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-25 21:06:08.548 | {'loss': 0.1496, 'grad_norm': 4.121433258056641, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-25 21:06:23.739 | {'loss': 0.1603, 'grad_norm': 5.747756004333496, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-25 21:06:38.851 | {'loss': 0.1272, 'grad_norm': 4.625914573669434, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-25 21:06:54.369 | {'loss': 0.1278, 'grad_norm': 2.9037132263183594, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-25 21:06:54.369 | {'train_runtime': 1685.2174, 'train_samples_per_second': 1.187, 'train_steps_per_second': 0.593, 'train_loss': 0.4688576620817184, 'epoch': 5.0}
2025-05-25 21:07:03.659 | INFO :      Sent reply
2025-05-25 21:13:10.277 | INFO :      
2025-05-25 21:13:10.277 | INFO :      Received: evaluate message 7620fc40-2693-43db-9ef0-e4c41b49f9fb
2025-05-25 21:13:24.636 | {'eval_loss': 3.050192356109619, 'eval_runtime': 13.2529, 'eval_samples_per_second': 7.546, 'eval_steps_per_second': 0.981, 'epoch': 5.0}
2025-05-25 21:13:24.647 | INFO :      Sent reply
2025-05-25 21:13:35.052 | INFO :      
2025-05-25 21:13:35.052 | INFO :      Received: train message ede12e6a-2d4d-4820-b2c4-c48dab75514a
2025-05-25 21:13:58.290 | {'loss': 0.497, 'grad_norm': 11.905014038085938, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 21:14:13.636 | {'loss': 0.5976, 'grad_norm': 10.940659523010254, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 21:14:35.622 | {'loss': 0.493, 'grad_norm': 11.999476432800293, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 21:14:50.866 | {'loss': 0.6952, 'grad_norm': 10.814835548400879, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 21:15:06.752 | {'loss': 0.7107, 'grad_norm': 14.364583969116211, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 21:15:22.737 | {'loss': 0.7025, 'grad_norm': 10.65264892578125, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 21:15:38.566 | {'loss': 0.6223, 'grad_norm': 10.928692817687988, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 21:15:54.214 | {'loss': 0.6391, 'grad_norm': 18.490495681762695, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 21:16:16.291 | {'loss': 0.6584, 'grad_norm': 13.218474388122559, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 21:16:31.769 | {'loss': 0.602, 'grad_norm': 14.18509292602539, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 21:16:46.951 | {'loss': 0.6565, 'grad_norm': 9.115594863891602, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 21:17:02.462 | {'loss': 0.6252, 'grad_norm': 12.677978515625, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 21:17:23.934 | {'loss': 0.6441, 'grad_norm': 16.79806900024414, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 21:17:39.851 | {'loss': 0.7256, 'grad_norm': 11.68313217163086, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 21:17:55.102 | {'loss': 0.5864, 'grad_norm': 8.3790283203125, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 21:18:10.511 | {'loss': 0.6681, 'grad_norm': 11.00043773651123, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 21:18:32.398 | {'loss': 0.6706, 'grad_norm': 12.074901580810547, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 21:18:47.279 | {'loss': 0.7474, 'grad_norm': 13.773238182067871, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 21:19:02.560 | {'loss': 0.786, 'grad_norm': 13.52341365814209, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 21:19:17.648 | {'loss': 0.721, 'grad_norm': 12.009206771850586, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 21:19:39.574 | {'loss': 0.4999, 'grad_norm': 11.827680587768555, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 21:19:54.936 | {'loss': 0.3913, 'grad_norm': 9.365917205810547, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 21:20:10.541 | {'loss': 0.3933, 'grad_norm': 9.739999771118164, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 21:20:26.070 | {'loss': 0.4777, 'grad_norm': 10.9210205078125, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 21:20:41.638 | {'loss': 0.4183, 'grad_norm': 11.088033676147461, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 21:21:03.649 | {'loss': 0.4559, 'grad_norm': 8.900546073913574, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 21:21:18.840 | {'loss': 0.4226, 'grad_norm': 11.818778991699219, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 21:21:34.355 | {'loss': 0.4316, 'grad_norm': 8.5488920211792, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 21:21:49.512 | {'loss': 0.4302, 'grad_norm': 10.26880931854248, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 21:22:11.487 | {'loss': 0.3634, 'grad_norm': 10.835779190063477, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 21:22:26.956 | {'loss': 0.4445, 'grad_norm': 11.2207670211792, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 21:22:42.547 | {'loss': 0.4739, 'grad_norm': 11.374558448791504, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 21:22:58.076 | {'loss': 0.4079, 'grad_norm': 7.930043697357178, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 21:23:20.018 | {'loss': 0.4951, 'grad_norm': 8.560285568237305, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 21:23:35.491 | {'loss': 0.5632, 'grad_norm': 11.599045753479004, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 21:23:50.607 | {'loss': 0.4098, 'grad_norm': 12.410569190979004, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 21:24:05.956 | {'loss': 0.4639, 'grad_norm': 12.710946083068848, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 21:24:21.034 | {'loss': 0.4571, 'grad_norm': 12.054448127746582, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 21:24:42.948 | {'loss': 0.4834, 'grad_norm': 8.190590858459473, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 21:24:58.202 | {'loss': 0.3842, 'grad_norm': 6.995010852813721, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 21:25:13.555 | {'loss': 0.2346, 'grad_norm': 6.7851128578186035, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 21:25:29.217 | {'loss': 0.2988, 'grad_norm': 7.694911003112793, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 21:25:51.614 | {'loss': 0.2481, 'grad_norm': 8.06265640258789, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 21:26:07.228 | {'loss': 0.2682, 'grad_norm': 8.408586502075195, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 21:26:22.436 | {'loss': 0.3507, 'grad_norm': 2.7825565338134766, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 21:26:37.641 | {'loss': 0.2973, 'grad_norm': 7.804443836212158, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 21:26:52.848 | {'loss': 0.3076, 'grad_norm': 6.815134525299072, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 21:27:14.577 | {'loss': 0.3628, 'grad_norm': 6.829745292663574, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 21:27:30.225 | {'loss': 0.3532, 'grad_norm': 10.292213439941406, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 21:27:45.364 | {'loss': 0.2606, 'grad_norm': 5.381237983703613, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 21:28:01.378 | {'loss': 0.312, 'grad_norm': 8.78566837310791, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 21:28:23.500 | {'loss': 0.2879, 'grad_norm': 6.1880106925964355, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 21:28:38.609 | {'loss': 0.262, 'grad_norm': 5.563810348510742, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 21:28:53.623 | {'loss': 0.3458, 'grad_norm': 6.823083400726318, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 21:29:09.467 | {'loss': 0.2958, 'grad_norm': 6.51508903503418, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 21:29:30.676 | {'loss': 0.2696, 'grad_norm': 9.36227035522461, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 21:29:46.052 | {'loss': 0.275, 'grad_norm': 6.352938175201416, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 21:30:01.608 | {'loss': 0.26, 'grad_norm': 6.775660514831543, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 21:30:17.419 | {'loss': 0.3159, 'grad_norm': 7.79465389251709, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 21:30:32.791 | {'loss': 0.2826, 'grad_norm': 8.227944374084473, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 21:30:54.767 | {'loss': 0.1895, 'grad_norm': 10.10285758972168, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 21:31:09.841 | {'loss': 0.203, 'grad_norm': 9.687342643737793, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 21:31:24.845 | {'loss': 0.2124, 'grad_norm': 5.817760467529297, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 21:31:40.422 | {'loss': 0.2391, 'grad_norm': 7.108055114746094, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 21:32:02.528 | {'loss': 0.1702, 'grad_norm': 4.742913246154785, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 21:32:18.178 | {'loss': 0.1832, 'grad_norm': 5.047060012817383, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 21:32:34.019 | {'loss': 0.1956, 'grad_norm': 7.3746113777160645, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 21:32:49.028 | {'loss': 0.1767, 'grad_norm': 5.969593048095703, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 21:33:10.602 | {'loss': 0.1854, 'grad_norm': 4.1400227546691895, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 21:33:25.806 | {'loss': 0.1824, 'grad_norm': 8.169525146484375, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 21:33:41.077 | {'loss': 0.1931, 'grad_norm': 7.252786636352539, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 21:33:56.130 | {'loss': 0.2139, 'grad_norm': 6.432013511657715, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 21:34:11.610 | {'loss': 0.1629, 'grad_norm': 4.000777721405029, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 21:34:27.116 | {'loss': 0.2204, 'grad_norm': 6.1818108558654785, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 21:34:49.670 | {'loss': 0.1658, 'grad_norm': 6.9014739990234375, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 21:35:05.142 | {'loss': 0.17, 'grad_norm': 7.84290885925293, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 21:35:20.255 | {'loss': 0.299, 'grad_norm': 3.4185898303985596, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 21:35:35.581 | {'loss': 0.1913, 'grad_norm': 5.92897367477417, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 21:35:50.864 | {'loss': 0.1931, 'grad_norm': 5.194798469543457, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 21:36:12.684 | {'loss': 0.1895, 'grad_norm': 5.82636833190918, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 21:36:27.780 | {'loss': 0.1286, 'grad_norm': 2.8004918098449707, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 21:36:43.299 | {'loss': 0.1282, 'grad_norm': 2.7055816650390625, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 21:36:58.465 | {'loss': 0.119, 'grad_norm': 2.6355857849121094, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 21:37:14.179 | {'loss': 0.1355, 'grad_norm': 3.8997530937194824, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 21:37:36.787 | {'loss': 0.1186, 'grad_norm': 2.3670871257781982, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 21:37:52.312 | {'loss': 0.1408, 'grad_norm': 3.804985523223877, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 21:38:07.804 | {'loss': 0.1205, 'grad_norm': 3.50355863571167, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 21:38:22.974 | {'loss': 0.1197, 'grad_norm': 3.0767457485198975, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 21:38:45.112 | {'loss': 0.1072, 'grad_norm': 3.3958165645599365, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 21:39:00.293 | {'loss': 0.1318, 'grad_norm': 3.72287917137146, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 21:39:15.780 | {'loss': 0.2168, 'grad_norm': 3.4171266555786133, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 21:39:31.081 | {'loss': 0.1225, 'grad_norm': 5.407827377319336, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 21:39:52.604 | {'loss': 0.1166, 'grad_norm': 4.400193691253662, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-25 21:40:08.001 | {'loss': 0.1147, 'grad_norm': 1.9735631942749023, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-25 21:40:23.329 | {'loss': 0.1281, 'grad_norm': 5.147767066955566, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-25 21:40:38.994 | {'loss': 0.127, 'grad_norm': 5.74486780166626, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-25 21:41:00.501 | {'loss': 0.12, 'grad_norm': 4.014448165893555, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-25 21:41:15.833 | {'loss': 0.116, 'grad_norm': 3.599756956100464, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-25 21:41:30.996 | {'loss': 0.1091, 'grad_norm': 3.6313774585723877, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-25 21:41:46.281 | {'loss': 0.1222, 'grad_norm': 4.138863563537598, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-25 21:41:46.281 | {'train_runtime': 1688.7781, 'train_samples_per_second': 1.184, 'train_steps_per_second': 0.592, 'train_loss': 0.3428348381519318, 'epoch': 5.0}
2025-05-25 21:41:59.188 | INFO :      Sent reply
2025-05-25 21:48:09.943 | INFO :      
2025-05-25 21:48:09.943 | INFO :      Received: evaluate message d36c6b43-7169-41bb-ba36-5f979b50eeb8
2025-05-25 21:48:22.759 | {'eval_loss': 3.1774730682373047, 'eval_runtime': 9.5503, 'eval_samples_per_second': 10.471, 'eval_steps_per_second': 1.361, 'epoch': 5.0}
2025-05-25 21:48:22.760 | INFO :      Sent reply
2025-05-25 21:48:38.196 | INFO :      
2025-05-25 21:48:38.196 | INFO :      Received: train message 1980963e-66f8-4a24-acf5-4497278580ca
2025-05-25 21:49:13.352 | {'loss': 0.3027, 'grad_norm': 8.664938926696777, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 21:49:28.193 | {'loss': 0.3826, 'grad_norm': 9.616727828979492, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 21:49:43.755 | {'loss': 0.3354, 'grad_norm': 10.983076095581055, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 21:49:58.877 | {'loss': 0.4667, 'grad_norm': 8.588460922241211, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 21:50:14.484 | {'loss': 0.458, 'grad_norm': 8.787186622619629, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 21:50:29.420 | {'loss': 0.4887, 'grad_norm': 9.874497413635254, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 21:50:51.088 | {'loss': 0.4216, 'grad_norm': 10.644342422485352, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 21:51:06.197 | {'loss': 0.4624, 'grad_norm': 16.723289489746094, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 21:51:20.948 | {'loss': 0.4661, 'grad_norm': 11.05444049835205, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 21:51:35.865 | {'loss': 0.4378, 'grad_norm': 11.987011909484863, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 21:51:57.261 | {'loss': 0.4759, 'grad_norm': 8.781611442565918, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 21:52:12.846 | {'loss': 0.4692, 'grad_norm': 11.510334968566895, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 21:52:27.872 | {'loss': 0.4912, 'grad_norm': 12.812220573425293, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 21:52:43.230 | {'loss': 0.517, 'grad_norm': 8.0703125, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 21:52:58.255 | {'loss': 0.4467, 'grad_norm': 7.606640815734863, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 21:53:19.825 | {'loss': 0.4804, 'grad_norm': 7.516103744506836, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 21:53:34.728 | {'loss': 0.4915, 'grad_norm': 11.97667121887207, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 21:53:50.022 | {'loss': 0.5438, 'grad_norm': 12.428892135620117, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 21:54:04.998 | {'loss': 0.5662, 'grad_norm': 10.628026008605957, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 21:54:20.204 | {'loss': 0.528, 'grad_norm': 10.937972068786621, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 21:54:42.116 | {'loss': 0.5007, 'grad_norm': 10.928860664367676, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 21:54:57.500 | {'loss': 0.3337, 'grad_norm': 6.842249393463135, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 21:55:13.107 | {'loss': 0.3171, 'grad_norm': 6.417919635772705, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 21:55:34.539 | {'loss': 0.3857, 'grad_norm': 9.564242362976074, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 21:55:49.845 | {'loss': 0.3409, 'grad_norm': 11.967138290405273, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 21:56:04.719 | {'loss': 0.3429, 'grad_norm': 7.605373859405518, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 21:56:20.029 | {'loss': 0.3439, 'grad_norm': 8.233128547668457, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 21:56:34.967 | {'loss': 0.3395, 'grad_norm': 8.841686248779297, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 21:56:56.956 | {'loss': 0.3664, 'grad_norm': 10.590853691101074, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 21:57:12.596 | {'loss': 0.2947, 'grad_norm': 7.052844524383545, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 21:57:28.041 | {'loss': 0.3623, 'grad_norm': 9.544164657592773, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 21:57:43.365 | {'loss': 0.407, 'grad_norm': 10.67423152923584, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 21:58:05.044 | {'loss': 0.3404, 'grad_norm': 7.855517387390137, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 21:58:20.424 | {'loss': 0.4076, 'grad_norm': 8.656294822692871, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 21:58:35.458 | {'loss': 0.4316, 'grad_norm': 11.673991203308105, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 21:58:50.865 | {'loss': 0.3385, 'grad_norm': 11.842803955078125, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 21:59:12.766 | {'loss': 0.3957, 'grad_norm': 8.941699981689453, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 21:59:28.144 | {'loss': 0.373, 'grad_norm': 10.899456024169922, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 21:59:43.826 | {'loss': 0.3831, 'grad_norm': 12.109106063842773, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 21:59:59.244 | {'loss': 0.3045, 'grad_norm': 7.832786560058594, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 22:00:14.754 | {'loss': 0.2265, 'grad_norm': 5.730356216430664, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 22:00:36.082 | {'loss': 0.259, 'grad_norm': 6.3463029861450195, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 22:00:51.275 | {'loss': 0.2246, 'grad_norm': 9.725695610046387, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 22:01:06.219 | {'loss': 0.2341, 'grad_norm': 7.362449645996094, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 22:01:21.660 | {'loss': 0.2847, 'grad_norm': 4.054443836212158, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 22:01:36.333 | {'loss': 0.2333, 'grad_norm': 5.587565898895264, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 22:01:58.035 | {'loss': 0.2417, 'grad_norm': 5.401113986968994, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 22:02:13.507 | {'loss': 0.3574, 'grad_norm': 4.506986141204834, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 22:02:28.816 | {'loss': 0.2864, 'grad_norm': 7.803133010864258, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 22:02:44.098 | {'loss': 0.2418, 'grad_norm': 5.6316938400268555, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 22:03:05.607 | {'loss': 0.2574, 'grad_norm': 7.732008457183838, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 22:03:21.043 | {'loss': 0.2531, 'grad_norm': 5.762979507446289, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 22:03:36.037 | {'loss': 0.2396, 'grad_norm': 5.529104232788086, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 22:03:51.387 | {'loss': 0.267, 'grad_norm': 5.17203950881958, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 22:04:13.094 | {'loss': 0.2406, 'grad_norm': 6.065966606140137, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 22:04:28.752 | {'loss': 0.2425, 'grad_norm': 8.839926719665527, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 22:04:43.944 | {'loss': 0.2478, 'grad_norm': 5.99171781539917, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 22:04:59.550 | {'loss': 0.2522, 'grad_norm': 7.184958457946777, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 22:05:15.169 | {'loss': 0.277, 'grad_norm': 6.096107006072998, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 22:05:36.964 | {'loss': 0.2318, 'grad_norm': 5.682206153869629, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 22:05:51.964 | {'loss': 0.1627, 'grad_norm': 6.9616007804870605, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 22:06:06.728 | {'loss': 0.1476, 'grad_norm': 8.172457695007324, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 22:06:22.248 | {'loss': 0.1842, 'grad_norm': 5.576269626617432, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 22:06:43.854 | {'loss': 0.17, 'grad_norm': 5.525527477264404, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 22:06:59.655 | {'loss': 0.1541, 'grad_norm': 5.629444599151611, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 22:07:15.358 | {'loss': 0.1594, 'grad_norm': 3.5797033309936523, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 22:07:30.342 | {'loss': 0.1779, 'grad_norm': 7.683941841125488, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 22:07:52.361 | {'loss': 0.1566, 'grad_norm': 6.324016094207764, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 22:08:07.022 | {'loss': 0.1604, 'grad_norm': 3.9519519805908203, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 22:08:22.148 | {'loss': 0.1621, 'grad_norm': 5.954984188079834, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 22:08:36.974 | {'loss': 0.1757, 'grad_norm': 5.286906719207764, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 22:08:52.291 | {'loss': 0.1865, 'grad_norm': 5.1964311599731445, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 22:09:13.957 | {'loss': 0.1494, 'grad_norm': 3.697006940841675, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 22:09:29.481 | {'loss': 0.1781, 'grad_norm': 4.151203632354736, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 22:09:44.902 | {'loss': 0.1587, 'grad_norm': 6.078758716583252, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 22:10:00.139 | {'loss': 0.1488, 'grad_norm': 6.363705158233643, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 22:10:15.456 | {'loss': 0.2267, 'grad_norm': 4.328303337097168, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 22:10:37.000 | {'loss': 0.1491, 'grad_norm': 3.890352725982666, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 22:10:52.246 | {'loss': 0.1476, 'grad_norm': 4.413086891174316, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 22:11:07.142 | {'loss': 0.1604, 'grad_norm': 4.219361305236816, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 22:11:22.427 | {'loss': 0.1194, 'grad_norm': 2.2106661796569824, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 22:11:37.420 | {'loss': 0.1005, 'grad_norm': 3.862623453140259, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 22:11:59.415 | {'loss': 0.103, 'grad_norm': 2.5441901683807373, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 22:12:14.968 | {'loss': 0.1121, 'grad_norm': 3.001070737838745, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 22:12:30.506 | {'loss': 0.1135, 'grad_norm': 4.210225582122803, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 22:12:45.879 | {'loss': 0.1137, 'grad_norm': 3.9879469871520996, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 22:13:00.849 | {'loss': 0.1025, 'grad_norm': 3.7945683002471924, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 22:13:22.905 | {'loss': 0.1045, 'grad_norm': 2.4733452796936035, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 22:13:37.687 | {'loss': 0.1084, 'grad_norm': 3.4065794944763184, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 22:13:52.658 | {'loss': 0.1232, 'grad_norm': 3.539632558822632, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 22:14:07.771 | {'loss': 0.1675, 'grad_norm': 3.427220106124878, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 22:14:29.911 | {'loss': 0.1062, 'grad_norm': 2.788564920425415, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 22:14:45.404 | {'loss': 0.1081, 'grad_norm': 3.4871268272399902, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-25 22:15:00.620 | {'loss': 0.1047, 'grad_norm': 1.8262341022491455, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-25 22:15:15.896 | {'loss': 0.117, 'grad_norm': 4.662248134613037, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-25 22:15:30.998 | {'loss': 0.1145, 'grad_norm': 4.786839008331299, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-25 22:15:52.444 | {'loss': 0.1013, 'grad_norm': 2.853748083114624, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-25 22:16:07.276 | {'loss': 0.0944, 'grad_norm': 3.0688958168029785, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-25 22:16:22.564 | {'loss': 0.0923, 'grad_norm': 2.735239267349243, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-25 22:16:36.648 | {'loss': 0.0963, 'grad_norm': 2.555391788482666, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-25 22:16:36.648 | {'train_runtime': 1672.2733, 'train_samples_per_second': 1.196, 'train_steps_per_second': 0.598, 'train_loss': 0.27158282142877577, 'epoch': 5.0}
2025-05-25 22:16:40.524 | INFO :      Sent reply
2025-05-25 22:22:49.301 | INFO :      
2025-05-25 22:22:49.301 | INFO :      Received: evaluate message 14417b8c-8fa1-4b49-96e5-a9fd39fee97a
2025-05-25 22:23:03.745 | {'eval_loss': 3.281327724456787, 'eval_runtime': 13.6849, 'eval_samples_per_second': 7.307, 'eval_steps_per_second': 0.95, 'epoch': 5.0}
2025-05-25 22:23:03.746 | INFO :      Sent reply
2025-05-25 22:23:15.504 | INFO :      
2025-05-25 22:23:15.504 | INFO :      Received: train message b8f52996-e23b-4ff8-96bf-5c94ed13dd6b
2025-05-25 22:23:51.555 | {'loss': 0.2041, 'grad_norm': 9.505302429199219, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 22:24:13.258 | {'loss': 0.2935, 'grad_norm': 8.553871154785156, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 22:24:28.836 | {'loss': 0.2904, 'grad_norm': 11.144180297851562, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 22:24:44.226 | {'loss': 0.332, 'grad_norm': 7.4246649742126465, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 22:24:59.886 | {'loss': 0.3672, 'grad_norm': 8.703164100646973, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 22:25:15.622 | {'loss': 0.347, 'grad_norm': 8.449708938598633, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 22:25:37.441 | {'loss': 0.3212, 'grad_norm': 8.876399040222168, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 22:25:52.804 | {'loss': 0.331, 'grad_norm': 13.33893871307373, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 22:26:08.174 | {'loss': 0.3244, 'grad_norm': 10.627277374267578, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 22:26:30.257 | {'loss': 0.3196, 'grad_norm': 11.466197967529297, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 22:26:45.632 | {'loss': 0.3727, 'grad_norm': 7.362919807434082, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 22:27:07.390 | {'loss': 0.3392, 'grad_norm': 10.70483112335205, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 22:27:22.741 | {'loss': 0.3752, 'grad_norm': 10.893542289733887, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 22:27:37.877 | {'loss': 0.3816, 'grad_norm': 9.076695442199707, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 22:27:59.819 | {'loss': 0.3412, 'grad_norm': 6.659234523773193, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 22:28:15.261 | {'loss': 0.397, 'grad_norm': 7.984790802001953, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 22:28:30.876 | {'loss': 0.3788, 'grad_norm': 10.690103530883789, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 22:28:46.107 | {'loss': 0.4, 'grad_norm': 11.21566104888916, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 22:29:08.125 | {'loss': 0.4209, 'grad_norm': 10.54716968536377, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 22:29:23.523 | {'loss': 0.4301, 'grad_norm': 11.28162956237793, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 22:29:39.100 | {'loss': 0.4001, 'grad_norm': 10.084936141967773, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 22:30:01.811 | {'loss': 0.3226, 'grad_norm': 9.18777847290039, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 22:30:16.719 | {'loss': 0.2729, 'grad_norm': 7.968265056610107, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 22:30:32.466 | {'loss': 0.3191, 'grad_norm': 7.751004695892334, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 22:30:53.923 | {'loss': 0.2687, 'grad_norm': 10.024706840515137, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 22:31:09.127 | {'loss': 0.2994, 'grad_norm': 8.196980476379395, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 22:31:24.739 | {'loss': 0.2565, 'grad_norm': 9.082818031311035, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 22:31:46.498 | {'loss': 0.2999, 'grad_norm': 8.475802421569824, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 22:32:01.851 | {'loss': 0.2995, 'grad_norm': 8.156173706054688, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 22:32:17.232 | {'loss': 0.2417, 'grad_norm': 7.479922771453857, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 22:32:32.964 | {'loss': 0.3194, 'grad_norm': 10.16234016418457, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 22:32:54.825 | {'loss': 0.3461, 'grad_norm': 10.870736122131348, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 22:33:09.666 | {'loss': 0.3187, 'grad_norm': 6.005552291870117, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 22:33:24.969 | {'loss': 0.3325, 'grad_norm': 7.3096795082092285, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 22:33:40.315 | {'loss': 0.3751, 'grad_norm': 10.051329612731934, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 22:34:01.509 | {'loss': 0.3108, 'grad_norm': 10.609728813171387, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 22:34:16.503 | {'loss': 0.3281, 'grad_norm': 9.865192413330078, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 22:34:32.264 | {'loss': 0.3445, 'grad_norm': 11.094892501831055, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 22:34:47.594 | {'loss': 0.3089, 'grad_norm': 10.481082916259766, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 22:35:09.671 | {'loss': 0.2867, 'grad_norm': 9.050958633422852, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 22:35:24.990 | {'loss': 0.1871, 'grad_norm': 3.7474610805511475, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 22:35:40.125 | {'loss': 0.2387, 'grad_norm': 8.758234977722168, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 22:35:55.401 | {'loss': 0.1867, 'grad_norm': 6.246364116668701, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 22:36:17.023 | {'loss': 0.1919, 'grad_norm': 6.21790075302124, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 22:36:32.477 | {'loss': 0.2449, 'grad_norm': 3.825571060180664, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 22:36:47.597 | {'loss': 0.1994, 'grad_norm': 6.139913558959961, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 22:37:03.318 | {'loss': 0.228, 'grad_norm': 4.883917808532715, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 22:37:25.800 | {'loss': 0.2862, 'grad_norm': 6.314049243927002, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 22:37:41.661 | {'loss': 0.2491, 'grad_norm': 6.802785396575928, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 22:37:57.360 | {'loss': 0.2039, 'grad_norm': 4.62065315246582, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 22:38:12.728 | {'loss': 0.2364, 'grad_norm': 7.54592752456665, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 22:38:28.198 | {'loss': 0.2046, 'grad_norm': 4.753092288970947, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 22:38:49.728 | {'loss': 0.2029, 'grad_norm': 5.142430305480957, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 22:39:05.222 | {'loss': 0.2224, 'grad_norm': 6.684719085693359, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 22:39:20.645 | {'loss': 0.2213, 'grad_norm': 5.435552597045898, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 22:39:35.851 | {'loss': 0.193, 'grad_norm': 7.306754112243652, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 22:39:51.109 | {'loss': 0.2496, 'grad_norm': 5.966058731079102, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 22:40:13.457 | {'loss': 0.2237, 'grad_norm': 6.220445156097412, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 22:40:29.215 | {'loss': 0.2348, 'grad_norm': 7.67634916305542, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 22:40:44.081 | {'loss': 0.1996, 'grad_norm': 5.879062175750732, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 22:40:59.960 | {'loss': 0.1459, 'grad_norm': 5.463621139526367, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 22:41:20.994 | {'loss': 0.1307, 'grad_norm': 6.870179176330566, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 22:41:36.479 | {'loss': 0.1551, 'grad_norm': 4.591263294219971, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 22:41:51.901 | {'loss': 0.155, 'grad_norm': 4.5057692527771, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 22:42:06.910 | {'loss': 0.1469, 'grad_norm': 3.992419719696045, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 22:42:28.849 | {'loss': 0.1379, 'grad_norm': 3.3511850833892822, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 22:42:44.417 | {'loss': 0.1491, 'grad_norm': 5.990523338317871, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 22:43:00.356 | {'loss': 0.1389, 'grad_norm': 6.453723430633545, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 22:43:15.546 | {'loss': 0.1564, 'grad_norm': 6.898764610290527, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 22:43:37.794 | {'loss': 0.148, 'grad_norm': 3.9733855724334717, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 22:43:53.412 | {'loss': 0.133, 'grad_norm': 5.2177300453186035, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 22:44:08.902 | {'loss': 0.1726, 'grad_norm': 7.208332538604736, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 22:44:31.024 | {'loss': 0.1409, 'grad_norm': 3.1303884983062744, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 22:44:46.366 | {'loss': 0.161, 'grad_norm': 6.927301406860352, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 22:45:01.973 | {'loss': 0.1245, 'grad_norm': 5.432861328125, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 22:45:23.941 | {'loss': 0.1204, 'grad_norm': 3.2146084308624268, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 22:45:39.645 | {'loss': 0.2277, 'grad_norm': 4.033931732177734, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 22:45:55.422 | {'loss': 0.1459, 'grad_norm': 5.706601619720459, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 22:46:11.037 | {'loss': 0.1334, 'grad_norm': 4.240015029907227, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 22:46:32.564 | {'loss': 0.147, 'grad_norm': 3.6710617542266846, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 22:46:47.685 | {'loss': 0.1032, 'grad_norm': 2.0179951190948486, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 22:47:03.218 | {'loss': 0.0954, 'grad_norm': 2.6326255798339844, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 22:47:18.315 | {'loss': 0.092, 'grad_norm': 2.3164546489715576, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 22:47:40.142 | {'loss': 0.0957, 'grad_norm': 3.0551044940948486, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 22:47:55.883 | {'loss': 0.0988, 'grad_norm': 3.7184505462646484, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 22:48:11.579 | {'loss': 0.1018, 'grad_norm': 3.247941493988037, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 22:48:33.840 | {'loss': 0.0903, 'grad_norm': 3.341118335723877, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 22:48:49.142 | {'loss': 0.089, 'grad_norm': 1.8475080728530884, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 22:49:04.630 | {'loss': 0.0925, 'grad_norm': 2.4908969402313232, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 22:49:19.917 | {'loss': 0.1046, 'grad_norm': 2.9012956619262695, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 22:49:35.281 | {'loss': 0.1609, 'grad_norm': 4.5913920402526855, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 22:49:57.209 | {'loss': 0.1034, 'grad_norm': 3.620410442352295, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 22:50:12.200 | {'loss': 0.0866, 'grad_norm': 2.513599395751953, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-25 22:50:27.658 | {'loss': 0.0939, 'grad_norm': 2.2080118656158447, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-25 22:50:42.733 | {'loss': 0.1073, 'grad_norm': 6.917037010192871, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-25 22:50:58.050 | {'loss': 0.0989, 'grad_norm': 3.8120460510253906, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-25 22:51:13.328 | {'loss': 0.0915, 'grad_norm': 2.1160800457000732, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-25 22:51:34.932 | {'loss': 0.0907, 'grad_norm': 4.61368989944458, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-25 22:51:41.128 | {'loss': 0.088, 'grad_norm': 4.051972389221191, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-25 22:51:43.337 | {'loss': 0.0959, 'grad_norm': 2.035029649734497, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-25 22:51:43.337 | {'train_runtime': 1704.8305, 'train_samples_per_second': 1.173, 'train_steps_per_second': 0.587, 'train_loss': 0.2257325730919838, 'epoch': 5.0}
2025-05-25 22:51:47.809 | INFO :      Sent reply
2025-05-25 22:57:48.015 | INFO :      
2025-05-25 22:57:48.015 | INFO :      Received: evaluate message 2e903a95-c888-4ed7-85f9-33ce7ce41bb6
2025-05-25 22:57:50.334 | {'eval_loss': 3.3651838302612305, 'eval_runtime': 1.5077, 'eval_samples_per_second': 66.324, 'eval_steps_per_second': 8.622, 'epoch': 5.0}
2025-05-25 22:57:50.355 | INFO :      Sent reply
2025-05-25 22:58:12.242 | INFO :      
2025-05-25 22:58:12.242 | INFO :      Received: train message 3a76968a-54d3-444c-ace5-9f7235056f49
2025-05-25 22:58:37.750 | {'loss': 0.1405, 'grad_norm': 6.0208001136779785, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 22:58:53.252 | {'loss': 0.2153, 'grad_norm': 7.541180610656738, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 22:59:08.993 | {'loss': 0.2316, 'grad_norm': 8.401933670043945, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 22:59:31.473 | {'loss': 0.2469, 'grad_norm': 7.523153781890869, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 22:59:47.598 | {'loss': 0.2602, 'grad_norm': 6.091914653778076, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 23:00:02.860 | {'loss': 0.2729, 'grad_norm': 7.882956027984619, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 23:00:24.946 | {'loss': 0.2657, 'grad_norm': 6.488691329956055, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 23:00:40.960 | {'loss': 0.2778, 'grad_norm': 11.418070793151855, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 23:00:55.839 | {'loss': 0.279, 'grad_norm': 8.191598892211914, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 23:01:17.872 | {'loss': 0.2726, 'grad_norm': 9.48828125, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 23:01:33.530 | {'loss': 0.2838, 'grad_norm': 6.445278167724609, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 23:01:49.120 | {'loss': 0.2716, 'grad_norm': 9.377655029296875, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 23:02:05.094 | {'loss': 0.3148, 'grad_norm': 9.654030799865723, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 23:02:27.260 | {'loss': 0.2961, 'grad_norm': 5.611457824707031, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 23:02:43.125 | {'loss': 0.2773, 'grad_norm': 7.3138427734375, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 23:02:58.487 | {'loss': 0.3164, 'grad_norm': 6.6682305335998535, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 23:03:13.484 | {'loss': 0.3203, 'grad_norm': 9.809542655944824, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 23:03:28.581 | {'loss': 0.3403, 'grad_norm': 9.196151733398438, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 23:03:50.575 | {'loss': 0.3405, 'grad_norm': 9.84599781036377, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 23:04:06.219 | {'loss': 0.3264, 'grad_norm': 8.740226745605469, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 23:04:28.679 | {'loss': 0.3467, 'grad_norm': 11.074407577514648, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 23:04:44.752 | {'loss': 0.2526, 'grad_norm': 7.044478893280029, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 23:05:00.393 | {'loss': 0.2291, 'grad_norm': 7.295366287231445, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 23:05:22.022 | {'loss': 0.2962, 'grad_norm': 7.486475467681885, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 23:05:37.189 | {'loss': 0.2689, 'grad_norm': 9.916637420654297, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 23:05:58.641 | {'loss': 0.2424, 'grad_norm': 6.485844612121582, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 23:06:14.502 | {'loss': 0.2424, 'grad_norm': 9.705717086791992, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 23:06:29.188 | {'loss': 0.2503, 'grad_norm': 7.208719730377197, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 23:06:44.752 | {'loss': 0.2846, 'grad_norm': 6.821938991546631, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 23:07:07.188 | {'loss': 0.2007, 'grad_norm': 7.019242763519287, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 23:07:22.501 | {'loss': 0.2987, 'grad_norm': 8.675019264221191, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 23:07:37.805 | {'loss': 0.2851, 'grad_norm': 8.841063499450684, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 23:07:53.055 | {'loss': 0.2778, 'grad_norm': 7.389888763427734, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 23:08:14.592 | {'loss': 0.2956, 'grad_norm': 5.626870632171631, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 23:08:29.841 | {'loss': 0.3343, 'grad_norm': 8.513297080993652, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 23:08:45.195 | {'loss': 0.2463, 'grad_norm': 11.53652572631836, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 23:09:00.385 | {'loss': 0.2789, 'grad_norm': 8.592483520507812, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 23:09:15.613 | {'loss': 0.2851, 'grad_norm': 7.3641839027404785, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 23:09:38.017 | {'loss': 0.3105, 'grad_norm': 9.077959060668945, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 23:09:53.667 | {'loss': 0.2688, 'grad_norm': 6.332055568695068, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 23:10:09.549 | {'loss': 0.1721, 'grad_norm': 4.613856315612793, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 23:10:30.667 | {'loss': 0.1919, 'grad_norm': 7.288071155548096, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 23:10:46.048 | {'loss': 0.1628, 'grad_norm': 7.670966625213623, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 23:11:01.083 | {'loss': 0.1651, 'grad_norm': 5.098942756652832, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 23:11:16.525 | {'loss': 0.2252, 'grad_norm': 2.680542230606079, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 23:11:31.918 | {'loss': 0.1899, 'grad_norm': 5.256518363952637, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 23:11:53.980 | {'loss': 0.2032, 'grad_norm': 6.227043628692627, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 23:12:10.690 | {'loss': 0.2733, 'grad_norm': 4.249463081359863, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 23:12:26.012 | {'loss': 0.1956, 'grad_norm': 6.326825141906738, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 23:12:41.790 | {'loss': 0.1968, 'grad_norm': 5.7799506187438965, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 23:13:03.109 | {'loss': 0.2008, 'grad_norm': 5.290407657623291, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 23:13:18.351 | {'loss': 0.181, 'grad_norm': 5.863531589508057, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 23:13:33.630 | {'loss': 0.1744, 'grad_norm': 4.542275428771973, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 23:13:48.904 | {'loss': 0.2126, 'grad_norm': 7.82343864440918, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 23:14:04.206 | {'loss': 0.2033, 'grad_norm': 7.291525840759277, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 23:14:26.176 | {'loss': 0.2055, 'grad_norm': 8.11080265045166, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 23:14:42.100 | {'loss': 0.2298, 'grad_norm': 6.150053977966309, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 23:14:57.886 | {'loss': 0.1806, 'grad_norm': 5.713181972503662, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 23:15:20.016 | {'loss': 0.1866, 'grad_norm': 5.085751533508301, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 23:15:35.421 | {'loss': 0.1839, 'grad_norm': 6.748719692230225, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 23:15:50.830 | {'loss': 0.1171, 'grad_norm': 4.827128887176514, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 23:16:06.339 | {'loss': 0.1154, 'grad_norm': 5.1498517990112305, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 23:16:28.148 | {'loss': 0.1358, 'grad_norm': 4.282224655151367, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 23:16:43.726 | {'loss': 0.1424, 'grad_norm': 2.9857475757598877, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 23:16:59.336 | {'loss': 0.1293, 'grad_norm': 5.022472858428955, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 23:17:15.071 | {'loss': 0.1393, 'grad_norm': 3.8072423934936523, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 23:17:37.575 | {'loss': 0.153, 'grad_norm': 5.696312427520752, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 23:17:52.848 | {'loss': 0.1237, 'grad_norm': 5.813706874847412, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 23:18:08.672 | {'loss': 0.1335, 'grad_norm': 2.815896987915039, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 23:18:24.140 | {'loss': 0.124, 'grad_norm': 5.3059916496276855, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 23:18:45.859 | {'loss': 0.1184, 'grad_norm': 4.7649431228637695, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 23:19:01.447 | {'loss': 0.1666, 'grad_norm': 6.010412693023682, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 23:19:17.614 | {'loss': 0.1118, 'grad_norm': 2.3064749240875244, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 23:19:32.775 | {'loss': 0.143, 'grad_norm': 3.219515800476074, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 23:19:54.503 | {'loss': 0.1164, 'grad_norm': 3.3648128509521484, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 23:20:09.902 | {'loss': 0.1241, 'grad_norm': 4.665000915527344, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 23:20:25.150 | {'loss': 0.2182, 'grad_norm': 3.766850233078003, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 23:20:40.346 | {'loss': 0.1253, 'grad_norm': 4.439171314239502, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 23:21:01.993 | {'loss': 0.1163, 'grad_norm': 4.079740524291992, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 23:21:17.711 | {'loss': 0.1262, 'grad_norm': 5.599241256713867, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 23:21:33.398 | {'loss': 0.1004, 'grad_norm': 2.2369773387908936, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 23:21:49.372 | {'loss': 0.1001, 'grad_norm': 3.491102457046509, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 23:22:04.767 | {'loss': 0.089, 'grad_norm': 3.0416595935821533, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 23:22:26.733 | {'loss': 0.0913, 'grad_norm': 3.430299997329712, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 23:22:42.211 | {'loss': 0.0925, 'grad_norm': 3.4918124675750732, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 23:22:57.455 | {'loss': 0.0996, 'grad_norm': 2.708831310272217, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 23:23:12.884 | {'loss': 0.0984, 'grad_norm': 3.3045191764831543, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 23:23:34.580 | {'loss': 0.0892, 'grad_norm': 7.404778003692627, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 23:23:50.412 | {'loss': 0.0876, 'grad_norm': 3.422356367111206, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 23:24:06.134 | {'loss': 0.0986, 'grad_norm': 2.105649471282959, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 23:24:28.595 | {'loss': 0.1517, 'grad_norm': 3.3792715072631836, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 23:24:44.824 | {'loss': 0.0887, 'grad_norm': 2.3045670986175537, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 23:25:00.346 | {'loss': 0.0871, 'grad_norm': 2.8637537956237793, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-25 23:25:16.094 | {'loss': 0.0822, 'grad_norm': 1.7849445343017578, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-25 23:25:38.123 | {'loss': 0.0972, 'grad_norm': 3.4564497470855713, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-25 23:25:53.460 | {'loss': 0.0837, 'grad_norm': 4.411502361297607, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-25 23:26:08.784 | {'loss': 0.0812, 'grad_norm': 3.6057698726654053, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-25 23:26:24.015 | {'loss': 0.0839, 'grad_norm': 1.948394775390625, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-25 23:26:45.907 | {'loss': 0.086, 'grad_norm': 2.164052963256836, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-25 23:26:59.153 | {'loss': 0.0953, 'grad_norm': 1.9939297437667847, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-25 23:26:59.153 | {'train_runtime': 1724.3475, 'train_samples_per_second': 1.16, 'train_steps_per_second': 0.58, 'train_loss': 0.19542706608772278, 'epoch': 5.0}
2025-05-25 23:27:06.915 | INFO :      Sent reply
2025-05-25 23:33:11.331 | INFO :      
2025-05-25 23:33:11.331 | INFO :      Received: evaluate message 8e009f2f-b3a8-4ec7-ab0d-684624a9c7d5
2025-05-25 23:33:27.354 | {'eval_loss': 3.447418212890625, 'eval_runtime': 12.2624, 'eval_samples_per_second': 8.155, 'eval_steps_per_second': 1.06, 'epoch': 5.0}
2025-05-25 23:33:27.363 | INFO :      Sent reply
2025-05-25 23:33:40.431 | INFO :      
2025-05-25 23:33:40.431 | INFO :      Received: train message 795484d3-a480-425d-b7dd-bf77efc2e498
2025-05-25 23:34:02.797 | {'loss': 0.115, 'grad_norm': 4.983479022979736, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-25 23:34:25.197 | {'loss': 0.1733, 'grad_norm': 7.138607501983643, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-25 23:34:40.700 | {'loss': 0.194, 'grad_norm': 7.711016654968262, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-25 23:34:56.443 | {'loss': 0.2072, 'grad_norm': 5.622521877288818, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-25 23:35:12.168 | {'loss': 0.2274, 'grad_norm': 4.076615333557129, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-25 23:35:33.996 | {'loss': 0.2108, 'grad_norm': 8.664871215820312, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-25 23:35:49.506 | {'loss': 0.2157, 'grad_norm': 5.5945940017700195, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-25 23:36:04.668 | {'loss': 0.214, 'grad_norm': 9.363924980163574, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-25 23:36:20.144 | {'loss': 0.2255, 'grad_norm': 8.66696834564209, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-25 23:36:41.889 | {'loss': 0.2333, 'grad_norm': 8.714032173156738, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-25 23:36:57.211 | {'loss': 0.2409, 'grad_norm': 5.459617614746094, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-25 23:37:12.725 | {'loss': 0.2282, 'grad_norm': 7.969770431518555, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-25 23:37:28.290 | {'loss': 0.2596, 'grad_norm': 7.973288536071777, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-25 23:37:50.638 | {'loss': 0.2527, 'grad_norm': 4.8343706130981445, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-25 23:38:05.748 | {'loss': 0.2258, 'grad_norm': 4.638484001159668, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-25 23:38:21.155 | {'loss': 0.2482, 'grad_norm': 6.957198143005371, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-25 23:38:36.156 | {'loss': 0.2519, 'grad_norm': 9.26375961303711, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-25 23:38:58.118 | {'loss': 0.2613, 'grad_norm': 8.408890724182129, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-25 23:39:13.517 | {'loss': 0.2788, 'grad_norm': 9.256296157836914, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-25 23:39:28.733 | {'loss': 0.2599, 'grad_norm': 8.169085502624512, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-25 23:39:44.240 | {'loss': 0.3653, 'grad_norm': 8.979395866394043, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-25 23:40:00.105 | {'loss': 0.2302, 'grad_norm': 4.947334289550781, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-25 23:40:22.168 | {'loss': 0.2035, 'grad_norm': 5.126967906951904, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-25 23:40:37.381 | {'loss': 0.2794, 'grad_norm': 6.242337703704834, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-25 23:40:52.687 | {'loss': 0.2464, 'grad_norm': 9.866817474365234, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-25 23:41:08.008 | {'loss': 0.2661, 'grad_norm': 4.642829895019531, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-25 23:41:29.579 | {'loss': 0.2076, 'grad_norm': 7.886380195617676, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-25 23:41:44.980 | {'loss': 0.2341, 'grad_norm': 7.7171783447265625, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-25 23:42:00.165 | {'loss': 0.2197, 'grad_norm': 6.643360614776611, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-25 23:42:15.600 | {'loss': 0.1796, 'grad_norm': 5.123875617980957, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-25 23:42:30.811 | {'loss': 0.2401, 'grad_norm': 9.122228622436523, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-25 23:42:46.686 | {'loss': 0.2658, 'grad_norm': 10.077923774719238, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-25 23:43:08.482 | {'loss': 0.2405, 'grad_norm': 6.68171501159668, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-25 23:43:24.023 | {'loss': 0.2573, 'grad_norm': 7.006482124328613, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-25 23:43:39.237 | {'loss': 0.2972, 'grad_norm': 9.108170509338379, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-25 23:43:54.810 | {'loss': 0.2479, 'grad_norm': 9.657110214233398, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-25 23:44:17.121 | {'loss': 0.2601, 'grad_norm': 9.4993896484375, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-25 23:44:32.570 | {'loss': 0.2626, 'grad_norm': 8.468206405639648, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-25 23:44:48.169 | {'loss': 0.2937, 'grad_norm': 8.998032569885254, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-25 23:45:03.742 | {'loss': 0.2102, 'grad_norm': 4.944918632507324, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-25 23:45:19.726 | {'loss': 0.1519, 'grad_norm': 3.0801360607147217, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-25 23:45:42.443 | {'loss': 0.1669, 'grad_norm': 5.462888240814209, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-25 23:45:58.014 | {'loss': 0.1577, 'grad_norm': 5.88004732131958, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-25 23:46:13.632 | {'loss': 0.167, 'grad_norm': 7.2620062828063965, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-25 23:46:35.206 | {'loss': 0.1834, 'grad_norm': 3.5911569595336914, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-25 23:46:50.835 | {'loss': 0.172, 'grad_norm': 4.416006088256836, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-25 23:47:05.731 | {'loss': 0.2062, 'grad_norm': 6.423120021820068, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-25 23:47:20.940 | {'loss': 0.2596, 'grad_norm': 3.4740402698516846, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-25 23:47:36.316 | {'loss': 0.1795, 'grad_norm': 5.0233564376831055, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-25 23:47:59.137 | {'loss': 0.1706, 'grad_norm': 3.3990893363952637, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-25 23:48:15.022 | {'loss': 0.1689, 'grad_norm': 8.450905799865723, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-25 23:48:29.930 | {'loss': 0.1657, 'grad_norm': 8.901628494262695, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-25 23:48:45.232 | {'loss': 0.1645, 'grad_norm': 4.0533857345581055, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-25 23:48:59.984 | {'loss': 0.2087, 'grad_norm': 6.968394756317139, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-25 23:49:21.473 | {'loss': 0.172, 'grad_norm': 4.009765148162842, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-25 23:49:36.605 | {'loss': 0.182, 'grad_norm': 7.33811616897583, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-25 23:49:52.292 | {'loss': 0.1827, 'grad_norm': 3.9592437744140625, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-25 23:50:07.728 | {'loss': 0.1803, 'grad_norm': 5.555037021636963, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-25 23:50:30.474 | {'loss': 0.1778, 'grad_norm': 5.476558685302734, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-25 23:50:45.976 | {'loss': 0.1567, 'grad_norm': 6.3883233070373535, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-25 23:51:00.971 | {'loss': 0.1143, 'grad_norm': 4.686542510986328, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-25 23:51:16.387 | {'loss': 0.1186, 'grad_norm': 6.67128849029541, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-25 23:51:31.690 | {'loss': 0.1257, 'grad_norm': 4.432841777801514, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-25 23:51:53.180 | {'loss': 0.1349, 'grad_norm': 6.5240373611450195, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-25 23:52:08.352 | {'loss': 0.112, 'grad_norm': 3.2256274223327637, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-25 23:52:23.777 | {'loss': 0.1175, 'grad_norm': 2.0193099975585938, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-25 23:52:39.049 | {'loss': 0.1365, 'grad_norm': 6.327786445617676, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-25 23:53:01.695 | {'loss': 0.1189, 'grad_norm': 4.9354939460754395, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-25 23:53:17.051 | {'loss': 0.1249, 'grad_norm': 4.02946662902832, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-25 23:53:32.109 | {'loss': 0.126, 'grad_norm': 3.5967178344726562, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-25 23:53:54.141 | {'loss': 0.1207, 'grad_norm': 3.6421711444854736, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-25 23:54:09.007 | {'loss': 0.1398, 'grad_norm': 5.480392932891846, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-25 23:54:24.320 | {'loss': 0.1129, 'grad_norm': 3.4541680812835693, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-25 23:54:39.529 | {'loss': 0.1351, 'grad_norm': 3.3484385013580322, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-25 23:55:01.611 | {'loss': 0.1226, 'grad_norm': 3.4509739875793457, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-25 23:55:17.352 | {'loss': 0.1263, 'grad_norm': 6.191438674926758, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-25 23:55:33.009 | {'loss': 0.19, 'grad_norm': 7.026595592498779, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-25 23:55:48.777 | {'loss': 0.1125, 'grad_norm': 3.452852487564087, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-25 23:56:03.984 | {'loss': 0.1207, 'grad_norm': 5.672521114349365, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-25 23:56:26.080 | {'loss': 0.1171, 'grad_norm': 3.19579815864563, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-25 23:56:41.467 | {'loss': 0.0933, 'grad_norm': 1.9656918048858643, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-25 23:56:56.704 | {'loss': 0.0948, 'grad_norm': 1.2281328439712524, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-25 23:57:11.825 | {'loss': 0.0847, 'grad_norm': 2.093104839324951, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-25 23:57:33.604 | {'loss': 0.0858, 'grad_norm': 3.8108975887298584, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-25 23:57:49.448 | {'loss': 0.0892, 'grad_norm': 3.393599033355713, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-25 23:58:05.271 | {'loss': 0.0913, 'grad_norm': 2.3728768825531006, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-25 23:58:20.986 | {'loss': 0.0802, 'grad_norm': 3.147196054458618, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-25 23:58:36.374 | {'loss': 0.0876, 'grad_norm': 4.309080600738525, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-25 23:58:51.759 | {'loss': 0.0827, 'grad_norm': 2.333622455596924, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-25 23:59:13.605 | {'loss': 0.0967, 'grad_norm': 2.639451265335083, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-25 23:59:29.149 | {'loss': 0.1253, 'grad_norm': 2.4580092430114746, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-25 23:59:44.886 | {'loss': 0.0875, 'grad_norm': 2.3170998096466064, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-25 23:59:59.901 | {'loss': 0.0887, 'grad_norm': 2.6782476902008057, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-26 00:00:16.276 | {'loss': 0.0771, 'grad_norm': 1.377366065979004, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-26 00:00:38.501 | {'loss': 0.0978, 'grad_norm': 4.841150760650635, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-26 00:00:54.077 | {'loss': 0.0853, 'grad_norm': 3.370868444442749, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-26 00:01:09.731 | {'loss': 0.0842, 'grad_norm': 3.699554204940796, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-26 00:01:25.379 | {'loss': 0.0769, 'grad_norm': 3.0494518280029297, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-26 00:01:47.206 | {'loss': 0.0748, 'grad_norm': 1.7859270572662354, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-26 00:02:02.249 | {'loss': 0.0861, 'grad_norm': 1.907686710357666, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-26 00:02:02.249 | {'train_runtime': 1699.1198, 'train_samples_per_second': 1.177, 'train_steps_per_second': 0.589, 'train_loss': 0.1740229229927063, 'epoch': 5.0}
2025-05-26 00:02:09.755 | INFO :      Sent reply
2025-05-26 00:08:35.148 | INFO :      
2025-05-26 00:08:35.148 | INFO :      Received: evaluate message 6373e31f-0c37-4be8-8662-e8c9af4ef5dc
2025-05-26 00:08:55.674 | {'eval_loss': 3.5111935138702393, 'eval_runtime': 9.4679, 'eval_samples_per_second': 10.562, 'eval_steps_per_second': 1.373, 'epoch': 5.0}
2025-05-26 00:08:55.682 | INFO :      Sent reply
2025-05-26 00:09:08.640 | INFO :      
2025-05-26 00:09:08.640 | INFO :      Received: train message 28d4284f-5b0f-4060-a1e7-eac4c6a086b0
2025-05-26 00:09:33.474 | {'loss': 0.1069, 'grad_norm': 4.365306377410889, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-26 00:09:55.277 | {'loss': 0.1502, 'grad_norm': 6.408729553222656, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-26 00:10:10.432 | {'loss': 0.183, 'grad_norm': 6.970149040222168, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-26 00:10:25.794 | {'loss': 0.1837, 'grad_norm': 5.421513557434082, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-26 00:10:41.156 | {'loss': 0.1731, 'grad_norm': 3.3274221420288086, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-26 00:10:56.746 | {'loss': 0.1877, 'grad_norm': 7.7357001304626465, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-26 00:11:18.803 | {'loss': 0.1823, 'grad_norm': 6.2852559089660645, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-26 00:11:34.155 | {'loss': 0.1914, 'grad_norm': 10.875560760498047, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-26 00:11:49.503 | {'loss': 0.1849, 'grad_norm': 5.465397834777832, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-26 00:12:04.756 | {'loss': 0.2045, 'grad_norm': 6.803266525268555, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-26 00:12:26.630 | {'loss': 0.2001, 'grad_norm': 6.276971340179443, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-26 00:12:41.747 | {'loss': 0.1951, 'grad_norm': 6.392311096191406, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-26 00:12:57.129 | {'loss': 0.236, 'grad_norm': 5.778931617736816, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-26 00:13:12.233 | {'loss': 0.201, 'grad_norm': 4.23482608795166, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-26 00:13:34.403 | {'loss': 0.2, 'grad_norm': 4.045721530914307, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-26 00:13:49.811 | {'loss': 0.2232, 'grad_norm': 5.062675476074219, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-26 00:14:05.588 | {'loss': 0.2197, 'grad_norm': 9.833523750305176, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-26 00:14:27.810 | {'loss': 0.2291, 'grad_norm': 9.45151424407959, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-26 00:14:43.191 | {'loss': 0.2446, 'grad_norm': 7.756732940673828, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-26 00:14:59.212 | {'loss': 0.2121, 'grad_norm': 6.321877479553223, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-26 00:15:20.738 | {'loss': 0.3267, 'grad_norm': 7.07569694519043, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-26 00:15:35.602 | {'loss': 0.2033, 'grad_norm': 5.764591217041016, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-26 00:15:50.673 | {'loss': 0.2066, 'grad_norm': 6.7502665519714355, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-26 00:16:05.833 | {'loss': 0.25, 'grad_norm': 7.1700849533081055, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-26 00:16:27.922 | {'loss': 0.2169, 'grad_norm': 7.3880438804626465, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-26 00:16:42.884 | {'loss': 0.2279, 'grad_norm': 4.592934608459473, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-26 00:16:58.678 | {'loss': 0.186, 'grad_norm': 5.818331718444824, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-26 00:17:20.242 | {'loss': 0.2157, 'grad_norm': 7.8223466873168945, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-26 00:17:35.301 | {'loss': 0.2355, 'grad_norm': 7.579126358032227, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-26 00:17:57.110 | {'loss': 0.217, 'grad_norm': 7.287575721740723, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-26 00:18:12.301 | {'loss': 0.2323, 'grad_norm': 7.501286506652832, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-26 00:18:27.939 | {'loss': 0.2266, 'grad_norm': 7.519370079040527, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-26 00:18:49.162 | {'loss': 0.216, 'grad_norm': 4.763121604919434, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-26 00:19:04.277 | {'loss': 0.2467, 'grad_norm': 5.690856456756592, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-26 00:19:19.344 | {'loss': 0.2722, 'grad_norm': 7.009121894836426, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-26 00:19:34.762 | {'loss': 0.2161, 'grad_norm': 11.033533096313477, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-26 00:19:56.847 | {'loss': 0.2419, 'grad_norm': 7.597417831420898, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-26 00:20:11.635 | {'loss': 0.2458, 'grad_norm': 6.8433451652526855, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-26 00:20:26.761 | {'loss': 0.2749, 'grad_norm': 7.608382701873779, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-26 00:20:41.828 | {'loss': 0.1894, 'grad_norm': 4.882579803466797, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-26 00:20:57.029 | {'loss': 0.1365, 'grad_norm': 3.2064127922058105, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-26 00:21:18.656 | {'loss': 0.173, 'grad_norm': 7.001742839813232, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-26 00:21:34.165 | {'loss': 0.1541, 'grad_norm': 7.6154561042785645, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-26 00:21:49.543 | {'loss': 0.1483, 'grad_norm': 6.616778373718262, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-26 00:22:11.506 | {'loss': 0.1867, 'grad_norm': 2.078794240951538, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-26 00:22:26.812 | {'loss': 0.1527, 'grad_norm': 2.8827342987060547, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-26 00:22:42.094 | {'loss': 0.1766, 'grad_norm': 5.660038948059082, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-26 00:22:57.330 | {'loss': 0.2107, 'grad_norm': 5.022429466247559, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-26 00:23:19.153 | {'loss': 0.1771, 'grad_norm': 6.1517415046691895, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-26 00:23:34.714 | {'loss': 0.1543, 'grad_norm': 4.580789089202881, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-26 00:23:50.475 | {'loss': 0.169, 'grad_norm': 7.274761199951172, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-26 00:24:12.214 | {'loss': 0.1587, 'grad_norm': 5.16560697555542, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-26 00:24:27.826 | {'loss': 0.157, 'grad_norm': 4.920812606811523, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-26 00:24:43.114 | {'loss': 0.1803, 'grad_norm': 4.389316558837891, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-26 00:25:04.887 | {'loss': 0.1526, 'grad_norm': 4.623469829559326, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-26 00:25:19.780 | {'loss': 0.1416, 'grad_norm': 6.229955673217773, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-26 00:25:34.991 | {'loss': 0.1624, 'grad_norm': 11.627205848693848, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-26 00:25:57.178 | {'loss': 0.1471, 'grad_norm': 6.436284065246582, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-26 00:26:12.521 | {'loss': 0.1597, 'grad_norm': 3.964963436126709, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-26 00:26:27.717 | {'loss': 0.1516, 'grad_norm': 3.7967896461486816, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-26 00:26:48.963 | {'loss': 0.1084, 'grad_norm': 5.6447343826293945, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-26 00:27:04.544 | {'loss': 0.1084, 'grad_norm': 7.532851219177246, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-26 00:27:19.469 | {'loss': 0.1212, 'grad_norm': 5.343543529510498, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-26 00:27:34.633 | {'loss': 0.1256, 'grad_norm': 3.378169298171997, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-26 00:27:50.035 | {'loss': 0.1073, 'grad_norm': 3.496945858001709, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-26 00:28:11.582 | {'loss': 0.1201, 'grad_norm': 3.7136919498443604, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-26 00:28:27.114 | {'loss': 0.1146, 'grad_norm': 3.1882505416870117, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-26 00:28:42.311 | {'loss': 0.1067, 'grad_norm': 7.022860527038574, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-26 00:28:57.575 | {'loss': 0.119, 'grad_norm': 3.7354936599731445, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-26 00:29:19.198 | {'loss': 0.1155, 'grad_norm': 4.483699321746826, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-26 00:29:34.409 | {'loss': 0.1178, 'grad_norm': 3.655872344970703, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-26 00:29:49.287 | {'loss': 0.133, 'grad_norm': 6.292351722717285, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-26 00:30:04.529 | {'loss': 0.1037, 'grad_norm': 2.5459539890289307, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-26 00:30:19.671 | {'loss': 0.1163, 'grad_norm': 4.751105785369873, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-26 00:30:35.330 | {'loss': 0.1082, 'grad_norm': 2.9467642307281494, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-26 00:30:57.578 | {'loss': 0.0946, 'grad_norm': 4.37296199798584, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-26 00:31:12.629 | {'loss': 0.1639, 'grad_norm': 2.873372793197632, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-26 00:31:27.688 | {'loss': 0.1065, 'grad_norm': 3.396653890609741, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-26 00:31:42.657 | {'loss': 0.1078, 'grad_norm': 7.620046615600586, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-26 00:31:57.724 | {'loss': 0.1163, 'grad_norm': 6.795312404632568, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-26 00:32:19.250 | {'loss': 0.0841, 'grad_norm': 1.8020931482315063, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-26 00:32:34.794 | {'loss': 0.0753, 'grad_norm': 1.9477449655532837, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-26 00:32:49.975 | {'loss': 0.0733, 'grad_norm': 1.72419011592865, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-26 00:33:05.759 | {'loss': 0.0839, 'grad_norm': 2.5556788444519043, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-26 00:33:20.834 | {'loss': 0.0863, 'grad_norm': 2.3334248065948486, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-26 00:33:42.338 | {'loss': 0.0847, 'grad_norm': 3.603259801864624, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-26 00:33:58.046 | {'loss': 0.0763, 'grad_norm': 2.760267972946167, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-26 00:34:12.811 | {'loss': 0.083, 'grad_norm': 1.463781714439392, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-26 00:34:28.271 | {'loss': 0.0773, 'grad_norm': 2.619551658630371, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-26 00:34:49.371 | {'loss': 0.0895, 'grad_norm': 2.697909355163574, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-26 00:35:04.945 | {'loss': 0.1252, 'grad_norm': 2.8875045776367188, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-26 00:35:20.505 | {'loss': 0.0781, 'grad_norm': 1.8826321363449097, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-26 00:35:35.738 | {'loss': 0.0758, 'grad_norm': 1.831323504447937, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-26 00:35:50.555 | {'loss': 0.0764, 'grad_norm': 1.1059232950210571, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-26 00:36:12.145 | {'loss': 0.0941, 'grad_norm': 5.46815824508667, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-26 00:36:27.308 | {'loss': 0.0786, 'grad_norm': 4.168757915496826, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-26 00:36:42.354 | {'loss': 0.0795, 'grad_norm': 2.657714366912842, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-26 00:36:57.503 | {'loss': 0.079, 'grad_norm': 1.5276544094085693, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-26 00:37:17.208 | {'loss': 0.0763, 'grad_norm': 1.9575849771499634, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-26 00:37:27.340 | {'loss': 0.0827, 'grad_norm': 1.7065255641937256, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-26 00:37:27.340 | {'train_runtime': 1694.972, 'train_samples_per_second': 1.18, 'train_steps_per_second': 0.59, 'train_loss': 0.15780793994665146, 'epoch': 5.0}
2025-05-26 00:37:32.719 | INFO :      Sent reply
2025-05-26 00:43:51.004 | INFO :      
2025-05-26 00:43:51.004 | INFO :      Received: evaluate message 846735f3-4e16-40ea-bc0c-32b94c493ff5
2025-05-26 00:43:54.196 | {'eval_loss': 3.5854456424713135, 'eval_runtime': 1.6197, 'eval_samples_per_second': 61.742, 'eval_steps_per_second': 8.026, 'epoch': 5.0}
2025-05-26 00:43:54.199 | INFO :      Sent reply
2025-05-26 00:44:10.821 | INFO :      
2025-05-26 00:44:10.821 | INFO :      Received: train message 5328f5c7-1448-4423-8dbb-7ff0fb7bec52
2025-05-26 00:44:33.994 | {'loss': 0.0962, 'grad_norm': 3.102280616760254, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-26 00:44:49.291 | {'loss': 0.1222, 'grad_norm': 5.070703506469727, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-26 00:45:11.474 | {'loss': 0.1598, 'grad_norm': 5.302144527435303, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-26 00:45:27.079 | {'loss': 0.1727, 'grad_norm': 4.701129913330078, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-26 00:45:42.563 | {'loss': 0.1568, 'grad_norm': 3.122537612915039, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-26 00:45:58.109 | {'loss': 0.1788, 'grad_norm': 5.916638374328613, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-26 00:46:13.612 | {'loss': 0.148, 'grad_norm': 5.582551956176758, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-26 00:46:35.186 | {'loss': 0.1741, 'grad_norm': 11.089982032775879, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-26 00:46:50.361 | {'loss': 0.1674, 'grad_norm': 6.719420433044434, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-26 00:47:05.511 | {'loss': 0.1722, 'grad_norm': 8.790404319763184, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-26 00:47:20.546 | {'loss': 0.1806, 'grad_norm': 4.516628742218018, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-26 00:47:35.782 | {'loss': 0.1825, 'grad_norm': 6.245229721069336, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-26 00:47:57.613 | {'loss': 0.2003, 'grad_norm': 5.548074245452881, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-26 00:48:13.015 | {'loss': 0.1915, 'grad_norm': 5.583163738250732, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-26 00:48:28.522 | {'loss': 0.1688, 'grad_norm': 4.008667945861816, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-26 00:48:44.150 | {'loss': 0.1979, 'grad_norm': 4.904061794281006, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-26 00:49:06.375 | {'loss': 0.1853, 'grad_norm': 7.620786190032959, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-26 00:49:21.103 | {'loss': 0.1935, 'grad_norm': 6.707087993621826, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-26 00:49:36.182 | {'loss': 0.2049, 'grad_norm': 8.80733871459961, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-26 00:49:51.257 | {'loss': 0.1955, 'grad_norm': 5.265450477600098, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-26 00:50:13.308 | {'loss': 0.3006, 'grad_norm': 9.328076362609863, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-26 00:50:28.499 | {'loss': 0.205, 'grad_norm': 8.476619720458984, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-26 00:50:43.955 | {'loss': 0.1816, 'grad_norm': 4.784859657287598, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-26 00:51:05.815 | {'loss': 0.2572, 'grad_norm': 7.944087505340576, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-26 00:51:21.004 | {'loss': 0.2351, 'grad_norm': 9.610054016113281, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-26 00:51:36.411 | {'loss': 0.2164, 'grad_norm': 6.4395270347595215, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-26 00:51:51.847 | {'loss': 0.1683, 'grad_norm': 5.307501792907715, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-26 00:52:13.751 | {'loss': 0.2036, 'grad_norm': 7.571437835693359, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-26 00:52:29.157 | {'loss': 0.2214, 'grad_norm': 8.155304908752441, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-26 00:52:44.375 | {'loss': 0.1805, 'grad_norm': 4.910566806793213, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-26 00:53:00.045 | {'loss': 0.211, 'grad_norm': 8.01611614227295, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-26 00:53:14.874 | {'loss': 0.2233, 'grad_norm': 6.823680400848389, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-26 00:53:36.379 | {'loss': 0.192, 'grad_norm': 7.059736728668213, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-26 00:53:51.745 | {'loss': 0.2037, 'grad_norm': 5.739542007446289, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-26 00:54:07.530 | {'loss': 0.2414, 'grad_norm': 7.1671013832092285, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-26 00:54:22.250 | {'loss': 0.2095, 'grad_norm': 8.831014633178711, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-26 00:54:37.515 | {'loss': 0.2222, 'grad_norm': 8.692814826965332, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-26 00:54:59.142 | {'loss': 0.2171, 'grad_norm': 8.247014999389648, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-26 00:55:14.663 | {'loss': 0.2447, 'grad_norm': 9.814284324645996, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-26 00:55:29.648 | {'loss': 0.1671, 'grad_norm': 4.588834285736084, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-26 00:55:45.218 | {'loss': 0.1202, 'grad_norm': 3.6080033779144287, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-26 00:56:00.942 | {'loss': 0.1557, 'grad_norm': 6.48988151550293, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-26 00:56:22.501 | {'loss': 0.1265, 'grad_norm': 4.951407432556152, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-26 00:56:38.073 | {'loss': 0.1329, 'grad_norm': 6.464153289794922, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-26 00:56:53.533 | {'loss': 0.1739, 'grad_norm': 3.0283396244049072, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-26 00:57:08.494 | {'loss': 0.1855, 'grad_norm': 5.469282150268555, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-26 00:57:29.854 | {'loss': 0.1555, 'grad_norm': 7.69849967956543, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-26 00:57:44.994 | {'loss': 0.2473, 'grad_norm': 3.0946266651153564, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-26 00:58:00.292 | {'loss': 0.1642, 'grad_norm': 6.582474708557129, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-26 00:58:15.249 | {'loss': 0.1384, 'grad_norm': 3.1680960655212402, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-26 00:58:37.237 | {'loss': 0.1557, 'grad_norm': 5.47916316986084, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-26 00:58:52.763 | {'loss': 0.151, 'grad_norm': 4.761776924133301, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-26 00:59:07.750 | {'loss': 0.1474, 'grad_norm': 4.592723846435547, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-26 00:59:22.597 | {'loss': 0.1759, 'grad_norm': 4.587545394897461, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-26 00:59:44.133 | {'loss': 0.1492, 'grad_norm': 4.3103227615356445, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-26 00:59:59.249 | {'loss': 0.1353, 'grad_norm': 5.699286460876465, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-26 01:00:14.684 | {'loss': 0.1494, 'grad_norm': 4.487473487854004, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-26 01:00:29.786 | {'loss': 0.1236, 'grad_norm': 3.3295493125915527, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-26 01:00:45.328 | {'loss': 0.1298, 'grad_norm': 4.1285200119018555, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-26 01:01:00.964 | {'loss': 0.1575, 'grad_norm': 5.594059467315674, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-26 01:01:22.720 | {'loss': 0.1077, 'grad_norm': 5.301972389221191, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-26 01:01:38.071 | {'loss': 0.0968, 'grad_norm': 5.346639633178711, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-26 01:01:52.890 | {'loss': 0.1143, 'grad_norm': 3.825946807861328, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-26 01:02:08.035 | {'loss': 0.0955, 'grad_norm': 3.16408109664917, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-26 01:02:23.062 | {'loss': 0.095, 'grad_norm': 2.4648780822753906, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-26 01:02:38.345 | {'loss': 0.106, 'grad_norm': 1.3480403423309326, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-26 01:03:00.610 | {'loss': 0.1019, 'grad_norm': 2.750444173812866, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-26 01:03:15.688 | {'loss': 0.0959, 'grad_norm': 2.9849281311035156, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-26 01:03:30.808 | {'loss': 0.1045, 'grad_norm': 4.024682521820068, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-26 01:03:46.100 | {'loss': 0.1169, 'grad_norm': 4.853121757507324, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-26 01:04:07.372 | {'loss': 0.1162, 'grad_norm': 3.008387804031372, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-26 01:04:22.430 | {'loss': 0.1304, 'grad_norm': 5.095831394195557, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-26 01:04:37.558 | {'loss': 0.1063, 'grad_norm': 1.6649221181869507, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-26 01:04:52.994 | {'loss': 0.1096, 'grad_norm': 3.7112629413604736, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-26 01:05:09.047 | {'loss': 0.1062, 'grad_norm': 2.4904656410217285, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-26 01:05:24.103 | {'loss': 0.1069, 'grad_norm': 5.648449420928955, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-26 01:05:45.746 | {'loss': 0.1997, 'grad_norm': 2.3153598308563232, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-26 01:06:00.917 | {'loss': 0.1075, 'grad_norm': 3.311682939529419, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-26 01:06:15.997 | {'loss': 0.1168, 'grad_norm': 2.5539023876190186, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-26 01:06:30.849 | {'loss': 0.1067, 'grad_norm': 3.9830803871154785, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-26 01:06:45.750 | {'loss': 0.0803, 'grad_norm': 1.7851758003234863, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-26 01:07:07.609 | {'loss': 0.0802, 'grad_norm': 3.030270576477051, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-26 01:07:23.110 | {'loss': 0.074, 'grad_norm': 2.5038204193115234, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-26 01:07:38.545 | {'loss': 0.0822, 'grad_norm': 2.4645214080810547, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-26 01:07:53.705 | {'loss': 0.0828, 'grad_norm': 4.557595729827881, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-26 01:08:15.282 | {'loss': 0.083, 'grad_norm': 1.698118805885315, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-26 01:08:30.332 | {'loss': 0.0735, 'grad_norm': 1.8411729335784912, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-26 01:08:45.415 | {'loss': 0.0821, 'grad_norm': 1.7035057544708252, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-26 01:09:00.672 | {'loss': 0.0732, 'grad_norm': 1.7161537408828735, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-26 01:09:15.740 | {'loss': 0.0811, 'grad_norm': 3.2345569133758545, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-26 01:09:31.125 | {'loss': 0.1379, 'grad_norm': 2.684664487838745, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-26 01:09:46.785 | {'loss': 0.0742, 'grad_norm': 3.210662364959717, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-26 01:10:09.195 | {'loss': 0.0851, 'grad_norm': 2.2836368083953857, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-26 01:10:24.262 | {'loss': 0.0738, 'grad_norm': 1.6710426807403564, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-26 01:10:39.471 | {'loss': 0.0823, 'grad_norm': 5.20700740814209, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-26 01:10:54.658 | {'loss': 0.0739, 'grad_norm': 2.167543649673462, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-26 01:11:09.992 | {'loss': 0.0744, 'grad_norm': 1.964388370513916, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-26 01:11:31.709 | {'loss': 0.0723, 'grad_norm': 2.2278404235839844, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-26 01:11:47.258 | {'loss': 0.0714, 'grad_norm': 3.063328266143799, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-26 01:12:03.049 | {'loss': 0.0815, 'grad_norm': 1.4427083730697632, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-26 01:12:03.049 | {'train_runtime': 1669.5675, 'train_samples_per_second': 1.198, 'train_steps_per_second': 0.599, 'train_loss': 0.14685710275173186, 'epoch': 5.0}
2025-05-26 01:12:09.392 | INFO :      Sent reply
2025-05-26 01:18:34.818 | INFO :      
2025-05-26 01:18:34.818 | INFO :      Received: evaluate message 0558578c-5288-438b-93b2-1605c9ca508a
2025-05-26 01:18:51.905 | {'eval_loss': 3.6715924739837646, 'eval_runtime': 9.0682, 'eval_samples_per_second': 11.027, 'eval_steps_per_second': 1.434, 'epoch': 5.0}
2025-05-26 01:18:51.906 | INFO :      Sent reply
2025-05-26 01:19:02.769 | INFO :      
2025-05-26 01:19:02.769 | INFO :      Received: train message 9994801f-e8ec-4784-b39c-1d43f6641614
2025-05-26 01:19:38.787 | {'loss': 0.0904, 'grad_norm': 2.6852316856384277, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-26 01:19:55.121 | {'loss': 0.1098, 'grad_norm': 4.849240303039551, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-26 01:20:17.757 | {'loss': 0.1466, 'grad_norm': 4.71922492980957, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-26 01:20:32.980 | {'loss': 0.1338, 'grad_norm': 4.997873783111572, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-26 01:20:54.708 | {'loss': 0.1359, 'grad_norm': 3.9721882343292236, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-26 01:21:09.885 | {'loss': 0.1495, 'grad_norm': 5.380557060241699, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-26 01:21:25.272 | {'loss': 0.1488, 'grad_norm': 3.955265998840332, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-26 01:21:40.139 | {'loss': 0.1702, 'grad_norm': 9.428768157958984, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-26 01:21:55.085 | {'loss': 0.1541, 'grad_norm': 8.026241302490234, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-26 01:22:16.973 | {'loss': 0.1719, 'grad_norm': 6.754040718078613, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-26 01:22:32.377 | {'loss': 0.1614, 'grad_norm': 5.045413970947266, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-26 01:22:47.690 | {'loss': 0.1689, 'grad_norm': 6.459379196166992, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-26 01:23:02.870 | {'loss': 0.2054, 'grad_norm': 4.087439060211182, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-26 01:23:17.918 | {'loss': 0.1913, 'grad_norm': 3.7955214977264404, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-26 01:23:39.683 | {'loss': 0.1633, 'grad_norm': 3.1674649715423584, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-26 01:23:54.803 | {'loss': 0.1776, 'grad_norm': 3.1452431678771973, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-26 01:24:10.052 | {'loss': 0.177, 'grad_norm': 7.612010478973389, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-26 01:24:25.163 | {'loss': 0.1953, 'grad_norm': 8.3077974319458, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-26 01:24:47.388 | {'loss': 0.1965, 'grad_norm': 7.277010917663574, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-26 01:25:02.860 | {'loss': 0.1959, 'grad_norm': 5.0817694664001465, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-26 01:25:18.148 | {'loss': 0.3681, 'grad_norm': 9.347283363342285, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-26 01:25:33.324 | {'loss': 0.1877, 'grad_norm': 3.8858792781829834, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-26 01:25:48.396 | {'loss': 0.1639, 'grad_norm': 3.8692150115966797, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-26 01:26:10.056 | {'loss': 0.2079, 'grad_norm': 5.181404113769531, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-26 01:26:25.215 | {'loss': 0.1848, 'grad_norm': 6.674292087554932, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-26 01:26:40.643 | {'loss': 0.2014, 'grad_norm': 4.6708879470825195, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-26 01:26:55.699 | {'loss': 0.1697, 'grad_norm': 6.244838237762451, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-26 01:27:11.387 | {'loss': 0.1987, 'grad_norm': 6.486496448516846, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-26 01:27:33.154 | {'loss': 0.2122, 'grad_norm': 6.427101135253906, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-26 01:27:48.227 | {'loss': 0.1497, 'grad_norm': 7.449224472045898, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-26 01:28:03.360 | {'loss': 0.1984, 'grad_norm': 5.872408390045166, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-26 01:28:18.095 | {'loss': 0.2162, 'grad_norm': 9.575190544128418, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-26 01:28:33.008 | {'loss': 0.1874, 'grad_norm': 4.00874662399292, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-26 01:28:54.339 | {'loss': 0.191, 'grad_norm': 3.5705597400665283, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-26 01:29:09.623 | {'loss': 0.2189, 'grad_norm': 6.034793853759766, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-26 01:29:24.867 | {'loss': 0.1583, 'grad_norm': 6.975922584533691, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-26 01:29:40.285 | {'loss': 0.2221, 'grad_norm': 6.568490982055664, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-26 01:29:55.485 | {'loss': 0.1885, 'grad_norm': 6.229809284210205, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-26 01:30:10.516 | {'loss': 0.2293, 'grad_norm': 8.12123966217041, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-26 01:30:31.917 | {'loss': 0.1494, 'grad_norm': 3.392969846725464, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-26 01:30:47.131 | {'loss': 0.1103, 'grad_norm': 3.6894779205322266, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-26 01:31:02.173 | {'loss': 0.1536, 'grad_norm': 4.603747844696045, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-26 01:31:17.336 | {'loss': 0.1308, 'grad_norm': 5.772445201873779, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-26 01:31:32.298 | {'loss': 0.149, 'grad_norm': 4.012545108795166, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-26 01:31:53.935 | {'loss': 0.1598, 'grad_norm': 2.115184783935547, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-26 01:32:09.408 | {'loss': 0.1252, 'grad_norm': 2.6317341327667236, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-26 01:32:24.775 | {'loss': 0.1593, 'grad_norm': 3.6831960678100586, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-26 01:32:40.093 | {'loss': 0.1869, 'grad_norm': 3.3499016761779785, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-26 01:32:55.151 | {'loss': 0.1617, 'grad_norm': 5.379802227020264, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-26 01:33:16.690 | {'loss': 0.1378, 'grad_norm': 6.148521423339844, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-26 01:33:31.797 | {'loss': 0.1699, 'grad_norm': 5.715448379516602, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-26 01:33:47.018 | {'loss': 0.1437, 'grad_norm': 3.3417882919311523, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-26 01:34:02.129 | {'loss': 0.1324, 'grad_norm': 3.738067388534546, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-26 01:34:17.534 | {'loss': 0.1599, 'grad_norm': 3.3714399337768555, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-26 01:34:39.156 | {'loss': 0.1392, 'grad_norm': 4.5355353355407715, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-26 01:34:54.464 | {'loss': 0.1416, 'grad_norm': 5.941009521484375, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-26 01:35:09.972 | {'loss': 0.136, 'grad_norm': 4.360126972198486, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-26 01:35:25.203 | {'loss': 0.1378, 'grad_norm': 5.5093255043029785, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-26 01:35:46.546 | {'loss': 0.1398, 'grad_norm': 3.1291375160217285, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-26 01:36:01.537 | {'loss': 0.1507, 'grad_norm': 6.711363315582275, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-26 01:36:16.753 | {'loss': 0.0983, 'grad_norm': 3.8804373741149902, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-26 01:36:31.842 | {'loss': 0.095, 'grad_norm': 4.986245632171631, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-26 01:36:47.355 | {'loss': 0.0918, 'grad_norm': 4.449719429016113, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-26 01:37:09.519 | {'loss': 0.0951, 'grad_norm': 2.443542957305908, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-26 01:37:24.801 | {'loss': 0.0973, 'grad_norm': 4.097212791442871, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-26 01:37:40.058 | {'loss': 0.1168, 'grad_norm': 2.459170341491699, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-26 01:37:55.199 | {'loss': 0.1102, 'grad_norm': 4.78550910949707, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-26 01:38:16.895 | {'loss': 0.0935, 'grad_norm': 2.681825637817383, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-26 01:38:31.811 | {'loss': 0.1037, 'grad_norm': 2.3041558265686035, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-26 01:38:46.859 | {'loss': 0.1106, 'grad_norm': 4.009328365325928, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-26 01:39:01.946 | {'loss': 0.1086, 'grad_norm': 3.176328659057617, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-26 01:39:17.398 | {'loss': 0.128, 'grad_norm': 7.039224624633789, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-26 01:39:39.463 | {'loss': 0.1043, 'grad_norm': 1.949919581413269, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-26 01:39:54.633 | {'loss': 0.1081, 'grad_norm': 4.253447532653809, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-26 01:40:09.809 | {'loss': 0.1033, 'grad_norm': 3.040884256362915, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-26 01:40:24.883 | {'loss': 0.0861, 'grad_norm': 2.3575165271759033, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-26 01:40:40.108 | {'loss': 0.1729, 'grad_norm': 3.2703585624694824, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-26 01:41:01.581 | {'loss': 0.0916, 'grad_norm': 1.9448989629745483, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-26 01:41:16.722 | {'loss': 0.1007, 'grad_norm': 3.971261739730835, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-26 01:41:31.690 | {'loss': 0.1061, 'grad_norm': 3.505797863006592, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-26 01:41:46.944 | {'loss': 0.0762, 'grad_norm': 2.845018148422241, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-26 01:42:02.361 | {'loss': 0.0785, 'grad_norm': 1.7523784637451172, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-26 01:42:24.678 | {'loss': 0.0755, 'grad_norm': 1.259649634361267, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-26 01:42:39.684 | {'loss': 0.0774, 'grad_norm': 4.569836139678955, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-26 01:42:54.861 | {'loss': 0.0736, 'grad_norm': 1.4402471780776978, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-26 01:43:09.678 | {'loss': 0.0803, 'grad_norm': 1.963005781173706, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-26 01:43:24.597 | {'loss': 0.071, 'grad_norm': 1.7198599576950073, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-26 01:43:46.215 | {'loss': 0.0752, 'grad_norm': 1.454617977142334, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-26 01:44:01.373 | {'loss': 0.0812, 'grad_norm': 1.3873077630996704, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-26 01:44:16.800 | {'loss': 0.0825, 'grad_norm': 2.109315872192383, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-26 01:44:32.214 | {'loss': 0.1067, 'grad_norm': 1.5021772384643555, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-26 01:44:47.902 | {'loss': 0.073, 'grad_norm': 2.6485743522644043, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-26 01:45:09.260 | {'loss': 0.0695, 'grad_norm': 1.524324893951416, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-26 01:45:24.252 | {'loss': 0.0747, 'grad_norm': 1.1964980363845825, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-26 01:45:39.505 | {'loss': 0.077, 'grad_norm': 3.4342658519744873, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-26 01:45:54.996 | {'loss': 0.0751, 'grad_norm': 1.658308982849121, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-26 01:46:16.516 | {'loss': 0.0712, 'grad_norm': 2.3225510120391846, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-26 01:46:31.855 | {'loss': 0.0687, 'grad_norm': 3.3416292667388916, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-26 01:46:47.380 | {'loss': 0.0646, 'grad_norm': 1.4854774475097656, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-26 01:47:00.212 | {'loss': 0.0813, 'grad_norm': 1.5361871719360352, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-26 01:47:00.213 | {'train_runtime': 1668.7831, 'train_samples_per_second': 1.198, 'train_steps_per_second': 0.599, 'train_loss': 0.13827646374702454, 'epoch': 5.0}
2025-05-26 01:47:04.055 | INFO :      Sent reply
2025-05-26 01:53:03.514 | INFO :      
2025-05-26 01:53:03.515 | INFO :      Received: evaluate message 36653f05-7d91-4793-8ecb-ac22a734916e
2025-05-26 01:53:06.212 | {'eval_loss': 3.715017795562744, 'eval_runtime': 1.5361, 'eval_samples_per_second': 65.098, 'eval_steps_per_second': 8.463, 'epoch': 5.0}
2025-05-26 01:53:06.213 | INFO :      Sent reply
2025-05-26 01:53:25.568 | INFO :      
2025-05-26 01:53:25.568 | INFO :      Received: train message 35f43d6e-6c93-44cf-aef1-f6e41c4f3550
2025-05-26 01:53:45.977 | {'loss': 0.0861, 'grad_norm': 2.848388671875, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-26 01:54:07.613 | {'loss': 0.0986, 'grad_norm': 3.662708282470703, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-26 01:54:22.678 | {'loss': 0.1484, 'grad_norm': 5.55433988571167, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-26 01:54:37.827 | {'loss': 0.1608, 'grad_norm': 4.231381893157959, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-26 01:54:53.156 | {'loss': 0.1523, 'grad_norm': 2.2178752422332764, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-26 01:55:08.767 | {'loss': 0.1548, 'grad_norm': 4.657537460327148, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-26 01:55:30.761 | {'loss': 0.1348, 'grad_norm': 3.8468475341796875, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-26 01:55:45.963 | {'loss': 0.1324, 'grad_norm': 4.916913032531738, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-26 01:56:01.066 | {'loss': 0.1407, 'grad_norm': 4.735694885253906, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-26 01:56:16.482 | {'loss': 0.1376, 'grad_norm': 8.28296947479248, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-26 01:56:31.695 | {'loss': 0.1571, 'grad_norm': 5.363380432128906, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-26 01:56:53.441 | {'loss': 0.1487, 'grad_norm': 4.642039775848389, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-26 01:57:08.726 | {'loss': 0.1721, 'grad_norm': 2.2537288665771484, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-26 01:57:23.938 | {'loss': 0.1497, 'grad_norm': 3.8945376873016357, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-26 01:57:39.118 | {'loss': 0.1614, 'grad_norm': 3.4742560386657715, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-26 01:57:54.319 | {'loss': 0.1666, 'grad_norm': 2.377192735671997, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-26 01:58:16.117 | {'loss': 0.1667, 'grad_norm': 6.548006057739258, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-26 01:58:31.267 | {'loss': 0.176, 'grad_norm': 7.3059844970703125, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-26 01:58:46.524 | {'loss': 0.1756, 'grad_norm': 6.488381862640381, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-26 01:59:01.803 | {'loss': 0.1656, 'grad_norm': 6.6577301025390625, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-26 01:59:23.678 | {'loss': 0.2731, 'grad_norm': 9.382386207580566, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-26 01:59:38.834 | {'loss': 0.2105, 'grad_norm': 5.461849689483643, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-26 01:59:54.071 | {'loss': 0.1812, 'grad_norm': 5.681868553161621, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-26 02:00:09.384 | {'loss': 0.1932, 'grad_norm': 6.561605453491211, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-26 02:00:24.671 | {'loss': 0.1746, 'grad_norm': 6.026893615722656, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-26 02:00:47.130 | {'loss': 0.1889, 'grad_norm': 4.835794925689697, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-26 02:01:02.307 | {'loss': 0.1731, 'grad_norm': 4.938685417175293, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-26 02:01:17.478 | {'loss': 0.1679, 'grad_norm': 7.207393646240234, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-26 02:01:32.727 | {'loss': 0.206, 'grad_norm': 6.373091697692871, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-26 02:01:47.839 | {'loss': 0.175, 'grad_norm': 4.273599624633789, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-26 02:02:09.377 | {'loss': 0.1988, 'grad_norm': 7.876157283782959, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-26 02:02:24.892 | {'loss': 0.1749, 'grad_norm': 6.810428619384766, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-26 02:02:40.400 | {'loss': 0.1715, 'grad_norm': 1.8118197917938232, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-26 02:02:55.947 | {'loss': 0.1845, 'grad_norm': 3.1071715354919434, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-26 02:03:10.930 | {'loss': 0.1822, 'grad_norm': 7.362030029296875, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-26 02:03:26.077 | {'loss': 0.1536, 'grad_norm': 8.526028633117676, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-26 02:03:47.588 | {'loss': 0.1966, 'grad_norm': 10.013287544250488, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-26 02:04:02.646 | {'loss': 0.1784, 'grad_norm': 6.812542915344238, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-26 02:04:18.179 | {'loss': 0.1867, 'grad_norm': 7.990260124206543, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-26 02:04:32.861 | {'loss': 0.1576, 'grad_norm': 2.6423349380493164, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-26 02:04:47.776 | {'loss': 0.1309, 'grad_norm': 2.928551197052002, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-26 02:05:03.151 | {'loss': 0.1494, 'grad_norm': 4.728003978729248, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-26 02:05:25.159 | {'loss': 0.1343, 'grad_norm': 5.352011680603027, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-26 02:05:40.945 | {'loss': 0.129, 'grad_norm': 3.881136655807495, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-26 02:05:56.421 | {'loss': 0.1477, 'grad_norm': 2.643649101257324, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-26 02:06:11.863 | {'loss': 0.1256, 'grad_norm': 3.6678671836853027, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-26 02:06:27.187 | {'loss': 0.126, 'grad_norm': 2.9460415840148926, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-26 02:06:42.454 | {'loss': 0.1454, 'grad_norm': 3.5702831745147705, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-26 02:07:04.056 | {'loss': 0.1388, 'grad_norm': 4.0805487632751465, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-26 02:07:19.141 | {'loss': 0.1354, 'grad_norm': 2.7119791507720947, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-26 02:07:34.652 | {'loss': 0.1613, 'grad_norm': 6.176931381225586, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-26 02:07:49.803 | {'loss': 0.1482, 'grad_norm': 5.460714817047119, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-26 02:08:04.907 | {'loss': 0.1299, 'grad_norm': 3.279463291168213, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-26 02:08:26.823 | {'loss': 0.1732, 'grad_norm': 6.650633335113525, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-26 02:08:42.026 | {'loss': 0.1484, 'grad_norm': 2.9559271335601807, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-26 02:08:56.946 | {'loss': 0.1268, 'grad_norm': 5.452642440795898, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-26 02:09:11.935 | {'loss': 0.1386, 'grad_norm': 4.9411516189575195, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-26 02:09:27.104 | {'loss': 0.1342, 'grad_norm': 4.090914249420166, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-26 02:09:48.758 | {'loss': 0.1474, 'grad_norm': 4.280163764953613, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-26 02:10:04.269 | {'loss': 0.1293, 'grad_norm': 5.366008281707764, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-26 02:10:19.904 | {'loss': 0.0953, 'grad_norm': 2.893287181854248, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-26 02:10:35.516 | {'loss': 0.0959, 'grad_norm': 4.648070335388184, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-26 02:10:57.587 | {'loss': 0.1082, 'grad_norm': 4.920047760009766, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-26 02:11:12.383 | {'loss': 0.1035, 'grad_norm': 2.2878055572509766, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-26 02:11:27.231 | {'loss': 0.0945, 'grad_norm': 2.3063454627990723, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-26 02:11:42.446 | {'loss': 0.105, 'grad_norm': 2.175016164779663, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-26 02:11:57.627 | {'loss': 0.1043, 'grad_norm': 3.6678316593170166, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-26 02:12:12.934 | {'loss': 0.0888, 'grad_norm': 2.464831590652466, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-26 02:12:35.035 | {'loss': 0.1044, 'grad_norm': 4.02121114730835, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-26 02:12:50.734 | {'loss': 0.0977, 'grad_norm': 4.953240394592285, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-26 02:13:05.635 | {'loss': 0.098, 'grad_norm': 2.6307713985443115, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-26 02:13:20.746 | {'loss': 0.1047, 'grad_norm': 4.8878631591796875, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-26 02:13:35.795 | {'loss': 0.0977, 'grad_norm': 4.3803911209106445, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-26 02:13:57.214 | {'loss': 0.112, 'grad_norm': 3.892364263534546, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-26 02:14:12.037 | {'loss': 0.083, 'grad_norm': 2.2467076778411865, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-26 02:14:27.035 | {'loss': 0.0916, 'grad_norm': 3.9485180377960205, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-26 02:14:42.084 | {'loss': 0.1489, 'grad_norm': 3.550454616546631, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-26 02:15:03.655 | {'loss': 0.0935, 'grad_norm': 3.1550984382629395, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-26 02:15:18.978 | {'loss': 0.092, 'grad_norm': 1.5094610452651978, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-26 02:15:34.238 | {'loss': 0.0916, 'grad_norm': 3.270003318786621, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-26 02:15:49.622 | {'loss': 0.073, 'grad_norm': 2.1983561515808105, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-26 02:16:04.910 | {'loss': 0.0755, 'grad_norm': 0.9423308968544006, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-26 02:16:26.399 | {'loss': 0.0835, 'grad_norm': 1.8323732614517212, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-26 02:16:41.433 | {'loss': 0.0733, 'grad_norm': 1.4248108863830566, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-26 02:16:56.610 | {'loss': 0.0738, 'grad_norm': 4.314432144165039, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-26 02:17:11.794 | {'loss': 0.0745, 'grad_norm': 2.491929531097412, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-26 02:17:26.874 | {'loss': 0.0688, 'grad_norm': 2.466470956802368, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-26 02:17:48.402 | {'loss': 0.0803, 'grad_norm': 1.5968316793441772, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-26 02:18:03.737 | {'loss': 0.0753, 'grad_norm': 1.572216272354126, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-26 02:18:19.505 | {'loss': 0.0801, 'grad_norm': 1.3376268148422241, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-26 02:18:34.634 | {'loss': 0.1034, 'grad_norm': 2.3779959678649902, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-26 02:18:49.660 | {'loss': 0.073, 'grad_norm': 2.271559953689575, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-26 02:19:11.281 | {'loss': 0.0734, 'grad_norm': 1.7683504819869995, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-26 02:19:26.109 | {'loss': 0.0697, 'grad_norm': 1.1388448476791382, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-26 02:19:41.062 | {'loss': 0.0768, 'grad_norm': 2.506418466567993, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-26 02:19:55.933 | {'loss': 0.0713, 'grad_norm': 1.8941781520843506, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-26 02:20:10.921 | {'loss': 0.0711, 'grad_norm': 1.3120157718658447, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-26 02:20:32.373 | {'loss': 0.0692, 'grad_norm': 1.4594370126724243, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-26 02:20:47.808 | {'loss': 0.0677, 'grad_norm': 2.424914598464966, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-26 02:21:03.165 | {'loss': 0.082, 'grad_norm': 1.6655333042144775, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-26 02:21:03.165 | {'train_runtime': 1654.7426, 'train_samples_per_second': 1.209, 'train_steps_per_second': 0.604, 'train_loss': 0.13040604466199876, 'epoch': 5.0}
2025-05-26 02:21:10.348 | INFO :      Sent reply
2025-05-26 02:27:34.950 | INFO :      
2025-05-26 02:27:34.950 | INFO :      Received: evaluate message 7b29f0ba-c44c-4d31-95c4-33d89f9ede90
2025-05-26 02:27:50.780 | {'eval_loss': 3.7696845531463623, 'eval_runtime': 12.5171, 'eval_samples_per_second': 7.989, 'eval_steps_per_second': 1.039, 'epoch': 5.0}
2025-05-26 02:27:50.786 | INFO :      Sent reply
2025-05-26 02:28:00.229 | INFO :      
2025-05-26 02:28:00.229 | INFO :      Received: train message 26d93d24-838c-4f80-8eb1-9ed601353312
2025-05-26 02:28:38.969 | {'loss': 0.0789, 'grad_norm': 4.082277297973633, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-26 02:28:54.366 | {'loss': 0.1034, 'grad_norm': 4.122331619262695, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-26 02:29:09.690 | {'loss': 0.1361, 'grad_norm': 5.247456073760986, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-26 02:29:31.870 | {'loss': 0.1223, 'grad_norm': 2.9637506008148193, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-26 02:29:47.281 | {'loss': 0.1198, 'grad_norm': 1.7317330837249756, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-26 02:30:02.648 | {'loss': 0.119, 'grad_norm': 7.491246700286865, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-26 02:30:17.825 | {'loss': 0.1279, 'grad_norm': 2.9864141941070557, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-26 02:30:33.205 | {'loss': 0.1355, 'grad_norm': 5.4308905601501465, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-26 02:30:55.201 | {'loss': 0.1351, 'grad_norm': 4.513584136962891, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-26 02:31:10.658 | {'loss': 0.14, 'grad_norm': 6.317615985870361, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-26 02:31:25.738 | {'loss': 0.1453, 'grad_norm': 3.7276268005371094, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-26 02:31:41.158 | {'loss': 0.1479, 'grad_norm': 5.472118854522705, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-26 02:31:57.158 | {'loss': 0.1794, 'grad_norm': 3.331657648086548, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-26 02:32:12.892 | {'loss': 0.1429, 'grad_norm': 5.362067699432373, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-26 02:32:35.072 | {'loss': 0.1475, 'grad_norm': 2.9118106365203857, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-26 02:32:50.811 | {'loss': 0.1575, 'grad_norm': 4.639233589172363, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-26 02:33:06.314 | {'loss': 0.1569, 'grad_norm': 7.9948859214782715, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-26 02:33:28.295 | {'loss': 0.153, 'grad_norm': 5.89388370513916, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-26 02:33:43.655 | {'loss': 0.1549, 'grad_norm': 8.769423484802246, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-26 02:33:58.979 | {'loss': 0.1555, 'grad_norm': 6.353598117828369, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-26 02:34:14.637 | {'loss': 0.3212, 'grad_norm': 5.062854290008545, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-26 02:34:37.116 | {'loss': 0.1637, 'grad_norm': 3.09279727935791, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-26 02:34:52.708 | {'loss': 0.1645, 'grad_norm': 4.595317363739014, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-26 02:35:07.864 | {'loss': 0.1904, 'grad_norm': 6.378076553344727, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-26 02:35:23.112 | {'loss': 0.1706, 'grad_norm': 8.727909088134766, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-26 02:35:44.983 | {'loss': 0.1324, 'grad_norm': 3.7893786430358887, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-26 02:36:00.108 | {'loss': 0.1423, 'grad_norm': 6.439733505249023, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-26 02:36:15.315 | {'loss': 0.1613, 'grad_norm': 5.247397422790527, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-26 02:36:36.995 | {'loss': 0.1636, 'grad_norm': 3.5959770679473877, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-26 02:36:52.848 | {'loss': 0.1459, 'grad_norm': 11.778884887695312, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-26 02:37:08.408 | {'loss': 0.1771, 'grad_norm': 4.981941223144531, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-26 02:37:23.947 | {'loss': 0.1628, 'grad_norm': 4.561757564544678, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-26 02:37:39.240 | {'loss': 0.1859, 'grad_norm': 4.859043598175049, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-26 02:38:00.923 | {'loss': 0.1645, 'grad_norm': 8.6509370803833, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-26 02:38:16.126 | {'loss': 0.1881, 'grad_norm': 9.067855834960938, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-26 02:38:31.551 | {'loss': 0.1888, 'grad_norm': 8.042767524719238, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-26 02:38:47.071 | {'loss': 0.195, 'grad_norm': 7.237354278564453, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-26 02:39:02.576 | {'loss': 0.1493, 'grad_norm': 4.485514163970947, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-26 02:39:18.009 | {'loss': 0.1775, 'grad_norm': 6.309256553649902, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-26 02:39:40.078 | {'loss': 0.1571, 'grad_norm': 3.1302809715270996, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-26 02:39:55.844 | {'loss': 0.1098, 'grad_norm': 2.5934948921203613, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-26 02:40:11.431 | {'loss': 0.1091, 'grad_norm': 2.6051535606384277, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-26 02:40:26.905 | {'loss': 0.1243, 'grad_norm': 5.284648418426514, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-26 02:40:48.998 | {'loss': 0.1093, 'grad_norm': 3.4837868213653564, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-26 02:41:04.369 | {'loss': 0.1209, 'grad_norm': 2.890540361404419, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-26 02:41:19.629 | {'loss': 0.1356, 'grad_norm': 7.3847336769104, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-26 02:41:35.148 | {'loss': 0.1354, 'grad_norm': 5.79280948638916, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-26 02:41:56.733 | {'loss': 0.1927, 'grad_norm': 3.198554277420044, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-26 02:42:11.602 | {'loss': 0.1329, 'grad_norm': 4.1721415519714355, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-26 02:42:27.273 | {'loss': 0.1169, 'grad_norm': 3.2281086444854736, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-26 02:42:42.619 | {'loss': 0.148, 'grad_norm': 4.161896228790283, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-26 02:43:04.594 | {'loss': 0.1483, 'grad_norm': 5.398335933685303, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-26 02:43:19.851 | {'loss': 0.1251, 'grad_norm': 2.5871083736419678, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-26 02:43:35.080 | {'loss': 0.1393, 'grad_norm': 3.1931920051574707, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-26 02:43:50.085 | {'loss': 0.1569, 'grad_norm': 5.636190414428711, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-26 02:44:11.651 | {'loss': 0.1459, 'grad_norm': 7.067777633666992, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-26 02:44:26.961 | {'loss': 0.1484, 'grad_norm': 5.774200439453125, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-26 02:44:41.927 | {'loss': 0.1251, 'grad_norm': 3.127640724182129, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-26 02:44:57.519 | {'loss': 0.1611, 'grad_norm': 5.464263439178467, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-26 02:45:19.726 | {'loss': 0.1115, 'grad_norm': 4.929222583770752, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-26 02:45:34.937 | {'loss': 0.0873, 'grad_norm': 4.396457195281982, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-26 02:45:50.097 | {'loss': 0.0762, 'grad_norm': 3.618238687515259, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-26 02:46:05.391 | {'loss': 0.1233, 'grad_norm': 2.18213152885437, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-26 02:46:27.134 | {'loss': 0.0928, 'grad_norm': 1.7163550853729248, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-26 02:46:42.311 | {'loss': 0.1133, 'grad_norm': 2.528806686401367, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-26 02:46:57.527 | {'loss': 0.0886, 'grad_norm': 3.160743474960327, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-26 02:47:12.920 | {'loss': 0.0831, 'grad_norm': 3.92604660987854, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-26 02:47:35.248 | {'loss': 0.0769, 'grad_norm': 1.66736900806427, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-26 02:47:50.999 | {'loss': 0.0882, 'grad_norm': 2.3938517570495605, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-26 02:48:06.354 | {'loss': 0.0963, 'grad_norm': 2.532912254333496, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-26 02:48:21.527 | {'loss': 0.0869, 'grad_norm': 1.4860334396362305, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-26 02:48:36.663 | {'loss': 0.1157, 'grad_norm': 3.135720729827881, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-26 02:48:58.623 | {'loss': 0.0914, 'grad_norm': 3.0499346256256104, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-26 02:49:13.983 | {'loss': 0.1166, 'grad_norm': 3.496593475341797, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-26 02:49:28.783 | {'loss': 0.089, 'grad_norm': 1.2420196533203125, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-26 02:49:44.099 | {'loss': 0.0953, 'grad_norm': 2.781731367111206, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-26 02:49:59.578 | {'loss': 0.1369, 'grad_norm': 2.9873993396759033, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-26 02:50:21.252 | {'loss': 0.0882, 'grad_norm': 3.5910890102386475, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-26 02:50:36.453 | {'loss': 0.1036, 'grad_norm': 5.1522135734558105, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-26 02:50:51.765 | {'loss': 0.0921, 'grad_norm': 1.8619954586029053, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-26 02:51:06.520 | {'loss': 0.0732, 'grad_norm': 1.3020182847976685, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-26 02:51:21.730 | {'loss': 0.0734, 'grad_norm': 0.950900673866272, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-26 02:51:42.840 | {'loss': 0.0698, 'grad_norm': 1.997626543045044, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-26 02:51:57.836 | {'loss': 0.0811, 'grad_norm': 1.2924948930740356, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-26 02:52:13.067 | {'loss': 0.0773, 'grad_norm': 3.2942419052124023, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-26 02:52:28.558 | {'loss': 0.0746, 'grad_norm': 2.0705654621124268, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-26 02:52:50.643 | {'loss': 0.0711, 'grad_norm': 1.4648146629333496, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-26 02:53:05.806 | {'loss': 0.0714, 'grad_norm': 1.9789425134658813, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-26 02:53:20.956 | {'loss': 0.0631, 'grad_norm': 1.6029855012893677, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-26 02:53:36.194 | {'loss': 0.071, 'grad_norm': 1.3517972230911255, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-26 02:53:57.958 | {'loss': 0.1018, 'grad_norm': 2.8566999435424805, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-26 02:54:13.045 | {'loss': 0.0751, 'grad_norm': 2.1559877395629883, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-26 02:54:28.202 | {'loss': 0.0709, 'grad_norm': 1.8517868518829346, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-26 02:54:43.260 | {'loss': 0.0702, 'grad_norm': 0.9623684287071228, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-26 02:55:05.350 | {'loss': 0.0889, 'grad_norm': 8.903258323669434, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-26 02:55:20.910 | {'loss': 0.0739, 'grad_norm': 4.039224147796631, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-26 02:55:36.239 | {'loss': 0.0694, 'grad_norm': 1.0421571731567383, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-26 02:55:51.399 | {'loss': 0.067, 'grad_norm': 2.862865924835205, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-26 02:56:06.438 | {'loss': 0.066, 'grad_norm': 2.088639497756958, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-26 02:56:15.696 | {'loss': 0.0784, 'grad_norm': 1.334953784942627, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-26 02:56:15.696 | {'train_runtime': 1690.509, 'train_samples_per_second': 1.183, 'train_steps_per_second': 0.592, 'train_loss': 0.12386635154485702, 'epoch': 5.0}
2025-05-26 02:56:19.680 | INFO :      Sent reply
2025-05-26 03:02:24.045 | INFO :      
2025-05-26 03:02:24.045 | INFO :      Received: evaluate message 24973c5d-f926-4d49-beb7-f01efd0df5f0
2025-05-26 03:02:39.344 | {'eval_loss': 3.8188064098358154, 'eval_runtime': 14.2819, 'eval_samples_per_second': 7.002, 'eval_steps_per_second': 0.91, 'epoch': 5.0}
2025-05-26 03:02:39.350 | INFO :      Sent reply
2025-05-26 03:02:50.697 | INFO :      
2025-05-26 03:02:50.697 | INFO :      Received: train message 3646acd5-ca27-4049-9ace-d25e05d68183
2025-05-26 03:03:15.645 | {'loss': 0.0753, 'grad_norm': 1.6376441717147827, 'learning_rate': 4.9550000000000005e-05, 'epoch': 0.05}
2025-05-26 03:03:31.034 | {'loss': 0.0882, 'grad_norm': 2.5202279090881348, 'learning_rate': 4.905e-05, 'epoch': 0.1}
2025-05-26 03:03:46.442 | {'loss': 0.1177, 'grad_norm': 4.257241249084473, 'learning_rate': 4.855e-05, 'epoch': 0.15}
2025-05-26 03:04:08.421 | {'loss': 0.1055, 'grad_norm': 1.5561559200286865, 'learning_rate': 4.805e-05, 'epoch': 0.2}
2025-05-26 03:04:23.883 | {'loss': 0.1239, 'grad_norm': 2.031644582748413, 'learning_rate': 4.755e-05, 'epoch': 0.25}
2025-05-26 03:04:39.420 | {'loss': 0.1173, 'grad_norm': 3.2893574237823486, 'learning_rate': 4.705e-05, 'epoch': 0.3}
2025-05-26 03:04:54.781 | {'loss': 0.1598, 'grad_norm': 2.649091958999634, 'learning_rate': 4.655000000000001e-05, 'epoch': 0.35}
2025-05-26 03:05:16.443 | {'loss': 0.1287, 'grad_norm': 5.621176242828369, 'learning_rate': 4.605e-05, 'epoch': 0.4}
2025-05-26 03:05:31.570 | {'loss': 0.1345, 'grad_norm': 6.407670974731445, 'learning_rate': 4.555e-05, 'epoch': 0.45}
2025-05-26 03:05:46.768 | {'loss': 0.1589, 'grad_norm': 7.6472086906433105, 'learning_rate': 4.5050000000000004e-05, 'epoch': 0.5}
2025-05-26 03:06:01.918 | {'loss': 0.1782, 'grad_norm': 3.1640703678131104, 'learning_rate': 4.4550000000000005e-05, 'epoch': 0.55}
2025-05-26 03:06:17.149 | {'loss': 0.1359, 'grad_norm': 4.866777420043945, 'learning_rate': 4.405e-05, 'epoch': 0.6}
2025-05-26 03:06:38.649 | {'loss': 0.1437, 'grad_norm': 2.245189905166626, 'learning_rate': 4.355e-05, 'epoch': 0.65}
2025-05-26 03:06:54.133 | {'loss': 0.1425, 'grad_norm': 3.514066219329834, 'learning_rate': 4.305e-05, 'epoch': 0.7}
2025-05-26 03:07:09.646 | {'loss': 0.143, 'grad_norm': 3.5646862983703613, 'learning_rate': 4.2550000000000004e-05, 'epoch': 0.75}
2025-05-26 03:07:25.034 | {'loss': 0.1507, 'grad_norm': 3.4708657264709473, 'learning_rate': 4.205e-05, 'epoch': 0.8}
2025-05-26 03:07:40.210 | {'loss': 0.1381, 'grad_norm': 5.569668769836426, 'learning_rate': 4.155e-05, 'epoch': 0.85}
2025-05-26 03:08:01.443 | {'loss': 0.1298, 'grad_norm': 6.367486000061035, 'learning_rate': 4.105e-05, 'epoch': 0.9}
2025-05-26 03:08:16.465 | {'loss': 0.1533, 'grad_norm': 5.003818035125732, 'learning_rate': 4.055e-05, 'epoch': 0.95}
2025-05-26 03:08:31.832 | {'loss': 0.1482, 'grad_norm': 3.0254600048065186, 'learning_rate': 4.0050000000000004e-05, 'epoch': 1.0}
2025-05-26 03:08:46.708 | {'loss': 0.3281, 'grad_norm': 5.708765983581543, 'learning_rate': 3.9550000000000006e-05, 'epoch': 1.05}
2025-05-26 03:09:02.045 | {'loss': 0.1333, 'grad_norm': 3.6194980144500732, 'learning_rate': 3.905e-05, 'epoch': 1.1}
2025-05-26 03:09:17.450 | {'loss': 0.1444, 'grad_norm': 3.455920934677124, 'learning_rate': 3.855e-05, 'epoch': 1.15}
2025-05-26 03:09:39.347 | {'loss': 0.1861, 'grad_norm': 7.278521537780762, 'learning_rate': 3.805e-05, 'epoch': 1.2}
2025-05-26 03:09:54.579 | {'loss': 0.122, 'grad_norm': 6.949906826019287, 'learning_rate': 3.7550000000000005e-05, 'epoch': 1.25}
2025-05-26 03:10:09.750 | {'loss': 0.1405, 'grad_norm': 6.139505386352539, 'learning_rate': 3.705e-05, 'epoch': 1.3}
2025-05-26 03:10:24.905 | {'loss': 0.1431, 'grad_norm': 5.415167331695557, 'learning_rate': 3.655e-05, 'epoch': 1.35}
2025-05-26 03:10:46.619 | {'loss': 0.1497, 'grad_norm': 5.984954833984375, 'learning_rate': 3.605e-05, 'epoch': 1.4}
2025-05-26 03:11:01.904 | {'loss': 0.1683, 'grad_norm': 6.765397548675537, 'learning_rate': 3.555e-05, 'epoch': 1.45}
2025-05-26 03:11:17.104 | {'loss': 0.1506, 'grad_norm': 4.5421061515808105, 'learning_rate': 3.505e-05, 'epoch': 1.5}
2025-05-26 03:11:32.451 | {'loss': 0.171, 'grad_norm': 5.521432399749756, 'learning_rate': 3.455e-05, 'epoch': 1.55}
2025-05-26 03:11:47.998 | {'loss': 0.1481, 'grad_norm': 4.158291816711426, 'learning_rate': 3.405e-05, 'epoch': 1.6}
2025-05-26 03:12:03.480 | {'loss': 0.1711, 'grad_norm': 4.440058708190918, 'learning_rate': 3.355e-05, 'epoch': 1.65}
2025-05-26 03:12:25.152 | {'loss': 0.1878, 'grad_norm': 4.0289716720581055, 'learning_rate': 3.3050000000000004e-05, 'epoch': 1.7}
2025-05-26 03:12:40.030 | {'loss': 0.2062, 'grad_norm': 3.098400354385376, 'learning_rate': 3.2550000000000005e-05, 'epoch': 1.75}
2025-05-26 03:12:55.084 | {'loss': 0.1764, 'grad_norm': 8.43706226348877, 'learning_rate': 3.205e-05, 'epoch': 1.8}
2025-05-26 03:13:10.236 | {'loss': 0.1839, 'grad_norm': 5.935217380523682, 'learning_rate': 3.155e-05, 'epoch': 1.85}
2025-05-26 03:13:25.394 | {'loss': 0.1791, 'grad_norm': 4.239304065704346, 'learning_rate': 3.105e-05, 'epoch': 1.9}
2025-05-26 03:13:46.938 | {'loss': 0.1904, 'grad_norm': 7.022029399871826, 'learning_rate': 3.0550000000000004e-05, 'epoch': 1.95}
2025-05-26 03:14:02.288 | {'loss': 0.1578, 'grad_norm': 3.5522992610931396, 'learning_rate': 3.0050000000000002e-05, 'epoch': 2.0}
2025-05-26 03:14:17.842 | {'loss': 0.1186, 'grad_norm': 2.343323230743408, 'learning_rate': 2.955e-05, 'epoch': 2.05}
2025-05-26 03:14:33.270 | {'loss': 0.1326, 'grad_norm': 6.818234920501709, 'learning_rate': 2.9049999999999998e-05, 'epoch': 2.1}
2025-05-26 03:14:48.580 | {'loss': 0.1139, 'grad_norm': 4.01230525970459, 'learning_rate': 2.855e-05, 'epoch': 2.15}
2025-05-26 03:15:10.255 | {'loss': 0.114, 'grad_norm': 2.5883607864379883, 'learning_rate': 2.8050000000000004e-05, 'epoch': 2.2}
2025-05-26 03:15:25.435 | {'loss': 0.1443, 'grad_norm': 2.165567398071289, 'learning_rate': 2.7550000000000002e-05, 'epoch': 2.25}
2025-05-26 03:15:40.706 | {'loss': 0.1423, 'grad_norm': 4.0969367027282715, 'learning_rate': 2.7050000000000004e-05, 'epoch': 2.3}
2025-05-26 03:15:55.698 | {'loss': 0.1339, 'grad_norm': 2.005575656890869, 'learning_rate': 2.655e-05, 'epoch': 2.35}
2025-05-26 03:16:10.766 | {'loss': 0.1918, 'grad_norm': 3.4120099544525146, 'learning_rate': 2.6050000000000003e-05, 'epoch': 2.4}
2025-05-26 03:16:26.590 | {'loss': 0.1282, 'grad_norm': 4.732181072235107, 'learning_rate': 2.555e-05, 'epoch': 2.45}
2025-05-26 03:16:41.504 | {'loss': 0.1356, 'grad_norm': 2.7327685356140137, 'learning_rate': 2.5050000000000002e-05, 'epoch': 2.5}
2025-05-26 03:17:03.920 | {'loss': 0.1363, 'grad_norm': 5.456078052520752, 'learning_rate': 2.455e-05, 'epoch': 2.55}
2025-05-26 03:17:18.761 | {'loss': 0.141, 'grad_norm': 4.4459733963012695, 'learning_rate': 2.4050000000000002e-05, 'epoch': 2.6}
2025-05-26 03:17:33.702 | {'loss': 0.1458, 'grad_norm': 2.257129430770874, 'learning_rate': 2.355e-05, 'epoch': 2.65}
2025-05-26 03:17:49.253 | {'loss': 0.1517, 'grad_norm': 3.957364797592163, 'learning_rate': 2.305e-05, 'epoch': 2.7}
2025-05-26 03:18:03.954 | {'loss': 0.1407, 'grad_norm': 3.436523914337158, 'learning_rate': 2.2550000000000003e-05, 'epoch': 2.75}
2025-05-26 03:18:19.030 | {'loss': 0.0996, 'grad_norm': 3.607114315032959, 'learning_rate': 2.205e-05, 'epoch': 2.8}
2025-05-26 03:18:40.577 | {'loss': 0.1348, 'grad_norm': 6.097684383392334, 'learning_rate': 2.1550000000000002e-05, 'epoch': 2.85}
2025-05-26 03:18:55.935 | {'loss': 0.1145, 'grad_norm': 3.49364972114563, 'learning_rate': 2.105e-05, 'epoch': 2.9}
2025-05-26 03:19:11.458 | {'loss': 0.1227, 'grad_norm': 4.868059158325195, 'learning_rate': 2.055e-05, 'epoch': 2.95}
2025-05-26 03:19:27.083 | {'loss': 0.1098, 'grad_norm': 4.772768497467041, 'learning_rate': 2.0050000000000003e-05, 'epoch': 3.0}
2025-05-26 03:19:42.758 | {'loss': 0.0837, 'grad_norm': 2.8489716053009033, 'learning_rate': 1.955e-05, 'epoch': 3.05}
2025-05-26 03:20:04.474 | {'loss': 0.0884, 'grad_norm': 4.713433742523193, 'learning_rate': 1.9050000000000002e-05, 'epoch': 3.1}
2025-05-26 03:20:19.894 | {'loss': 0.0937, 'grad_norm': 3.275212526321411, 'learning_rate': 1.855e-05, 'epoch': 3.15}
2025-05-26 03:20:35.138 | {'loss': 0.0976, 'grad_norm': 2.337414503097534, 'learning_rate': 1.805e-05, 'epoch': 3.2}
2025-05-26 03:20:50.438 | {'loss': 0.0932, 'grad_norm': 4.380721569061279, 'learning_rate': 1.755e-05, 'epoch': 3.25}
2025-05-26 03:21:12.320 | {'loss': 0.0815, 'grad_norm': 5.519311428070068, 'learning_rate': 1.705e-05, 'epoch': 3.3}
2025-05-26 03:21:28.082 | {'loss': 0.0967, 'grad_norm': 5.026252746582031, 'learning_rate': 1.6550000000000002e-05, 'epoch': 3.35}
2025-05-26 03:21:43.805 | {'loss': 0.0841, 'grad_norm': 3.183103084564209, 'learning_rate': 1.605e-05, 'epoch': 3.4}
2025-05-26 03:21:59.335 | {'loss': 0.0988, 'grad_norm': 2.0417754650115967, 'learning_rate': 1.5550000000000002e-05, 'epoch': 3.45}
2025-05-26 03:22:21.584 | {'loss': 0.1033, 'grad_norm': 4.942052841186523, 'learning_rate': 1.505e-05, 'epoch': 3.5}
2025-05-26 03:22:37.088 | {'loss': 0.09, 'grad_norm': 2.5429461002349854, 'learning_rate': 1.455e-05, 'epoch': 3.55}
2025-05-26 03:22:52.470 | {'loss': 0.1093, 'grad_norm': 3.759416341781616, 'learning_rate': 1.4050000000000003e-05, 'epoch': 3.6}
2025-05-26 03:23:07.650 | {'loss': 0.0857, 'grad_norm': 2.288182258605957, 'learning_rate': 1.3550000000000002e-05, 'epoch': 3.65}
2025-05-26 03:23:23.141 | {'loss': 0.0975, 'grad_norm': 2.7370994091033936, 'learning_rate': 1.305e-05, 'epoch': 3.7}
2025-05-26 03:23:44.852 | {'loss': 0.0838, 'grad_norm': 3.972670078277588, 'learning_rate': 1.255e-05, 'epoch': 3.75}
2025-05-26 03:24:00.140 | {'loss': 0.0919, 'grad_norm': 4.713095188140869, 'learning_rate': 1.205e-05, 'epoch': 3.8}
2025-05-26 03:24:15.122 | {'loss': 0.1196, 'grad_norm': 1.5865916013717651, 'learning_rate': 1.1550000000000001e-05, 'epoch': 3.85}
2025-05-26 03:24:30.710 | {'loss': 0.0999, 'grad_norm': 3.0453195571899414, 'learning_rate': 1.1050000000000001e-05, 'epoch': 3.9}
2025-05-26 03:24:46.360 | {'loss': 0.0965, 'grad_norm': 4.261318683624268, 'learning_rate': 1.055e-05, 'epoch': 3.95}
2025-05-26 03:25:01.707 | {'loss': 0.0906, 'grad_norm': 3.753929853439331, 'learning_rate': 1.005e-05, 'epoch': 4.0}
2025-05-26 03:25:23.226 | {'loss': 0.073, 'grad_norm': 1.4109833240509033, 'learning_rate': 9.55e-06, 'epoch': 4.05}
2025-05-26 03:25:38.390 | {'loss': 0.073, 'grad_norm': 0.9302538633346558, 'learning_rate': 9.05e-06, 'epoch': 4.1}
2025-05-26 03:25:53.293 | {'loss': 0.0686, 'grad_norm': 1.1996893882751465, 'learning_rate': 8.550000000000001e-06, 'epoch': 4.15}
2025-05-26 03:26:08.312 | {'loss': 0.0728, 'grad_norm': 3.012809991836548, 'learning_rate': 8.050000000000001e-06, 'epoch': 4.2}
2025-05-26 03:26:23.529 | {'loss': 0.0707, 'grad_norm': 2.5015199184417725, 'learning_rate': 7.55e-06, 'epoch': 4.25}
2025-05-26 03:26:45.682 | {'loss': 0.0723, 'grad_norm': 2.6061277389526367, 'learning_rate': 7.049999999999999e-06, 'epoch': 4.3}
2025-05-26 03:27:01.276 | {'loss': 0.0762, 'grad_norm': 1.5672712326049805, 'learning_rate': 6.550000000000001e-06, 'epoch': 4.35}
2025-05-26 03:27:16.749 | {'loss': 0.0754, 'grad_norm': 1.621878743171692, 'learning_rate': 6.0500000000000005e-06, 'epoch': 4.4}
2025-05-26 03:27:32.042 | {'loss': 0.0688, 'grad_norm': 1.276859164237976, 'learning_rate': 5.55e-06, 'epoch': 4.45}
2025-05-26 03:27:47.618 | {'loss': 0.0672, 'grad_norm': 2.05389142036438, 'learning_rate': 5.050000000000001e-06, 'epoch': 4.5}
2025-05-26 03:28:08.826 | {'loss': 0.0966, 'grad_norm': 1.9443353414535522, 'learning_rate': 4.5500000000000005e-06, 'epoch': 4.55}
2025-05-26 03:28:24.245 | {'loss': 0.0722, 'grad_norm': 2.0206754207611084, 'learning_rate': 4.05e-06, 'epoch': 4.6}
2025-05-26 03:28:39.403 | {'loss': 0.0683, 'grad_norm': 1.4868718385696411, 'learning_rate': 3.55e-06, 'epoch': 4.65}
2025-05-26 03:28:54.551 | {'loss': 0.0676, 'grad_norm': 1.0130773782730103, 'learning_rate': 3.05e-06, 'epoch': 4.7}
2025-05-26 03:29:17.360 | {'loss': 0.0838, 'grad_norm': 2.904599189758301, 'learning_rate': 2.55e-06, 'epoch': 4.75}
2025-05-26 03:29:32.511 | {'loss': 0.0727, 'grad_norm': 2.076672077178955, 'learning_rate': 2.0500000000000003e-06, 'epoch': 4.8}
2025-05-26 03:29:47.614 | {'loss': 0.0657, 'grad_norm': 0.9110913276672363, 'learning_rate': 1.55e-06, 'epoch': 4.85}
2025-05-26 03:30:02.689 | {'loss': 0.0764, 'grad_norm': 5.316222190856934, 'learning_rate': 1.0500000000000001e-06, 'epoch': 4.9}
2025-05-26 03:30:24.388 | {'loss': 0.0655, 'grad_norm': 1.9590089321136475, 'learning_rate': 5.5e-07, 'epoch': 4.95}
2025-05-26 03:30:39.422 | {'loss': 0.0721, 'grad_norm': 1.1771928071975708, 'learning_rate': 5.0000000000000004e-08, 'epoch': 5.0}
2025-05-26 03:30:39.422 | {'train_runtime': 1665.7726, 'train_samples_per_second': 1.201, 'train_steps_per_second': 0.6, 'train_loss': 0.12108064502477646, 'epoch': 5.0}
2025-05-26 03:30:45.019 | INFO :      Sent reply
2025-05-26 03:36:52.526 | INFO :      
2025-05-26 03:36:52.526 | INFO :      Received: evaluate message bb493a04-8013-41a0-b71e-30e421c475fc
2025-05-26 03:36:58.987 | {'eval_loss': 3.8560245037078857, 'eval_runtime': 3.7685, 'eval_samples_per_second': 26.535, 'eval_steps_per_second': 3.45, 'epoch': 5.0}
2025-05-26 03:36:58.988 | INFO :      Sent reply
2025-05-26 03:37:10.291 | INFO :      
2025-05-26 03:37:10.291 | INFO :      Received: reconnect message 1643d575-c10b-44e6-9fa9-bf4759d9031d
2025-05-26 03:37:10.327 | INFO :      Disconnect and shut down
