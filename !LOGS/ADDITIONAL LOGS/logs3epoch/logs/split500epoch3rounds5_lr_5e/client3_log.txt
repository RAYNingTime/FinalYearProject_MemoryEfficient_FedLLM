2025-05-24 00:09:06.486 | Repo card metadata block was not found. Setting CardData to empty.
2025-05-24 00:10:19.264 | 
2025-05-24 00:10:32.958 | 
2025-05-24 00:10:33.363 | 
2025-05-24 00:10:33.464 | /app/client.py:49: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-05-24 00:10:33.464 |   trainer = Trainer(
2025-05-24 00:10:33.884 | WARNING :   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
2025-05-24 00:10:33.884 | 	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
2025-05-24 00:10:33.884 | 	flwr.client.start_client(
2025-05-24 00:10:33.884 | 		server_address='<IP>:<PORT>',
2025-05-24 00:10:33.884 | 		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
2025-05-24 00:10:33.884 | 	)
2025-05-24 00:10:33.884 | 	Using `start_numpy_client()` is deprecated.
2025-05-24 00:10:33.884 | 
2025-05-24 00:10:33.884 |             This is a deprecated feature. It will be removed
2025-05-24 00:10:33.884 |             entirely in future versions of Flower.
2025-05-24 00:10:33.884 |         
2025-05-24 00:10:33.884 | WARNING :   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
2025-05-24 00:10:33.884 | 	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:
2025-05-24 00:10:33.884 | 
2025-05-24 00:10:33.884 | 		$ flower-supernode --insecure --superlink='<IP>:<PORT>'
2025-05-24 00:10:33.884 | 
2025-05-24 00:10:33.884 | 	To view all available options, run:
2025-05-24 00:10:33.884 | 
2025-05-24 00:10:33.884 | 		$ flower-supernode --help
2025-05-24 00:10:33.884 | 
2025-05-24 00:10:33.884 | 	Using `start_client()` is deprecated.
2025-05-24 00:10:33.884 | 
2025-05-24 00:10:33.884 |             This is a deprecated feature. It will be removed
2025-05-24 00:10:33.884 |             entirely in future versions of Flower.
2025-05-24 00:10:33.884 |         
2025-05-24 00:23:26.157 | INFO :      
2025-05-24 00:23:26.158 | INFO :      Received: evaluate message 681b3f92-f420-41df-9cd6-c4d0d36759a7
2025-05-24 00:23:34.125 | {'eval_loss': 2.4812510013580322, 'eval_model_preparation_time': 0.0079, 'eval_runtime': 5.4158, 'eval_samples_per_second': 18.464, 'eval_steps_per_second': 2.4}
2025-05-24 00:23:34.130 | INFO :      Sent reply
2025-05-24 00:23:41.258 | INFO :      
2025-05-24 00:23:41.258 | INFO :      Received: train message e4604faf-ed78-4116-8d8f-fc3f06b6a689
2025-05-24 00:23:51.438 | {'loss': 3.2304, 'grad_norm': 14.776091575622559, 'learning_rate': 4.9250000000000004e-05, 'epoch': 0.05}
2025-05-24 00:24:06.512 | {'loss': 3.1477, 'grad_norm': 14.530832290649414, 'learning_rate': 4.8416666666666673e-05, 'epoch': 0.1}
2025-05-24 00:24:22.447 | {'loss': 2.9711, 'grad_norm': 14.141366958618164, 'learning_rate': 4.7583333333333336e-05, 'epoch': 0.15}
2025-05-24 00:24:37.129 | {'loss': 2.642, 'grad_norm': 7.944112300872803, 'learning_rate': 4.6750000000000005e-05, 'epoch': 0.2}
2025-05-24 00:24:52.717 | {'loss': 3.1487, 'grad_norm': 16.27460289001465, 'learning_rate': 4.591666666666667e-05, 'epoch': 0.25}
2025-05-24 00:25:07.344 | {'loss': 2.8717, 'grad_norm': 12.603198051452637, 'learning_rate': 4.5083333333333336e-05, 'epoch': 0.3}
2025-05-24 00:25:23.063 | {'loss': 3.2406, 'grad_norm': 12.493035316467285, 'learning_rate': 4.4250000000000005e-05, 'epoch': 0.35}
2025-05-24 00:25:37.615 | {'loss': 2.7536, 'grad_norm': 16.923233032226562, 'learning_rate': 4.341666666666667e-05, 'epoch': 0.4}
2025-05-24 00:25:53.343 | {'loss': 3.4382, 'grad_norm': 13.955137252807617, 'learning_rate': 4.2583333333333336e-05, 'epoch': 0.45}
2025-05-24 00:26:07.901 | {'loss': 3.2546, 'grad_norm': 17.72146224975586, 'learning_rate': 4.175e-05, 'epoch': 0.5}
2025-05-24 00:26:23.396 | {'loss': 2.6883, 'grad_norm': 8.73013973236084, 'learning_rate': 4.091666666666667e-05, 'epoch': 0.55}
2025-05-24 00:26:44.237 | {'loss': 2.8638, 'grad_norm': 14.906792640686035, 'learning_rate': 4.0083333333333336e-05, 'epoch': 0.6}
2025-05-24 00:27:00.032 | {'loss': 2.4507, 'grad_norm': 11.223286628723145, 'learning_rate': 3.9250000000000005e-05, 'epoch': 0.65}
2025-05-24 00:27:14.675 | {'loss': 2.8593, 'grad_norm': 11.551407814025879, 'learning_rate': 3.841666666666667e-05, 'epoch': 0.7}
2025-05-24 00:27:30.293 | {'loss': 2.7587, 'grad_norm': 14.229127883911133, 'learning_rate': 3.7583333333333337e-05, 'epoch': 0.75}
2025-05-24 00:27:44.697 | {'loss': 3.0069, 'grad_norm': 14.358903884887695, 'learning_rate': 3.675e-05, 'epoch': 0.8}
2025-05-24 00:28:00.103 | {'loss': 2.4581, 'grad_norm': 12.470908164978027, 'learning_rate': 3.591666666666667e-05, 'epoch': 0.85}
2025-05-24 00:28:14.527 | {'loss': 2.9265, 'grad_norm': 12.061297416687012, 'learning_rate': 3.508333333333334e-05, 'epoch': 0.9}
2025-05-24 00:28:30.058 | {'loss': 2.7387, 'grad_norm': 13.330694198608398, 'learning_rate': 3.4250000000000006e-05, 'epoch': 0.95}
2025-05-24 00:28:44.499 | {'loss': 2.9667, 'grad_norm': 11.790497779846191, 'learning_rate': 3.341666666666667e-05, 'epoch': 1.0}
2025-05-24 00:28:59.876 | {'loss': 2.0291, 'grad_norm': 11.940563201904297, 'learning_rate': 3.258333333333333e-05, 'epoch': 1.05}
2025-05-24 00:29:14.421 | {'loss': 1.7835, 'grad_norm': 12.409098625183105, 'learning_rate': 3.175e-05, 'epoch': 1.1}
2025-05-24 00:29:30.116 | {'loss': 2.1028, 'grad_norm': 13.353140830993652, 'learning_rate': 3.091666666666667e-05, 'epoch': 1.15}
2025-05-24 00:29:44.854 | {'loss': 1.948, 'grad_norm': 10.292085647583008, 'learning_rate': 3.0083333333333337e-05, 'epoch': 1.2}
2025-05-24 00:30:06.731 | {'loss': 1.8348, 'grad_norm': 13.835025787353516, 'learning_rate': 2.925e-05, 'epoch': 1.25}
2025-05-24 00:30:21.154 | {'loss': 2.1695, 'grad_norm': 12.943520545959473, 'learning_rate': 2.841666666666667e-05, 'epoch': 1.3}
2025-05-24 00:30:36.622 | {'loss': 2.1695, 'grad_norm': 13.140059471130371, 'learning_rate': 2.7583333333333334e-05, 'epoch': 1.35}
2025-05-24 00:30:51.069 | {'loss': 2.0598, 'grad_norm': 15.657783508300781, 'learning_rate': 2.6750000000000003e-05, 'epoch': 1.4}
2025-05-24 00:31:06.581 | {'loss': 1.7498, 'grad_norm': 11.469832420349121, 'learning_rate': 2.5916666666666665e-05, 'epoch': 1.45}
2025-05-24 00:31:21.230 | {'loss': 1.9808, 'grad_norm': 12.958758354187012, 'learning_rate': 2.5083333333333338e-05, 'epoch': 1.5}
2025-05-24 00:31:36.723 | {'loss': 1.7875, 'grad_norm': 10.851153373718262, 'learning_rate': 2.425e-05, 'epoch': 1.55}
2025-05-24 00:31:51.298 | {'loss': 1.8824, 'grad_norm': 9.866255760192871, 'learning_rate': 2.341666666666667e-05, 'epoch': 1.6}
2025-05-24 00:32:07.108 | {'loss': 1.7991, 'grad_norm': 9.626190185546875, 'learning_rate': 2.2583333333333335e-05, 'epoch': 1.65}
2025-05-24 00:32:21.739 | {'loss': 1.9249, 'grad_norm': 15.714189529418945, 'learning_rate': 2.175e-05, 'epoch': 1.7}
2025-05-24 00:32:43.705 | {'loss': 1.9155, 'grad_norm': 10.214215278625488, 'learning_rate': 2.091666666666667e-05, 'epoch': 1.75}
2025-05-24 00:32:58.099 | {'loss': 1.8036, 'grad_norm': 11.061491012573242, 'learning_rate': 2.0083333333333335e-05, 'epoch': 1.8}
2025-05-24 00:33:13.583 | {'loss': 2.0126, 'grad_norm': 12.037556648254395, 'learning_rate': 1.925e-05, 'epoch': 1.85}
2025-05-24 00:33:28.002 | {'loss': 2.1871, 'grad_norm': 12.267672538757324, 'learning_rate': 1.841666666666667e-05, 'epoch': 1.9}
2025-05-24 00:33:43.486 | {'loss': 1.8581, 'grad_norm': 9.858231544494629, 'learning_rate': 1.7583333333333335e-05, 'epoch': 1.95}
2025-05-24 00:33:57.895 | {'loss': 1.7866, 'grad_norm': 10.944293975830078, 'learning_rate': 1.675e-05, 'epoch': 2.0}
2025-05-24 00:34:13.448 | {'loss': 1.5753, 'grad_norm': 11.696898460388184, 'learning_rate': 1.591666666666667e-05, 'epoch': 2.05}
2025-05-24 00:34:27.980 | {'loss': 1.2298, 'grad_norm': 4.248023986816406, 'learning_rate': 1.5083333333333335e-05, 'epoch': 2.1}
2025-05-24 00:34:43.642 | {'loss': 1.1284, 'grad_norm': 10.563986778259277, 'learning_rate': 1.4249999999999999e-05, 'epoch': 2.15}
2025-05-24 00:34:58.193 | {'loss': 1.3053, 'grad_norm': 9.673094749450684, 'learning_rate': 1.3416666666666666e-05, 'epoch': 2.2}
2025-05-24 00:35:13.718 | {'loss': 1.3484, 'grad_norm': 9.102103233337402, 'learning_rate': 1.2583333333333334e-05, 'epoch': 2.25}
2025-05-24 00:35:35.243 | {'loss': 1.354, 'grad_norm': 6.817354679107666, 'learning_rate': 1.175e-05, 'epoch': 2.3}
2025-05-24 00:35:49.737 | {'loss': 1.2983, 'grad_norm': 11.274535179138184, 'learning_rate': 1.0916666666666667e-05, 'epoch': 2.35}
2025-05-24 00:36:03.884 | {'loss': 1.1442, 'grad_norm': 7.568645477294922, 'learning_rate': 1.0083333333333334e-05, 'epoch': 2.4}
2025-05-24 00:36:19.357 | {'loss': 1.4624, 'grad_norm': 11.974184036254883, 'learning_rate': 9.25e-06, 'epoch': 2.45}
2025-05-24 00:36:33.907 | {'loss': 1.4073, 'grad_norm': 11.119321823120117, 'learning_rate': 8.416666666666667e-06, 'epoch': 2.5}
2025-05-24 00:36:49.185 | {'loss': 1.3578, 'grad_norm': 9.360856056213379, 'learning_rate': 7.583333333333334e-06, 'epoch': 2.55}
2025-05-24 00:37:03.620 | {'loss': 1.4363, 'grad_norm': 11.936993598937988, 'learning_rate': 6.750000000000001e-06, 'epoch': 2.6}
2025-05-24 00:37:19.137 | {'loss': 1.1092, 'grad_norm': 12.320991516113281, 'learning_rate': 5.916666666666667e-06, 'epoch': 2.65}
2025-05-24 00:37:33.670 | {'loss': 1.1747, 'grad_norm': 11.541574478149414, 'learning_rate': 5.0833333333333335e-06, 'epoch': 2.7}
2025-05-24 00:37:48.901 | {'loss': 1.5822, 'grad_norm': 9.41086196899414, 'learning_rate': 4.250000000000001e-06, 'epoch': 2.75}
2025-05-24 00:38:03.245 | {'loss': 1.4443, 'grad_norm': 9.270675659179688, 'learning_rate': 3.4166666666666664e-06, 'epoch': 2.8}
2025-05-24 00:38:18.917 | {'loss': 1.225, 'grad_norm': 9.387784004211426, 'learning_rate': 2.5833333333333333e-06, 'epoch': 2.85}
2025-05-24 00:38:40.246 | {'loss': 1.401, 'grad_norm': 11.49422550201416, 'learning_rate': 1.7500000000000002e-06, 'epoch': 2.9}
2025-05-24 00:38:54.766 | {'loss': 1.0977, 'grad_norm': 7.336981296539307, 'learning_rate': 9.166666666666667e-07, 'epoch': 2.95}
2025-05-24 00:39:09.181 | {'loss': 1.4869, 'grad_norm': 10.5049467086792, 'learning_rate': 8.333333333333334e-08, 'epoch': 3.0}
2025-05-24 00:39:09.181 | {'train_runtime': 925.164, 'train_samples_per_second': 1.297, 'train_steps_per_second': 0.649, 'train_loss': 2.062833201090495, 'epoch': 3.0}
2025-05-24 00:39:26.801 | INFO :      Sent reply
2025-05-24 00:41:24.196 | INFO :      
2025-05-24 00:41:24.196 | INFO :      Received: evaluate message 951fa64a-2432-4c25-b5af-cfaf6a862e37
2025-05-24 00:41:34.025 | {'eval_loss': 2.3552963733673096, 'eval_model_preparation_time': 0.0079, 'eval_runtime': 6.002, 'eval_samples_per_second': 16.661, 'eval_steps_per_second': 2.166, 'epoch': 3.0}
2025-05-24 00:41:34.027 | INFO :      Sent reply
2025-05-24 00:41:48.513 | INFO :      
2025-05-24 00:41:48.513 | INFO :      Received: train message b2b4a538-e2e1-4d40-957c-539fb30187fb
2025-05-24 00:42:27.772 | {'loss': 1.9071, 'grad_norm': 13.263776779174805, 'learning_rate': 4.9250000000000004e-05, 'epoch': 0.05}
2025-05-24 00:42:42.235 | {'loss': 2.0636, 'grad_norm': 14.545980453491211, 'learning_rate': 4.8416666666666673e-05, 'epoch': 0.1}
2025-05-24 00:42:57.576 | {'loss': 2.1055, 'grad_norm': 14.175890922546387, 'learning_rate': 4.7583333333333336e-05, 'epoch': 0.15}
2025-05-24 00:43:12.166 | {'loss': 1.8874, 'grad_norm': 7.38477087020874, 'learning_rate': 4.6750000000000005e-05, 'epoch': 0.2}
2025-05-24 00:43:27.579 | {'loss': 2.2747, 'grad_norm': 15.998210906982422, 'learning_rate': 4.591666666666667e-05, 'epoch': 0.25}
2025-05-24 00:43:42.043 | {'loss': 2.0342, 'grad_norm': 11.813655853271484, 'learning_rate': 4.5083333333333336e-05, 'epoch': 0.3}
2025-05-24 00:43:57.530 | {'loss': 2.3904, 'grad_norm': 13.746612548828125, 'learning_rate': 4.4250000000000005e-05, 'epoch': 0.35}
2025-05-24 00:44:11.923 | {'loss': 2.0365, 'grad_norm': 17.69704818725586, 'learning_rate': 4.341666666666667e-05, 'epoch': 0.4}
2025-05-24 00:44:27.498 | {'loss': 2.5146, 'grad_norm': 14.779180526733398, 'learning_rate': 4.2583333333333336e-05, 'epoch': 0.45}
2025-05-24 00:44:48.934 | {'loss': 2.3744, 'grad_norm': 17.292644500732422, 'learning_rate': 4.175e-05, 'epoch': 0.5}
2025-05-24 00:45:04.795 | {'loss': 1.9928, 'grad_norm': 6.0332770347595215, 'learning_rate': 4.091666666666667e-05, 'epoch': 0.55}
2025-05-24 00:45:19.208 | {'loss': 2.0666, 'grad_norm': 15.374908447265625, 'learning_rate': 4.0083333333333336e-05, 'epoch': 0.6}
2025-05-24 00:45:34.709 | {'loss': 1.8262, 'grad_norm': 11.457685470581055, 'learning_rate': 3.9250000000000005e-05, 'epoch': 0.65}
2025-05-24 00:45:49.144 | {'loss': 2.1951, 'grad_norm': 13.334671974182129, 'learning_rate': 3.841666666666667e-05, 'epoch': 0.7}
2025-05-24 00:46:04.613 | {'loss': 2.0301, 'grad_norm': 14.791241645812988, 'learning_rate': 3.7583333333333337e-05, 'epoch': 0.75}
2025-05-24 00:46:19.069 | {'loss': 2.2436, 'grad_norm': 15.020133018493652, 'learning_rate': 3.675e-05, 'epoch': 0.8}
2025-05-24 00:46:34.755 | {'loss': 1.8139, 'grad_norm': 13.673494338989258, 'learning_rate': 3.591666666666667e-05, 'epoch': 0.85}
2025-05-24 00:46:49.499 | {'loss': 2.1985, 'grad_norm': 13.3313570022583, 'learning_rate': 3.508333333333334e-05, 'epoch': 0.9}
2025-05-24 00:47:12.220 | {'loss': 2.0451, 'grad_norm': 14.537664413452148, 'learning_rate': 3.4250000000000006e-05, 'epoch': 0.95}
2025-05-24 00:47:28.341 | {'loss': 2.2234, 'grad_norm': 14.161539077758789, 'learning_rate': 3.341666666666667e-05, 'epoch': 1.0}
2025-05-24 00:47:43.235 | {'loss': 1.4047, 'grad_norm': 11.448653221130371, 'learning_rate': 3.258333333333333e-05, 'epoch': 1.05}
2025-05-24 00:47:59.039 | {'loss': 1.2866, 'grad_norm': 12.531210899353027, 'learning_rate': 3.175e-05, 'epoch': 1.1}
2025-05-24 00:48:13.796 | {'loss': 1.4431, 'grad_norm': 12.904755592346191, 'learning_rate': 3.091666666666667e-05, 'epoch': 1.15}
2025-05-24 00:48:29.202 | {'loss': 1.3018, 'grad_norm': 9.65150260925293, 'learning_rate': 3.0083333333333337e-05, 'epoch': 1.2}
2025-05-24 00:48:43.872 | {'loss': 1.2862, 'grad_norm': 12.604844093322754, 'learning_rate': 2.925e-05, 'epoch': 1.25}
2025-05-24 00:48:58.593 | {'loss': 1.5605, 'grad_norm': 13.764824867248535, 'learning_rate': 2.841666666666667e-05, 'epoch': 1.3}
2025-05-24 00:49:14.540 | {'loss': 1.5693, 'grad_norm': 12.747344970703125, 'learning_rate': 2.7583333333333334e-05, 'epoch': 1.35}
2025-05-24 00:49:30.285 | {'loss': 1.4164, 'grad_norm': 11.872529983520508, 'learning_rate': 2.6750000000000003e-05, 'epoch': 1.4}
2025-05-24 00:49:52.223 | {'loss': 1.2144, 'grad_norm': 12.052693367004395, 'learning_rate': 2.5916666666666665e-05, 'epoch': 1.45}
2025-05-24 00:50:07.461 | {'loss': 1.3426, 'grad_norm': 11.14830493927002, 'learning_rate': 2.5083333333333338e-05, 'epoch': 1.5}
2025-05-24 00:50:22.110 | {'loss': 1.2691, 'grad_norm': 10.931297302246094, 'learning_rate': 2.425e-05, 'epoch': 1.55}
2025-05-24 00:50:37.595 | {'loss': 1.2667, 'grad_norm': 8.701008796691895, 'learning_rate': 2.341666666666667e-05, 'epoch': 1.6}
2025-05-24 00:50:52.045 | {'loss': 1.2444, 'grad_norm': 9.686103820800781, 'learning_rate': 2.2583333333333335e-05, 'epoch': 1.65}
2025-05-24 00:51:07.626 | {'loss': 1.3522, 'grad_norm': 13.757088661193848, 'learning_rate': 2.175e-05, 'epoch': 1.7}
2025-05-24 00:51:22.159 | {'loss': 1.2998, 'grad_norm': 11.849997520446777, 'learning_rate': 2.091666666666667e-05, 'epoch': 1.75}
2025-05-24 00:51:37.747 | {'loss': 1.2871, 'grad_norm': 10.564638137817383, 'learning_rate': 2.0083333333333335e-05, 'epoch': 1.8}
2025-05-24 00:51:52.397 | {'loss': 1.4417, 'grad_norm': 12.376448631286621, 'learning_rate': 1.925e-05, 'epoch': 1.85}
2025-05-24 00:52:07.840 | {'loss': 1.4956, 'grad_norm': 11.233979225158691, 'learning_rate': 1.841666666666667e-05, 'epoch': 1.9}
2025-05-24 00:52:22.416 | {'loss': 1.292, 'grad_norm': 10.043282508850098, 'learning_rate': 1.7583333333333335e-05, 'epoch': 1.95}
2025-05-24 00:52:38.031 | {'loss': 1.3029, 'grad_norm': 10.357457160949707, 'learning_rate': 1.675e-05, 'epoch': 2.0}
2025-05-24 00:52:58.719 | {'loss': 1.005, 'grad_norm': 11.63743782043457, 'learning_rate': 1.591666666666667e-05, 'epoch': 2.05}
2025-05-24 00:53:14.321 | {'loss': 0.8061, 'grad_norm': 3.096511125564575, 'learning_rate': 1.5083333333333335e-05, 'epoch': 2.1}
2025-05-24 00:53:28.863 | {'loss': 0.7368, 'grad_norm': 9.993301391601562, 'learning_rate': 1.4249999999999999e-05, 'epoch': 2.15}
2025-05-24 00:53:44.297 | {'loss': 0.8566, 'grad_norm': 8.871652603149414, 'learning_rate': 1.3416666666666666e-05, 'epoch': 2.2}
2025-05-24 00:53:58.699 | {'loss': 0.8771, 'grad_norm': 8.439329147338867, 'learning_rate': 1.2583333333333334e-05, 'epoch': 2.25}
2025-05-24 00:54:14.021 | {'loss': 0.885, 'grad_norm': 7.09290885925293, 'learning_rate': 1.175e-05, 'epoch': 2.3}
2025-05-24 00:54:28.404 | {'loss': 0.8618, 'grad_norm': 13.198817253112793, 'learning_rate': 1.0916666666666667e-05, 'epoch': 2.35}
2025-05-24 00:54:43.976 | {'loss': 0.745, 'grad_norm': 6.860071182250977, 'learning_rate': 1.0083333333333334e-05, 'epoch': 2.4}
2025-05-24 00:55:04.889 | {'loss': 0.999, 'grad_norm': 10.294215202331543, 'learning_rate': 9.25e-06, 'epoch': 2.45}
2025-05-24 00:55:20.491 | {'loss': 0.9465, 'grad_norm': 10.245055198669434, 'learning_rate': 8.416666666666667e-06, 'epoch': 2.5}
2025-05-24 00:55:34.968 | {'loss': 0.9289, 'grad_norm': 9.013766288757324, 'learning_rate': 7.583333333333334e-06, 'epoch': 2.55}
2025-05-24 00:55:50.319 | {'loss': 0.9433, 'grad_norm': 8.772310256958008, 'learning_rate': 6.750000000000001e-06, 'epoch': 2.6}
2025-05-24 00:56:04.848 | {'loss': 0.7224, 'grad_norm': 9.395105361938477, 'learning_rate': 5.916666666666667e-06, 'epoch': 2.65}
2025-05-24 00:56:20.554 | {'loss': 0.8004, 'grad_norm': 10.589795112609863, 'learning_rate': 5.0833333333333335e-06, 'epoch': 2.7}
2025-05-24 00:56:34.794 | {'loss': 1.076, 'grad_norm': 8.663382530212402, 'learning_rate': 4.250000000000001e-06, 'epoch': 2.75}
2025-05-24 00:56:50.469 | {'loss': 1.012, 'grad_norm': 8.181504249572754, 'learning_rate': 3.4166666666666664e-06, 'epoch': 2.8}
2025-05-24 00:57:04.824 | {'loss': 0.815, 'grad_norm': 8.05595588684082, 'learning_rate': 2.5833333333333333e-06, 'epoch': 2.85}
2025-05-24 00:57:20.277 | {'loss': 0.8966, 'grad_norm': 10.384697914123535, 'learning_rate': 1.7500000000000002e-06, 'epoch': 2.9}
2025-05-24 00:57:34.900 | {'loss': 0.6817, 'grad_norm': 6.562796115875244, 'learning_rate': 9.166666666666667e-07, 'epoch': 2.95}
2025-05-24 00:57:51.430 | {'loss': 0.711, 'grad_norm': 7.536477088928223, 'learning_rate': 8.333333333333334e-08, 'epoch': 3.0}
2025-05-24 00:57:51.430 | {'train_runtime': 956.5458, 'train_samples_per_second': 1.255, 'train_steps_per_second': 0.627, 'train_loss': 1.4434441701571146, 'epoch': 3.0}
2025-05-24 00:58:07.346 | INFO :      Sent reply
2025-05-24 00:59:00.467 | INFO :      
2025-05-24 00:59:00.467 | INFO :      Received: evaluate message c5280fc0-eab9-45b3-bf6d-e5f91219da1f
2025-05-24 00:59:07.834 | {'eval_loss': 2.3930132389068604, 'eval_model_preparation_time': 0.0079, 'eval_runtime': 3.6234, 'eval_samples_per_second': 27.598, 'eval_steps_per_second': 3.588, 'epoch': 3.0}
2025-05-24 00:59:07.837 | INFO :      Sent reply
2025-05-24 00:59:20.068 | INFO :      
2025-05-24 00:59:20.068 | INFO :      Received: train message 1051cbaa-137b-4ab8-ad9d-4abbf1a41c1c
2025-05-24 00:59:53.535 | {'loss': 1.2657, 'grad_norm': 12.547187805175781, 'learning_rate': 4.9250000000000004e-05, 'epoch': 0.05}
2025-05-24 01:00:08.033 | {'loss': 1.5076, 'grad_norm': 14.099794387817383, 'learning_rate': 4.8416666666666673e-05, 'epoch': 0.1}
2025-05-24 01:00:23.433 | {'loss': 1.5814, 'grad_norm': 13.68724536895752, 'learning_rate': 4.7583333333333336e-05, 'epoch': 0.15}
2025-05-24 01:00:38.240 | {'loss': 1.4408, 'grad_norm': 6.577728748321533, 'learning_rate': 4.6750000000000005e-05, 'epoch': 0.2}
2025-05-24 01:00:53.969 | {'loss': 1.703, 'grad_norm': 14.632798194885254, 'learning_rate': 4.591666666666667e-05, 'epoch': 0.25}
2025-05-24 01:01:08.700 | {'loss': 1.5455, 'grad_norm': 11.417322158813477, 'learning_rate': 4.5083333333333336e-05, 'epoch': 0.3}
2025-05-24 01:01:24.048 | {'loss': 1.8692, 'grad_norm': 15.530655860900879, 'learning_rate': 4.4250000000000005e-05, 'epoch': 0.35}
2025-05-24 01:01:38.480 | {'loss': 1.5697, 'grad_norm': 16.288801193237305, 'learning_rate': 4.341666666666667e-05, 'epoch': 0.4}
2025-05-24 01:01:53.925 | {'loss': 1.964, 'grad_norm': 16.49758529663086, 'learning_rate': 4.2583333333333336e-05, 'epoch': 0.45}
2025-05-24 01:02:08.417 | {'loss': 1.8513, 'grad_norm': 15.848526954650879, 'learning_rate': 4.175e-05, 'epoch': 0.5}
2025-05-24 01:02:30.043 | {'loss': 1.5725, 'grad_norm': 5.282046794891357, 'learning_rate': 4.091666666666667e-05, 'epoch': 0.55}
2025-05-24 01:02:44.514 | {'loss': 1.6375, 'grad_norm': 16.102821350097656, 'learning_rate': 4.0083333333333336e-05, 'epoch': 0.6}
2025-05-24 01:03:00.211 | {'loss': 1.411, 'grad_norm': 10.998642921447754, 'learning_rate': 3.9250000000000005e-05, 'epoch': 0.65}
2025-05-24 01:03:14.386 | {'loss': 1.7321, 'grad_norm': 12.727578163146973, 'learning_rate': 3.841666666666667e-05, 'epoch': 0.7}
2025-05-24 01:03:29.602 | {'loss': 1.6051, 'grad_norm': 15.17313289642334, 'learning_rate': 3.7583333333333337e-05, 'epoch': 0.75}
2025-05-24 01:03:43.955 | {'loss': 1.7544, 'grad_norm': 15.621772766113281, 'learning_rate': 3.675e-05, 'epoch': 0.8}
2025-05-24 01:03:59.293 | {'loss': 1.4583, 'grad_norm': 14.014457702636719, 'learning_rate': 3.591666666666667e-05, 'epoch': 0.85}
2025-05-24 01:04:13.838 | {'loss': 1.7259, 'grad_norm': 12.581887245178223, 'learning_rate': 3.508333333333334e-05, 'epoch': 0.9}
2025-05-24 01:04:29.275 | {'loss': 1.577, 'grad_norm': 15.197661399841309, 'learning_rate': 3.4250000000000006e-05, 'epoch': 0.95}
2025-05-24 01:04:50.248 | {'loss': 1.8179, 'grad_norm': 15.48855972290039, 'learning_rate': 3.341666666666667e-05, 'epoch': 1.0}
2025-05-24 01:05:06.055 | {'loss': 1.0511, 'grad_norm': 12.193403244018555, 'learning_rate': 3.258333333333333e-05, 'epoch': 1.05}
2025-05-24 01:05:20.674 | {'loss': 0.9168, 'grad_norm': 11.988982200622559, 'learning_rate': 3.175e-05, 'epoch': 1.1}
2025-05-24 01:05:36.353 | {'loss': 1.076, 'grad_norm': 11.794836044311523, 'learning_rate': 3.091666666666667e-05, 'epoch': 1.15}
2025-05-24 01:05:51.152 | {'loss': 0.9623, 'grad_norm': 9.25091552734375, 'learning_rate': 3.0083333333333337e-05, 'epoch': 1.2}
2025-05-24 01:06:06.775 | {'loss': 0.9382, 'grad_norm': 13.228547096252441, 'learning_rate': 2.925e-05, 'epoch': 1.25}
2025-05-24 01:06:21.916 | {'loss': 1.1855, 'grad_norm': 11.91795825958252, 'learning_rate': 2.841666666666667e-05, 'epoch': 1.3}
2025-05-24 01:06:37.573 | {'loss': 1.1793, 'grad_norm': 12.154012680053711, 'learning_rate': 2.7583333333333334e-05, 'epoch': 1.35}
2025-05-24 01:06:52.184 | {'loss': 1.0326, 'grad_norm': 10.410985946655273, 'learning_rate': 2.6750000000000003e-05, 'epoch': 1.4}
2025-05-24 01:07:08.017 | {'loss': 0.8748, 'grad_norm': 11.092514991760254, 'learning_rate': 2.5916666666666665e-05, 'epoch': 1.45}
2025-05-24 01:07:22.232 | {'loss': 0.9871, 'grad_norm': 11.050810813903809, 'learning_rate': 2.5083333333333338e-05, 'epoch': 1.5}
2025-05-24 01:07:37.510 | {'loss': 0.9078, 'grad_norm': 11.003445625305176, 'learning_rate': 2.425e-05, 'epoch': 1.55}
2025-05-24 01:07:58.613 | {'loss': 0.9381, 'grad_norm': 8.841663360595703, 'learning_rate': 2.341666666666667e-05, 'epoch': 1.6}
2025-05-24 01:08:14.077 | {'loss': 0.9145, 'grad_norm': 10.287057876586914, 'learning_rate': 2.2583333333333335e-05, 'epoch': 1.65}
2025-05-24 01:08:28.700 | {'loss': 1.0384, 'grad_norm': 14.030550956726074, 'learning_rate': 2.175e-05, 'epoch': 1.7}
2025-05-24 01:08:44.096 | {'loss': 0.9289, 'grad_norm': 11.129091262817383, 'learning_rate': 2.091666666666667e-05, 'epoch': 1.75}
2025-05-24 01:08:58.482 | {'loss': 0.9913, 'grad_norm': 10.441405296325684, 'learning_rate': 2.0083333333333335e-05, 'epoch': 1.8}
2025-05-24 01:09:13.812 | {'loss': 1.0644, 'grad_norm': 12.576752662658691, 'learning_rate': 1.925e-05, 'epoch': 1.85}
2025-05-24 01:09:28.264 | {'loss': 1.0956, 'grad_norm': 11.245431900024414, 'learning_rate': 1.841666666666667e-05, 'epoch': 1.9}
2025-05-24 01:09:43.590 | {'loss': 0.9626, 'grad_norm': 9.922797203063965, 'learning_rate': 1.7583333333333335e-05, 'epoch': 1.95}
2025-05-24 01:09:57.965 | {'loss': 0.9901, 'grad_norm': 10.508615493774414, 'learning_rate': 1.675e-05, 'epoch': 2.0}
2025-05-24 01:10:13.384 | {'loss': 0.6739, 'grad_norm': 7.84913969039917, 'learning_rate': 1.591666666666667e-05, 'epoch': 2.05}
2025-05-24 01:10:28.252 | {'loss': 0.5711, 'grad_norm': 2.8460536003112793, 'learning_rate': 1.5083333333333335e-05, 'epoch': 2.1}
2025-05-24 01:10:43.883 | {'loss': 0.4795, 'grad_norm': 8.828744888305664, 'learning_rate': 1.4249999999999999e-05, 'epoch': 2.15}
2025-05-24 01:11:04.860 | {'loss': 0.5872, 'grad_norm': 6.541954040527344, 'learning_rate': 1.3416666666666666e-05, 'epoch': 2.2}
2025-05-24 01:11:20.218 | {'loss': 0.5883, 'grad_norm': 8.572263717651367, 'learning_rate': 1.2583333333333334e-05, 'epoch': 2.25}
2025-05-24 01:11:34.753 | {'loss': 0.6219, 'grad_norm': 5.462071418762207, 'learning_rate': 1.175e-05, 'epoch': 2.3}
2025-05-24 01:11:50.105 | {'loss': 0.5926, 'grad_norm': 8.148733139038086, 'learning_rate': 1.0916666666666667e-05, 'epoch': 2.35}
2025-05-24 01:12:04.622 | {'loss': 0.5387, 'grad_norm': 6.030914306640625, 'learning_rate': 1.0083333333333334e-05, 'epoch': 2.4}
2025-05-24 01:12:20.041 | {'loss': 0.6764, 'grad_norm': 8.7349853515625, 'learning_rate': 9.25e-06, 'epoch': 2.45}
2025-05-24 01:12:34.493 | {'loss': 0.6575, 'grad_norm': 10.404626846313477, 'learning_rate': 8.416666666666667e-06, 'epoch': 2.5}
2025-05-24 01:12:50.077 | {'loss': 0.6636, 'grad_norm': 7.648116111755371, 'learning_rate': 7.583333333333334e-06, 'epoch': 2.55}
2025-05-24 01:13:04.732 | {'loss': 0.6233, 'grad_norm': 9.035011291503906, 'learning_rate': 6.750000000000001e-06, 'epoch': 2.6}
2025-05-24 01:13:20.650 | {'loss': 0.5082, 'grad_norm': 9.982612609863281, 'learning_rate': 5.916666666666667e-06, 'epoch': 2.65}
2025-05-24 01:13:34.973 | {'loss': 0.5446, 'grad_norm': 9.721720695495605, 'learning_rate': 5.0833333333333335e-06, 'epoch': 2.7}
2025-05-24 01:13:50.327 | {'loss': 0.7792, 'grad_norm': 8.115910530090332, 'learning_rate': 4.250000000000001e-06, 'epoch': 2.75}
2025-05-24 01:14:10.953 | {'loss': 0.7066, 'grad_norm': 7.192878723144531, 'learning_rate': 3.4166666666666664e-06, 'epoch': 2.8}
2025-05-24 01:14:26.339 | {'loss': 0.5445, 'grad_norm': 6.625454425811768, 'learning_rate': 2.5833333333333333e-06, 'epoch': 2.85}
2025-05-24 01:14:40.774 | {'loss': 0.6104, 'grad_norm': 8.069316864013672, 'learning_rate': 1.7500000000000002e-06, 'epoch': 2.9}
2025-05-24 01:14:56.150 | {'loss': 0.4607, 'grad_norm': 6.57449197769165, 'learning_rate': 9.166666666666667e-07, 'epoch': 2.95}
2025-05-24 01:15:10.224 | {'loss': 0.4015, 'grad_norm': 6.62153959274292, 'learning_rate': 8.333333333333334e-08, 'epoch': 3.0}
2025-05-24 01:15:10.224 | {'train_runtime': 947.3465, 'train_samples_per_second': 1.267, 'train_steps_per_second': 0.633, 'train_loss': 1.074247988065084, 'epoch': 3.0}
2025-05-24 01:15:21.551 | INFO :      Sent reply
2025-05-24 01:16:10.064 | INFO :      
2025-05-24 01:16:10.064 | INFO :      Received: evaluate message 5af125fc-38d4-4920-903e-66d331cdfa19
2025-05-24 01:16:14.660 | {'eval_loss': 2.4662859439849854, 'eval_model_preparation_time': 0.0079, 'eval_runtime': 3.3594, 'eval_samples_per_second': 29.768, 'eval_steps_per_second': 3.87, 'epoch': 3.0}
2025-05-24 01:16:14.661 | INFO :      Sent reply
2025-05-24 01:16:33.802 | INFO :      
2025-05-24 01:16:33.802 | INFO :      Received: train message 3724cd27-172c-4bd1-a312-8c3c928c13d1
2025-05-24 01:17:10.078 | {'loss': 0.8803, 'grad_norm': 12.7559814453125, 'learning_rate': 4.9250000000000004e-05, 'epoch': 0.05}
2025-05-24 01:17:25.393 | {'loss': 1.0763, 'grad_norm': 15.110662460327148, 'learning_rate': 4.8416666666666673e-05, 'epoch': 0.1}
2025-05-24 01:17:41.107 | {'loss': 1.1723, 'grad_norm': 13.657112121582031, 'learning_rate': 4.7583333333333336e-05, 'epoch': 0.15}
2025-05-24 01:17:56.023 | {'loss': 1.0993, 'grad_norm': 6.827060699462891, 'learning_rate': 4.6750000000000005e-05, 'epoch': 0.2}
2025-05-24 01:18:10.491 | {'loss': 1.3073, 'grad_norm': 14.470151901245117, 'learning_rate': 4.591666666666667e-05, 'epoch': 0.25}
2025-05-24 01:18:32.074 | {'loss': 1.1626, 'grad_norm': 10.407782554626465, 'learning_rate': 4.5083333333333336e-05, 'epoch': 0.3}
2025-05-24 01:18:46.443 | {'loss': 1.4301, 'grad_norm': 14.61426830291748, 'learning_rate': 4.4250000000000005e-05, 'epoch': 0.35}
2025-05-24 01:19:01.855 | {'loss': 1.2111, 'grad_norm': 15.018073081970215, 'learning_rate': 4.341666666666667e-05, 'epoch': 0.4}
2025-05-24 01:19:16.363 | {'loss': 1.5595, 'grad_norm': 16.778335571289062, 'learning_rate': 4.2583333333333336e-05, 'epoch': 0.45}
2025-05-24 01:19:32.035 | {'loss': 1.4355, 'grad_norm': 14.800283432006836, 'learning_rate': 4.175e-05, 'epoch': 0.5}
2025-05-24 01:19:47.028 | {'loss': 1.2323, 'grad_norm': 4.159323215484619, 'learning_rate': 4.091666666666667e-05, 'epoch': 0.55}
2025-05-24 01:20:02.496 | {'loss': 1.2825, 'grad_norm': 16.135984420776367, 'learning_rate': 4.0083333333333336e-05, 'epoch': 0.6}
2025-05-24 01:20:16.957 | {'loss': 1.0916, 'grad_norm': 10.164962768554688, 'learning_rate': 3.9250000000000005e-05, 'epoch': 0.65}
2025-05-24 01:20:32.366 | {'loss': 1.3965, 'grad_norm': 12.391721725463867, 'learning_rate': 3.841666666666667e-05, 'epoch': 0.7}
2025-05-24 01:20:47.074 | {'loss': 1.267, 'grad_norm': 14.684041976928711, 'learning_rate': 3.7583333333333337e-05, 'epoch': 0.75}
2025-05-24 01:21:02.239 | {'loss': 1.3466, 'grad_norm': 14.023076057434082, 'learning_rate': 3.675e-05, 'epoch': 0.8}
2025-05-24 01:21:16.744 | {'loss': 1.1516, 'grad_norm': 14.000619888305664, 'learning_rate': 3.591666666666667e-05, 'epoch': 0.85}
2025-05-24 01:21:32.394 | {'loss': 1.3839, 'grad_norm': 13.486815452575684, 'learning_rate': 3.508333333333334e-05, 'epoch': 0.9}
2025-05-24 01:21:53.744 | {'loss': 1.2412, 'grad_norm': 13.710267066955566, 'learning_rate': 3.4250000000000006e-05, 'epoch': 0.95}
2025-05-24 01:22:09.195 | {'loss': 1.439, 'grad_norm': 15.416349411010742, 'learning_rate': 3.341666666666667e-05, 'epoch': 1.0}
2025-05-24 01:22:23.828 | {'loss': 0.7754, 'grad_norm': 11.45161247253418, 'learning_rate': 3.258333333333333e-05, 'epoch': 1.05}
2025-05-24 01:22:39.560 | {'loss': 0.6926, 'grad_norm': 12.405342102050781, 'learning_rate': 3.175e-05, 'epoch': 1.1}
2025-05-24 01:22:54.001 | {'loss': 0.8448, 'grad_norm': 12.473933219909668, 'learning_rate': 3.091666666666667e-05, 'epoch': 1.15}
2025-05-24 01:23:09.452 | {'loss': 0.7419, 'grad_norm': 8.862428665161133, 'learning_rate': 3.0083333333333337e-05, 'epoch': 1.2}
2025-05-24 01:23:23.863 | {'loss': 0.6868, 'grad_norm': 12.24234676361084, 'learning_rate': 2.925e-05, 'epoch': 1.25}
2025-05-24 01:23:40.148 | {'loss': 0.8585, 'grad_norm': 12.094564437866211, 'learning_rate': 2.841666666666667e-05, 'epoch': 1.3}
2025-05-24 01:23:55.127 | {'loss': 0.8831, 'grad_norm': 10.918339729309082, 'learning_rate': 2.7583333333333334e-05, 'epoch': 1.35}
2025-05-24 01:24:10.541 | {'loss': 0.7579, 'grad_norm': 9.268665313720703, 'learning_rate': 2.6750000000000003e-05, 'epoch': 1.4}
2025-05-24 01:24:25.110 | {'loss': 0.6637, 'grad_norm': 10.270294189453125, 'learning_rate': 2.5916666666666665e-05, 'epoch': 1.45}
2025-05-24 01:24:40.714 | {'loss': 0.7569, 'grad_norm': 11.674981117248535, 'learning_rate': 2.5083333333333338e-05, 'epoch': 1.5}
2025-05-24 01:24:55.436 | {'loss': 0.6956, 'grad_norm': 10.310291290283203, 'learning_rate': 2.425e-05, 'epoch': 1.55}
2025-05-24 01:25:10.889 | {'loss': 0.6905, 'grad_norm': 7.958409786224365, 'learning_rate': 2.341666666666667e-05, 'epoch': 1.6}
2025-05-24 01:25:25.543 | {'loss': 0.7242, 'grad_norm': 8.670466423034668, 'learning_rate': 2.2583333333333335e-05, 'epoch': 1.65}
2025-05-24 01:25:41.497 | {'loss': 0.7748, 'grad_norm': 13.921194076538086, 'learning_rate': 2.175e-05, 'epoch': 1.7}
2025-05-24 01:25:57.088 | {'loss': 0.7044, 'grad_norm': 11.563948631286621, 'learning_rate': 2.091666666666667e-05, 'epoch': 1.75}
2025-05-24 01:26:19.460 | {'loss': 0.7316, 'grad_norm': 10.307029724121094, 'learning_rate': 2.0083333333333335e-05, 'epoch': 1.8}
2025-05-24 01:26:34.335 | {'loss': 0.8541, 'grad_norm': 13.508810043334961, 'learning_rate': 1.925e-05, 'epoch': 1.85}
2025-05-24 01:26:50.067 | {'loss': 0.8891, 'grad_norm': 10.501548767089844, 'learning_rate': 1.841666666666667e-05, 'epoch': 1.9}
2025-05-24 01:27:04.689 | {'loss': 0.739, 'grad_norm': 9.446520805358887, 'learning_rate': 1.7583333333333335e-05, 'epoch': 1.95}
2025-05-24 01:27:20.545 | {'loss': 0.7801, 'grad_norm': 11.362533569335938, 'learning_rate': 1.675e-05, 'epoch': 2.0}
2025-05-24 01:27:35.961 | {'loss': 0.4804, 'grad_norm': 7.614771842956543, 'learning_rate': 1.591666666666667e-05, 'epoch': 2.05}
2025-05-24 01:27:52.286 | {'loss': 0.4, 'grad_norm': 2.589606285095215, 'learning_rate': 1.5083333333333335e-05, 'epoch': 2.1}
2025-05-24 01:28:07.189 | {'loss': 0.3578, 'grad_norm': 7.991476058959961, 'learning_rate': 1.4249999999999999e-05, 'epoch': 2.15}
2025-05-24 01:28:28.833 | {'loss': 0.4039, 'grad_norm': 5.844109535217285, 'learning_rate': 1.3416666666666666e-05, 'epoch': 2.2}
2025-05-24 01:28:44.057 | {'loss': 0.4366, 'grad_norm': 8.033681869506836, 'learning_rate': 1.2583333333333334e-05, 'epoch': 2.25}
2025-05-24 01:28:58.546 | {'loss': 0.4468, 'grad_norm': 6.086202621459961, 'learning_rate': 1.175e-05, 'epoch': 2.3}
2025-05-24 01:29:13.800 | {'loss': 0.441, 'grad_norm': 6.838022708892822, 'learning_rate': 1.0916666666666667e-05, 'epoch': 2.35}
2025-05-24 01:29:28.561 | {'loss': 0.3699, 'grad_norm': 6.143865585327148, 'learning_rate': 1.0083333333333334e-05, 'epoch': 2.4}
2025-05-24 01:29:44.250 | {'loss': 0.4838, 'grad_norm': 7.876499176025391, 'learning_rate': 9.25e-06, 'epoch': 2.45}
2025-05-24 01:29:59.362 | {'loss': 0.4655, 'grad_norm': 9.120543479919434, 'learning_rate': 8.416666666666667e-06, 'epoch': 2.5}
2025-05-24 01:30:15.182 | {'loss': 0.4995, 'grad_norm': 6.010606288909912, 'learning_rate': 7.583333333333334e-06, 'epoch': 2.55}
2025-05-24 01:30:29.636 | {'loss': 0.4605, 'grad_norm': 7.532249450683594, 'learning_rate': 6.750000000000001e-06, 'epoch': 2.6}
2025-05-24 01:30:44.220 | {'loss': 0.3733, 'grad_norm': 9.079276084899902, 'learning_rate': 5.916666666666667e-06, 'epoch': 2.65}
2025-05-24 01:30:59.397 | {'loss': 0.4027, 'grad_norm': 8.713077545166016, 'learning_rate': 5.0833333333333335e-06, 'epoch': 2.7}
2025-05-24 01:31:13.743 | {'loss': 0.5448, 'grad_norm': 8.335691452026367, 'learning_rate': 4.250000000000001e-06, 'epoch': 2.75}
2025-05-24 01:31:35.374 | {'loss': 0.5473, 'grad_norm': 6.186660289764404, 'learning_rate': 3.4166666666666664e-06, 'epoch': 2.8}
2025-05-24 01:31:51.170 | {'loss': 0.403, 'grad_norm': 5.856085300445557, 'learning_rate': 2.5833333333333333e-06, 'epoch': 2.85}
2025-05-24 01:32:06.686 | {'loss': 0.4573, 'grad_norm': 7.49631929397583, 'learning_rate': 1.7500000000000002e-06, 'epoch': 2.9}
2025-05-24 01:32:22.091 | {'loss': 0.3261, 'grad_norm': 6.654073238372803, 'learning_rate': 9.166666666666667e-07, 'epoch': 2.95}
2025-05-24 01:32:30.729 | {'loss': 0.2712, 'grad_norm': 6.03787088394165, 'learning_rate': 8.333333333333334e-08, 'epoch': 3.0}
2025-05-24 01:32:30.730 | {'train_runtime': 948.8379, 'train_samples_per_second': 1.265, 'train_steps_per_second': 0.632, 'train_loss': 0.8163784992694855, 'epoch': 3.0}
2025-05-24 01:32:35.820 | INFO :      Sent reply
2025-05-24 01:33:06.604 | INFO :      
2025-05-24 01:33:06.604 | INFO :      Received: evaluate message 32d15fa8-d040-4dfd-b9d9-afca96e1c7b3
2025-05-24 01:33:18.341 | {'eval_loss': 2.540912389755249, 'eval_model_preparation_time': 0.0079, 'eval_runtime': 8.6686, 'eval_samples_per_second': 11.536, 'eval_steps_per_second': 1.5, 'epoch': 3.0}
2025-05-24 01:33:18.356 | INFO :      Sent reply
2025-05-24 01:33:18.680 | INFO :      
2025-05-24 01:33:18.680 | INFO :      Received: reconnect message 7f8b1fad-2b9a-4a44-9902-2f78d09a56d0
2025-05-24 01:33:18.724 | INFO :      Disconnect and shut down
2025-05-24 01:34:48.589 | Generating train split:   0%|          | 0/61373 [00:00<?, ? examples/s]
2025-05-24 01:34:48.589 | Generating train split:   3%|▎         | 1949/61373 [00:00<00:04, 12562.49 examples/s]
2025-05-24 01:34:48.589 | Generating train split:   6%|▋         | 3962/61373 [00:00<00:03, 15192.61 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  10%|▉         | 6069/61373 [00:00<00:03, 16729.64 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  13%|█▎        | 8249/61373 [00:00<00:02, 17887.37 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  17%|█▋        | 10337/61373 [00:00<00:02, 18425.27 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  21%|██▏       | 13169/61373 [00:00<00:02, 17900.61 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  25%|██▍       | 15138/61373 [00:00<00:02, 18128.60 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  28%|██▊       | 17129/61373 [00:00<00:02, 18435.98 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  31%|███       | 19086/61373 [00:01<00:02, 17966.22 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  35%|███▍      | 21243/61373 [00:01<00:02, 18778.91 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  38%|███▊      | 23358/61373 [00:01<00:02, 18429.89 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  41%|████      | 25295/61373 [00:01<00:02, 17817.95 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  44%|████▍     | 27259/61373 [00:01<00:01, 17725.75 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  48%|████▊     | 29326/61373 [00:01<00:01, 17955.94 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  51%|█████▏    | 31479/61373 [00:01<00:01, 17881.63 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  54%|█████▍    | 33426/61373 [00:01<00:01, 17462.55 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  58%|█████▊    | 35444/61373 [00:02<00:01, 17732.26 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  61%|██████    | 37442/61373 [00:02<00:01, 17624.98 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  64%|██████▍   | 39433/61373 [00:02<00:01, 17297.82 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  68%|██████▊   | 41577/61373 [00:02<00:01, 17415.03 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  71%|███████   | 43692/61373 [00:02<00:00, 17777.48 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  75%|███████▍  | 45755/61373 [00:02<00:00, 17928.14 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  78%|███████▊  | 47705/61373 [00:02<00:00, 18138.00 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  81%|████████  | 49773/61373 [00:02<00:00, 18407.26 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  84%|████████▍ | 51792/61373 [00:02<00:00, 18654.39 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  88%|████████▊ | 53862/61373 [00:03<00:00, 18281.65 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  92%|█████████▏| 56666/61373 [00:03<00:00, 18022.68 examples/s]
2025-05-24 01:34:48.589 | Generating train split:  96%|█████████▌| 58709/61373 [00:03<00:00, 18265.30 examples/s]
2025-05-24 01:34:48.589 | Generating train split: 100%|██████████| 61373/61373 [00:03<00:00, 17686.40 examples/s]
2025-05-24 01:34:48.589 | Generating train split: 100%|██████████| 61373/61373 [00:03<00:00, 17803.64 examples/s]
2025-05-24 01:34:48.589 | Map:   0%|          | 0/500 [00:00<?, ? examples/s]
2025-05-24 01:34:48.589 | Map: 100%|██████████| 500/500 [00:12<00:00, 40.59 examples/s]
2025-05-24 01:34:48.589 | Map: 100%|██████████| 500/500 [00:12<00:00, 40.57 examples/s]
2025-05-24 01:34:48.589 | Map:   0%|          | 0/500 [00:00<?, ? examples/s]
2025-05-24 01:34:48.589 | Map:  24%|██▍       | 119/500 [00:00<00:00, 1152.94 examples/s]
2025-05-24 01:34:48.589 | Map:  51%|█████     | 256/500 [00:00<00:00, 1275.03 examples/s]
2025-05-24 01:34:48.589 | Map:  80%|███████▉  | 398/500 [00:00<00:00, 1338.54 examples/s]
2025-05-24 01:34:48.589 | Map: 100%|██████████| 500/500 [00:00<00:00, 1242.76 examples/s]