2025-05-24 00:08:57.005 | Repo card metadata block was not found. Setting CardData to empty.
2025-05-24 00:09:29.434 | 
2025-05-24 00:09:49.061 | 
2025-05-24 00:09:49.478 | 
2025-05-24 00:09:49.817 | /app/client.py:49: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-05-24 00:09:49.817 |   trainer = Trainer(
2025-05-24 00:09:50.322 | WARNING :   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
2025-05-24 00:09:50.322 | 	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
2025-05-24 00:09:50.322 | 	flwr.client.start_client(
2025-05-24 00:09:50.322 | 		server_address='<IP>:<PORT>',
2025-05-24 00:09:50.322 | 		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
2025-05-24 00:09:50.322 | 	)
2025-05-24 00:09:50.322 | 	Using `start_numpy_client()` is deprecated.
2025-05-24 00:09:50.322 | 
2025-05-24 00:09:50.322 |             This is a deprecated feature. It will be removed
2025-05-24 00:09:50.322 |             entirely in future versions of Flower.
2025-05-24 00:09:50.322 |         
2025-05-24 00:09:50.322 | WARNING :   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
2025-05-24 00:09:50.322 | 	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:
2025-05-24 00:09:50.322 | 
2025-05-24 00:09:50.322 | 		$ flower-supernode --insecure --superlink='<IP>:<PORT>'
2025-05-24 00:09:50.322 | 
2025-05-24 00:09:50.322 | 	To view all available options, run:
2025-05-24 00:09:50.322 | 
2025-05-24 00:09:50.322 | 		$ flower-supernode --help
2025-05-24 00:09:50.322 | 
2025-05-24 00:09:50.322 | 	Using `start_client()` is deprecated.
2025-05-24 00:09:50.322 | 
2025-05-24 00:09:50.322 |             This is a deprecated feature. It will be removed
2025-05-24 00:09:50.322 |             entirely in future versions of Flower.
2025-05-24 00:09:50.322 |         
2025-05-24 00:09:50.341 | INFO :      
2025-05-24 00:09:50.341 | INFO :      Received: get_parameters message d1234298-02c9-4c6f-88a8-772900e78a3e
2025-05-24 00:09:53.712 | INFO :      Sent reply
2025-05-24 00:11:18.923 | INFO :      
2025-05-24 00:11:18.923 | INFO :      Received: train message 65127b3d-dcc3-477c-a7bd-e4a49e33ce02
2025-05-24 00:11:59.638 | {'loss': 6.2828, 'grad_norm': 18.44326400756836, 'learning_rate': 4.9250000000000004e-05, 'epoch': 0.05}
2025-05-24 00:12:09.874 | {'loss': 5.2394, 'grad_norm': 24.21378517150879, 'learning_rate': 4.8416666666666673e-05, 'epoch': 0.1}
2025-05-24 00:12:21.643 | {'loss': 4.5851, 'grad_norm': 20.43598175048828, 'learning_rate': 4.7583333333333336e-05, 'epoch': 0.15}
2025-05-24 00:12:31.305 | {'loss': 4.2962, 'grad_norm': 19.120136260986328, 'learning_rate': 4.6750000000000005e-05, 'epoch': 0.2}
2025-05-24 00:12:44.877 | {'loss': 4.3573, 'grad_norm': 13.79123306274414, 'learning_rate': 4.591666666666667e-05, 'epoch': 0.25}
2025-05-24 00:12:55.549 | {'loss': 4.0654, 'grad_norm': 17.327394485473633, 'learning_rate': 4.5083333333333336e-05, 'epoch': 0.3}
2025-05-24 00:13:05.235 | {'loss': 3.6307, 'grad_norm': 17.199983596801758, 'learning_rate': 4.4250000000000005e-05, 'epoch': 0.35}
2025-05-24 00:13:14.878 | {'loss': 3.5679, 'grad_norm': 26.715957641601562, 'learning_rate': 4.341666666666667e-05, 'epoch': 0.4}
2025-05-24 00:13:25.459 | {'loss': 3.9117, 'grad_norm': 17.34555435180664, 'learning_rate': 4.2583333333333336e-05, 'epoch': 0.45}
2025-05-24 00:13:35.000 | {'loss': 3.703, 'grad_norm': 17.665096282958984, 'learning_rate': 4.175e-05, 'epoch': 0.5}
2025-05-24 00:13:44.774 | {'loss': 3.6117, 'grad_norm': 25.396907806396484, 'learning_rate': 4.091666666666667e-05, 'epoch': 0.55}
2025-05-24 00:13:55.265 | {'loss': 3.586, 'grad_norm': 17.08053207397461, 'learning_rate': 4.0083333333333336e-05, 'epoch': 0.6}
2025-05-24 00:14:04.798 | {'loss': 2.9286, 'grad_norm': 15.078259468078613, 'learning_rate': 3.9250000000000005e-05, 'epoch': 0.65}
2025-05-24 00:14:14.695 | {'loss': 3.653, 'grad_norm': 13.025355339050293, 'learning_rate': 3.841666666666667e-05, 'epoch': 0.7}
2025-05-24 00:14:28.917 | {'loss': 3.328, 'grad_norm': 12.963765144348145, 'learning_rate': 3.7583333333333337e-05, 'epoch': 0.75}
2025-05-24 00:14:38.581 | {'loss': 3.3189, 'grad_norm': 9.240642547607422, 'learning_rate': 3.675e-05, 'epoch': 0.8}
2025-05-24 00:14:48.255 | {'loss': 3.3555, 'grad_norm': 16.63874053955078, 'learning_rate': 3.591666666666667e-05, 'epoch': 0.85}
2025-05-24 00:14:59.121 | {'loss': 3.2809, 'grad_norm': 14.689998626708984, 'learning_rate': 3.508333333333334e-05, 'epoch': 0.9}
2025-05-24 00:15:08.928 | {'loss': 3.0507, 'grad_norm': 12.895963668823242, 'learning_rate': 3.4250000000000006e-05, 'epoch': 0.95}
2025-05-24 00:15:18.480 | {'loss': 2.5533, 'grad_norm': 12.38427734375, 'learning_rate': 3.341666666666667e-05, 'epoch': 1.0}
2025-05-24 00:15:29.119 | {'loss': 2.5147, 'grad_norm': 15.405326843261719, 'learning_rate': 3.258333333333333e-05, 'epoch': 1.05}
2025-05-24 00:15:38.752 | {'loss': 2.5474, 'grad_norm': 15.776190757751465, 'learning_rate': 3.175e-05, 'epoch': 1.1}
2025-05-24 00:15:52.372 | {'loss': 2.5988, 'grad_norm': 13.84915542602539, 'learning_rate': 3.091666666666667e-05, 'epoch': 1.15}
2025-05-24 00:16:03.204 | {'loss': 2.6439, 'grad_norm': 16.601577758789062, 'learning_rate': 3.0083333333333337e-05, 'epoch': 1.2}
2025-05-24 00:16:13.274 | {'loss': 2.4128, 'grad_norm': 14.746563911437988, 'learning_rate': 2.925e-05, 'epoch': 1.25}
2025-05-24 00:16:22.854 | {'loss': 2.5295, 'grad_norm': 17.0684757232666, 'learning_rate': 2.841666666666667e-05, 'epoch': 1.3}
2025-05-24 00:16:33.530 | {'loss': 2.4407, 'grad_norm': 9.793231010437012, 'learning_rate': 2.7583333333333334e-05, 'epoch': 1.35}
2025-05-24 00:16:43.171 | {'loss': 2.2603, 'grad_norm': 12.19602108001709, 'learning_rate': 2.6750000000000003e-05, 'epoch': 1.4}
2025-05-24 00:16:52.804 | {'loss': 2.0686, 'grad_norm': 12.118014335632324, 'learning_rate': 2.5916666666666665e-05, 'epoch': 1.45}
2025-05-24 00:17:03.527 | {'loss': 2.1201, 'grad_norm': 11.123869895935059, 'learning_rate': 2.5083333333333338e-05, 'epoch': 1.5}
2025-05-24 00:17:13.170 | {'loss': 2.2502, 'grad_norm': 8.45447826385498, 'learning_rate': 2.425e-05, 'epoch': 1.55}
2025-05-24 00:17:22.767 | {'loss': 2.4473, 'grad_norm': 12.255906105041504, 'learning_rate': 2.341666666666667e-05, 'epoch': 1.6}
2025-05-24 00:17:33.361 | {'loss': 1.8306, 'grad_norm': 11.663105010986328, 'learning_rate': 2.2583333333333335e-05, 'epoch': 1.65}
2025-05-24 00:17:42.861 | {'loss': 2.2808, 'grad_norm': 14.157930374145508, 'learning_rate': 2.175e-05, 'epoch': 1.7}
2025-05-24 00:17:52.669 | {'loss': 2.4918, 'grad_norm': 16.660327911376953, 'learning_rate': 2.091666666666667e-05, 'epoch': 1.75}
2025-05-24 00:18:03.216 | {'loss': 2.0912, 'grad_norm': 12.00361442565918, 'learning_rate': 2.0083333333333335e-05, 'epoch': 1.8}
2025-05-24 00:18:16.574 | {'loss': 2.1488, 'grad_norm': 14.784455299377441, 'learning_rate': 1.925e-05, 'epoch': 1.85}
2025-05-24 00:18:26.033 | {'loss': 2.0897, 'grad_norm': 12.80500602722168, 'learning_rate': 1.841666666666667e-05, 'epoch': 1.9}
2025-05-24 00:18:36.603 | {'loss': 2.2743, 'grad_norm': 14.674945831298828, 'learning_rate': 1.7583333333333335e-05, 'epoch': 1.95}
2025-05-24 00:18:46.115 | {'loss': 2.3324, 'grad_norm': 11.691215515136719, 'learning_rate': 1.675e-05, 'epoch': 2.0}
2025-05-24 00:18:55.643 | {'loss': 1.8058, 'grad_norm': 11.512012481689453, 'learning_rate': 1.591666666666667e-05, 'epoch': 2.05}
2025-05-24 00:19:06.231 | {'loss': 1.8285, 'grad_norm': 12.753686904907227, 'learning_rate': 1.5083333333333335e-05, 'epoch': 2.1}
2025-05-24 00:19:15.798 | {'loss': 1.632, 'grad_norm': 11.375960350036621, 'learning_rate': 1.4249999999999999e-05, 'epoch': 2.15}
2025-05-24 00:19:25.284 | {'loss': 1.5907, 'grad_norm': 13.191789627075195, 'learning_rate': 1.3416666666666666e-05, 'epoch': 2.2}
2025-05-24 00:19:35.833 | {'loss': 1.7706, 'grad_norm': 12.902981758117676, 'learning_rate': 1.2583333333333334e-05, 'epoch': 2.25}
2025-05-24 00:19:45.305 | {'loss': 1.7215, 'grad_norm': 11.683184623718262, 'learning_rate': 1.175e-05, 'epoch': 2.3}
2025-05-24 00:19:54.854 | {'loss': 1.4899, 'grad_norm': 6.476076602935791, 'learning_rate': 1.0916666666666667e-05, 'epoch': 2.35}
2025-05-24 00:20:05.696 | {'loss': 1.5964, 'grad_norm': 9.483935356140137, 'learning_rate': 1.0083333333333334e-05, 'epoch': 2.4}
2025-05-24 00:20:15.145 | {'loss': 1.6724, 'grad_norm': 15.54079818725586, 'learning_rate': 9.25e-06, 'epoch': 2.45}
2025-05-24 00:20:24.626 | {'loss': 1.529, 'grad_norm': 10.435460090637207, 'learning_rate': 8.416666666666667e-06, 'epoch': 2.5}
2025-05-24 00:20:35.226 | {'loss': 1.8109, 'grad_norm': 11.946487426757812, 'learning_rate': 7.583333333333334e-06, 'epoch': 2.55}
2025-05-24 00:20:48.667 | {'loss': 1.491, 'grad_norm': 9.52701473236084, 'learning_rate': 6.750000000000001e-06, 'epoch': 2.6}
2025-05-24 00:20:58.302 | {'loss': 1.4947, 'grad_norm': 10.502889633178711, 'learning_rate': 5.916666666666667e-06, 'epoch': 2.65}
2025-05-24 00:21:09.040 | {'loss': 1.5483, 'grad_norm': 9.837992668151855, 'learning_rate': 5.0833333333333335e-06, 'epoch': 2.7}
2025-05-24 00:21:18.981 | {'loss': 1.6434, 'grad_norm': 12.63332462310791, 'learning_rate': 4.250000000000001e-06, 'epoch': 2.75}
2025-05-24 00:21:28.509 | {'loss': 1.4195, 'grad_norm': 4.893303871154785, 'learning_rate': 3.4166666666666664e-06, 'epoch': 2.8}
2025-05-24 00:21:39.104 | {'loss': 1.6773, 'grad_norm': 12.319487571716309, 'learning_rate': 2.5833333333333333e-06, 'epoch': 2.85}
2025-05-24 00:21:48.761 | {'loss': 1.726, 'grad_norm': 10.145922660827637, 'learning_rate': 1.7500000000000002e-06, 'epoch': 2.9}
2025-05-24 00:21:58.422 | {'loss': 1.6563, 'grad_norm': 12.880773544311523, 'learning_rate': 9.166666666666667e-07, 'epoch': 2.95}
2025-05-24 00:22:08.857 | {'loss': 1.4776, 'grad_norm': 8.806371688842773, 'learning_rate': 8.333333333333334e-08, 'epoch': 3.0}
2025-05-24 00:22:08.858 | {'train_runtime': 648.7126, 'train_samples_per_second': 1.85, 'train_steps_per_second': 0.925, 'train_loss': 2.587698548634847, 'epoch': 3.0}
2025-05-24 00:22:41.590 | INFO :      Sent reply
2025-05-24 00:23:18.094 | INFO :      
2025-05-24 00:23:18.094 | INFO :      Received: evaluate message 6f13c039-df4c-4c6f-ac7e-cab0778d4fed
2025-05-24 00:23:23.264 | {'eval_loss': 2.7618188858032227, 'eval_runtime': 1.2297, 'eval_samples_per_second': 81.32, 'eval_steps_per_second': 10.572, 'epoch': 3.0}
2025-05-24 00:23:23.317 | INFO :      Sent reply
2025-05-24 00:23:46.259 | INFO :      
2025-05-24 00:23:46.260 | INFO :      Received: train message c5351dbb-8ef9-4d18-bc7a-9ec5cd6d6258
2025-05-24 00:24:12.792 | {'loss': 2.0645, 'grad_norm': 8.38330078125, 'learning_rate': 4.9250000000000004e-05, 'epoch': 0.05}
2025-05-24 00:24:27.585 | {'loss': 2.25, 'grad_norm': 16.99970245361328, 'learning_rate': 4.8416666666666673e-05, 'epoch': 0.1}
2025-05-24 00:24:43.316 | {'loss': 2.3893, 'grad_norm': 16.296772003173828, 'learning_rate': 4.7583333333333336e-05, 'epoch': 0.15}
2025-05-24 00:24:58.000 | {'loss': 2.1927, 'grad_norm': 13.604647636413574, 'learning_rate': 4.6750000000000005e-05, 'epoch': 0.2}
2025-05-24 00:25:12.651 | {'loss': 2.4319, 'grad_norm': 9.972945213317871, 'learning_rate': 4.591666666666667e-05, 'epoch': 0.25}
2025-05-24 00:25:34.582 | {'loss': 2.2178, 'grad_norm': 16.227384567260742, 'learning_rate': 4.5083333333333336e-05, 'epoch': 0.3}
2025-05-24 00:25:50.237 | {'loss': 1.9503, 'grad_norm': 13.6656494140625, 'learning_rate': 4.4250000000000005e-05, 'epoch': 0.35}
2025-05-24 00:26:04.696 | {'loss': 2.0135, 'grad_norm': 17.85817527770996, 'learning_rate': 4.341666666666667e-05, 'epoch': 0.4}
2025-05-24 00:26:20.178 | {'loss': 2.2908, 'grad_norm': 15.932194709777832, 'learning_rate': 4.2583333333333336e-05, 'epoch': 0.45}
2025-05-24 00:26:34.694 | {'loss': 2.2151, 'grad_norm': 17.130945205688477, 'learning_rate': 4.175e-05, 'epoch': 0.5}
2025-05-24 00:26:50.341 | {'loss': 2.1894, 'grad_norm': 16.978511810302734, 'learning_rate': 4.091666666666667e-05, 'epoch': 0.55}
2025-05-24 00:27:05.066 | {'loss': 2.2286, 'grad_norm': 14.786858558654785, 'learning_rate': 4.0083333333333336e-05, 'epoch': 0.6}
2025-05-24 00:27:20.680 | {'loss': 1.6596, 'grad_norm': 12.507623672485352, 'learning_rate': 3.9250000000000005e-05, 'epoch': 0.65}
2025-05-24 00:27:35.246 | {'loss': 2.3188, 'grad_norm': 8.388189315795898, 'learning_rate': 3.841666666666667e-05, 'epoch': 0.7}
2025-05-24 00:27:50.616 | {'loss': 2.1041, 'grad_norm': 10.052387237548828, 'learning_rate': 3.7583333333333337e-05, 'epoch': 0.75}
2025-05-24 00:28:05.092 | {'loss': 2.2141, 'grad_norm': 6.908106803894043, 'learning_rate': 3.675e-05, 'epoch': 0.8}
2025-05-24 00:28:20.511 | {'loss': 2.1745, 'grad_norm': 14.088151931762695, 'learning_rate': 3.591666666666667e-05, 'epoch': 0.85}
2025-05-24 00:28:35.037 | {'loss': 2.1551, 'grad_norm': 14.611413955688477, 'learning_rate': 3.508333333333334e-05, 'epoch': 0.9}
2025-05-24 00:28:49.464 | {'loss': 2.0119, 'grad_norm': 13.202929496765137, 'learning_rate': 3.4250000000000006e-05, 'epoch': 0.95}
2025-05-24 00:29:04.933 | {'loss': 1.6148, 'grad_norm': 10.691137313842773, 'learning_rate': 3.341666666666667e-05, 'epoch': 1.0}
2025-05-24 00:29:26.840 | {'loss': 1.4321, 'grad_norm': 13.14428424835205, 'learning_rate': 3.258333333333333e-05, 'epoch': 1.05}
2025-05-24 00:29:41.667 | {'loss': 1.489, 'grad_norm': 14.447827339172363, 'learning_rate': 3.175e-05, 'epoch': 1.1}
2025-05-24 00:29:57.277 | {'loss': 1.4844, 'grad_norm': 10.829655647277832, 'learning_rate': 3.091666666666667e-05, 'epoch': 1.15}
2025-05-24 00:30:11.800 | {'loss': 1.5912, 'grad_norm': 16.16710090637207, 'learning_rate': 3.0083333333333337e-05, 'epoch': 1.2}
2025-05-24 00:30:27.187 | {'loss': 1.4348, 'grad_norm': 12.170951843261719, 'learning_rate': 2.925e-05, 'epoch': 1.25}
2025-05-24 00:30:41.594 | {'loss': 1.5734, 'grad_norm': 12.559270858764648, 'learning_rate': 2.841666666666667e-05, 'epoch': 1.3}
2025-05-24 00:30:57.046 | {'loss': 1.5631, 'grad_norm': 7.699121952056885, 'learning_rate': 2.7583333333333334e-05, 'epoch': 1.35}
2025-05-24 00:31:11.755 | {'loss': 1.4463, 'grad_norm': 9.96280574798584, 'learning_rate': 2.6750000000000003e-05, 'epoch': 1.4}
2025-05-24 00:31:27.209 | {'loss': 1.2477, 'grad_norm': 9.511028289794922, 'learning_rate': 2.5916666666666665e-05, 'epoch': 1.45}
2025-05-24 00:31:41.770 | {'loss': 1.2634, 'grad_norm': 9.646919250488281, 'learning_rate': 2.5083333333333338e-05, 'epoch': 1.5}
2025-05-24 00:32:03.925 | {'loss': 1.3501, 'grad_norm': 9.094734191894531, 'learning_rate': 2.425e-05, 'epoch': 1.55}
2025-05-24 00:32:18.553 | {'loss': 1.492, 'grad_norm': 11.648073196411133, 'learning_rate': 2.341666666666667e-05, 'epoch': 1.6}
2025-05-24 00:32:34.153 | {'loss': 1.1302, 'grad_norm': 11.445419311523438, 'learning_rate': 2.2583333333333335e-05, 'epoch': 1.65}
2025-05-24 00:32:48.761 | {'loss': 1.4039, 'grad_norm': 12.802078247070312, 'learning_rate': 2.175e-05, 'epoch': 1.7}
2025-05-24 00:33:04.188 | {'loss': 1.532, 'grad_norm': 14.428857803344727, 'learning_rate': 2.091666666666667e-05, 'epoch': 1.75}
2025-05-24 00:33:18.651 | {'loss': 1.3598, 'grad_norm': 11.19330883026123, 'learning_rate': 2.0083333333333335e-05, 'epoch': 1.8}
2025-05-24 00:33:34.082 | {'loss': 1.3801, 'grad_norm': 14.132379531860352, 'learning_rate': 1.925e-05, 'epoch': 1.85}
2025-05-24 00:33:48.546 | {'loss': 1.2775, 'grad_norm': 12.375049591064453, 'learning_rate': 1.841666666666667e-05, 'epoch': 1.9}
2025-05-24 00:34:04.045 | {'loss': 1.505, 'grad_norm': 12.444058418273926, 'learning_rate': 1.7583333333333335e-05, 'epoch': 1.95}
2025-05-24 00:34:18.599 | {'loss': 1.4649, 'grad_norm': 10.567329406738281, 'learning_rate': 1.675e-05, 'epoch': 2.0}
2025-05-24 00:34:34.185 | {'loss': 1.0462, 'grad_norm': 10.943894386291504, 'learning_rate': 1.591666666666667e-05, 'epoch': 2.05}
2025-05-24 00:34:55.359 | {'loss': 1.125, 'grad_norm': 10.575406074523926, 'learning_rate': 1.5083333333333335e-05, 'epoch': 2.1}
2025-05-24 00:35:10.870 | {'loss': 0.9059, 'grad_norm': 11.687166213989258, 'learning_rate': 1.4249999999999999e-05, 'epoch': 2.15}
2025-05-24 00:35:25.407 | {'loss': 0.9096, 'grad_norm': 13.237833976745605, 'learning_rate': 1.3416666666666666e-05, 'epoch': 2.2}
2025-05-24 00:35:40.507 | {'loss': 0.979, 'grad_norm': 10.353455543518066, 'learning_rate': 1.2583333333333334e-05, 'epoch': 2.25}
2025-05-24 00:35:54.972 | {'loss': 0.9892, 'grad_norm': 10.537386894226074, 'learning_rate': 1.175e-05, 'epoch': 2.3}
2025-05-24 00:36:10.159 | {'loss': 0.8384, 'grad_norm': 5.421596050262451, 'learning_rate': 1.0916666666666667e-05, 'epoch': 2.35}
2025-05-24 00:36:24.795 | {'loss': 0.8532, 'grad_norm': 8.083674430847168, 'learning_rate': 1.0083333333333334e-05, 'epoch': 2.4}
2025-05-24 00:36:39.937 | {'loss': 0.9772, 'grad_norm': 12.444901466369629, 'learning_rate': 9.25e-06, 'epoch': 2.45}
2025-05-24 00:36:54.333 | {'loss': 0.898, 'grad_norm': 7.489016532897949, 'learning_rate': 8.416666666666667e-06, 'epoch': 2.5}
2025-05-24 00:37:16.031 | {'loss': 1.102, 'grad_norm': 10.727694511413574, 'learning_rate': 7.583333333333334e-06, 'epoch': 2.55}
2025-05-24 00:37:30.711 | {'loss': 0.8534, 'grad_norm': 6.746796607971191, 'learning_rate': 6.750000000000001e-06, 'epoch': 2.6}
2025-05-24 00:37:45.975 | {'loss': 0.8636, 'grad_norm': 7.055846214294434, 'learning_rate': 5.916666666666667e-06, 'epoch': 2.65}
2025-05-24 00:38:00.285 | {'loss': 0.9056, 'grad_norm': 9.326653480529785, 'learning_rate': 5.0833333333333335e-06, 'epoch': 2.7}
2025-05-24 00:38:15.958 | {'loss': 0.9633, 'grad_norm': 11.111510276794434, 'learning_rate': 4.250000000000001e-06, 'epoch': 2.75}
2025-05-24 00:38:30.113 | {'loss': 0.8723, 'grad_norm': 4.510401248931885, 'learning_rate': 3.4166666666666664e-06, 'epoch': 2.8}
2025-05-24 00:38:45.521 | {'loss': 1.0079, 'grad_norm': 9.790741920471191, 'learning_rate': 2.5833333333333333e-06, 'epoch': 2.85}
2025-05-24 00:38:59.979 | {'loss': 0.9984, 'grad_norm': 8.52914810180664, 'learning_rate': 1.7500000000000002e-06, 'epoch': 2.9}
2025-05-24 00:39:15.393 | {'loss': 0.8861, 'grad_norm': 9.77236557006836, 'learning_rate': 9.166666666666667e-07, 'epoch': 2.95}
2025-05-24 00:39:27.391 | {'loss': 0.6891, 'grad_norm': 5.849879741668701, 'learning_rate': 8.333333333333334e-08, 'epoch': 3.0}
2025-05-24 00:39:27.392 | {'train_runtime': 938.1196, 'train_samples_per_second': 1.279, 'train_steps_per_second': 0.64, 'train_loss': 1.4961827556292215, 'epoch': 3.0}
2025-05-24 00:39:56.140 | INFO :      Sent reply
2025-05-24 00:41:21.802 | INFO :      
2025-05-24 00:41:21.802 | INFO :      Received: evaluate message c14b29e3-7aa9-4374-8129-5de67ddbd286
2025-05-24 00:41:25.666 | {'eval_loss': 2.6657564640045166, 'eval_runtime': 1.1744, 'eval_samples_per_second': 85.15, 'eval_steps_per_second': 11.069, 'epoch': 3.0}
2025-05-24 00:41:25.667 | INFO :      Sent reply
2025-05-24 00:41:49.380 | INFO :      
2025-05-24 00:41:49.380 | INFO :      Received: train message a9462e79-cf01-47e4-8608-21773ce5de41
2025-05-24 00:42:23.061 | {'loss': 1.4794, 'grad_norm': 7.042605400085449, 'learning_rate': 4.9250000000000004e-05, 'epoch': 0.05}
2025-05-24 00:42:37.695 | {'loss': 1.7323, 'grad_norm': 15.903972625732422, 'learning_rate': 4.8416666666666673e-05, 'epoch': 0.1}
2025-05-24 00:42:53.060 | {'loss': 1.7977, 'grad_norm': 15.90192699432373, 'learning_rate': 4.7583333333333336e-05, 'epoch': 0.15}
2025-05-24 00:43:07.511 | {'loss': 1.6779, 'grad_norm': 11.914970397949219, 'learning_rate': 4.6750000000000005e-05, 'epoch': 0.2}
2025-05-24 00:43:22.914 | {'loss': 1.8802, 'grad_norm': 9.245620727539062, 'learning_rate': 4.591666666666667e-05, 'epoch': 0.25}
2025-05-24 00:43:37.304 | {'loss': 1.705, 'grad_norm': 14.951409339904785, 'learning_rate': 4.5083333333333336e-05, 'epoch': 0.3}
2025-05-24 00:43:52.821 | {'loss': 1.5441, 'grad_norm': 12.392340660095215, 'learning_rate': 4.4250000000000005e-05, 'epoch': 0.35}
2025-05-24 00:44:07.230 | {'loss': 1.5553, 'grad_norm': 18.112045288085938, 'learning_rate': 4.341666666666667e-05, 'epoch': 0.4}
2025-05-24 00:44:22.840 | {'loss': 1.8086, 'grad_norm': 16.60947608947754, 'learning_rate': 4.2583333333333336e-05, 'epoch': 0.45}
2025-05-24 00:44:44.015 | {'loss': 1.7833, 'grad_norm': 17.122936248779297, 'learning_rate': 4.175e-05, 'epoch': 0.5}
2025-05-24 00:44:59.639 | {'loss': 1.7304, 'grad_norm': 15.666259765625, 'learning_rate': 4.091666666666667e-05, 'epoch': 0.55}
2025-05-24 00:45:14.190 | {'loss': 1.7567, 'grad_norm': 11.962992668151855, 'learning_rate': 4.0083333333333336e-05, 'epoch': 0.6}
2025-05-24 00:45:29.634 | {'loss': 1.28, 'grad_norm': 12.220708847045898, 'learning_rate': 3.9250000000000005e-05, 'epoch': 0.65}
2025-05-24 00:45:44.103 | {'loss': 1.8687, 'grad_norm': 8.01710033416748, 'learning_rate': 3.841666666666667e-05, 'epoch': 0.7}
2025-05-24 00:45:59.503 | {'loss': 1.7203, 'grad_norm': 8.531554222106934, 'learning_rate': 3.7583333333333337e-05, 'epoch': 0.75}
2025-05-24 00:46:13.887 | {'loss': 1.801, 'grad_norm': 6.98089599609375, 'learning_rate': 3.675e-05, 'epoch': 0.8}
2025-05-24 00:46:29.520 | {'loss': 1.7366, 'grad_norm': 13.74269962310791, 'learning_rate': 3.591666666666667e-05, 'epoch': 0.85}
2025-05-24 00:46:44.265 | {'loss': 1.7093, 'grad_norm': 13.9932222366333, 'learning_rate': 3.508333333333334e-05, 'epoch': 0.9}
2025-05-24 00:47:00.156 | {'loss': 1.5955, 'grad_norm': 12.912704467773438, 'learning_rate': 3.4250000000000006e-05, 'epoch': 0.95}
2025-05-24 00:47:15.411 | {'loss': 1.2537, 'grad_norm': 10.390189170837402, 'learning_rate': 3.341666666666667e-05, 'epoch': 1.0}
2025-05-24 00:47:31.581 | {'loss': 1.0719, 'grad_norm': 11.299036026000977, 'learning_rate': 3.258333333333333e-05, 'epoch': 1.05}
2025-05-24 00:47:46.444 | {'loss': 1.0928, 'grad_norm': 15.657379150390625, 'learning_rate': 3.175e-05, 'epoch': 1.1}
2025-05-24 00:48:08.563 | {'loss': 1.0775, 'grad_norm': 11.375825881958008, 'learning_rate': 3.091666666666667e-05, 'epoch': 1.15}
2025-05-24 00:48:23.144 | {'loss': 1.1883, 'grad_norm': 14.354995727539062, 'learning_rate': 3.0083333333333337e-05, 'epoch': 1.2}
2025-05-24 00:48:38.604 | {'loss': 1.0523, 'grad_norm': 12.008096694946289, 'learning_rate': 2.925e-05, 'epoch': 1.25}
2025-05-24 00:48:53.208 | {'loss': 1.3136, 'grad_norm': 11.288378715515137, 'learning_rate': 2.841666666666667e-05, 'epoch': 1.3}
2025-05-24 00:49:08.870 | {'loss': 1.1653, 'grad_norm': 6.1513471603393555, 'learning_rate': 2.7583333333333334e-05, 'epoch': 1.35}
2025-05-24 00:49:24.036 | {'loss': 1.0693, 'grad_norm': 9.997465133666992, 'learning_rate': 2.6750000000000003e-05, 'epoch': 1.4}
2025-05-24 00:49:40.017 | {'loss': 0.9212, 'grad_norm': 8.75724983215332, 'learning_rate': 2.5916666666666665e-05, 'epoch': 1.45}
2025-05-24 00:49:55.063 | {'loss': 0.9634, 'grad_norm': 9.405942916870117, 'learning_rate': 2.5083333333333338e-05, 'epoch': 1.5}
2025-05-24 00:50:10.193 | {'loss': 1.0266, 'grad_norm': 6.78693151473999, 'learning_rate': 2.425e-05, 'epoch': 1.55}
2025-05-24 00:50:24.828 | {'loss': 1.1164, 'grad_norm': 11.044742584228516, 'learning_rate': 2.341666666666667e-05, 'epoch': 1.6}
2025-05-24 00:50:40.336 | {'loss': 0.8445, 'grad_norm': 11.380123138427734, 'learning_rate': 2.2583333333333335e-05, 'epoch': 1.65}
2025-05-24 00:50:54.918 | {'loss': 1.0522, 'grad_norm': 12.745366096496582, 'learning_rate': 2.175e-05, 'epoch': 1.7}
2025-05-24 00:51:10.365 | {'loss': 1.204, 'grad_norm': 15.221759796142578, 'learning_rate': 2.091666666666667e-05, 'epoch': 1.75}
2025-05-24 00:51:24.901 | {'loss': 1.0464, 'grad_norm': 9.966604232788086, 'learning_rate': 2.0083333333333335e-05, 'epoch': 1.8}
2025-05-24 00:51:40.531 | {'loss': 1.0538, 'grad_norm': 12.981287002563477, 'learning_rate': 1.925e-05, 'epoch': 1.85}
2025-05-24 00:52:01.359 | {'loss': 0.9481, 'grad_norm': 12.270132064819336, 'learning_rate': 1.841666666666667e-05, 'epoch': 1.9}
2025-05-24 00:52:16.884 | {'loss': 1.1781, 'grad_norm': 11.848926544189453, 'learning_rate': 1.7583333333333335e-05, 'epoch': 1.95}
2025-05-24 00:52:31.472 | {'loss': 1.1144, 'grad_norm': 11.004711151123047, 'learning_rate': 1.675e-05, 'epoch': 2.0}
2025-05-24 00:52:47.013 | {'loss': 0.7199, 'grad_norm': 8.429874420166016, 'learning_rate': 1.591666666666667e-05, 'epoch': 2.05}
2025-05-24 00:53:01.429 | {'loss': 0.8006, 'grad_norm': 9.032781600952148, 'learning_rate': 1.5083333333333335e-05, 'epoch': 2.1}
2025-05-24 00:53:17.069 | {'loss': 0.6662, 'grad_norm': 9.290075302124023, 'learning_rate': 1.4249999999999999e-05, 'epoch': 2.15}
2025-05-24 00:53:31.563 | {'loss': 0.679, 'grad_norm': 12.687743186950684, 'learning_rate': 1.3416666666666666e-05, 'epoch': 2.2}
2025-05-24 00:53:47.043 | {'loss': 0.7037, 'grad_norm': 9.440321922302246, 'learning_rate': 1.2583333333333334e-05, 'epoch': 2.25}
2025-05-24 00:54:01.386 | {'loss': 0.68, 'grad_norm': 11.260486602783203, 'learning_rate': 1.175e-05, 'epoch': 2.3}
2025-05-24 00:54:16.750 | {'loss': 0.5927, 'grad_norm': 5.893879413604736, 'learning_rate': 1.0916666666666667e-05, 'epoch': 2.35}
2025-05-24 00:54:31.141 | {'loss': 0.641, 'grad_norm': 7.149306297302246, 'learning_rate': 1.0083333333333334e-05, 'epoch': 2.4}
2025-05-24 00:54:52.840 | {'loss': 0.7006, 'grad_norm': 11.174539566040039, 'learning_rate': 9.25e-06, 'epoch': 2.45}
2025-05-24 00:55:07.419 | {'loss': 0.6792, 'grad_norm': 7.228370666503906, 'learning_rate': 8.416666666666667e-06, 'epoch': 2.5}
2025-05-24 00:55:23.102 | {'loss': 0.8032, 'grad_norm': 9.958521842956543, 'learning_rate': 7.583333333333334e-06, 'epoch': 2.55}
2025-05-24 00:55:37.485 | {'loss': 0.6332, 'grad_norm': 5.871249198913574, 'learning_rate': 6.750000000000001e-06, 'epoch': 2.6}
2025-05-24 00:55:52.845 | {'loss': 0.6216, 'grad_norm': 5.724648952484131, 'learning_rate': 5.916666666666667e-06, 'epoch': 2.65}
2025-05-24 00:56:07.393 | {'loss': 0.6817, 'grad_norm': 5.356570720672607, 'learning_rate': 5.0833333333333335e-06, 'epoch': 2.7}
2025-05-24 00:56:22.991 | {'loss': 0.7467, 'grad_norm': 11.638683319091797, 'learning_rate': 4.250000000000001e-06, 'epoch': 2.75}
2025-05-24 00:56:37.199 | {'loss': 0.6355, 'grad_norm': 4.887485980987549, 'learning_rate': 3.4166666666666664e-06, 'epoch': 2.8}
2025-05-24 00:56:52.904 | {'loss': 0.726, 'grad_norm': 8.665924072265625, 'learning_rate': 2.5833333333333333e-06, 'epoch': 2.85}
2025-05-24 00:57:07.217 | {'loss': 0.709, 'grad_norm': 8.265010833740234, 'learning_rate': 1.7500000000000002e-06, 'epoch': 2.9}
2025-05-24 00:57:22.740 | {'loss': 0.6076, 'grad_norm': 9.163636207580566, 'learning_rate': 9.166666666666667e-07, 'epoch': 2.95}
2025-05-24 00:57:37.264 | {'loss': 0.4367, 'grad_norm': 3.6073951721191406, 'learning_rate': 8.333333333333334e-08, 'epoch': 3.0}
2025-05-24 00:57:37.265 | {'train_runtime': 942.3706, 'train_samples_per_second': 1.273, 'train_steps_per_second': 0.637, 'train_loss': 1.139673843383789, 'epoch': 3.0}
2025-05-24 00:58:05.957 | INFO :      Sent reply
2025-05-24 00:58:53.557 | INFO :      
2025-05-24 00:58:53.557 | INFO :      Received: evaluate message 2264f678-21d2-46da-9484-41cd75f353f7
2025-05-24 00:58:56.660 | {'eval_loss': 2.7255771160125732, 'eval_runtime': 1.2011, 'eval_samples_per_second': 83.259, 'eval_steps_per_second': 10.824, 'epoch': 3.0}
2025-05-24 00:58:56.673 | INFO :      Sent reply
2025-05-24 00:59:20.092 | INFO :      
2025-05-24 00:59:20.092 | INFO :      Received: train message f6d8c65c-4ad4-4238-ba67-a67ac0b3f4b6
2025-05-24 00:59:42.880 | {'loss': 1.011, 'grad_norm': 6.032527446746826, 'learning_rate': 4.9250000000000004e-05, 'epoch': 0.05}
2025-05-24 00:59:58.416 | {'loss': 1.2637, 'grad_norm': 13.999959945678711, 'learning_rate': 4.8416666666666673e-05, 'epoch': 0.1}
2025-05-24 01:00:12.920 | {'loss': 1.3325, 'grad_norm': 14.378400802612305, 'learning_rate': 4.7583333333333336e-05, 'epoch': 0.15}
2025-05-24 01:00:28.508 | {'loss': 1.2836, 'grad_norm': 11.1576509475708, 'learning_rate': 4.6750000000000005e-05, 'epoch': 0.2}
2025-05-24 01:00:43.302 | {'loss': 1.4738, 'grad_norm': 7.818267345428467, 'learning_rate': 4.591666666666667e-05, 'epoch': 0.25}
2025-05-24 01:00:59.003 | {'loss': 1.2738, 'grad_norm': 15.721198081970215, 'learning_rate': 4.5083333333333336e-05, 'epoch': 0.3}
2025-05-24 01:01:13.562 | {'loss': 1.2062, 'grad_norm': 11.806102752685547, 'learning_rate': 4.4250000000000005e-05, 'epoch': 0.35}
2025-05-24 01:01:28.926 | {'loss': 1.2027, 'grad_norm': 17.573646545410156, 'learning_rate': 4.341666666666667e-05, 'epoch': 0.4}
2025-05-24 01:01:43.422 | {'loss': 1.42, 'grad_norm': 14.893651962280273, 'learning_rate': 4.2583333333333336e-05, 'epoch': 0.45}
2025-05-24 01:02:05.133 | {'loss': 1.412, 'grad_norm': 15.566207885742188, 'learning_rate': 4.175e-05, 'epoch': 0.5}
2025-05-24 01:02:19.531 | {'loss': 1.3812, 'grad_norm': 11.836142539978027, 'learning_rate': 4.091666666666667e-05, 'epoch': 0.55}
2025-05-24 01:02:34.956 | {'loss': 1.3972, 'grad_norm': 11.35469913482666, 'learning_rate': 4.0083333333333336e-05, 'epoch': 0.6}
2025-05-24 01:02:49.313 | {'loss': 1.0118, 'grad_norm': 9.941307067871094, 'learning_rate': 3.9250000000000005e-05, 'epoch': 0.65}
2025-05-24 01:03:04.931 | {'loss': 1.4835, 'grad_norm': 6.145802974700928, 'learning_rate': 3.841666666666667e-05, 'epoch': 0.7}
2025-05-24 01:03:19.160 | {'loss': 1.3802, 'grad_norm': 8.45602035522461, 'learning_rate': 3.7583333333333337e-05, 'epoch': 0.75}
2025-05-24 01:03:34.412 | {'loss': 1.466, 'grad_norm': 8.017705917358398, 'learning_rate': 3.675e-05, 'epoch': 0.8}
2025-05-24 01:03:48.759 | {'loss': 1.3977, 'grad_norm': 16.572477340698242, 'learning_rate': 3.591666666666667e-05, 'epoch': 0.85}
2025-05-24 01:04:04.054 | {'loss': 1.3701, 'grad_norm': 13.749613761901855, 'learning_rate': 3.508333333333334e-05, 'epoch': 0.9}
2025-05-24 01:04:18.417 | {'loss': 1.2971, 'grad_norm': 12.672442436218262, 'learning_rate': 3.4250000000000006e-05, 'epoch': 0.95}
2025-05-24 01:04:33.932 | {'loss': 0.9773, 'grad_norm': 10.421664237976074, 'learning_rate': 3.341666666666667e-05, 'epoch': 1.0}
2025-05-24 01:04:48.623 | {'loss': 0.7907, 'grad_norm': 8.704334259033203, 'learning_rate': 3.258333333333333e-05, 'epoch': 1.05}
2025-05-24 01:05:04.376 | {'loss': 0.8403, 'grad_norm': 13.663067817687988, 'learning_rate': 3.175e-05, 'epoch': 1.1}
2025-05-24 01:05:19.013 | {'loss': 0.8073, 'grad_norm': 8.016724586486816, 'learning_rate': 3.091666666666667e-05, 'epoch': 1.15}
2025-05-24 01:05:40.841 | {'loss': 0.915, 'grad_norm': 14.952335357666016, 'learning_rate': 3.0083333333333337e-05, 'epoch': 1.2}
2025-05-24 01:05:55.736 | {'loss': 0.7877, 'grad_norm': 12.683213233947754, 'learning_rate': 2.925e-05, 'epoch': 1.25}
2025-05-24 01:06:11.615 | {'loss': 1.0429, 'grad_norm': 12.448233604431152, 'learning_rate': 2.841666666666667e-05, 'epoch': 1.3}
2025-05-24 01:06:26.669 | {'loss': 0.9037, 'grad_norm': 8.30855655670166, 'learning_rate': 2.7583333333333334e-05, 'epoch': 1.35}
2025-05-24 01:06:42.171 | {'loss': 0.7914, 'grad_norm': 8.580316543579102, 'learning_rate': 2.6750000000000003e-05, 'epoch': 1.4}
2025-05-24 01:06:56.751 | {'loss': 0.6977, 'grad_norm': 8.601215362548828, 'learning_rate': 2.5916666666666665e-05, 'epoch': 1.45}
2025-05-24 01:07:12.612 | {'loss': 0.7298, 'grad_norm': 8.286772727966309, 'learning_rate': 2.5083333333333338e-05, 'epoch': 1.5}
2025-05-24 01:07:26.806 | {'loss': 0.8074, 'grad_norm': 8.06680679321289, 'learning_rate': 2.425e-05, 'epoch': 1.55}
2025-05-24 01:07:42.111 | {'loss': 0.8749, 'grad_norm': 11.096900939941406, 'learning_rate': 2.341666666666667e-05, 'epoch': 1.6}
2025-05-24 01:07:57.091 | {'loss': 0.6634, 'grad_norm': 10.611477851867676, 'learning_rate': 2.2583333333333335e-05, 'epoch': 1.65}
2025-05-24 01:08:18.839 | {'loss': 0.8055, 'grad_norm': 13.801249504089355, 'learning_rate': 2.175e-05, 'epoch': 1.7}
2025-05-24 01:08:33.389 | {'loss': 0.9029, 'grad_norm': 15.412543296813965, 'learning_rate': 2.091666666666667e-05, 'epoch': 1.75}
2025-05-24 01:08:48.725 | {'loss': 0.7999, 'grad_norm': 10.142151832580566, 'learning_rate': 2.0083333333333335e-05, 'epoch': 1.8}
2025-05-24 01:09:03.135 | {'loss': 0.7873, 'grad_norm': 11.22346019744873, 'learning_rate': 1.925e-05, 'epoch': 1.85}
2025-05-24 01:09:18.482 | {'loss': 0.7387, 'grad_norm': 13.325093269348145, 'learning_rate': 1.841666666666667e-05, 'epoch': 1.9}
2025-05-24 01:09:32.906 | {'loss': 0.9312, 'grad_norm': 11.747289657592773, 'learning_rate': 1.7583333333333335e-05, 'epoch': 1.95}
2025-05-24 01:09:48.324 | {'loss': 0.8355, 'grad_norm': 10.088794708251953, 'learning_rate': 1.675e-05, 'epoch': 2.0}
2025-05-24 01:10:02.712 | {'loss': 0.507, 'grad_norm': 7.4111127853393555, 'learning_rate': 1.591666666666667e-05, 'epoch': 2.05}
2025-05-24 01:10:18.255 | {'loss': 0.5382, 'grad_norm': 8.651158332824707, 'learning_rate': 1.5083333333333335e-05, 'epoch': 2.1}
2025-05-24 01:10:33.246 | {'loss': 0.5103, 'grad_norm': 8.704645156860352, 'learning_rate': 1.4249999999999999e-05, 'epoch': 2.15}
2025-05-24 01:10:55.320 | {'loss': 0.4857, 'grad_norm': 11.521583557128906, 'learning_rate': 1.3416666666666666e-05, 'epoch': 2.2}
2025-05-24 01:11:09.711 | {'loss': 0.51, 'grad_norm': 14.101593971252441, 'learning_rate': 1.2583333333333334e-05, 'epoch': 2.25}
2025-05-24 01:11:25.272 | {'loss': 0.4803, 'grad_norm': 9.348323822021484, 'learning_rate': 1.175e-05, 'epoch': 2.3}
2025-05-24 01:11:39.655 | {'loss': 0.4346, 'grad_norm': 4.617821216583252, 'learning_rate': 1.0916666666666667e-05, 'epoch': 2.35}
2025-05-24 01:11:55.018 | {'loss': 0.4389, 'grad_norm': 7.098589897155762, 'learning_rate': 1.0083333333333334e-05, 'epoch': 2.4}
2025-05-24 01:12:09.580 | {'loss': 0.5105, 'grad_norm': 11.267644882202148, 'learning_rate': 9.25e-06, 'epoch': 2.45}
2025-05-24 01:12:25.017 | {'loss': 0.52, 'grad_norm': 7.2302045822143555, 'learning_rate': 8.416666666666667e-06, 'epoch': 2.5}
2025-05-24 01:12:39.699 | {'loss': 0.5931, 'grad_norm': 9.10201358795166, 'learning_rate': 7.583333333333334e-06, 'epoch': 2.55}
2025-05-24 01:12:55.256 | {'loss': 0.4598, 'grad_norm': 4.811787128448486, 'learning_rate': 6.750000000000001e-06, 'epoch': 2.6}
2025-05-24 01:13:17.599 | {'loss': 0.477, 'grad_norm': 5.373963832855225, 'learning_rate': 5.916666666666667e-06, 'epoch': 2.65}
2025-05-24 01:13:31.921 | {'loss': 0.5249, 'grad_norm': 4.868968486785889, 'learning_rate': 5.0833333333333335e-06, 'epoch': 2.7}
2025-05-24 01:13:47.307 | {'loss': 0.5313, 'grad_norm': 10.545707702636719, 'learning_rate': 4.250000000000001e-06, 'epoch': 2.75}
2025-05-24 01:14:01.763 | {'loss': 0.4861, 'grad_norm': 4.483273029327393, 'learning_rate': 3.4166666666666664e-06, 'epoch': 2.8}
2025-05-24 01:14:17.171 | {'loss': 0.5158, 'grad_norm': 7.88477087020874, 'learning_rate': 2.5833333333333333e-06, 'epoch': 2.85}
2025-05-24 01:14:31.649 | {'loss': 0.5064, 'grad_norm': 6.533155918121338, 'learning_rate': 1.7500000000000002e-06, 'epoch': 2.9}
2025-05-24 01:14:46.315 | {'loss': 0.4409, 'grad_norm': 7.932869911193848, 'learning_rate': 9.166666666666667e-07, 'epoch': 2.95}
2025-05-24 01:15:01.416 | {'loss': 0.3036, 'grad_norm': 3.8018529415130615, 'learning_rate': 8.333333333333334e-08, 'epoch': 3.0}
2025-05-24 01:15:01.416 | {'train_runtime': 938.1433, 'train_samples_per_second': 1.279, 'train_steps_per_second': 0.64, 'train_loss': 0.8711519547303518, 'epoch': 3.0}
2025-05-24 01:15:18.786 | INFO :      Sent reply
2025-05-24 01:16:16.510 | INFO :      
2025-05-24 01:16:16.510 | INFO :      Received: evaluate message 4be86ea6-0e14-4115-9dba-ccb790fccb61
2025-05-24 01:16:21.686 | {'eval_loss': 2.798680305480957, 'eval_runtime': 2.6021, 'eval_samples_per_second': 38.431, 'eval_steps_per_second': 4.996, 'epoch': 3.0}
2025-05-24 01:16:21.689 | INFO :      Sent reply
2025-05-24 01:16:31.548 | INFO :      
2025-05-24 01:16:31.548 | INFO :      Received: train message 1e9dd66c-c73e-4891-9a77-a375655bfea1
2025-05-24 01:16:45.189 | {'loss': 0.7195, 'grad_norm': 8.269913673400879, 'learning_rate': 4.9250000000000004e-05, 'epoch': 0.05}
2025-05-24 01:17:00.362 | {'loss': 0.9432, 'grad_norm': 13.584368705749512, 'learning_rate': 4.8416666666666673e-05, 'epoch': 0.1}
2025-05-24 01:17:15.160 | {'loss': 0.985, 'grad_norm': 14.612432479858398, 'learning_rate': 4.7583333333333336e-05, 'epoch': 0.15}
2025-05-24 01:17:30.445 | {'loss': 0.9884, 'grad_norm': 10.323957443237305, 'learning_rate': 4.6750000000000005e-05, 'epoch': 0.2}
2025-05-24 01:17:45.980 | {'loss': 1.1144, 'grad_norm': 6.490532875061035, 'learning_rate': 4.591666666666667e-05, 'epoch': 0.25}
2025-05-24 01:18:00.852 | {'loss': 0.9657, 'grad_norm': 14.171090126037598, 'learning_rate': 4.5083333333333336e-05, 'epoch': 0.3}
2025-05-24 01:18:21.588 | {'loss': 0.9313, 'grad_norm': 9.548919677734375, 'learning_rate': 4.4250000000000005e-05, 'epoch': 0.35}
2025-05-24 01:18:36.935 | {'loss': 0.9227, 'grad_norm': 15.11367130279541, 'learning_rate': 4.341666666666667e-05, 'epoch': 0.4}
2025-05-24 01:18:51.366 | {'loss': 1.0955, 'grad_norm': 15.39128303527832, 'learning_rate': 4.2583333333333336e-05, 'epoch': 0.45}
2025-05-24 01:19:06.761 | {'loss': 1.1282, 'grad_norm': 15.605600357055664, 'learning_rate': 4.175e-05, 'epoch': 0.5}
2025-05-24 01:19:21.448 | {'loss': 1.0783, 'grad_norm': 9.771974563598633, 'learning_rate': 4.091666666666667e-05, 'epoch': 0.55}
2025-05-24 01:19:37.279 | {'loss': 1.1168, 'grad_norm': 10.288026809692383, 'learning_rate': 4.0083333333333336e-05, 'epoch': 0.6}
2025-05-24 01:19:52.144 | {'loss': 0.7924, 'grad_norm': 8.805047988891602, 'learning_rate': 3.9250000000000005e-05, 'epoch': 0.65}
2025-05-24 01:20:07.567 | {'loss': 1.2136, 'grad_norm': 6.016876220703125, 'learning_rate': 3.841666666666667e-05, 'epoch': 0.7}
2025-05-24 01:20:22.096 | {'loss': 1.104, 'grad_norm': 8.049782752990723, 'learning_rate': 3.7583333333333337e-05, 'epoch': 0.75}
2025-05-24 01:20:44.027 | {'loss': 1.1713, 'grad_norm': 7.467852592468262, 'learning_rate': 3.675e-05, 'epoch': 0.8}
2025-05-24 01:20:59.207 | {'loss': 1.1363, 'grad_norm': 14.558667182922363, 'learning_rate': 3.591666666666667e-05, 'epoch': 0.85}
2025-05-24 01:21:13.638 | {'loss': 1.1041, 'grad_norm': 14.17421817779541, 'learning_rate': 3.508333333333334e-05, 'epoch': 0.9}
2025-05-24 01:21:28.963 | {'loss': 1.0284, 'grad_norm': 12.798407554626465, 'learning_rate': 3.4250000000000006e-05, 'epoch': 0.95}
2025-05-24 01:21:44.421 | {'loss': 0.7863, 'grad_norm': 10.046506881713867, 'learning_rate': 3.341666666666667e-05, 'epoch': 1.0}
2025-05-24 01:21:59.065 | {'loss': 0.6504, 'grad_norm': 11.184477806091309, 'learning_rate': 3.258333333333333e-05, 'epoch': 1.05}
2025-05-24 01:22:14.649 | {'loss': 0.6386, 'grad_norm': 13.521461486816406, 'learning_rate': 3.175e-05, 'epoch': 1.1}
2025-05-24 01:22:29.403 | {'loss': 0.6275, 'grad_norm': 9.705855369567871, 'learning_rate': 3.091666666666667e-05, 'epoch': 1.15}
2025-05-24 01:22:45.009 | {'loss': 0.7147, 'grad_norm': 12.203442573547363, 'learning_rate': 3.0083333333333337e-05, 'epoch': 1.2}
2025-05-24 01:22:59.669 | {'loss': 0.6195, 'grad_norm': 12.188924789428711, 'learning_rate': 2.925e-05, 'epoch': 1.25}
2025-05-24 01:23:20.974 | {'loss': 0.8019, 'grad_norm': 10.83719253540039, 'learning_rate': 2.841666666666667e-05, 'epoch': 1.3}
2025-05-24 01:23:37.550 | {'loss': 0.7607, 'grad_norm': 8.091390609741211, 'learning_rate': 2.7583333333333334e-05, 'epoch': 1.35}
2025-05-24 01:23:52.428 | {'loss': 0.6286, 'grad_norm': 8.154403686523438, 'learning_rate': 2.6750000000000003e-05, 'epoch': 1.4}
2025-05-24 01:24:08.008 | {'loss': 0.5614, 'grad_norm': 8.748137474060059, 'learning_rate': 2.5916666666666665e-05, 'epoch': 1.45}
2025-05-24 01:24:22.570 | {'loss': 0.605, 'grad_norm': 7.876866340637207, 'learning_rate': 2.5083333333333338e-05, 'epoch': 1.5}
2025-05-24 01:24:38.210 | {'loss': 0.6058, 'grad_norm': 6.989892959594727, 'learning_rate': 2.425e-05, 'epoch': 1.55}
2025-05-24 01:24:53.062 | {'loss': 0.7113, 'grad_norm': 11.157780647277832, 'learning_rate': 2.341666666666667e-05, 'epoch': 1.6}
2025-05-24 01:25:08.430 | {'loss': 0.5198, 'grad_norm': 8.95173168182373, 'learning_rate': 2.2583333333333335e-05, 'epoch': 1.65}
2025-05-24 01:25:23.063 | {'loss': 0.6039, 'grad_norm': 12.609796524047852, 'learning_rate': 2.175e-05, 'epoch': 1.7}
2025-05-24 01:25:38.924 | {'loss': 0.7135, 'grad_norm': 15.911442756652832, 'learning_rate': 2.091666666666667e-05, 'epoch': 1.75}
2025-05-24 01:25:54.387 | {'loss': 0.6724, 'grad_norm': 8.883304595947266, 'learning_rate': 2.0083333333333335e-05, 'epoch': 1.8}
2025-05-24 01:26:10.510 | {'loss': 0.615, 'grad_norm': 11.996853828430176, 'learning_rate': 1.925e-05, 'epoch': 1.85}
2025-05-24 01:26:25.225 | {'loss': 0.5509, 'grad_norm': 11.325789451599121, 'learning_rate': 1.841666666666667e-05, 'epoch': 1.9}
2025-05-24 01:26:40.766 | {'loss': 0.7354, 'grad_norm': 11.685507774353027, 'learning_rate': 1.7583333333333335e-05, 'epoch': 1.95}
2025-05-24 01:26:55.565 | {'loss': 0.639, 'grad_norm': 9.946417808532715, 'learning_rate': 1.675e-05, 'epoch': 2.0}
2025-05-24 01:27:11.143 | {'loss': 0.376, 'grad_norm': 6.501284122467041, 'learning_rate': 1.591666666666667e-05, 'epoch': 2.05}
2025-05-24 01:27:25.959 | {'loss': 0.4449, 'grad_norm': 7.294993877410889, 'learning_rate': 1.5083333333333335e-05, 'epoch': 2.1}
2025-05-24 01:27:42.210 | {'loss': 0.3649, 'grad_norm': 7.425583362579346, 'learning_rate': 1.4249999999999999e-05, 'epoch': 2.15}
2025-05-24 01:28:04.002 | {'loss': 0.3777, 'grad_norm': 11.6083984375, 'learning_rate': 1.3416666666666666e-05, 'epoch': 2.2}
2025-05-24 01:28:19.721 | {'loss': 0.4234, 'grad_norm': 8.698845863342285, 'learning_rate': 1.2583333333333334e-05, 'epoch': 2.25}
2025-05-24 01:28:33.993 | {'loss': 0.3627, 'grad_norm': 11.903590202331543, 'learning_rate': 1.175e-05, 'epoch': 2.3}
2025-05-24 01:28:49.659 | {'loss': 0.3253, 'grad_norm': 3.974029779434204, 'learning_rate': 1.0916666666666667e-05, 'epoch': 2.35}
2025-05-24 01:29:03.919 | {'loss': 0.3375, 'grad_norm': 6.621653079986572, 'learning_rate': 1.0083333333333334e-05, 'epoch': 2.4}
2025-05-24 01:29:25.950 | {'loss': 0.421, 'grad_norm': 8.777215957641602, 'learning_rate': 9.25e-06, 'epoch': 2.45}
2025-05-24 01:29:40.577 | {'loss': 0.3917, 'grad_norm': 5.05227518081665, 'learning_rate': 8.416666666666667e-06, 'epoch': 2.5}
2025-05-24 01:29:56.738 | {'loss': 0.4446, 'grad_norm': 8.478815078735352, 'learning_rate': 7.583333333333334e-06, 'epoch': 2.55}
2025-05-24 01:30:11.659 | {'loss': 0.3468, 'grad_norm': 4.766419410705566, 'learning_rate': 6.750000000000001e-06, 'epoch': 2.6}
2025-05-24 01:30:27.161 | {'loss': 0.3575, 'grad_norm': 5.157185077667236, 'learning_rate': 5.916666666666667e-06, 'epoch': 2.65}
2025-05-24 01:30:41.753 | {'loss': 0.4115, 'grad_norm': 4.096095085144043, 'learning_rate': 5.0833333333333335e-06, 'epoch': 2.7}
2025-05-24 01:30:56.950 | {'loss': 0.4057, 'grad_norm': 8.779619216918945, 'learning_rate': 4.250000000000001e-06, 'epoch': 2.75}
2025-05-24 01:31:11.266 | {'loss': 0.3462, 'grad_norm': 4.514336585998535, 'learning_rate': 3.4166666666666664e-06, 'epoch': 2.8}
2025-05-24 01:31:26.764 | {'loss': 0.4018, 'grad_norm': 7.454329967498779, 'learning_rate': 2.5833333333333333e-06, 'epoch': 2.85}
2025-05-24 01:31:48.643 | {'loss': 0.3729, 'grad_norm': 6.572659015655518, 'learning_rate': 1.7500000000000002e-06, 'epoch': 2.9}
2025-05-24 01:32:04.154 | {'loss': 0.3463, 'grad_norm': 8.118168830871582, 'learning_rate': 9.166666666666667e-07, 'epoch': 2.95}
2025-05-24 01:32:19.900 | {'loss': 0.2401, 'grad_norm': 2.6709654331207275, 'learning_rate': 8.333333333333334e-08, 'epoch': 3.0}
2025-05-24 01:32:19.900 | {'train_runtime': 947.2963, 'train_samples_per_second': 1.267, 'train_steps_per_second': 0.633, 'train_loss': 0.679985664288203, 'epoch': 3.0}
2025-05-24 01:32:28.350 | INFO :      Sent reply
2025-05-24 01:33:05.758 | INFO :      
2025-05-24 01:33:05.758 | INFO :      Received: evaluate message 0b1d1256-a057-4f57-ab2c-a25b75d97bc3
2025-05-24 01:33:17.169 | {'eval_loss': 2.8833508491516113, 'eval_runtime': 8.8019, 'eval_samples_per_second': 11.361, 'eval_steps_per_second': 1.477, 'epoch': 3.0}
2025-05-24 01:33:17.173 | INFO :      Sent reply
2025-05-24 01:33:18.647 | INFO :      
2025-05-24 01:33:18.647 | INFO :      Received: reconnect message 0890a312-e98a-4ad8-a2f4-a8bb4636e335
2025-05-24 01:33:18.823 | INFO :      Disconnect and shut down
2025-05-24 01:34:41.042 | Generating train split:   0%|          | 0/61373 [00:00<?, ? examples/s]
2025-05-24 01:34:41.042 | Generating train split:   3%|▎         | 1949/61373 [00:00<00:04, 12602.93 examples/s]
2025-05-24 01:34:41.042 | Generating train split:   6%|▋         | 3962/61373 [00:00<00:03, 15023.04 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  10%|▉         | 6069/61373 [00:00<00:03, 16466.95 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  13%|█▎        | 8249/61373 [00:00<00:02, 18125.53 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  17%|█▋        | 10337/61373 [00:00<00:02, 18926.12 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  20%|██        | 12286/61373 [00:00<00:02, 18554.35 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  25%|██▍       | 15138/61373 [00:00<00:02, 17702.67 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  28%|██▊       | 17129/61373 [00:00<00:02, 17879.52 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  31%|███       | 19086/61373 [00:01<00:02, 17878.14 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  35%|███▍      | 21243/61373 [00:01<00:02, 18617.86 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  38%|███▊      | 23358/61373 [00:01<00:02, 18896.32 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  41%|████      | 25295/61373 [00:01<00:01, 18740.34 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  44%|████▍     | 27259/61373 [00:01<00:01, 18387.71 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  48%|████▊     | 29326/61373 [00:01<00:01, 18407.23 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  51%|█████▏    | 31479/61373 [00:01<00:01, 18682.94 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  54%|█████▍    | 33426/61373 [00:01<00:01, 17874.07 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  58%|█████▊    | 35444/61373 [00:01<00:01, 17944.26 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  61%|██████    | 37442/61373 [00:02<00:01, 17920.68 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  64%|██████▍   | 39433/61373 [00:02<00:01, 17745.70 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  68%|██████▊   | 41577/61373 [00:02<00:01, 18250.12 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  71%|███████   | 43692/61373 [00:02<00:00, 18544.12 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  75%|███████▍  | 45755/61373 [00:02<00:00, 18262.98 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  78%|███████▊  | 47705/61373 [00:02<00:00, 18052.82 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  81%|████████  | 49773/61373 [00:02<00:00, 18077.32 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  84%|████████▍ | 51792/61373 [00:02<00:00, 17825.37 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  88%|████████▊ | 53862/61373 [00:03<00:00, 17701.62 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  91%|█████████ | 55664/61373 [00:03<00:00, 17387.75 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  94%|█████████▍| 57650/61373 [00:03<00:00, 16874.89 examples/s]
2025-05-24 01:34:41.042 | Generating train split:  97%|█████████▋| 59628/61373 [00:03<00:00, 16265.58 examples/s]
2025-05-24 01:34:41.042 | Generating train split: 100%|██████████| 61373/61373 [00:03<00:00, 17714.10 examples/s]
2025-05-24 01:34:41.042 | Map:   0%|          | 0/500 [00:00<?, ? examples/s]
2025-05-24 01:34:41.042 | Map: 100%|██████████| 500/500 [00:18<00:00, 27.31 examples/s]
2025-05-24 01:34:41.042 | Map: 100%|██████████| 500/500 [00:18<00:00, 27.30 examples/s]
2025-05-24 01:34:41.042 | Map:   0%|          | 0/500 [00:00<?, ? examples/s]
2025-05-24 01:34:41.042 | Map:  23%|██▎       | 114/500 [00:00<00:00, 1110.42 examples/s]
2025-05-24 01:34:41.042 | Map:  49%|████▉     | 247/500 [00:00<00:00, 1233.29 examples/s]
2025-05-24 01:34:41.042 | Map:  78%|███████▊  | 390/500 [00:00<00:00, 1317.29 examples/s]
2025-05-24 01:34:41.042 | Map: 100%|██████████| 500/500 [00:00<00:00, 1203.89 examples/s]