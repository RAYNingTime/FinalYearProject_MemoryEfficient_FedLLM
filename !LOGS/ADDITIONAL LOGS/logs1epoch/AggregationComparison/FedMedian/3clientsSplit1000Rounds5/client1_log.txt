2025-05-21 17:16:19 
Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]
Generating train split:  95%|█████████▌| 114000/120000 [00:00<00:00, 1129458.61 examples/s]
Generating train split: 100%|██████████| 120000/120000 [00:00<00:00, 1148290.69 examples/s]
2025-05-21 17:16:19 
Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]
Generating test split: 100%|██████████| 7600/7600 [00:00<00:00, 944467.14 examples/s]
2025-05-21 17:16:21 
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 1226.50 examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 1221.26 examples/s]
2025-05-21 17:16:21 
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]
Map:  32%|███▏      | 318/1000 [00:00<00:00, 3150.64 examples/s]
Map:  75%|███████▍  | 746/1000 [00:00<00:00, 2940.70 examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 2768.38 examples/s]
2025-05-21 17:16:22 /app/client.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-05-21 17:16:22   trainer = Trainer(
2025-05-21 17:16:22 WARNING :   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
2025-05-21 17:16:22 Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
2025-05-21 17:16:22 flwr.client.start_client(
2025-05-21 17:16:22 server_address='<IP>:<PORT>',
2025-05-21 17:16:22 client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
2025-05-21 17:16:22 )
2025-05-21 17:16:22 Using `start_numpy_client()` is deprecated.
2025-05-21 17:16:22 
2025-05-21 17:16:22             This is a deprecated feature. It will be removed
2025-05-21 17:16:22             entirely in future versions of Flower.
2025-05-21 17:16:22         
2025-05-21 17:16:22 WARNING :   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
2025-05-21 17:16:22 Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:
2025-05-21 17:16:22 
2025-05-21 17:16:22 $ flower-supernode --insecure --superlink='<IP>:<PORT>'
2025-05-21 17:16:22 
2025-05-21 17:16:22 To view all available options, run:
2025-05-21 17:16:22 
2025-05-21 17:16:22 $ flower-supernode --help
2025-05-21 17:16:22 
2025-05-21 17:16:22 Using `start_client()` is deprecated.
2025-05-21 17:16:22 
2025-05-21 17:16:22             This is a deprecated feature. It will be removed
2025-05-21 17:16:22             entirely in future versions of Flower.
2025-05-21 17:16:22         
2025-05-21 17:16:48 INFO :      
2025-05-21 17:16:48 INFO :      Received: train message 8d61fbb3-0179-4d67-85cb-c7d98d57c949
2025-05-21 17:27:38 INFO :      Sent reply
2025-05-21 17:28:18 INFO :      
2025-05-21 17:28:18 INFO :      Received: evaluate message cbe0fa1d-5b69-402e-aaa9-4a0c4a2dd544
2025-05-21 17:28:29 INFO :      Sent reply
2025-05-21 17:28:43 INFO :      
2025-05-21 17:28:43 INFO :      Received: train message 9f466d1c-227e-4d69-9716-e53a7e23c2f7
2025-05-21 17:38:48 INFO :      Sent reply
2025-05-21 17:40:05 INFO :      
2025-05-21 17:40:05 INFO :      Received: evaluate message e1e4999d-aafd-4150-acfb-13a4536059de
2025-05-21 17:40:19 INFO :      Sent reply
2025-05-21 17:40:34 INFO :      
2025-05-21 17:40:34 INFO :      Received: train message 1c9e237d-4867-45ab-aecf-0970fbe12e81
2025-05-21 17:51:17 INFO :      Sent reply
2025-05-21 17:52:04 INFO :      
2025-05-21 17:52:04 INFO :      Received: evaluate message edf440be-597a-4f85-98ee-b68a0aefcba5
2025-05-21 17:52:20 INFO :      Sent reply
2025-05-21 17:52:34 INFO :      
2025-05-21 17:52:34 INFO :      Received: train message 52445f00-024f-4149-aaba-75d31f758feb
2025-05-21 17:17:13 {'loss': 4.2671, 'grad_norm': 15.139053344726562, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-21 17:17:28 {'loss': 2.3361, 'grad_norm': 13.945996284484863, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-21 17:17:50 {'loss': 2.5598, 'grad_norm': 15.005311012268066, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-21 17:18:05 {'loss': 2.3087, 'grad_norm': 11.413382530212402, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-21 17:18:20 {'loss': 2.1787, 'grad_norm': 14.819804191589355, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-21 17:18:35 {'loss': 2.1118, 'grad_norm': 11.589983940124512, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-21 17:18:50 {'loss': 2.0426, 'grad_norm': 11.164360046386719, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-21 17:19:04 {'loss': 1.9066, 'grad_norm': 9.724199295043945, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-21 17:19:25 {'loss': 1.8787, 'grad_norm': 10.878616333007812, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-21 17:19:40 {'loss': 2.2328, 'grad_norm': 11.55444622039795, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-21 17:19:55 {'loss': 1.7506, 'grad_norm': 9.321246147155762, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-21 17:20:10 {'loss': 1.9119, 'grad_norm': 10.226726531982422, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-21 17:20:25 {'loss': 1.7709, 'grad_norm': 10.91862678527832, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-21 17:20:40 {'loss': 1.7254, 'grad_norm': 10.339165687561035, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-21 17:20:55 {'loss': 1.7426, 'grad_norm': 10.719693183898926, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-21 17:21:10 {'loss': 1.8833, 'grad_norm': 8.897167205810547, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-21 17:21:30 {'loss': 1.6951, 'grad_norm': 12.327390670776367, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-21 17:21:45 {'loss': 2.0136, 'grad_norm': 13.943894386291504, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-21 17:22:00 {'loss': 1.6411, 'grad_norm': 11.502079010009766, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-21 17:22:15 {'loss': 1.859, 'grad_norm': 11.927268981933594, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-21 17:22:30 {'loss': 1.8747, 'grad_norm': 10.391292572021484, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-21 17:22:44 {'loss': 1.8126, 'grad_norm': 9.716133117675781, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-21 17:23:05 {'loss': 1.9067, 'grad_norm': 13.490721702575684, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-21 17:23:20 {'loss': 1.8576, 'grad_norm': 12.68990707397461, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-21 17:23:35 {'loss': 1.925, 'grad_norm': 11.56401252746582, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-21 17:23:50 {'loss': 1.9916, 'grad_norm': 15.391741752624512, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-21 17:24:05 {'loss': 1.9093, 'grad_norm': 13.830284118652344, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-21 17:24:20 {'loss': 1.8468, 'grad_norm': 7.8115315437316895, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-21 17:24:35 {'loss': 1.6615, 'grad_norm': 9.07811450958252, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-21 17:24:50 {'loss': 1.5077, 'grad_norm': 14.740429878234863, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-21 17:25:05 {'loss': 1.8395, 'grad_norm': 9.445335388183594, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-21 17:25:26 {'loss': 1.7573, 'grad_norm': 14.262674331665039, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-21 17:25:41 {'loss': 1.7646, 'grad_norm': 12.696463584899902, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-21 17:25:56 {'loss': 1.9948, 'grad_norm': 10.62035083770752, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-21 17:26:10 {'loss': 1.649, 'grad_norm': 10.297358512878418, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-21 17:26:25 {'loss': 1.6035, 'grad_norm': 8.711451530456543, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-21 17:26:40 {'loss': 1.5629, 'grad_norm': 9.151179313659668, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-21 17:26:55 {'loss': 1.6508, 'grad_norm': 10.442797660827637, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-21 17:27:10 {'loss': 1.8837, 'grad_norm': 13.723731994628906, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-21 17:27:31 {'loss': 2.0578, 'grad_norm': 10.443061828613281, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-21 17:27:31 {'train_runtime': 641.7796, 'train_samples_per_second': 1.247, 'train_steps_per_second': 0.623, 'train_loss': 1.946838583946228, 'epoch': 1.0}
2025-05-21 17:28:29 {'eval_loss': 1.496952772140503, 'eval_runtime': 9.6211, 'eval_samples_per_second': 20.788, 'eval_steps_per_second': 2.598, 'epoch': 1.0}
2025-05-21 17:28:47 {'loss': 1.3586, 'grad_norm': 9.933616638183594, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-21 17:28:49 {'loss': 1.4354, 'grad_norm': 9.955110549926758, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-21 17:29:01 {'loss': 1.5483, 'grad_norm': 10.839619636535645, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-21 17:29:15 {'loss': 1.5408, 'grad_norm': 9.120226860046387, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-21 17:29:30 {'loss': 1.5086, 'grad_norm': 14.987730026245117, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-21 17:29:45 {'loss': 1.4262, 'grad_norm': 11.572370529174805, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-21 17:30:00 {'loss': 1.4418, 'grad_norm': 11.172344207763672, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-21 17:30:21 {'loss': 1.4551, 'grad_norm': 7.856420993804932, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-21 17:30:35 {'loss': 1.3888, 'grad_norm': 8.406315803527832, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-21 17:30:50 {'loss': 1.6478, 'grad_norm': 10.836349487304688, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-21 17:31:05 {'loss': 1.3431, 'grad_norm': 7.696149826049805, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-21 17:31:19 {'loss': 1.4676, 'grad_norm': 10.764487266540527, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-21 17:31:41 {'loss': 1.3297, 'grad_norm': 11.10744571685791, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-21 17:31:55 {'loss': 1.289, 'grad_norm': 8.473104476928711, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-21 17:32:10 {'loss': 1.3627, 'grad_norm': 8.943937301635742, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-21 17:32:25 {'loss': 1.4471, 'grad_norm': 7.3482985496521, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-21 17:32:39 {'loss': 1.3217, 'grad_norm': 11.477287292480469, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-21 17:32:54 {'loss': 1.6153, 'grad_norm': 10.275215148925781, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-21 17:33:08 {'loss': 1.2824, 'grad_norm': 11.65211009979248, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-21 17:33:23 {'loss': 1.4711, 'grad_norm': 10.729072570800781, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-21 17:33:44 {'loss': 1.5214, 'grad_norm': 9.338732719421387, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-21 17:33:58 {'loss': 1.4335, 'grad_norm': 9.562750816345215, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-21 17:34:13 {'loss': 1.5259, 'grad_norm': 12.17725944519043, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-21 17:34:28 {'loss': 1.5066, 'grad_norm': 11.527494430541992, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-21 17:34:42 {'loss': 1.5795, 'grad_norm': 10.984009742736816, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-21 17:34:57 {'loss': 1.663, 'grad_norm': 13.750388145446777, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-21 17:35:12 {'loss': 1.5729, 'grad_norm': 12.982423782348633, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-21 17:35:27 {'loss': 1.5597, 'grad_norm': 7.209748268127441, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-21 17:35:48 {'loss': 1.3984, 'grad_norm': 7.564852714538574, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-21 17:36:02 {'loss': 1.2753, 'grad_norm': 12.789669036865234, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-21 17:36:17 {'loss': 1.5932, 'grad_norm': 10.610779762268066, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-21 17:36:32 {'loss': 1.4969, 'grad_norm': 12.722149848937988, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-21 17:36:46 {'loss': 1.5203, 'grad_norm': 11.134453773498535, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-21 17:37:01 {'loss': 1.7737, 'grad_norm': 10.931584358215332, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-21 17:37:15 {'loss': 1.4515, 'grad_norm': 10.542709350585938, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-21 17:37:30 {'loss': 1.4136, 'grad_norm': 9.503331184387207, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-21 17:37:51 {'loss': 1.3967, 'grad_norm': 8.496724128723145, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-21 17:38:06 {'loss': 1.3977, 'grad_norm': 9.142409324645996, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-21 17:38:20 {'loss': 1.4463, 'grad_norm': 11.032119750976562, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-21 17:38:35 {'loss': 1.2905, 'grad_norm': 6.230339050292969, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-21 17:38:35 {'train_runtime': 590.1287, 'train_samples_per_second': 1.356, 'train_steps_per_second': 0.678, 'train_loss': 1.462447497844696, 'epoch': 1.0}
2025-05-21 17:40:19 {'eval_loss': 1.4441914558410645, 'eval_runtime': 11.8454, 'eval_samples_per_second': 16.884, 'eval_steps_per_second': 2.111, 'epoch': 1.0}
2025-05-21 17:41:00 {'loss': 0.9744, 'grad_norm': 9.747066497802734, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-21 17:41:14 {'loss': 1.0903, 'grad_norm': 8.49919319152832, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-21 17:41:35 {'loss': 1.1695, 'grad_norm': 9.603739738464355, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-21 17:41:50 {'loss': 1.2248, 'grad_norm': 8.720438957214355, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-21 17:42:04 {'loss': 1.2458, 'grad_norm': 11.43808650970459, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-21 17:42:19 {'loss': 1.1486, 'grad_norm': 9.268241882324219, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-21 17:42:33 {'loss': 1.1474, 'grad_norm': 10.010736465454102, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-21 17:42:48 {'loss': 1.1999, 'grad_norm': 7.751521587371826, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-21 17:43:08 {'loss': 1.1208, 'grad_norm': 7.119026184082031, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-21 17:43:23 {'loss': 1.3414, 'grad_norm': 9.98330020904541, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-21 17:43:37 {'loss': 1.0999, 'grad_norm': 8.599196434020996, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-21 17:43:52 {'loss': 1.2246, 'grad_norm': 10.531014442443848, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-21 17:44:07 {'loss': 1.1274, 'grad_norm': 9.636672019958496, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-21 17:44:22 {'loss': 1.0785, 'grad_norm': 8.295145034790039, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-21 17:44:36 {'loss': 1.1337, 'grad_norm': 8.267021179199219, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-21 17:44:51 {'loss': 1.2118, 'grad_norm': 7.607565879821777, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-21 17:45:05 {'loss': 1.1259, 'grad_norm': 11.30788803100586, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-21 17:45:26 {'loss': 1.387, 'grad_norm': 9.485532760620117, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-21 17:45:41 {'loss': 1.0916, 'grad_norm': 9.77401065826416, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-21 17:45:56 {'loss': 1.2802, 'grad_norm': 11.604513168334961, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-21 17:46:10 {'loss': 1.3419, 'grad_norm': 8.960285186767578, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-21 17:46:25 {'loss': 1.2713, 'grad_norm': 8.37900447845459, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-21 17:46:40 {'loss': 1.3967, 'grad_norm': 12.856671333312988, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-21 17:46:55 {'loss': 1.3142, 'grad_norm': 10.770414352416992, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-21 17:47:10 {'loss': 1.4315, 'grad_norm': 10.830692291259766, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-21 17:47:31 {'loss': 1.4994, 'grad_norm': 12.024284362792969, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-21 17:47:46 {'loss': 1.4253, 'grad_norm': 12.572761535644531, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-21 17:48:00 {'loss': 1.4325, 'grad_norm': 7.966202259063721, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-21 17:48:15 {'loss': 1.2814, 'grad_norm': 7.241765022277832, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-21 17:48:30 {'loss': 1.1826, 'grad_norm': 11.636541366577148, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-21 17:48:45 {'loss': 1.4856, 'grad_norm': 10.174942970275879, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-21 17:49:00 {'loss': 1.3909, 'grad_norm': 15.465988159179688, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-21 17:49:15 {'loss': 1.4238, 'grad_norm': 11.510150909423828, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-21 17:49:36 {'loss': 1.6647, 'grad_norm': 10.821741104125977, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-21 17:49:51 {'loss': 1.378, 'grad_norm': 11.646780014038086, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-21 17:50:05 {'loss': 1.3674, 'grad_norm': 9.200931549072266, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-21 17:50:20 {'loss': 1.325, 'grad_norm': 8.035198211669922, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-21 17:50:35 {'loss': 1.3225, 'grad_norm': 9.505672454833984, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-21 17:50:50 {'loss': 1.3135, 'grad_norm': 12.287430763244629, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-21 17:51:04 {'loss': 1.0509, 'grad_norm': 7.3950886726379395, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-21 17:51:04 {'train_runtime': 625.4236, 'train_samples_per_second': 1.279, 'train_steps_per_second': 0.64, 'train_loss': 1.268061981201172, 'epoch': 1.0}
2025-05-21 17:52:20 {'eval_loss': 1.4474879503250122, 'eval_runtime': 13.6727, 'eval_samples_per_second': 14.628, 'eval_steps_per_second': 1.828, 'epoch': 1.0}
2025-05-21 17:52:42 {'loss': 0.7078, 'grad_norm': 8.530803680419922, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-21 17:52:55 {'loss': 0.8444, 'grad_norm': 7.354354381561279, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-21 17:53:10 {'loss': 0.8936, 'grad_norm': 8.237723350524902, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-21 17:53:25 {'loss': 0.9799, 'grad_norm': 7.364616870880127, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-21 17:53:45 {'loss': 1.0026, 'grad_norm': 9.802473068237305, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-21 17:54:00 {'loss': 0.9014, 'grad_norm': 9.036079406738281, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-21 17:54:15 {'loss': 0.9471, 'grad_norm': 9.84145450592041, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-21 17:54:30 {'loss': 0.9821, 'grad_norm': 7.777824878692627, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-21 17:54:44 {'loss': 0.9214, 'grad_norm': 6.791958332061768, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-21 17:54:59 {'loss': 1.1039, 'grad_norm': 9.096161842346191, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-21 17:55:13 {'loss': 0.9151, 'grad_norm': 8.916117668151855, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-21 17:55:28 {'loss': 1.0492, 'grad_norm': 8.886972427368164, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-21 17:55:43 {'loss': 0.9328, 'grad_norm': 10.057323455810547, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-21 17:56:04 {'loss': 0.9246, 'grad_norm': 7.566336631774902, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-21 17:56:18 {'loss': 0.9855, 'grad_norm': 8.225992202758789, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-21 17:56:33 {'loss': 1.024, 'grad_norm': 6.393807411193848, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-21 17:56:48 {'loss': 0.9664, 'grad_norm': 10.562664031982422, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-21 17:57:02 {'loss': 1.2419, 'grad_norm': 9.838701248168945, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-21 17:57:17 {'loss': 0.9576, 'grad_norm': 9.646149635314941, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-21 17:57:32 {'loss': 1.1014, 'grad_norm': 9.985835075378418, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-21 17:57:52 {'loss': 1.2148, 'grad_norm': 8.619155883789062, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-21 17:58:07 {'loss': 1.1256, 'grad_norm': 7.695400714874268, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-21 17:58:22 {'loss': 1.2414, 'grad_norm': 12.13337230682373, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-21 17:58:36 {'loss': 1.1828, 'grad_norm': 10.78306770324707, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-21 17:58:51 {'loss': 1.303, 'grad_norm': 10.092302322387695, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-21 17:59:05 {'loss': 1.378, 'grad_norm': 12.014385223388672, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-21 17:59:26 {'loss': 1.3075, 'grad_norm': 11.865662574768066, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-21 17:59:41 {'loss': 1.3521, 'grad_norm': 7.805521011352539, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-21 17:59:55 {'loss': 1.1838, 'grad_norm': 6.854614734649658, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-21 18:00:10 {'loss': 1.0945, 'grad_norm': 11.283769607543945, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-21 18:00:25 {'loss': 1.4105, 'grad_norm': 9.386799812316895, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-21 18:00:39 {'loss': 1.3333, 'grad_norm': 13.76817798614502, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-21 18:00:54 {'loss': 1.3575, 'grad_norm': 11.291056632995605, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-21 18:01:09 {'loss': 1.5984, 'grad_norm': 10.51717472076416, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-21 18:01:30 {'loss': 1.3412, 'grad_norm': 10.577214241027832, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-21 18:01:45 {'loss': 1.3244, 'grad_norm': 10.14846420288086, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-21 18:01:59 {'loss': 1.2994, 'grad_norm': 7.838681697845459, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-21 18:02:14 {'loss': 1.2998, 'grad_norm': 10.479564666748047, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-21 18:02:29 {'loss': 1.2304, 'grad_norm': 11.839643478393555, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-21 18:02:44 {'loss': 0.9511, 'grad_norm': 8.172575950622559, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-21 18:02:44 {'train_runtime': 607.9014, 'train_samples_per_second': 1.316, 'train_steps_per_second': 0.658, 'train_loss': 1.1227942144870757, 'epoch': 1.0}
2025-05-21 18:04:03 {'eval_loss': 1.4597795009613037, 'eval_runtime': 9.2656, 'eval_samples_per_second': 21.585, 'eval_steps_per_second': 2.698, 'epoch': 1.0}
2025-05-21 18:04:48 {'loss': 0.5078, 'grad_norm': 6.561286926269531, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-21 18:05:03 {'loss': 0.6183, 'grad_norm': 9.403108596801758, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-21 18:05:17 {'loss': 0.699, 'grad_norm': 9.643163681030273, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-21 18:05:32 {'loss': 0.8027, 'grad_norm': 6.5649919509887695, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-21 18:05:53 {'loss': 0.8182, 'grad_norm': 9.900993347167969, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-21 18:06:08 {'loss': 0.7171, 'grad_norm': 7.891289234161377, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-21 18:06:23 {'loss': 0.7831, 'grad_norm': 8.909998893737793, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-21 18:06:38 {'loss': 0.8428, 'grad_norm': 7.408092975616455, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-21 18:06:52 {'loss': 0.7713, 'grad_norm': 7.928995132446289, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-21 18:07:07 {'loss': 0.9154, 'grad_norm': 9.064770698547363, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-21 18:07:28 {'loss': 0.7526, 'grad_norm': 7.08613395690918, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-21 18:07:43 {'loss': 0.8842, 'grad_norm': 9.009407043457031, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-21 18:07:57 {'loss': 0.7862, 'grad_norm': 9.639004707336426, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-21 18:08:12 {'loss': 0.7826, 'grad_norm': 8.000261306762695, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-21 18:08:26 {'loss': 0.8394, 'grad_norm': 7.844605445861816, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-21 18:08:41 {'loss': 0.8914, 'grad_norm': 6.817647457122803, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-21 18:09:02 {'loss': 0.85, 'grad_norm': 10.30178165435791, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-21 18:09:17 {'loss': 1.0727, 'grad_norm': 8.922036170959473, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-21 18:09:32 {'loss': 0.8315, 'grad_norm': 10.442657470703125, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-21 18:09:46 {'loss': 0.9897, 'grad_norm': 10.651679039001465, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-21 18:10:01 {'loss': 1.0588, 'grad_norm': 8.260578155517578, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-21 18:10:16 {'loss': 0.9778, 'grad_norm': 7.17063045501709, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-21 18:10:31 {'loss': 1.1099, 'grad_norm': 12.023977279663086, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-21 18:10:45 {'loss': 1.0662, 'grad_norm': 11.302053451538086, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-21 18:11:00 {'loss': 1.1882, 'grad_norm': 11.099674224853516, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-21 18:11:22 {'loss': 1.2762, 'grad_norm': 13.601998329162598, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-21 18:11:36 {'loss': 1.2186, 'grad_norm': 13.44509506225586, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-21 18:11:51 {'loss': 1.2497, 'grad_norm': 8.496567726135254, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-21 18:12:06 {'loss': 1.1032, 'grad_norm': 6.983004093170166, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-21 18:12:20 {'loss': 1.0238, 'grad_norm': 11.631966590881348, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-21 18:12:35 {'loss': 1.3266, 'grad_norm': 10.89521598815918, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-21 18:12:50 {'loss': 1.2613, 'grad_norm': 17.747358322143555, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-21 18:13:05 {'loss': 1.3169, 'grad_norm': 12.58767318725586, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-21 18:13:26 {'loss': 1.5404, 'grad_norm': 10.794210433959961, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-21 18:13:41 {'loss': 1.3056, 'grad_norm': 12.048095703125, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-21 18:13:56 {'loss': 1.2802, 'grad_norm': 9.381341934204102, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-21 18:14:11 {'loss': 1.2723, 'grad_norm': 7.063794136047363, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-21 18:14:26 {'loss': 1.2623, 'grad_norm': 9.567001342773438, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-21 18:14:38 {'loss': 1.1591, 'grad_norm': 12.260937690734863, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-21 18:14:47 {'loss': 0.8321, 'grad_norm': 7.01669979095459, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-21 18:14:47 {'train_runtime': 620.7763, 'train_samples_per_second': 1.289, 'train_steps_per_second': 0.644, 'train_loss': 0.999628313779831, 'epoch': 1.0}
2025-05-21 18:15:32 {'eval_loss': 1.4781014919281006, 'eval_runtime': 2.5993, 'eval_samples_per_second': 76.945, 'eval_steps_per_second': 9.618, 'epoch': 1.0}
2025-05-21 18:02:58 INFO :      Sent reply
2025-05-21 18:03:52 INFO :      
2025-05-21 18:03:52 INFO :      Received: evaluate message e124d284-0322-435c-8dd5-ff46d8155b83
2025-05-21 18:04:03 INFO :      Sent reply
2025-05-21 18:04:20 INFO :      
2025-05-21 18:04:20 INFO :      Received: train message 479d45d7-c5e3-4d99-80e1-294c5808ec1a
2025-05-21 18:14:54 INFO :      Sent reply
2025-05-21 18:15:29 INFO :      
2025-05-21 18:15:29 INFO :      Received: evaluate message 77931f65-1f45-48e8-b73c-e369ff5f6e78
2025-05-21 18:15:32 INFO :      Sent reply
2025-05-21 18:15:48 INFO :      
2025-05-21 18:15:48 INFO :      Received: reconnect message 0a27bfb7-6640-4ce9-9fbe-385c5a4bc5f0
2025-05-21 18:15:48 INFO :      Disconnect and shut down
