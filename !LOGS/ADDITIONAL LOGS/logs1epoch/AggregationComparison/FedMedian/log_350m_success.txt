2025-05-19 19:50:29 server-1   | WARNING :   DEPRECATED FEATURE: flwr.server.start_server() is deprecated.
2025-05-19 19:52:45 client2-1  | 
Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]
Generating train split:  80%|████████  | 96000/120000 [00:00<00:00, 954876.28 examples/s]
Generating train split: 100%|██████████| 120000/120000 [00:00<00:00, 1032058.76 examples/s]
2025-05-19 19:50:29 server-1   | Instead, use the `flower-superlink` CLI command to start a SuperLink as shown below:
2025-05-19 19:50:29 server-1   | 
2025-05-19 19:52:24 client1-1  | 
Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]
Generating train split:  82%|████████▏ | 98000/120000 [00:00<00:00, 974973.00 examples/s]
Generating train split: 100%|██████████| 120000/120000 [00:00<00:00, 1039847.78 examples/s]
2025-05-19 19:52:24 client1-1  | 
Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]
Generating test split: 100%|██████████| 7600/7600 [00:00<00:00, 994965.68 examples/s]
2025-05-19 19:52:26 client1-1  | 
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 1133.55 examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 1127.32 examples/s]
2025-05-19 19:50:29 server-1   | $ flower-superlink --insecure
2025-05-19 19:52:45 client2-1  | 
Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]
Generating test split: 100%|██████████| 7600/7600 [00:00<00:00, 911049.48 examples/s]
2025-05-19 19:52:47 client2-1  | 
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 1208.73 examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 1203.04 examples/s]
2025-05-19 19:52:27 client1-1  | 
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]
Map:  25%|██▌       | 254/1000 [00:00<00:00, 2516.12 examples/s]
Map:  54%|█████▎    | 535/1000 [00:00<00:00, 2073.19 examples/s]
Map:  82%|████████▏ | 816/1000 [00:00<00:00, 1966.70 examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 1933.18 examples/s]
2025-05-19 19:52:47 client2-1  | 
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]
Map:  16%|█▌        | 159/1000 [00:00<00:00, 1574.09 examples/s]
Map:  51%|█████     | 510/1000 [00:00<00:00, 2705.07 examples/s]
Map:  88%|████████▊ | 876/1000 [00:00<00:00, 3136.16 examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 2768.99 examples/s]
2025-05-19 19:52:27 client1-1  | /app/client.py:49: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-05-19 19:50:29 server-1   | 
2025-05-19 19:50:29 server-1   | To view usage and all available options, run:
2025-05-19 19:50:29 server-1   | 
2025-05-19 19:50:29 server-1   | $ flower-superlink --help
2025-05-19 19:52:27 client1-1  |   trainer = Trainer(
2025-05-19 19:52:47 client2-1  | /app/client.py:49: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-05-19 19:52:28 client1-1  | WARNING :   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
2025-05-19 19:50:29 server-1   | 
2025-05-19 19:52:47 client2-1  |   trainer = Trainer(
2025-05-19 19:50:29 server-1   | Using `start_server()` is deprecated.
2025-05-19 19:52:28 client1-1  | Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
2025-05-19 19:52:48 client2-1  | WARNING :   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
2025-05-19 19:52:48 client2-1  | Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
2025-05-19 19:52:28 client1-1  | flwr.client.start_client(
2025-05-19 19:50:29 server-1   | 
2025-05-19 19:52:28 client1-1  | server_address='<IP>:<PORT>',
2025-05-19 19:50:29 server-1   |             This is a deprecated feature. It will be removed
2025-05-19 19:52:28 client1-1  | client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
2025-05-19 19:52:28 client1-1  | )
2025-05-19 19:52:28 client1-1  | Using `start_numpy_client()` is deprecated.
2025-05-19 19:52:28 client1-1  | 
2025-05-19 19:50:29 server-1   |             entirely in future versions of Flower.
2025-05-19 19:50:29 server-1   |         
2025-05-19 19:50:29 server-1   | INFO :      Starting Flower server, config: num_rounds=5, no round_timeout
2025-05-19 19:50:29 server-1   | INFO :      Flower ECE: gRPC server running (5 rounds), SSL is disabled
2025-05-19 19:52:48 client2-1  | flwr.client.start_client(
2025-05-19 19:52:48 client2-1  | server_address='<IP>:<PORT>',
2025-05-19 19:52:48 client2-1  | client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
2025-05-19 19:50:29 server-1   | INFO :      [INIT]
2025-05-19 19:50:29 server-1   | INFO :      Requesting initial parameters from one random client
2025-05-19 19:52:33 server-1   | INFO :      Received initial parameters from one random client
2025-05-19 19:52:28 client1-1  |             This is a deprecated feature. It will be removed
2025-05-19 19:52:33 server-1   | INFO :      Starting evaluation of initial global parameters
2025-05-19 19:52:33 server-1   | INFO :      Evaluation returned no results (`None`)
2025-05-19 19:52:48 client2-1  | )
2025-05-19 19:52:33 server-1   | INFO :      
2025-05-19 19:52:33 server-1   | INFO :      [ROUND 1]
2025-05-19 19:52:48 server-1   | INFO :      configure_fit: strategy sampled 2 clients (out of 2)
2025-05-19 20:00:46 server-1   | INFO :      aggregate_fit: received 2 results and 0 failures
2025-05-19 19:52:48 client2-1  | Using `start_numpy_client()` is deprecated.
2025-05-19 20:01:05 server-1   | WARNING :   No fit_metrics_aggregation_fn provided
2025-05-19 20:01:05 server-1   | INFO :      configure_evaluate: strategy sampled 2 clients (out of 2)
2025-05-19 20:01:27 server-1   | INFO :      aggregate_evaluate: received 2 results and 0 failures
2025-05-19 20:01:27 server-1   | WARNING :   No evaluate_metrics_aggregation_fn provided
2025-05-19 20:01:27 server-1   | INFO :      
2025-05-19 20:01:27 server-1   | INFO :      [ROUND 2]
2025-05-19 20:01:27 server-1   | INFO :      configure_fit: strategy sampled 2 clients (out of 2)
2025-05-19 20:09:06 server-1   | INFO :      aggregate_fit: received 2 results and 0 failures
2025-05-19 19:52:28 client1-1  |             entirely in future versions of Flower.
2025-05-19 19:52:28 client1-1  |         
2025-05-19 19:52:28 client1-1  | WARNING :   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
2025-05-19 19:52:28 client1-1  | Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:
2025-05-19 19:52:48 client2-1  | 
2025-05-19 19:52:28 client1-1  | 
2025-05-19 19:52:28 client1-1  | $ flower-supernode --insecure --superlink='<IP>:<PORT>'
2025-05-19 19:52:28 client1-1  | 
2025-05-19 19:52:48 client2-1  |             This is a deprecated feature. It will be removed
2025-05-19 19:52:28 client1-1  | To view all available options, run:
2025-05-19 19:52:48 client2-1  |             entirely in future versions of Flower.
2025-05-19 19:52:28 client1-1  | 
2025-05-19 19:52:48 client2-1  |         
2025-05-19 19:52:28 client1-1  | $ flower-supernode --help
2025-05-19 19:52:28 client1-1  | 
2025-05-19 19:52:28 client1-1  | Using `start_client()` is deprecated.
2025-05-19 19:52:48 client2-1  | WARNING :   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
2025-05-19 19:52:28 client1-1  | 
2025-05-19 20:09:26 server-1   | INFO :      configure_evaluate: strategy sampled 2 clients (out of 2)
2025-05-19 19:52:48 client2-1  | Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:
2025-05-19 19:52:48 client2-1  | 
2025-05-19 19:52:48 client2-1  | $ flower-supernode --insecure --superlink='<IP>:<PORT>'
2025-05-19 20:09:47 server-1   | INFO :      aggregate_evaluate: received 2 results and 0 failures
2025-05-19 19:52:28 client1-1  |             This is a deprecated feature. It will be removed
2025-05-19 20:09:47 server-1   | INFO :      
2025-05-19 19:52:28 client1-1  |             entirely in future versions of Flower.
2025-05-19 20:09:47 server-1   | INFO :      [ROUND 3]
2025-05-19 20:09:47 server-1   | INFO :      configure_fit: strategy sampled 2 clients (out of 2)
2025-05-19 19:52:48 client2-1  | 
2025-05-19 20:17:25 server-1   | INFO :      aggregate_fit: received 2 results and 0 failures
2025-05-19 19:52:48 client2-1  | To view all available options, run:
2025-05-19 20:17:44 server-1   | INFO :      configure_evaluate: strategy sampled 2 clients (out of 2)
2025-05-19 19:52:48 client2-1  | 
2025-05-19 19:52:28 client1-1  |         
2025-05-19 20:18:05 server-1   | INFO :      aggregate_evaluate: received 2 results and 0 failures
2025-05-19 20:18:05 server-1   | INFO :      
2025-05-19 19:52:48 client2-1  | $ flower-supernode --help
2025-05-19 19:52:48 client2-1  | 
2025-05-19 19:52:28 client1-1  | INFO :      
2025-05-19 20:18:05 server-1   | INFO :      [ROUND 4]
2025-05-19 20:18:05 server-1   | INFO :      configure_fit: strategy sampled 2 clients (out of 2)
2025-05-19 19:52:28 client1-1  | INFO :      Received: get_parameters message c44b2d8d-4a1b-448a-b117-183ead547cef
2025-05-19 20:25:37 server-1   | INFO :      aggregate_fit: received 2 results and 0 failures
2025-05-19 19:52:32 client1-1  | INFO :      Sent reply
2025-05-19 19:52:57 client1-1  | INFO :      
2025-05-19 19:52:57 client1-1  | INFO :      Received: train message 360737be-1907-411d-95ae-98184aded80e
2025-05-19 19:52:48 client2-1  | Using `start_client()` is deprecated.
2025-05-19 19:53:25 client1-1  | {'loss': 2.779, 'grad_norm': 15.33484172821045, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-19 19:52:48 client2-1  | 
2025-05-19 19:52:48 client2-1  |             This is a deprecated feature. It will be removed
2025-05-19 19:53:35 client1-1  | {'loss': 1.6937, 'grad_norm': 24.514694213867188, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-19 20:25:56 server-1   | INFO :      configure_evaluate: strategy sampled 2 clients (out of 2)
2025-05-19 19:52:48 client2-1  |             entirely in future versions of Flower.
2025-05-19 19:53:45 client1-1  | {'loss': 1.3988, 'grad_norm': 18.37212371826172, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-19 19:53:55 client1-1  | {'loss': 1.5413, 'grad_norm': 12.579385757446289, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-19 20:26:15 server-1   | INFO :      aggregate_evaluate: received 2 results and 0 failures
2025-05-19 19:54:10 client1-1  | {'loss': 1.5633, 'grad_norm': 13.248905181884766, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-19 19:54:20 client1-1  | {'loss': 1.7557, 'grad_norm': 17.898086547851562, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-19 19:54:30 client1-1  | {'loss': 1.5492, 'grad_norm': 15.867897987365723, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-19 19:52:48 client2-1  |         
2025-05-19 19:52:57 client2-1  | INFO :      
2025-05-19 19:52:57 client2-1  | INFO :      Received: train message c77a372b-3e9a-4b9b-a4bd-aa29e6b172e3
2025-05-19 19:53:23 client2-1  | {'loss': 2.2945, 'grad_norm': 11.064933776855469, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-19 20:26:15 server-1   | INFO :      
2025-05-19 20:26:15 server-1   | INFO :      [ROUND 5]
2025-05-19 20:26:15 server-1   | INFO :      configure_fit: strategy sampled 2 clients (out of 2)
2025-05-19 19:53:33 client2-1  | {'loss': 1.701, 'grad_norm': 21.23773193359375, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-19 19:53:47 client2-1  | {'loss': 1.5569, 'grad_norm': 13.342575073242188, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-19 20:33:54 server-1   | INFO :      aggregate_fit: received 2 results and 0 failures
2025-05-19 19:53:57 client2-1  | {'loss': 1.4648, 'grad_norm': 18.72829818725586, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-19 19:54:40 client1-1  | {'loss': 1.5249, 'grad_norm': 10.537339210510254, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-19 20:34:12 server-1   | INFO :      configure_evaluate: strategy sampled 2 clients (out of 2)
2025-05-19 20:34:33 server-1   | INFO :      aggregate_evaluate: received 2 results and 0 failures
2025-05-19 20:34:33 server-1   | INFO :      
2025-05-19 19:54:54 client1-1  | {'loss': 1.4984, 'grad_norm': 11.082659721374512, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-19 20:34:33 server-1   | INFO :      [SUMMARY]
2025-05-19 19:55:05 client1-1  | {'loss': 1.3876, 'grad_norm': 11.777989387512207, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-19 20:34:33 server-1   | INFO :      Run finished 5 round(s) in 2519.83s
2025-05-19 20:34:33 server-1   | INFO :      History (loss, distributed):
2025-05-19 19:55:15 client1-1  | {'loss': 1.3508, 'grad_norm': 10.944311141967773, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-19 19:55:25 client1-1  | {'loss': 1.5242, 'grad_norm': 11.815328598022461, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-19 19:55:39 client1-1  | {'loss': 1.4819, 'grad_norm': 10.80756664276123, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-19 19:54:08 client2-1  | {'loss': 1.5071, 'grad_norm': 11.980740547180176, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-19 19:55:50 client1-1  | {'loss': 1.6342, 'grad_norm': 12.772502899169922, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-19 19:54:18 client2-1  | {'loss': 1.424, 'grad_norm': 11.991957664489746, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-19 19:54:32 client2-1  | {'loss': 1.4688, 'grad_norm': 11.91403579711914, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-19 19:56:00 client1-1  | {'loss': 1.3705, 'grad_norm': 9.417085647583008, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-19 19:56:14 client1-1  | {'loss': 1.3622, 'grad_norm': 13.629802703857422, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-19 20:34:33 server-1   | INFO :      round 1: 1.3308170437812805
2025-05-19 20:34:33 server-1   | INFO :      round 2: 1.352294921875
2025-05-19 19:56:24 client1-1  | {'loss': 1.5365, 'grad_norm': 12.325438499450684, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-19 19:56:34 client1-1  | {'loss': 1.4302, 'grad_norm': 9.572359085083008, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-19 19:56:44 client1-1  | {'loss': 1.5359, 'grad_norm': 17.035903930664062, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-19 19:54:42 client2-1  | {'loss': 1.5446, 'grad_norm': 15.853188514709473, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-19 19:54:52 client2-1  | {'loss': 1.537, 'grad_norm': 15.484393119812012, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-19 19:55:07 client2-1  | {'loss': 1.3502, 'grad_norm': 11.422891616821289, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-19 20:34:33 server-1   | INFO :      round 3: 1.3910496830940247
2025-05-19 19:55:17 client2-1  | {'loss': 1.3592, 'grad_norm': 12.05418586730957, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-19 20:34:33 server-1   | INFO :      round 4: 1.4317031502723694
2025-05-19 19:55:27 client2-1  | {'loss': 1.5397, 'grad_norm': 10.310639381408691, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-19 20:34:33 server-1   | INFO :      round 5: 1.4696086049079895
2025-05-19 19:56:59 client1-1  | {'loss': 1.3919, 'grad_norm': 14.22335433959961, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-19 19:55:38 client2-1  | {'loss': 1.4598, 'grad_norm': 11.953624725341797, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-19 19:55:52 client2-1  | {'loss': 1.5265, 'grad_norm': 9.541439056396484, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-19 19:56:02 client2-1  | {'loss': 1.3648, 'grad_norm': 11.88333511352539, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-19 20:34:33 server-1   | INFO :      
2025-05-19 19:56:12 client2-1  | {'loss': 1.4872, 'grad_norm': 11.61398983001709, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-19 19:56:22 client2-1  | {'loss': 1.5938, 'grad_norm': 10.558123588562012, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-19 19:57:09 client1-1  | {'loss': 1.3973, 'grad_norm': 13.49631118774414, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-19 19:56:36 client2-1  | {'loss': 1.4788, 'grad_norm': 11.01119327545166, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-19 19:57:19 client1-1  | {'loss': 1.3348, 'grad_norm': 9.85044002532959, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-19 19:56:46 client2-1  | {'loss': 1.1564, 'grad_norm': 11.586348533630371, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-19 19:57:29 client1-1  | {'loss': 1.3042, 'grad_norm': 12.208086013793945, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-19 19:56:56 client2-1  | {'loss': 1.3044, 'grad_norm': 14.305987358093262, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-19 19:57:11 client2-1  | {'loss': 1.4719, 'grad_norm': 9.837472915649414, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-19 19:57:21 client2-1  | {'loss': 1.6261, 'grad_norm': 15.578160285949707, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-19 19:57:31 client2-1  | {'loss': 1.431, 'grad_norm': 14.20395565032959, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-19 19:57:41 client2-1  | {'loss': 1.4817, 'grad_norm': 11.874073028564453, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-19 19:57:54 client2-1  | {'loss': 1.3515, 'grad_norm': 11.264806747436523, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-19 19:58:04 client2-1  | {'loss': 1.7449, 'grad_norm': 19.053123474121094, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-19 19:58:14 client2-1  | {'loss': 1.4738, 'grad_norm': 8.526243209838867, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-19 19:57:42 client1-1  | {'loss': 1.4083, 'grad_norm': 12.212202072143555, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-19 19:58:24 client2-1  | {'loss': 1.3714, 'grad_norm': 13.684335708618164, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-19 19:58:34 client2-1  | {'loss': 1.2877, 'grad_norm': 10.171380996704102, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-19 19:57:52 client1-1  | {'loss': 1.3802, 'grad_norm': 15.282905578613281, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-19 19:58:48 client2-1  | {'loss': 1.3728, 'grad_norm': 11.860494613647461, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-19 19:58:02 client1-1  | {'loss': 1.4742, 'grad_norm': 12.77016544342041, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-19 19:58:58 client2-1  | {'loss': 1.4071, 'grad_norm': 12.242050170898438, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-19 19:59:08 client2-1  | {'loss': 1.2555, 'grad_norm': 12.748291969299316, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-19 19:59:22 client2-1  | {'loss': 1.3953, 'grad_norm': 16.1539249420166, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-19 19:58:12 client1-1  | {'loss': 1.3258, 'grad_norm': 12.3956880569458, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-19 19:58:26 client1-1  | {'loss': 1.3029, 'grad_norm': 14.919289588928223, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-19 19:59:33 client2-1  | {'loss': 1.4254, 'grad_norm': 11.786551475524902, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-19 19:59:47 client2-1  | {'loss': 1.3129, 'grad_norm': 13.473575592041016, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-19 19:58:36 client1-1  | {'loss': 1.4238, 'grad_norm': 12.70351791381836, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-19 19:58:46 client1-1  | {'loss': 1.391, 'grad_norm': 14.199056625366211, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-19 19:58:56 client1-1  | {'loss': 1.5552, 'grad_norm': 12.598148345947266, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-19 19:59:06 client1-1  | {'loss': 1.3609, 'grad_norm': 12.959821701049805, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-19 19:59:57 client2-1  | {'loss': 1.5157, 'grad_norm': 12.698990821838379, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-19 20:00:07 client2-1  | {'loss': 1.311, 'grad_norm': 11.146778106689453, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-19 19:59:20 client1-1  | {'loss': 1.293, 'grad_norm': 13.00887393951416, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-19 20:00:16 client2-1  | {'loss': 1.476, 'grad_norm': 11.08121109008789, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-19 19:59:30 client1-1  | {'loss': 1.3681, 'grad_norm': 14.860785484313965, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-19 19:59:40 client1-1  | {'loss': 1.2628, 'grad_norm': 12.191110610961914, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-19 20:00:30 client2-1  | {'loss': 1.3676, 'grad_norm': 12.154397010803223, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-19 19:59:50 client1-1  | {'loss': 1.3197, 'grad_norm': 17.6649227142334, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-19 20:00:03 client1-1  | {'loss': 1.4387, 'grad_norm': 13.553362846374512, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-19 20:00:13 client1-1  | {'loss': 1.4165, 'grad_norm': 8.898282051086426, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-19 20:00:23 client1-1  | {'loss': 1.4283, 'grad_norm': 13.59922981262207, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-19 20:00:33 client1-1  | {'loss': 1.3802, 'grad_norm': 11.823150634765625, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-19 20:00:40 client2-1  | {'loss': 1.249, 'grad_norm': 14.740976333618164, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-19 20:00:40 client2-1  | {'train_runtime': 461.7681, 'train_samples_per_second': 1.732, 'train_steps_per_second': 0.866, 'train_loss': 1.4611909151077271, 'epoch': 1.0}
2025-05-19 20:00:45 client2-1  | INFO :      Sent reply
2025-05-19 20:01:16 client2-1  | INFO :      
2025-05-19 20:01:16 client2-1  | INFO :      Received: evaluate message 00870e35-1ce9-42ce-8495-c72291cdd869
2025-05-19 20:00:33 client1-1  | {'train_runtime': 455.0892, 'train_samples_per_second': 1.758, 'train_steps_per_second': 0.879, 'train_loss': 1.4719064927101135, 'epoch': 1.0}
2025-05-19 20:00:44 client1-1  | INFO :      Sent reply
2025-05-19 20:01:26 client2-1  | {'eval_loss': 1.3100181818008423, 'eval_runtime': 9.5167, 'eval_samples_per_second': 21.016, 'eval_steps_per_second': 2.627, 'epoch': 1.0}
2025-05-19 20:01:14 client1-1  | INFO :      
2025-05-19 20:01:26 client2-1  | INFO :      Sent reply
2025-05-19 20:01:35 client2-1  | INFO :      
2025-05-19 20:01:35 client2-1  | INFO :      Received: train message 718e2d8a-d870-4001-a708-f1bb4b3cb740
2025-05-19 20:01:48 client2-1  | {'loss': 0.8406, 'grad_norm': 9.982095718383789, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-19 20:02:02 client2-1  | {'loss': 1.0129, 'grad_norm': 10.709829330444336, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-19 20:02:12 client2-1  | {'loss': 1.0115, 'grad_norm': 10.882730484008789, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-19 20:02:26 client2-1  | {'loss': 1.0076, 'grad_norm': 11.984628677368164, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-19 20:01:14 client1-1  | INFO :      Received: evaluate message bba16a3c-9871-4cd9-8574-ffc39c0d0109
2025-05-19 20:01:27 client1-1  | {'eval_loss': 1.3516159057617188, 'eval_runtime': 11.7794, 'eval_samples_per_second': 16.979, 'eval_steps_per_second': 2.122, 'epoch': 1.0}
2025-05-19 20:02:36 client2-1  | {'loss': 1.0271, 'grad_norm': 11.665984153747559, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-19 20:02:46 client2-1  | {'loss': 0.9691, 'grad_norm': 9.582667350769043, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-19 20:01:27 client1-1  | INFO :      Sent reply
2025-05-19 20:01:35 client1-1  | INFO :      
2025-05-19 20:01:35 client1-1  | INFO :      Received: train message 25fc6709-cac2-48f3-9ea7-a57a0d33df41
2025-05-19 20:02:56 client2-1  | {'loss': 1.0268, 'grad_norm': 9.5341796875, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-19 20:03:10 client2-1  | {'loss': 1.1074, 'grad_norm': 13.570590019226074, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-19 20:03:20 client2-1  | {'loss': 1.1248, 'grad_norm': 9.741121292114258, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-19 20:01:55 client1-1  | {'loss': 0.889, 'grad_norm': 11.474447250366211, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-19 20:02:05 client1-1  | {'loss': 1.0528, 'grad_norm': 17.615478515625, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-19 20:03:30 client2-1  | {'loss': 0.9661, 'grad_norm': 11.40550708770752, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-19 20:02:15 client1-1  | {'loss': 0.9224, 'grad_norm': 11.755194664001465, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-19 20:03:43 client2-1  | {'loss': 0.9671, 'grad_norm': 9.594863891601562, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-19 20:03:53 client2-1  | {'loss': 1.1233, 'grad_norm': 10.451833724975586, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-19 20:04:03 client2-1  | {'loss': 1.0642, 'grad_norm': 10.450201034545898, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-19 20:04:13 client2-1  | {'loss': 1.1587, 'grad_norm': 8.348592758178711, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-19 20:04:27 client2-1  | {'loss': 1.0117, 'grad_norm': 10.826342582702637, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-19 20:02:29 client1-1  | {'loss': 1.0564, 'grad_norm': 10.245782852172852, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-19 20:02:39 client1-1  | {'loss': 1.0761, 'grad_norm': 11.406681060791016, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-19 20:02:49 client1-1  | {'loss': 1.1875, 'grad_norm': 15.759106636047363, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-19 20:02:58 client1-1  | {'loss': 1.0506, 'grad_norm': 13.805329322814941, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-19 20:03:12 client1-1  | {'loss': 1.0979, 'grad_norm': 11.872097969055176, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-19 20:04:37 client2-1  | {'loss': 1.1258, 'grad_norm': 9.385336875915527, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-19 20:04:47 client2-1  | {'loss': 1.1682, 'grad_norm': 13.523062705993652, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-19 20:05:00 client2-1  | {'loss': 1.1493, 'grad_norm': 9.537826538085938, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-19 20:05:10 client2-1  | {'loss': 0.9045, 'grad_norm': 9.440743446350098, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-19 20:03:22 client1-1  | {'loss': 1.0663, 'grad_norm': 10.724918365478516, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-19 20:05:20 client2-1  | {'loss': 1.0276, 'grad_norm': 12.386198043823242, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-19 20:05:34 client2-1  | {'loss': 1.1494, 'grad_norm': 8.877394676208496, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-19 20:05:43 client2-1  | {'loss': 1.2889, 'grad_norm': 13.42464542388916, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-19 20:03:32 client1-1  | {'loss': 1.0045, 'grad_norm': 7.902745723724365, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-19 20:05:53 client2-1  | {'loss': 1.146, 'grad_norm': 15.246772766113281, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-19 20:06:03 client2-1  | {'loss': 1.1986, 'grad_norm': 11.795522689819336, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-19 20:03:42 client1-1  | {'loss': 0.9859, 'grad_norm': 20.100479125976562, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-19 20:06:17 client2-1  | {'loss': 1.0924, 'grad_norm': 9.263814926147461, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-19 20:03:55 client1-1  | {'loss': 1.158, 'grad_norm': 13.429862976074219, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-19 20:06:27 client2-1  | {'loss': 1.4338, 'grad_norm': 18.033641815185547, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-19 20:06:36 client2-1  | {'loss': 1.2637, 'grad_norm': 8.415647506713867, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-19 20:06:46 client2-1  | {'loss': 1.1613, 'grad_norm': 10.878451347351074, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-19 20:04:05 client1-1  | {'loss': 1.0316, 'grad_norm': 9.925966262817383, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-19 20:07:00 client2-1  | {'loss': 1.0821, 'grad_norm': 10.089719772338867, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-19 20:04:15 client1-1  | {'loss': 1.2458, 'grad_norm': 12.445505142211914, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-19 20:07:10 client2-1  | {'loss': 1.1734, 'grad_norm': 11.442158699035645, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-19 20:07:20 client2-1  | {'loss': 1.2221, 'grad_norm': 11.120346069335938, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-19 20:04:25 client1-1  | {'loss': 1.0059, 'grad_norm': 8.499706268310547, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-19 20:07:30 client2-1  | {'loss': 1.1011, 'grad_norm': 10.874948501586914, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-19 20:07:44 client2-1  | {'loss': 1.2419, 'grad_norm': 14.353772163391113, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-19 20:07:54 client2-1  | {'loss': 1.2924, 'grad_norm': 11.861737251281738, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-19 20:08:03 client2-1  | {'loss': 1.2077, 'grad_norm': 14.267427444458008, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-19 20:08:13 client2-1  | {'loss': 1.3719, 'grad_norm': 12.339763641357422, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-19 20:08:27 client2-1  | {'loss': 1.1841, 'grad_norm': 8.572827339172363, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-19 20:08:37 client2-1  | {'loss': 1.3083, 'grad_norm': 10.202978134155273, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-19 20:08:47 client2-1  | {'loss': 1.0577, 'grad_norm': 11.079554557800293, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-19 20:04:39 client1-1  | {'loss': 1.0024, 'grad_norm': 13.033760070800781, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-19 20:08:57 client2-1  | {'loss': 0.7774, 'grad_norm': 9.449499130249023, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-19 20:08:57 client2-1  | {'train_runtime': 440.5569, 'train_samples_per_second': 1.816, 'train_steps_per_second': 0.908, 'train_loss': 1.113706842660904, 'epoch': 1.0}
2025-05-19 20:04:49 client1-1  | {'loss': 1.1712, 'grad_norm': 10.523344039916992, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-19 20:09:05 client2-1  | INFO :      Sent reply
2025-05-19 20:04:58 client1-1  | {'loss': 1.1207, 'grad_norm': 8.748915672302246, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-19 20:09:34 client2-1  | INFO :      
2025-05-19 20:09:34 client2-1  | INFO :      Received: evaluate message 2dbdc5c7-f16c-4dc5-a43c-1de6c5e6931f
2025-05-19 20:09:46 client2-1  | {'eval_loss': 1.3347809314727783, 'eval_runtime': 11.1846, 'eval_samples_per_second': 17.882, 'eval_steps_per_second': 2.235, 'epoch': 1.0}
2025-05-19 20:09:46 client2-1  | INFO :      Sent reply
2025-05-19 20:09:53 client2-1  | INFO :      
2025-05-19 20:05:08 client1-1  | {'loss': 1.2173, 'grad_norm': 16.68496322631836, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-19 20:05:22 client1-1  | {'loss': 1.0867, 'grad_norm': 13.52774429321289, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-19 20:05:32 client1-1  | {'loss': 1.1004, 'grad_norm': 11.776573181152344, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-19 20:05:41 client1-1  | {'loss': 1.0547, 'grad_norm': 8.750810623168945, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-19 20:05:51 client1-1  | {'loss': 1.0397, 'grad_norm': 12.49250602722168, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-19 20:09:53 client2-1  | INFO :      Received: train message 15fb5a64-5c95-4c13-993a-0250ab275e3f
2025-05-19 20:10:06 client2-1  | {'loss': 0.5341, 'grad_norm': 7.884671688079834, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-19 20:10:20 client2-1  | {'loss': 0.6807, 'grad_norm': 10.237810134887695, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-19 20:10:30 client2-1  | {'loss': 0.6816, 'grad_norm': 11.056694984436035, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-19 20:06:05 client1-1  | {'loss': 1.1305, 'grad_norm': 9.895142555236816, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-19 20:06:15 client1-1  | {'loss': 1.1205, 'grad_norm': 12.354031562805176, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-19 20:06:25 client1-1  | {'loss': 1.2402, 'grad_norm': 9.963717460632324, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-19 20:06:38 client1-1  | {'loss': 1.0816, 'grad_norm': 11.23161506652832, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-19 20:10:40 client2-1  | {'loss': 0.7107, 'grad_norm': 11.229220390319824, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-19 20:10:50 client2-1  | {'loss': 0.7575, 'grad_norm': 10.108731269836426, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-19 20:11:04 client2-1  | {'loss': 0.7151, 'grad_norm': 8.241986274719238, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-19 20:11:14 client2-1  | {'loss': 0.7734, 'grad_norm': 7.242096424102783, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-19 20:11:24 client2-1  | {'loss': 0.8352, 'grad_norm': 10.823545455932617, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-19 20:11:37 client2-1  | {'loss': 0.8314, 'grad_norm': 9.934041976928711, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-19 20:06:48 client1-1  | {'loss': 1.0966, 'grad_norm': 12.594035148620605, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-19 20:06:58 client1-1  | {'loss': 1.2173, 'grad_norm': 9.256046295166016, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-19 20:07:08 client1-1  | {'loss': 1.1866, 'grad_norm': 11.075396537780762, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-19 20:07:18 client1-1  | {'loss': 1.3504, 'grad_norm': 14.2737455368042, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-19 20:11:47 client2-1  | {'loss': 0.7203, 'grad_norm': 8.323953628540039, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-19 20:11:57 client2-1  | {'loss': 0.701, 'grad_norm': 8.153136253356934, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-19 20:12:07 client2-1  | {'loss': 0.8415, 'grad_norm': 8.78921890258789, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-19 20:07:32 client1-1  | {'loss': 1.1932, 'grad_norm': 11.889867782592773, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-19 20:12:21 client2-1  | {'loss': 0.7983, 'grad_norm': 10.178542137145996, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-19 20:07:42 client1-1  | {'loss': 1.1522, 'grad_norm': 12.33627700805664, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-19 20:12:31 client2-1  | {'loss': 0.9082, 'grad_norm': 8.601385116577148, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-19 20:12:41 client2-1  | {'loss': 0.7765, 'grad_norm': 9.442610740661621, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-19 20:12:51 client2-1  | {'loss': 0.8959, 'grad_norm': 9.268166542053223, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-19 20:07:51 client1-1  | {'loss': 1.2332, 'grad_norm': 14.203442573547363, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-19 20:08:01 client1-1  | {'loss': 1.1436, 'grad_norm': 11.181139945983887, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-19 20:13:05 client2-1  | {'loss': 0.9303, 'grad_norm': 10.84998893737793, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-19 20:08:15 client1-1  | {'loss': 1.1847, 'grad_norm': 14.25092887878418, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-19 20:08:25 client1-1  | {'loss': 1.3163, 'grad_norm': 12.033960342407227, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-19 20:08:35 client1-1  | {'loss': 1.2432, 'grad_norm': 8.480753898620605, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-19 20:08:45 client1-1  | {'loss': 1.145, 'grad_norm': 13.094032287597656, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-19 20:08:58 client1-1  | {'loss': 0.836, 'grad_norm': 10.012494087219238, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-19 20:13:15 client2-1  | {'loss': 0.9119, 'grad_norm': 8.877289772033691, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-19 20:13:25 client2-1  | {'loss': 0.7091, 'grad_norm': 8.49598217010498, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-19 20:13:34 client2-1  | {'loss': 0.8297, 'grad_norm': 10.63535213470459, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-19 20:13:48 client2-1  | {'loss': 0.9654, 'grad_norm': 8.201193809509277, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-19 20:13:58 client2-1  | {'loss': 1.0734, 'grad_norm': 12.10703182220459, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-19 20:08:58 client1-1  | {'train_runtime': 439.6451, 'train_samples_per_second': 1.82, 'train_steps_per_second': 0.91, 'train_loss': 1.1123775053024292, 'epoch': 1.0}
2025-05-19 20:14:09 client2-1  | {'loss': 0.9835, 'grad_norm': 14.363805770874023, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-19 20:09:04 client1-1  | INFO :      Sent reply
2025-05-19 20:14:18 client2-1  | {'loss': 1.0073, 'grad_norm': 11.174728393554688, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-19 20:09:34 client1-1  | INFO :      
2025-05-19 20:09:34 client1-1  | INFO :      Received: evaluate message 58a7d0c8-76f3-42e3-8a1d-027bf60f0c13
2025-05-19 20:09:47 client1-1  | {'eval_loss': 1.3698089122772217, 'eval_runtime': 11.3321, 'eval_samples_per_second': 17.649, 'eval_steps_per_second': 2.206, 'epoch': 1.0}
2025-05-19 20:09:47 client1-1  | INFO :      Sent reply
2025-05-19 20:14:28 client2-1  | {'loss': 0.9192, 'grad_norm': 9.367630958557129, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-19 20:14:42 client2-1  | {'loss': 1.2417, 'grad_norm': 13.9386568069458, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-19 20:14:52 client2-1  | {'loss': 1.094, 'grad_norm': 8.36176872253418, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-19 20:09:53 client1-1  | INFO :      
2025-05-19 20:09:53 client1-1  | INFO :      Received: train message 937c25c0-eeb2-4505-ab94-c1f052fad424
2025-05-19 20:10:13 client1-1  | {'loss': 0.5546, 'grad_norm': 11.02843952178955, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-19 20:10:23 client1-1  | {'loss': 0.6736, 'grad_norm': 13.009527206420898, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-19 20:10:37 client1-1  | {'loss': 0.6435, 'grad_norm': 10.909767150878906, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-19 20:15:01 client2-1  | {'loss': 0.9886, 'grad_norm': 10.992666244506836, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-19 20:15:11 client2-1  | {'loss': 0.9465, 'grad_norm': 9.928390502929688, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-19 20:15:26 client2-1  | {'loss': 1.0584, 'grad_norm': 11.723065376281738, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-19 20:15:35 client2-1  | {'loss': 1.1107, 'grad_norm': 11.955018997192383, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-19 20:15:49 client2-1  | {'loss': 1.0159, 'grad_norm': 10.326079368591309, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-19 20:10:47 client1-1  | {'loss': 0.7321, 'grad_norm': 10.189830780029297, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-19 20:15:59 client2-1  | {'loss': 1.1498, 'grad_norm': 14.105950355529785, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-19 20:10:57 client1-1  | {'loss': 0.7604, 'grad_norm': 13.245781898498535, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-19 20:16:08 client2-1  | {'loss': 1.2017, 'grad_norm': 12.169044494628906, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-19 20:16:18 client2-1  | {'loss': 1.1423, 'grad_norm': 15.359519958496094, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-19 20:11:07 client1-1  | {'loss': 0.8635, 'grad_norm': 12.217531204223633, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-19 20:11:21 client1-1  | {'loss': 0.7656, 'grad_norm': 12.122151374816895, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-19 20:11:31 client1-1  | {'loss': 0.8461, 'grad_norm': 10.231795310974121, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-19 20:11:40 client1-1  | {'loss': 0.8376, 'grad_norm': 10.500654220581055, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-19 20:16:32 client2-1  | {'loss': 1.2992, 'grad_norm': 13.27126693725586, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-19 20:11:50 client1-1  | {'loss': 0.7377, 'grad_norm': 6.31170654296875, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-19 20:16:42 client2-1  | {'loss': 1.1433, 'grad_norm': 9.290705680847168, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-19 20:16:51 client2-1  | {'loss': 1.2154, 'grad_norm': 9.908129692077637, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-19 20:17:01 client2-1  | {'loss': 0.9663, 'grad_norm': 9.27065658569336, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-19 20:17:15 client2-1  | {'loss': 0.5717, 'grad_norm': 11.393031120300293, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-19 20:12:04 client1-1  | {'loss': 0.7446, 'grad_norm': 9.77391242980957, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-19 20:17:15 client2-1  | {'train_runtime': 440.6689, 'train_samples_per_second': 1.815, 'train_steps_per_second': 0.908, 'train_loss': 0.9159161996841431, 'epoch': 1.0}
2025-05-19 20:17:22 client2-1  | INFO :      Sent reply
2025-05-19 20:17:52 client2-1  | INFO :      
2025-05-19 20:17:52 client2-1  | INFO :      Received: evaluate message 07a31bbb-7fbf-4b59-96a9-c3da01ea3d6c
2025-05-19 20:12:14 client1-1  | {'loss': 0.8659, 'grad_norm': 13.466057777404785, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-19 20:12:24 client1-1  | {'loss': 0.7873, 'grad_norm': 13.312376976013184, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-19 20:18:05 client2-1  | {'eval_loss': 1.3703720569610596, 'eval_runtime': 11.2508, 'eval_samples_per_second': 17.776, 'eval_steps_per_second': 2.222, 'epoch': 1.0}
2025-05-19 20:18:05 client2-1  | INFO :      Sent reply
2025-05-19 20:12:34 client1-1  | {'loss': 0.9732, 'grad_norm': 11.330785751342773, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-19 20:18:08 client2-1  | INFO :      
2025-05-19 20:18:08 client2-1  | INFO :      Received: train message 3e66edd0-266e-4931-9184-7418d60710e9
2025-05-19 20:18:22 client2-1  | {'loss': 0.349, 'grad_norm': 5.491666793823242, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-19 20:18:32 client2-1  | {'loss': 0.4774, 'grad_norm': 8.764683723449707, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-19 20:12:48 client1-1  | {'loss': 0.7984, 'grad_norm': 7.4205641746521, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-19 20:12:58 client1-1  | {'loss': 0.7889, 'grad_norm': 11.371676445007324, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-19 20:13:08 client1-1  | {'loss': 0.9626, 'grad_norm': 9.928948402404785, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-19 20:18:46 client2-1  | {'loss': 0.4685, 'grad_norm': 10.722294807434082, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-19 20:18:56 client2-1  | {'loss': 0.5045, 'grad_norm': 10.890524864196777, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-19 20:19:06 client2-1  | {'loss': 0.5573, 'grad_norm': 9.794373512268066, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-19 20:19:20 client2-1  | {'loss': 0.5458, 'grad_norm': 6.862859725952148, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-19 20:19:29 client2-1  | {'loss': 0.5516, 'grad_norm': 7.429704189300537, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-19 20:19:39 client2-1  | {'loss': 0.6109, 'grad_norm': 11.786690711975098, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-19 20:13:18 client1-1  | {'loss': 0.9106, 'grad_norm': 7.714757442474365, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-19 20:13:31 client1-1  | {'loss': 1.0013, 'grad_norm': 15.685127258300781, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-19 20:19:49 client2-1  | {'loss': 0.6182, 'grad_norm': 9.383697509765625, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-19 20:20:03 client2-1  | {'loss': 0.5244, 'grad_norm': 10.053088188171387, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-19 20:20:13 client2-1  | {'loss': 0.5299, 'grad_norm': 7.916771411895752, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-19 20:13:41 client1-1  | {'loss': 0.882, 'grad_norm': 12.763917922973633, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-19 20:13:51 client1-1  | {'loss': 0.8976, 'grad_norm': 11.483081817626953, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-19 20:14:01 client1-1  | {'loss': 0.8722, 'grad_norm': 9.243993759155273, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-19 20:14:15 client1-1  | {'loss': 0.875, 'grad_norm': 8.172551155090332, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-19 20:14:25 client1-1  | {'loss': 0.9528, 'grad_norm': 9.64354133605957, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-19 20:14:35 client1-1  | {'loss': 0.9533, 'grad_norm': 15.424835205078125, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-19 20:20:23 client2-1  | {'loss': 0.6302, 'grad_norm': 8.056668281555176, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-19 20:20:32 client2-1  | {'loss': 0.6136, 'grad_norm': 10.9111967086792, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-19 20:20:46 client2-1  | {'loss': 0.7051, 'grad_norm': 7.21281099319458, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-19 20:20:56 client2-1  | {'loss': 0.5994, 'grad_norm': 8.528038024902344, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-19 20:21:06 client2-1  | {'loss': 0.718, 'grad_norm': 9.488226890563965, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-19 20:21:16 client2-1  | {'loss': 0.7474, 'grad_norm': 9.543798446655273, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-19 20:21:30 client2-1  | {'loss': 0.7359, 'grad_norm': 9.188419342041016, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-19 20:21:40 client2-1  | {'loss': 0.5713, 'grad_norm': 9.346755981445312, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-19 20:21:49 client2-1  | {'loss': 0.6443, 'grad_norm': 10.151127815246582, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-19 20:22:03 client2-1  | {'loss': 0.8021, 'grad_norm': 9.164905548095703, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-19 20:22:13 client2-1  | {'loss': 0.9017, 'grad_norm': 12.151078224182129, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-19 20:22:23 client2-1  | {'loss': 0.8163, 'grad_norm': 13.442532539367676, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-19 20:22:33 client2-1  | {'loss': 0.8816, 'grad_norm': 12.338202476501465, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-19 20:22:47 client2-1  | {'loss': 0.8135, 'grad_norm': 11.282463073730469, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-19 20:22:57 client2-1  | {'loss': 1.0942, 'grad_norm': 15.32839584350586, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-19 20:23:07 client2-1  | {'loss': 0.9614, 'grad_norm': 11.397750854492188, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-19 20:23:17 client2-1  | {'loss': 0.8833, 'grad_norm': 11.71396541595459, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-19 20:23:30 client2-1  | {'loss': 0.8497, 'grad_norm': 10.76248836517334, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-19 20:14:45 client1-1  | {'loss': 1.0637, 'grad_norm': 9.882534980773926, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-19 20:23:40 client2-1  | {'loss': 0.9448, 'grad_norm': 12.961164474487305, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-19 20:23:50 client2-1  | {'loss': 1.0073, 'grad_norm': 12.353363990783691, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-19 20:24:00 client2-1  | {'loss': 0.9317, 'grad_norm': 10.382040977478027, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-19 20:24:10 client2-1  | {'loss': 1.0857, 'grad_norm': 12.868278503417969, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-19 20:24:24 client2-1  | {'loss': 1.1517, 'grad_norm': 14.17156982421875, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-19 20:24:33 client2-1  | {'loss': 1.1008, 'grad_norm': 15.955230712890625, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-19 20:24:43 client2-1  | {'loss': 1.2739, 'grad_norm': 13.493196487426758, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-19 20:24:53 client2-1  | {'loss': 1.1079, 'grad_norm': 9.745307922363281, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-19 20:14:58 client1-1  | {'loss': 0.9382, 'grad_norm': 9.864739418029785, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-19 20:25:08 client2-1  | {'loss': 1.1714, 'grad_norm': 10.96229362487793, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-19 20:15:08 client1-1  | {'loss': 0.943, 'grad_norm': 11.402226448059082, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-19 20:25:17 client2-1  | {'loss': 0.8469, 'grad_norm': 8.455384254455566, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-19 20:15:18 client1-1  | {'loss': 1.0821, 'grad_norm': 11.410287857055664, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-19 20:15:29 client1-1  | {'loss': 1.0757, 'grad_norm': 12.148334503173828, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-19 20:25:27 client2-1  | {'loss': 0.4681, 'grad_norm': 10.485034942626953, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-19 20:15:42 client1-1  | {'loss': 1.2489, 'grad_norm': 12.371475219726562, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-19 20:25:27 client2-1  | {'train_runtime': 437.7204, 'train_samples_per_second': 1.828, 'train_steps_per_second': 0.914, 'train_loss': 0.7699211466312409, 'epoch': 1.0}
2025-05-19 20:25:33 client2-1  | INFO :      Sent reply
2025-05-19 20:26:03 client2-1  | INFO :      
2025-05-19 20:26:03 client2-1  | INFO :      Received: evaluate message ce1089a4-34a7-4009-907d-0896701c59c0
2025-05-19 20:26:14 client2-1  | {'eval_loss': 1.412329077720642, 'eval_runtime': 8.8801, 'eval_samples_per_second': 22.522, 'eval_steps_per_second': 2.815, 'epoch': 1.0}
2025-05-19 20:26:14 client2-1  | INFO :      Sent reply
2025-05-19 20:15:52 client1-1  | {'loss': 1.0767, 'grad_norm': 11.361482620239258, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-19 20:16:02 client1-1  | {'loss': 1.0553, 'grad_norm': 11.43899154663086, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-19 20:16:15 client1-1  | {'loss': 1.1613, 'grad_norm': 14.552059173583984, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-19 20:16:25 client1-1  | {'loss': 1.0971, 'grad_norm': 11.597261428833008, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-19 20:26:24 client2-1  | INFO :      
2025-05-19 20:26:24 client2-1  | INFO :      Received: train message 131c6dc1-b4b5-4eea-b695-e5d2740217d9
2025-05-19 20:26:42 client2-1  | {'loss': 0.2313, 'grad_norm': 5.5171003341674805, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-19 20:16:35 client1-1  | {'loss': 1.1309, 'grad_norm': 15.12843132019043, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-19 20:16:44 client1-1  | {'loss': 1.2661, 'grad_norm': 12.56824779510498, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-19 20:26:51 client2-1  | {'loss': 0.3187, 'grad_norm': 7.540676593780518, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-19 20:27:01 client2-1  | {'loss': 0.3227, 'grad_norm': 10.805100440979004, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-19 20:27:11 client2-1  | {'loss': 0.3517, 'grad_norm': 8.453065872192383, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-19 20:27:25 client2-1  | {'loss': 0.4124, 'grad_norm': 8.25562858581543, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-19 20:27:35 client2-1  | {'loss': 0.4204, 'grad_norm': 6.405415058135986, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-19 20:27:45 client2-1  | {'loss': 0.407, 'grad_norm': 7.12857723236084, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-19 20:27:55 client2-1  | {'loss': 0.479, 'grad_norm': 9.715070724487305, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-19 20:28:09 client2-1  | {'loss': 0.4759, 'grad_norm': 8.257107734680176, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-19 20:28:18 client2-1  | {'loss': 0.4052, 'grad_norm': 11.212480545043945, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-19 20:28:28 client2-1  | {'loss': 0.4008, 'grad_norm': 8.375420570373535, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-19 20:28:38 client2-1  | {'loss': 0.4823, 'grad_norm': 8.19206428527832, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-19 20:16:58 client1-1  | {'loss': 1.1801, 'grad_norm': 8.919990539550781, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-19 20:17:09 client1-1  | {'loss': 1.0226, 'grad_norm': 10.887499809265137, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-19 20:17:19 client1-1  | {'loss': 0.6615, 'grad_norm': 12.714032173156738, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-19 20:17:19 client1-1  | {'train_runtime': 441.2143, 'train_samples_per_second': 1.813, 'train_steps_per_second': 0.907, 'train_loss': 0.9170981669425964, 'epoch': 1.0}
2025-05-19 20:17:24 client1-1  | INFO :      Sent reply
2025-05-19 20:17:52 client1-1  | INFO :      
2025-05-19 20:17:52 client1-1  | INFO :      Received: evaluate message 3222661f-65b5-4b9e-99da-039ddd7a3e8d
2025-05-19 20:18:04 client1-1  | {'eval_loss': 1.4117273092269897, 'eval_runtime': 11.5415, 'eval_samples_per_second': 17.329, 'eval_steps_per_second': 2.166, 'epoch': 1.0}
2025-05-19 20:28:52 client2-1  | {'loss': 0.4619, 'grad_norm': 9.524378776550293, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-19 20:29:02 client2-1  | {'loss': 0.5485, 'grad_norm': 6.477893352508545, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-19 20:29:11 client2-1  | {'loss': 0.4583, 'grad_norm': 8.128748893737793, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-19 20:18:04 client1-1  | INFO :      Sent reply
2025-05-19 20:18:11 client1-1  | INFO :      
2025-05-19 20:18:11 client1-1  | INFO :      Received: train message bb7278ef-3010-410b-8617-9b9f227f9cb0
2025-05-19 20:18:29 client1-1  | {'loss': 0.3507, 'grad_norm': 7.961800575256348, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-19 20:18:39 client1-1  | {'loss': 0.4386, 'grad_norm': 14.627103805541992, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-19 20:29:21 client2-1  | {'loss': 0.6024, 'grad_norm': 9.23415756225586, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-19 20:29:35 client2-1  | {'loss': 0.5854, 'grad_norm': 10.339985847473145, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-19 20:29:45 client2-1  | {'loss': 0.5867, 'grad_norm': 8.523423194885254, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-19 20:29:55 client2-1  | {'loss': 0.4391, 'grad_norm': 10.584872245788574, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-19 20:30:05 client2-1  | {'loss': 0.5153, 'grad_norm': 10.53619384765625, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-19 20:18:49 client1-1  | {'loss': 0.464, 'grad_norm': 9.979926109313965, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-19 20:19:03 client1-1  | {'loss': 0.5033, 'grad_norm': 8.008667945861816, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-19 20:30:19 client2-1  | {'loss': 0.6587, 'grad_norm': 8.744915008544922, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-19 20:19:13 client1-1  | {'loss': 0.5353, 'grad_norm': 11.534815788269043, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-19 20:19:23 client1-1  | {'loss': 0.6212, 'grad_norm': 11.883872985839844, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-19 20:19:33 client1-1  | {'loss': 0.5319, 'grad_norm': 13.870086669921875, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-19 20:19:46 client1-1  | {'loss': 0.6253, 'grad_norm': 9.337309837341309, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-19 20:19:56 client1-1  | {'loss': 0.6269, 'grad_norm': 9.318618774414062, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-19 20:20:06 client1-1  | {'loss': 0.557, 'grad_norm': 6.250629901885986, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-19 20:20:16 client1-1  | {'loss': 0.5805, 'grad_norm': 9.781439781188965, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-19 20:20:29 client1-1  | {'loss': 0.6994, 'grad_norm': 11.798791885375977, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-19 20:20:39 client1-1  | {'loss': 0.5905, 'grad_norm': 9.781699180603027, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-19 20:20:49 client1-1  | {'loss': 0.745, 'grad_norm': 11.379271507263184, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-19 20:20:59 client1-1  | {'loss': 0.603, 'grad_norm': 8.12216854095459, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-19 20:21:13 client1-1  | {'loss': 0.6178, 'grad_norm': 10.302294731140137, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-19 20:30:28 client2-1  | {'loss': 0.7675, 'grad_norm': 12.910635948181152, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-19 20:30:38 client2-1  | {'loss': 0.6925, 'grad_norm': 12.890836715698242, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-19 20:30:48 client2-1  | {'loss': 0.7313, 'grad_norm': 12.295623779296875, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-19 20:21:22 client1-1  | {'loss': 0.7881, 'grad_norm': 10.484752655029297, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-19 20:21:33 client1-1  | {'loss': 0.746, 'grad_norm': 7.9548821449279785, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-19 20:31:02 client2-1  | {'loss': 0.6793, 'grad_norm': 9.682273864746094, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-19 20:21:42 client1-1  | {'loss': 0.8033, 'grad_norm': 14.324920654296875, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-19 20:21:56 client1-1  | {'loss': 0.7063, 'grad_norm': 10.747191429138184, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-19 20:22:06 client1-1  | {'loss': 0.7375, 'grad_norm': 11.80844497680664, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-19 20:22:16 client1-1  | {'loss': 0.7133, 'grad_norm': 9.2686185836792, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-19 20:22:25 client1-1  | {'loss': 0.7053, 'grad_norm': 8.263036727905273, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-19 20:22:35 client1-1  | {'loss': 0.796, 'grad_norm': 8.32235336303711, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-19 20:22:49 client1-1  | {'loss': 0.8086, 'grad_norm': 13.98997688293457, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-19 20:22:59 client1-1  | {'loss': 0.9264, 'grad_norm': 10.203826904296875, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-19 20:23:09 client1-1  | {'loss': 0.8045, 'grad_norm': 10.619465827941895, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-19 20:23:19 client1-1  | {'loss': 0.8382, 'grad_norm': 12.874154090881348, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-19 20:23:33 client1-1  | {'loss': 0.9757, 'grad_norm': 9.890647888183594, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-19 20:31:12 client2-1  | {'loss': 0.9549, 'grad_norm': 14.988064765930176, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-19 20:31:22 client2-1  | {'loss': 0.8455, 'grad_norm': 8.328741073608398, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-19 20:31:32 client2-1  | {'loss': 0.788, 'grad_norm': 11.264127731323242, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-19 20:31:41 client2-1  | {'loss': 0.7417, 'grad_norm': 8.82124137878418, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-19 20:31:55 client2-1  | {'loss': 0.8536, 'grad_norm': 10.829649925231934, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-19 20:23:43 client1-1  | {'loss': 0.9741, 'grad_norm': 11.650824546813965, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-19 20:23:53 client1-1  | {'loss': 1.1366, 'grad_norm': 12.572630882263184, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-19 20:24:03 client1-1  | {'loss': 0.9994, 'grad_norm': 11.165063858032227, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-19 20:24:16 client1-1  | {'loss': 1.0091, 'grad_norm': 11.01586627960205, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-19 20:24:26 client1-1  | {'loss': 1.1096, 'grad_norm': 14.08565616607666, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-19 20:24:36 client1-1  | {'loss': 1.0216, 'grad_norm': 13.160332679748535, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-19 20:32:05 client2-1  | {'loss': 0.9166, 'grad_norm': 12.214113235473633, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-19 20:32:15 client2-1  | {'loss': 0.8596, 'grad_norm': 10.903911590576172, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-19 20:32:25 client2-1  | {'loss': 1.0347, 'grad_norm': 13.455314636230469, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-19 20:32:38 client2-1  | {'loss': 1.0923, 'grad_norm': 13.236258506774902, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-19 20:32:48 client2-1  | {'loss': 1.0492, 'grad_norm': 15.018377304077148, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-19 20:32:58 client2-1  | {'loss': 1.2397, 'grad_norm': 13.366999626159668, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-19 20:33:08 client2-1  | {'loss': 1.1108, 'grad_norm': 9.820595741271973, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-19 20:33:22 client2-1  | {'loss': 1.1394, 'grad_norm': 11.088785171508789, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-19 20:33:32 client2-1  | {'loss': 0.7644, 'grad_norm': 7.75261116027832, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-19 20:33:41 client2-1  | {'loss': 0.3893, 'grad_norm': 10.002300262451172, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-19 20:33:41 client2-1  | {'train_runtime': 435.5047, 'train_samples_per_second': 1.837, 'train_steps_per_second': 0.918, 'train_loss': 0.6553427857160569, 'epoch': 1.0}
2025-05-19 20:24:50 client1-1  | {'loss': 1.1005, 'grad_norm': 17.489940643310547, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-19 20:25:00 client1-1  | {'loss': 1.2252, 'grad_norm': 13.50774097442627, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-19 20:33:50 client2-1  | INFO :      Sent reply
2025-05-19 20:34:20 client2-1  | INFO :      
2025-05-19 20:34:20 client2-1  | INFO :      Received: evaluate message bfb31513-88bd-404c-8297-803d40032ac4
2025-05-19 20:34:33 client2-1  | {'eval_loss': 1.4491686820983887, 'eval_runtime': 11.6022, 'eval_samples_per_second': 17.238, 'eval_steps_per_second': 2.155, 'epoch': 1.0}
2025-05-19 20:34:33 client2-1  | INFO :      Sent reply
2025-05-19 20:25:10 client1-1  | {'loss': 1.1379, 'grad_norm': 9.212684631347656, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-19 20:25:20 client1-1  | {'loss': 0.9315, 'grad_norm': 10.441457748413086, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-19 20:25:30 client1-1  | {'loss': 0.5132, 'grad_norm': 7.5773024559021, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-19 20:25:30 client1-1  | {'train_runtime': 436.5705, 'train_samples_per_second': 1.832, 'train_steps_per_second': 0.916, 'train_loss': 0.7649610769748688, 'epoch': 1.0}
2025-05-19 20:34:33 client2-1  | INFO :      
2025-05-19 20:25:36 client1-1  | INFO :      Sent reply
2025-05-19 20:26:03 client1-1  | INFO :      
2025-05-19 20:26:03 client1-1  | INFO :      Received: evaluate message d0bed0a6-cb66-4f61-8a1e-c630b7c79964
2025-05-19 20:34:33 client2-1  | INFO :      Received: reconnect message 4b382ffa-f869-412c-87ac-079858132623
2025-05-19 20:26:15 client1-1  | {'eval_loss': 1.4510772228240967, 'eval_runtime': 9.1993, 'eval_samples_per_second': 21.741, 'eval_steps_per_second': 2.718, 'epoch': 1.0}
2025-05-19 20:26:15 client1-1  | INFO :      Sent reply
2025-05-19 20:26:25 client1-1  | INFO :      
2025-05-19 20:34:33 client2-1  | INFO :      Disconnect and shut down
2025-05-19 20:26:25 client1-1  | INFO :      Received: train message e03b5b7c-e6f8-4654-bf0a-6678dbd03aad
2025-05-19 20:26:44 client1-1  | {'loss': 0.2064, 'grad_norm': 7.625996112823486, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-19 20:26:54 client1-1  | {'loss': 0.2771, 'grad_norm': 12.264768600463867, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-19 20:27:04 client1-1  | {'loss': 0.3336, 'grad_norm': 8.960967063903809, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-19 20:27:14 client1-1  | {'loss': 0.3468, 'grad_norm': 8.636549949645996, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-19 20:27:28 client1-1  | {'loss': 0.3878, 'grad_norm': 10.00275707244873, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-19 20:27:38 client1-1  | {'loss': 0.4537, 'grad_norm': 10.824951171875, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-19 20:27:48 client1-1  | {'loss': 0.3951, 'grad_norm': 10.804141998291016, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-19 20:27:58 client1-1  | {'loss': 0.4807, 'grad_norm': 7.563554286956787, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-19 20:28:11 client1-1  | {'loss': 0.4499, 'grad_norm': 9.246800422668457, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-19 20:28:21 client1-1  | {'loss': 0.4119, 'grad_norm': 5.9660258293151855, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-19 20:28:31 client1-1  | {'loss': 0.4371, 'grad_norm': 8.687769889831543, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-19 20:28:41 client1-1  | {'loss': 0.5097, 'grad_norm': 9.607014656066895, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-19 20:28:54 client1-1  | {'loss': 0.4449, 'grad_norm': 9.033117294311523, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-19 20:29:04 client1-1  | {'loss': 0.607, 'grad_norm': 12.879858016967773, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-19 20:29:14 client1-1  | {'loss': 0.4851, 'grad_norm': 7.195497989654541, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-19 20:29:28 client1-1  | {'loss': 0.5097, 'grad_norm': 9.465287208557129, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-19 20:29:37 client1-1  | {'loss': 0.6247, 'grad_norm': 10.95999526977539, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-19 20:29:47 client1-1  | {'loss': 0.6071, 'grad_norm': 9.626545906066895, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-19 20:29:57 client1-1  | {'loss': 0.6658, 'grad_norm': 19.069875717163086, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-19 20:30:11 client1-1  | {'loss': 0.5801, 'grad_norm': 11.397224426269531, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-19 20:30:21 client1-1  | {'loss': 0.6017, 'grad_norm': 11.192805290222168, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-19 20:30:31 client1-1  | {'loss': 0.5898, 'grad_norm': 8.583730697631836, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-19 20:30:41 client1-1  | {'loss': 0.5862, 'grad_norm': 8.670289993286133, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-19 20:30:55 client1-1  | {'loss': 0.6762, 'grad_norm': 10.272116661071777, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-19 20:31:05 client1-1  | {'loss': 0.6982, 'grad_norm': 12.860069274902344, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-19 20:31:15 client1-1  | {'loss': 0.8208, 'grad_norm': 10.884089469909668, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-19 20:31:24 client1-1  | {'loss': 0.6976, 'grad_norm': 8.901874542236328, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-19 20:31:34 client1-1  | {'loss': 0.724, 'grad_norm': 12.351400375366211, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-19 20:31:48 client1-1  | {'loss': 0.8725, 'grad_norm': 10.029245376586914, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-19 20:31:58 client1-1  | {'loss': 0.8704, 'grad_norm': 11.482064247131348, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-19 20:32:08 client1-1  | {'loss': 1.0411, 'grad_norm': 14.843254089355469, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-19 20:32:21 client1-1  | {'loss': 0.9184, 'grad_norm': 10.634461402893066, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-19 20:32:31 client1-1  | {'loss': 0.9435, 'grad_norm': 11.141656875610352, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-19 20:32:41 client1-1  | {'loss': 1.0547, 'grad_norm': 14.56884479522705, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-19 20:32:51 client1-1  | {'loss': 0.9875, 'grad_norm': 11.894054412841797, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-19 20:33:05 client1-1  | {'loss': 1.038, 'grad_norm': 14.791433334350586, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-19 20:33:15 client1-1  | {'loss': 1.1936, 'grad_norm': 13.18530559539795, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-19 20:33:25 client1-1  | {'loss': 1.1133, 'grad_norm': 8.994257926940918, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-19 20:33:34 client1-1  | {'loss': 0.8543, 'grad_norm': 11.730727195739746, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-19 20:33:48 client1-1  | {'loss': 0.4093, 'grad_norm': 6.11272668838501, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-19 20:33:48 client1-1  | {'train_runtime': 439.3073, 'train_samples_per_second': 1.821, 'train_steps_per_second': 0.911, 'train_loss': 0.6476362150907516, 'epoch': 1.0}
2025-05-19 20:33:52 client1-1  | INFO :      Sent reply
2025-05-19 20:34:20 client1-1  | INFO :      
2025-05-19 20:34:20 client1-1  | INFO :      Received: evaluate message 1aa1a843-5246-4b77-b491-af297d667f4a
2025-05-19 20:34:32 client1-1  | {'eval_loss': 1.4900485277175903, 'eval_runtime': 11.3926, 'eval_samples_per_second': 17.555, 'eval_steps_per_second': 2.194, 'epoch': 1.0}
2025-05-19 20:34:32 client1-1  | INFO :      Sent reply
2025-05-19 20:34:33 client1-1  | INFO :      
2025-05-19 20:34:33 client1-1  | INFO :      Received: reconnect message 0a8185ad-a973-4fbc-a3b1-b1eda76f04df
2025-05-19 20:34:33 client1-1  | INFO :      Disconnect and shut down
