2025-05-22 02:52:27 client1-1  | 
Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]
Generating train split:  97%|█████████▋| 116000/120000 [00:00<00:00, 1152234.93 examples/s]
Generating train split: 100%|██████████| 120000/120000 [00:00<00:00, 1161945.58 examples/s]
2025-05-22 02:52:27 client1-1  | 
Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]
Generating test split: 100%|██████████| 7600/7600 [00:00<00:00, 1060718.43 examples/s]
2025-05-22 02:52:29 client1-1  | 
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 1137.67 examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 1133.41 examples/s]
2025-05-22 02:49:26 server-1   | WARNING :   DEPRECATED FEATURE: flwr.server.start_server() is deprecated.
2025-05-22 02:52:30 client1-1  | 
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]
Map:  28%|██▊       | 281/1000 [00:00<00:00, 2771.90 examples/s]
Map:  69%|██████▊   | 687/1000 [00:00<00:00, 2716.01 examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 2645.42 examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 2642.10 examples/s]
2025-05-22 02:52:30 client1-1  | /app/client.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-05-22 02:52:30 client1-1  |   trainer = Trainer(
2025-05-22 02:52:10 client2-1  | 
Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]
Generating train split:  92%|█████████▏| 110000/120000 [00:00<00:00, 1080396.12 examples/s]
Generating train split: 100%|██████████| 120000/120000 [00:00<00:00, 1102202.76 examples/s]
2025-05-22 02:49:26 server-1   | Instead, use the `flower-superlink` CLI command to start a SuperLink as shown below:
2025-05-22 02:52:10 client2-1  | 
Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]
Generating test split: 100%|██████████| 7600/7600 [00:00<00:00, 1059202.87 examples/s]
2025-05-22 02:52:30 client1-1  | WARNING :   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
2025-05-22 02:49:26 server-1   | 
2025-05-22 02:49:26 server-1   | $ flower-superlink --insecure
2025-05-22 02:52:30 client1-1  | Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
2025-05-22 02:52:30 client1-1  | flwr.client.start_client(
2025-05-22 02:52:30 client1-1  | server_address='<IP>:<PORT>',
2025-05-22 02:49:26 server-1   | 
2025-05-22 02:52:13 client2-1  | 
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 1005.13 examples/s]
Map: 100%|██████████| 1000/1000 [00:01<00:00, 999.60 examples/s] 
2025-05-22 02:52:30 client1-1  | client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
2025-05-22 02:52:30 client1-1  | )
2025-05-22 02:52:13 client3-1  | 
Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]
Generating train split:  92%|█████████▎| 111000/120000 [00:00<00:00, 1100820.34 examples/s]
Generating train split: 100%|██████████| 120000/120000 [00:00<00:00, 1109278.98 examples/s]
2025-05-22 02:52:30 client1-1  | Using `start_numpy_client()` is deprecated.
2025-05-22 02:49:26 server-1   | To view usage and all available options, run:
2025-05-22 02:52:13 client2-1  | 
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]
Map:  26%|██▌       | 260/1000 [00:00<00:00, 2578.72 examples/s]
Map:  56%|█████▋    | 565/1000 [00:00<00:00, 2851.47 examples/s]
Map:  98%|█████████▊| 975/1000 [00:00<00:00, 2780.43 examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 2483.20 examples/s]
2025-05-22 02:49:26 server-1   | 
2025-05-22 02:52:13 client3-1  | 
Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]
Generating test split: 100%|██████████| 7600/7600 [00:00<00:00, 1002380.76 examples/s]
2025-05-22 02:52:13 client2-1  | /app/client.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-05-22 02:52:16 client3-1  | 
Map:   0%|          | 0/999 [00:00<?, ? examples/s]
Map: 100%|██████████| 999/999 [00:00<00:00, 1002.55 examples/s]
Map: 100%|██████████| 999/999 [00:01<00:00, 998.35 examples/s] 
2025-05-22 02:49:26 server-1   | $ flower-superlink --help
2025-05-22 02:52:13 client2-1  |   trainer = Trainer(
2025-05-22 02:52:30 client1-1  | 
2025-05-22 02:52:30 client1-1  |             This is a deprecated feature. It will be removed
2025-05-22 02:52:30 client1-1  |             entirely in future versions of Flower.
2025-05-22 02:49:26 server-1   | 
2025-05-22 02:52:14 client2-1  | WARNING :   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
2025-05-22 02:49:26 server-1   | Using `start_server()` is deprecated.
2025-05-22 02:49:26 server-1   | 
2025-05-22 02:52:14 client2-1  | Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
2025-05-22 02:52:14 client2-1  | flwr.client.start_client(
2025-05-22 02:52:14 client2-1  | server_address='<IP>:<PORT>',
2025-05-22 02:52:14 client2-1  | client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
2025-05-22 02:52:14 client2-1  | )
2025-05-22 02:52:14 client2-1  | Using `start_numpy_client()` is deprecated.
2025-05-22 02:52:14 client2-1  | 
2025-05-22 02:52:30 client1-1  |         
2025-05-22 02:52:14 client2-1  |             This is a deprecated feature. It will be removed
2025-05-22 02:52:30 client1-1  | WARNING :   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
2025-05-22 02:52:30 client1-1  | Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:
2025-05-22 02:52:30 client1-1  | 
2025-05-22 02:52:14 client2-1  |             entirely in future versions of Flower.
2025-05-22 02:52:14 client2-1  |         
2025-05-22 02:52:14 client2-1  | WARNING :   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
2025-05-22 02:52:16 client3-1  | 
Map:   0%|          | 0/999 [00:00<?, ? examples/s]
Map:  24%|██▍       | 244/999 [00:00<00:00, 2414.69 examples/s]
Map:  52%|█████▏    | 516/999 [00:00<00:00, 2580.05 examples/s]
Map:  79%|███████▉  | 788/999 [00:00<00:00, 2639.23 examples/s]
Map: 100%|██████████| 999/999 [00:00<00:00, 2456.22 examples/s]
2025-05-22 02:52:16 client3-1  | /app/client.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-05-22 02:52:16 client3-1  |   trainer = Trainer(
2025-05-22 02:49:26 server-1   |             This is a deprecated feature. It will be removed
2025-05-22 02:49:26 server-1   |             entirely in future versions of Flower.
2025-05-22 02:52:14 client2-1  | Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:
2025-05-22 02:52:14 client2-1  | 
2025-05-22 02:52:14 client2-1  | $ flower-supernode --insecure --superlink='<IP>:<PORT>'
2025-05-22 02:52:14 client2-1  | 
2025-05-22 02:52:30 client1-1  | $ flower-supernode --insecure --superlink='<IP>:<PORT>'
2025-05-22 02:52:30 client1-1  | 
2025-05-22 02:52:30 client1-1  | To view all available options, run:
2025-05-22 02:52:30 client1-1  | 
2025-05-22 02:52:17 client3-1  | WARNING :   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
2025-05-22 02:52:30 client1-1  | $ flower-supernode --help
2025-05-22 02:52:30 client1-1  | 
2025-05-22 02:52:14 client2-1  | To view all available options, run:
2025-05-22 02:52:14 client2-1  | 
2025-05-22 02:52:14 client2-1  | $ flower-supernode --help
2025-05-22 02:52:17 client3-1  | Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
2025-05-22 02:52:14 client2-1  | 
2025-05-22 02:52:17 client3-1  | flwr.client.start_client(
2025-05-22 02:52:14 client2-1  | Using `start_client()` is deprecated.
2025-05-22 02:52:17 client3-1  | server_address='<IP>:<PORT>',
2025-05-22 02:52:14 client2-1  | 
2025-05-22 02:52:17 client3-1  | client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
2025-05-22 02:49:26 server-1   |         
2025-05-22 02:49:26 server-1   | INFO :      Starting Flower server, config: num_rounds=25, no round_timeout
2025-05-22 02:49:26 server-1   | INFO :      Flower ECE: gRPC server running (25 rounds), SSL is disabled
2025-05-22 02:49:26 server-1   | INFO :      [INIT]
2025-05-22 02:52:14 client2-1  |             This is a deprecated feature. It will be removed
2025-05-22 02:52:14 client2-1  |             entirely in future versions of Flower.
2025-05-22 02:52:17 client3-1  | )
2025-05-22 02:52:17 client3-1  | Using `start_numpy_client()` is deprecated.
2025-05-22 02:52:17 client3-1  | 
2025-05-22 02:52:17 client3-1  |             This is a deprecated feature. It will be removed
2025-05-22 02:52:30 client1-1  | Using `start_client()` is deprecated.
2025-05-22 02:52:30 client1-1  | 
2025-05-22 02:49:26 server-1   | INFO :      Requesting initial parameters from one random client
2025-05-22 02:52:19 server-1   | INFO :      Received initial parameters from one random client
2025-05-22 02:52:14 client2-1  |         
2025-05-22 02:52:14 client2-1  | INFO :      
2025-05-22 02:52:14 client2-1  | INFO :      Received: get_parameters message 3d85b95f-7e0f-485a-aa4c-a2eeb2c8563d
2025-05-22 02:52:18 client2-1  | INFO :      Sent reply
2025-05-22 02:52:30 client1-1  |             This is a deprecated feature. It will be removed
2025-05-22 02:52:30 client1-1  |             entirely in future versions of Flower.
2025-05-22 02:52:19 server-1   | INFO :      Starting evaluation of initial global parameters
2025-05-22 02:52:30 client1-1  |         
2025-05-22 02:52:41 client1-1  | INFO :      
2025-05-22 02:52:42 client2-1  | INFO :      
2025-05-22 02:52:42 client2-1  | INFO :      Received: train message 3e722de5-86c6-45a2-b0d1-f659714fe635
2025-05-22 02:52:19 server-1   | INFO :      Evaluation returned no results (`None`)
2025-05-22 02:52:41 client1-1  | INFO :      Received: train message 74e807f6-9349-4026-93da-df887a12740a
2025-05-22 02:53:43 client2-1  | {'loss': 4.4831, 'grad_norm': 29.669906616210938, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 02:53:59 client2-1  | {'loss': 2.302, 'grad_norm': 11.17900276184082, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 02:54:20 client2-1  | {'loss': 2.3065, 'grad_norm': 9.467931747436523, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 02:54:35 client2-1  | {'loss': 2.3574, 'grad_norm': 13.692049026489258, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 02:54:50 client2-1  | {'loss': 2.3566, 'grad_norm': 9.599953651428223, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 02:52:19 server-1   | INFO :      
2025-05-22 02:52:19 server-1   | INFO :      [ROUND 1]
2025-05-22 02:55:05 client2-1  | {'loss': 2.2018, 'grad_norm': 10.923206329345703, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 02:52:30 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 03:04:26 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 03:04:38 server-1   | WARNING :   No fit_metrics_aggregation_fn provided
2025-05-22 03:04:38 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 02:52:17 client3-1  |             entirely in future versions of Flower.
2025-05-22 02:53:06 client1-1  | {'loss': 4.5808, 'grad_norm': 14.152295112609863, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 02:53:18 client1-1  | {'loss': 2.2866, 'grad_norm': 13.933910369873047, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 02:53:41 client1-1  | {'loss': 2.1303, 'grad_norm': 10.132546424865723, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 02:55:27 client2-1  | {'loss': 1.8431, 'grad_norm': 10.343403816223145, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 03:05:07 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 02:53:56 client1-1  | {'loss': 2.4144, 'grad_norm': 14.334794044494629, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 02:55:42 client2-1  | {'loss': 1.9123, 'grad_norm': 12.376501083374023, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 02:54:11 client1-1  | {'loss': 2.3101, 'grad_norm': 10.569904327392578, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 02:54:32 client1-1  | {'loss': 2.174, 'grad_norm': 9.751813888549805, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 02:54:47 client1-1  | {'loss': 2.2681, 'grad_norm': 18.322538375854492, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 02:55:58 client2-1  | {'loss': 1.9491, 'grad_norm': 11.392165184020996, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 02:56:13 client2-1  | {'loss': 1.9512, 'grad_norm': 13.329320907592773, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 02:56:35 client2-1  | {'loss': 1.9179, 'grad_norm': 10.780351638793945, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 02:56:50 client2-1  | {'loss': 1.8299, 'grad_norm': 10.473296165466309, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 02:55:03 client1-1  | {'loss': 1.9177, 'grad_norm': 13.50943374633789, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 02:55:18 client1-1  | {'loss': 1.9453, 'grad_norm': 10.717592239379883, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 02:55:40 client1-1  | {'loss': 1.8998, 'grad_norm': 8.885875701904297, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 02:57:05 client2-1  | {'loss': 2.0095, 'grad_norm': 8.482797622680664, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 02:57:21 client2-1  | {'loss': 1.9323, 'grad_norm': 11.260568618774414, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 02:55:55 client1-1  | {'loss': 1.9588, 'grad_norm': 11.476001739501953, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 02:52:17 client3-1  |         
2025-05-22 02:56:10 client1-1  | {'loss': 1.873, 'grad_norm': 11.93674087524414, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 02:52:17 client3-1  | WARNING :   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
2025-05-22 03:05:07 server-1   | WARNING :   No evaluate_metrics_aggregation_fn provided
2025-05-22 02:52:17 client3-1  | Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:
2025-05-22 03:05:07 server-1   | INFO :      
2025-05-22 03:05:07 server-1   | INFO :      [ROUND 2]
2025-05-22 03:05:07 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 03:16:33 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 03:16:46 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 02:56:25 client1-1  | {'loss': 1.8785, 'grad_norm': 11.713848114013672, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 02:56:41 client1-1  | {'loss': 2.1068, 'grad_norm': 15.155735969543457, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 02:57:02 client1-1  | {'loss': 1.7856, 'grad_norm': 11.294758796691895, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 02:52:17 client3-1  | 
2025-05-22 03:17:12 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 03:17:12 server-1   | INFO :      
2025-05-22 02:57:18 client1-1  | {'loss': 1.8705, 'grad_norm': 11.032474517822266, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 02:52:17 client3-1  | $ flower-supernode --insecure --superlink='<IP>:<PORT>'
2025-05-22 02:52:17 client3-1  | 
2025-05-22 02:52:17 client3-1  | To view all available options, run:
2025-05-22 02:57:33 client1-1  | {'loss': 1.7439, 'grad_norm': 10.940563201904297, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 02:57:54 client1-1  | {'loss': 1.7297, 'grad_norm': 11.496228218078613, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 02:58:09 client1-1  | {'loss': 1.8346, 'grad_norm': 11.895949363708496, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 02:58:24 client1-1  | {'loss': 1.8042, 'grad_norm': 9.056474685668945, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 02:58:45 client1-1  | {'loss': 1.708, 'grad_norm': 11.77965259552002, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 02:59:01 client1-1  | {'loss': 1.7665, 'grad_norm': 9.87445068359375, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 02:59:16 client1-1  | {'loss': 1.7615, 'grad_norm': 13.33975887298584, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 03:17:12 server-1   | INFO :      [ROUND 3]
2025-05-22 02:59:38 client1-1  | {'loss': 1.6613, 'grad_norm': 10.189949989318848, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 03:17:12 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 02:57:42 client2-1  | {'loss': 1.6876, 'grad_norm': 10.287976264953613, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 02:57:57 client2-1  | {'loss': 1.8742, 'grad_norm': 11.081119537353516, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 02:58:12 client2-1  | {'loss': 1.9894, 'grad_norm': 10.405736923217773, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 02:58:33 client2-1  | {'loss': 1.945, 'grad_norm': 9.438078880310059, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 02:58:48 client2-1  | {'loss': 1.7589, 'grad_norm': 10.79733657836914, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 03:28:42 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 02:59:04 client2-1  | {'loss': 1.8914, 'grad_norm': 10.215517044067383, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 02:59:25 client2-1  | {'loss': 1.9199, 'grad_norm': 13.00604248046875, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 02:59:53 client1-1  | {'loss': 1.5779, 'grad_norm': 11.378743171691895, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 03:28:59 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 03:00:15 client1-1  | {'loss': 1.7919, 'grad_norm': 12.228571891784668, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 03:29:35 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 03:00:30 client1-1  | {'loss': 1.7568, 'grad_norm': 12.413297653198242, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 03:29:35 server-1   | INFO :      
2025-05-22 03:00:45 client1-1  | {'loss': 1.6057, 'grad_norm': 10.665051460266113, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 02:59:41 client2-1  | {'loss': 1.7377, 'grad_norm': 10.843364715576172, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 02:59:56 client2-1  | {'loss': 1.4688, 'grad_norm': 10.508099555969238, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 03:00:17 client2-1  | {'loss': 1.6746, 'grad_norm': 10.373340606689453, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 03:01:07 client1-1  | {'loss': 1.8666, 'grad_norm': 11.707508087158203, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 03:00:32 client2-1  | {'loss': 1.8402, 'grad_norm': 16.581647872924805, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 03:01:22 client1-1  | {'loss': 1.6814, 'grad_norm': 9.51572322845459, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 03:29:35 server-1   | INFO :      [ROUND 4]
2025-05-22 03:29:35 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 03:41:00 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 03:41:17 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 03:00:47 client2-1  | {'loss': 1.7317, 'grad_norm': 12.840420722961426, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 03:01:02 client2-1  | {'loss': 1.9635, 'grad_norm': 11.064619064331055, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 03:01:24 client2-1  | {'loss': 1.6605, 'grad_norm': 10.158869743347168, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 03:41:40 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 03:01:38 client1-1  | {'loss': 1.683, 'grad_norm': 11.066122055053711, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 03:41:40 server-1   | INFO :      
2025-05-22 03:41:40 server-1   | INFO :      [ROUND 5]
2025-05-22 03:41:40 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 03:53:10 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 03:53:23 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 03:53:48 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 03:53:48 server-1   | INFO :      
2025-05-22 03:01:40 client2-1  | {'loss': 1.4202, 'grad_norm': 10.065629959106445, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 03:01:55 client2-1  | {'loss': 1.7047, 'grad_norm': 10.86286449432373, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 03:02:10 client2-1  | {'loss': 1.5999, 'grad_norm': 8.865863800048828, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 03:02:25 client2-1  | {'loss': 1.8553, 'grad_norm': 10.823419570922852, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 03:02:47 client2-1  | {'loss': 1.5606, 'grad_norm': 9.507036209106445, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 03:03:02 client2-1  | {'loss': 1.7611, 'grad_norm': 10.144698143005371, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 03:53:48 server-1   | INFO :      [ROUND 6]
2025-05-22 03:53:48 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 03:03:17 client2-1  | {'loss': 1.8103, 'grad_norm': 11.94345474243164, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 03:03:38 client2-1  | {'loss': 1.6487, 'grad_norm': 10.835058212280273, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 03:03:54 client2-1  | {'loss': 1.7338, 'grad_norm': 11.304920196533203, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 03:04:09 client2-1  | {'loss': 1.7835, 'grad_norm': 9.872532844543457, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 03:04:18 client2-1  | {'loss': 1.9036, 'grad_norm': 13.281925201416016, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 04:05:13 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 03:04:20 client2-1  | {'loss': 1.7048, 'grad_norm': 13.107969284057617, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 03:01:53 client1-1  | {'loss': 1.7484, 'grad_norm': 13.485047340393066, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 03:04:20 client2-1  | {'train_runtime': 697.1145, 'train_samples_per_second': 1.148, 'train_steps_per_second': 0.574, 'train_loss': 1.9245592188835143, 'epoch': 1.0}
2025-05-22 03:04:25 client2-1  | INFO :      Sent reply
2025-05-22 03:04:49 client2-1  | INFO :      
2025-05-22 04:05:26 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 04:05:58 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 03:04:49 client2-1  | INFO :      Received: evaluate message 8c267b9d-2902-425b-9c2c-8872680ea893
2025-05-22 03:05:05 client2-1  | {'eval_loss': 1.5439304113388062, 'eval_runtime': 13.3418, 'eval_samples_per_second': 14.991, 'eval_steps_per_second': 1.874, 'epoch': 1.0}
2025-05-22 03:05:05 client2-1  | INFO :      Sent reply
2025-05-22 04:05:58 server-1   | INFO :      
2025-05-22 04:05:58 server-1   | INFO :      [ROUND 7]
2025-05-22 04:05:58 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 02:52:17 client3-1  | 
2025-05-22 02:52:17 client3-1  | $ flower-supernode --help
2025-05-22 02:52:17 client3-1  | 
2025-05-22 02:52:17 client3-1  | Using `start_client()` is deprecated.
2025-05-22 02:52:17 client3-1  | 
2025-05-22 03:05:14 client2-1  | INFO :      
2025-05-22 03:05:14 client2-1  | INFO :      Received: train message 0ad7ae87-224d-4ce5-bf01-390efd2ccd17
2025-05-22 03:05:38 client2-1  | {'loss': 1.4672, 'grad_norm': 11.621964454650879, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 04:17:36 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 04:17:48 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 02:52:17 client3-1  |             This is a deprecated feature. It will be removed
2025-05-22 03:02:14 client1-1  | {'loss': 1.7606, 'grad_norm': 10.172080039978027, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 02:52:17 client3-1  |             entirely in future versions of Flower.
2025-05-22 04:18:24 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 02:52:17 client3-1  |         
2025-05-22 04:18:24 server-1   | INFO :      
2025-05-22 02:52:40 client3-1  | INFO :      
2025-05-22 04:18:24 server-1   | INFO :      [ROUND 8]
2025-05-22 03:05:53 client2-1  | {'loss': 1.4058, 'grad_norm': 9.913310050964355, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 03:02:29 client1-1  | {'loss': 1.7487, 'grad_norm': 11.935487747192383, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 03:02:45 client1-1  | {'loss': 1.7269, 'grad_norm': 10.208909034729004, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 02:52:40 client3-1  | INFO :      Received: train message db3de58e-886e-4476-9f16-5473676be1e2
2025-05-22 02:53:09 client3-1  | {'loss': 4.0615, 'grad_norm': 16.10883903503418, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 02:53:23 client3-1  | {'loss': 2.8319, 'grad_norm': 12.21083927154541, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 02:53:38 client3-1  | {'loss': 2.3002, 'grad_norm': 13.953415870666504, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 03:06:14 client2-1  | {'loss': 1.4511, 'grad_norm': 10.317795753479004, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 03:06:29 client2-1  | {'loss': 1.5818, 'grad_norm': 15.121441841125488, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 03:06:44 client2-1  | {'loss': 1.6655, 'grad_norm': 8.584493637084961, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 02:53:54 client3-1  | {'loss': 2.3912, 'grad_norm': 15.733482360839844, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 03:06:59 client2-1  | {'loss': 1.5462, 'grad_norm': 8.845693588256836, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 03:07:20 client2-1  | {'loss': 1.3243, 'grad_norm': 8.826373100280762, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 04:18:24 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 04:29:48 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 04:30:02 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 04:30:38 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 03:03:00 client1-1  | {'loss': 1.7094, 'grad_norm': 10.087193489074707, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 03:03:21 client1-1  | {'loss': 1.7197, 'grad_norm': 9.899169921875, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 03:07:35 client2-1  | {'loss': 1.3821, 'grad_norm': 10.217155456542969, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 02:54:15 client3-1  | {'loss': 1.9498, 'grad_norm': 11.488936424255371, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 03:03:36 client1-1  | {'loss': 1.6382, 'grad_norm': 10.961466789245605, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 04:30:38 server-1   | INFO :      
2025-05-22 03:07:50 client2-1  | {'loss': 1.482, 'grad_norm': 8.693296432495117, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 02:54:30 client3-1  | {'loss': 1.8618, 'grad_norm': 9.735570907592773, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 03:08:05 client2-1  | {'loss': 1.4287, 'grad_norm': 11.122725486755371, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 03:08:26 client2-1  | {'loss': 1.4658, 'grad_norm': 10.445982933044434, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 02:54:45 client3-1  | {'loss': 2.1903, 'grad_norm': 10.279366493225098, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 04:30:38 server-1   | INFO :      [ROUND 9]
2025-05-22 02:55:00 client3-1  | {'loss': 2.1042, 'grad_norm': 10.596460342407227, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 03:08:42 client2-1  | {'loss': 1.367, 'grad_norm': 10.810348510742188, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 02:55:16 client3-1  | {'loss': 2.4082, 'grad_norm': 10.743971824645996, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 03:08:56 client2-1  | {'loss': 1.4927, 'grad_norm': 8.08050537109375, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 02:55:37 client3-1  | {'loss': 2.1245, 'grad_norm': 10.02277946472168, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 03:03:51 client1-1  | {'loss': 1.666, 'grad_norm': 9.452949523925781, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 02:55:53 client3-1  | {'loss': 1.9188, 'grad_norm': 8.90572452545166, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 03:04:07 client1-1  | {'loss': 1.6439, 'grad_norm': 10.206369400024414, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 02:56:08 client3-1  | {'loss': 1.8609, 'grad_norm': 11.491408348083496, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 03:04:07 client1-1  | {'train_runtime': 684.0463, 'train_samples_per_second': 1.17, 'train_steps_per_second': 0.585, 'train_loss': 1.9183701372146607, 'epoch': 1.0}
2025-05-22 02:56:23 client3-1  | {'loss': 2.103, 'grad_norm': 11.399720191955566, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 03:04:18 client1-1  | INFO :      Sent reply
2025-05-22 02:56:45 client3-1  | {'loss': 2.0528, 'grad_norm': 12.650108337402344, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 02:57:00 client3-1  | {'loss': 1.6948, 'grad_norm': 12.05008316040039, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 02:57:15 client3-1  | {'loss': 1.7705, 'grad_norm': 10.116246223449707, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 03:09:11 client2-1  | {'loss': 1.478, 'grad_norm': 11.798114776611328, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 03:09:33 client2-1  | {'loss': 1.3149, 'grad_norm': 8.916868209838867, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 03:09:47 client2-1  | {'loss': 1.438, 'grad_norm': 9.392560958862305, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 03:10:02 client2-1  | {'loss': 1.5623, 'grad_norm': 9.97701644897461, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 03:10:18 client2-1  | {'loss': 1.5205, 'grad_norm': 8.968749046325684, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 03:04:49 client1-1  | INFO :      
2025-05-22 03:04:49 client1-1  | INFO :      Received: evaluate message 15142fb7-3b29-4d9b-80b1-05af400671e1
2025-05-22 03:10:33 client2-1  | {'loss': 1.3786, 'grad_norm': 11.225712776184082, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 03:10:54 client2-1  | {'loss': 1.486, 'grad_norm': 8.549105644226074, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 03:11:09 client2-1  | {'loss': 1.5212, 'grad_norm': 12.105982780456543, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 03:11:24 client2-1  | {'loss': 1.3754, 'grad_norm': 9.555855751037598, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 03:11:46 client2-1  | {'loss': 1.1928, 'grad_norm': 8.726128578186035, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 02:57:30 client3-1  | {'loss': 1.7833, 'grad_norm': 10.34613037109375, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 03:05:07 client1-1  | {'eval_loss': 1.5775872468948364, 'eval_runtime': 15.2945, 'eval_samples_per_second': 13.077, 'eval_steps_per_second': 1.635, 'epoch': 1.0}
2025-05-22 03:12:01 client2-1  | {'loss': 1.3592, 'grad_norm': 9.593132972717285, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 03:05:07 client1-1  | INFO :      Sent reply
2025-05-22 03:05:12 client1-1  | INFO :      
2025-05-22 03:05:12 client1-1  | INFO :      Received: train message 7834761c-01d5-42b1-8e37-4d5e67e58205
2025-05-22 03:05:32 client1-1  | {'loss': 1.647, 'grad_norm': 11.160709381103516, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 03:12:16 client2-1  | {'loss': 1.5031, 'grad_norm': 14.083809852600098, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 02:57:52 client3-1  | {'loss': 1.6629, 'grad_norm': 13.222564697265625, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 03:05:47 client1-1  | {'loss': 1.3738, 'grad_norm': 10.682819366455078, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 02:58:07 client3-1  | {'loss': 1.8062, 'grad_norm': 12.866288185119629, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 02:58:21 client3-1  | {'loss': 1.7253, 'grad_norm': 8.873250007629395, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 02:58:36 client3-1  | {'loss': 1.7638, 'grad_norm': 10.86911392211914, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 03:06:02 client1-1  | {'loss': 1.3783, 'grad_norm': 8.900406837463379, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 04:30:38 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 04:42:08 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 04:42:20 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 02:58:58 client3-1  | {'loss': 1.8941, 'grad_norm': 11.081997871398926, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 02:59:13 client3-1  | {'loss': 1.6587, 'grad_norm': 11.474705696105957, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 02:59:29 client3-1  | {'loss': 1.6752, 'grad_norm': 8.671384811401367, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 04:42:46 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 03:12:31 client2-1  | {'loss': 1.4317, 'grad_norm': 11.347893714904785, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 03:12:46 client2-1  | {'loss': 1.6504, 'grad_norm': 9.648622512817383, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 02:59:50 client3-1  | {'loss': 1.7202, 'grad_norm': 8.654659271240234, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 03:00:06 client3-1  | {'loss': 1.8262, 'grad_norm': 10.658717155456543, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 03:00:21 client3-1  | {'loss': 1.5809, 'grad_norm': 9.499445915222168, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 03:00:42 client3-1  | {'loss': 1.5716, 'grad_norm': 10.190515518188477, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 04:42:46 server-1   | INFO :      
2025-05-22 04:42:46 server-1   | INFO :      [ROUND 10]
2025-05-22 04:42:46 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 03:06:17 client1-1  | {'loss': 1.7134, 'grad_norm': 14.03830337524414, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 03:06:39 client1-1  | {'loss': 1.62, 'grad_norm': 9.120502471923828, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 03:06:54 client1-1  | {'loss': 1.541, 'grad_norm': 8.176045417785645, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 03:13:07 client2-1  | {'loss': 1.4257, 'grad_norm': 9.261045455932617, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 03:07:09 client1-1  | {'loss': 1.4996, 'grad_norm': 13.543770790100098, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 04:54:18 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 04:54:30 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 04:54:56 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 03:00:57 client3-1  | {'loss': 1.7336, 'grad_norm': 10.618474006652832, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 04:54:56 server-1   | INFO :      
2025-05-22 03:07:24 client1-1  | {'loss': 1.3767, 'grad_norm': 11.98255443572998, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 04:54:56 server-1   | INFO :      [ROUND 11]
2025-05-22 03:07:45 client1-1  | {'loss': 1.4243, 'grad_norm': 9.368729591369629, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 03:01:12 client3-1  | {'loss': 1.8006, 'grad_norm': 10.167034149169922, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 03:13:22 client2-1  | {'loss': 1.1835, 'grad_norm': 9.693289756774902, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 03:01:35 client3-1  | {'loss': 1.6933, 'grad_norm': 8.898575782775879, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 04:54:56 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 03:08:00 client1-1  | {'loss': 1.3603, 'grad_norm': 8.19627857208252, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 05:06:29 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 03:13:38 client2-1  | {'loss': 1.4425, 'grad_norm': 7.887460231781006, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 03:13:53 client2-1  | {'loss': 1.3694, 'grad_norm': 7.49363899230957, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 03:14:14 client2-1  | {'loss': 1.6042, 'grad_norm': 9.908753395080566, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 03:14:29 client2-1  | {'loss': 1.3616, 'grad_norm': 10.161393165588379, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 03:01:50 client3-1  | {'loss': 1.6453, 'grad_norm': 9.754923820495605, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 03:14:44 client2-1  | {'loss': 1.5343, 'grad_norm': 9.71517562866211, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 03:14:58 client2-1  | {'loss': 1.6061, 'grad_norm': 9.13164234161377, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 03:02:05 client3-1  | {'loss': 1.8627, 'grad_norm': 14.828452110290527, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 03:15:13 client2-1  | {'loss': 1.4732, 'grad_norm': 11.505690574645996, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 03:02:20 client3-1  | {'loss': 1.6842, 'grad_norm': 10.391336441040039, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 05:06:43 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 03:15:34 client2-1  | {'loss': 1.5204, 'grad_norm': 10.255447387695312, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 05:07:18 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 05:07:18 server-1   | INFO :      
2025-05-22 03:02:42 client3-1  | {'loss': 1.5491, 'grad_norm': 14.596427917480469, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 03:15:49 client2-1  | {'loss': 1.5219, 'grad_norm': 9.451262474060059, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 05:07:18 server-1   | INFO :      [ROUND 12]
2025-05-22 03:02:57 client3-1  | {'loss': 1.8291, 'grad_norm': 9.760106086730957, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 03:03:12 client3-1  | {'loss': 1.7143, 'grad_norm': 12.596563339233398, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 03:03:27 client3-1  | {'loss': 1.6564, 'grad_norm': 11.705912590026855, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 05:07:18 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 05:18:51 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 03:16:04 client2-1  | {'loss': 1.5108, 'grad_norm': 9.916470527648926, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 03:16:19 client2-1  | {'loss': 1.0456, 'grad_norm': 8.58272933959961, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 03:03:48 client3-1  | {'loss': 1.7945, 'grad_norm': 11.735565185546875, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 03:16:19 client2-1  | {'train_runtime': 663.2885, 'train_samples_per_second': 1.206, 'train_steps_per_second': 0.603, 'train_loss': 1.446790645122528, 'epoch': 1.0}
2025-05-22 03:04:04 client3-1  | {'loss': 1.5245, 'grad_norm': 12.576373100280762, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 05:19:08 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 05:19:39 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 05:19:39 server-1   | INFO :      
2025-05-22 03:16:31 client2-1  | INFO :      Sent reply
2025-05-22 03:04:04 client3-1  | {'train_runtime': 681.826, 'train_samples_per_second': 1.172, 'train_steps_per_second': 0.587, 'train_loss': 1.9195148015022279, 'epoch': 1.0}
2025-05-22 03:04:17 client3-1  | INFO :      Sent reply
2025-05-22 03:04:47 client3-1  | INFO :      
2025-05-22 03:04:47 client3-1  | INFO :      Received: evaluate message ddea8623-8b6c-4d9b-a73c-25e191dcc882
2025-05-22 03:05:02 client3-1  | {'eval_loss': 1.6032986640930176, 'eval_runtime': 12.9013, 'eval_samples_per_second': 15.502, 'eval_steps_per_second': 1.938, 'epoch': 1.0}
2025-05-22 03:08:15 client1-1  | {'loss': 1.4892, 'grad_norm': 11.304689407348633, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 03:05:02 client3-1  | INFO :      Sent reply
2025-05-22 03:17:01 client2-1  | INFO :      
2025-05-22 05:19:39 server-1   | INFO :      [ROUND 13]
2025-05-22 05:19:39 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 05:31:16 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 05:31:32 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 03:17:01 client2-1  | INFO :      Received: evaluate message 34fc3301-0757-40a6-9a79-1dd2f311ae8b
2025-05-22 03:05:15 client3-1  | INFO :      
2025-05-22 03:05:15 client3-1  | INFO :      Received: train message 85760c90-d510-4e1c-9176-ef50439aba51
2025-05-22 03:05:43 client3-1  | {'loss': 1.3855, 'grad_norm': 8.284363746643066, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 03:06:04 client3-1  | {'loss': 1.7098, 'grad_norm': 9.199067115783691, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 03:06:19 client3-1  | {'loss': 1.4798, 'grad_norm': 11.290075302124023, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 05:32:01 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 05:32:01 server-1   | INFO :      
2025-05-22 03:17:12 client2-1  | {'eval_loss': 1.4930474758148193, 'eval_runtime': 8.3711, 'eval_samples_per_second': 23.892, 'eval_steps_per_second': 2.986, 'epoch': 1.0}
2025-05-22 03:17:12 client2-1  | INFO :      Sent reply
2025-05-22 03:17:20 client2-1  | INFO :      
2025-05-22 03:17:20 client2-1  | INFO :      Received: train message 0aca80d5-7c1e-4eaf-9724-479df6f35627
2025-05-22 03:08:30 client1-1  | {'loss': 1.4448, 'grad_norm': 9.672789573669434, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 03:08:51 client1-1  | {'loss': 1.4477, 'grad_norm': 10.925454139709473, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 03:09:06 client1-1  | {'loss': 1.5402, 'grad_norm': 11.763421058654785, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 03:09:21 client1-1  | {'loss': 1.3708, 'grad_norm': 10.117344856262207, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 03:17:47 client2-1  | {'loss': 1.0505, 'grad_norm': 10.724003791809082, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 03:18:02 client2-1  | {'loss': 1.0459, 'grad_norm': 7.905000686645508, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 03:18:17 client2-1  | {'loss': 1.1107, 'grad_norm': 8.591865539550781, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 03:18:32 client2-1  | {'loss': 1.2365, 'grad_norm': 10.334179878234863, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 03:06:34 client3-1  | {'loss': 1.5782, 'grad_norm': 10.520550727844238, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 03:06:49 client3-1  | {'loss': 1.3708, 'grad_norm': 10.671099662780762, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 03:07:10 client3-1  | {'loss': 1.3021, 'grad_norm': 7.620392322540283, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 03:09:36 client1-1  | {'loss': 1.406, 'grad_norm': 9.183019638061523, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 03:18:53 client2-1  | {'loss': 1.3078, 'grad_norm': 8.499587059020996, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 03:09:57 client1-1  | {'loss': 1.3815, 'grad_norm': 11.7588472366333, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 03:07:25 client3-1  | {'loss': 1.6081, 'grad_norm': 9.614666938781738, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 03:19:08 client2-1  | {'loss': 1.2461, 'grad_norm': 7.363776683807373, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 03:19:23 client2-1  | {'loss': 1.0878, 'grad_norm': 8.7218599319458, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 03:19:38 client2-1  | {'loss': 1.1375, 'grad_norm': 10.339544296264648, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 03:19:59 client2-1  | {'loss': 1.2325, 'grad_norm': 7.733646869659424, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 03:07:40 client3-1  | {'loss': 1.5317, 'grad_norm': 7.989253997802734, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 03:07:55 client3-1  | {'loss': 1.8065, 'grad_norm': 8.864545822143555, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 03:08:17 client3-1  | {'loss': 1.5785, 'grad_norm': 9.55676555633545, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 03:08:32 client3-1  | {'loss': 1.4315, 'grad_norm': 7.968244552612305, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 03:08:47 client3-1  | {'loss': 1.4657, 'grad_norm': 10.93181324005127, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 05:32:01 server-1   | INFO :      [ROUND 14]
2025-05-22 03:09:02 client3-1  | {'loss': 1.6235, 'grad_norm': 9.671987533569336, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 05:32:01 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 05:43:37 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 03:09:16 client3-1  | {'loss': 1.5633, 'grad_norm': 10.972016334533691, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 03:09:38 client3-1  | {'loss': 1.2954, 'grad_norm': 10.751559257507324, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 03:20:14 client2-1  | {'loss': 1.1498, 'grad_norm': 9.872336387634277, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 03:09:53 client3-1  | {'loss': 1.3833, 'grad_norm': 8.716779708862305, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 05:43:52 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 03:10:08 client3-1  | {'loss': 1.3952, 'grad_norm': 8.962336540222168, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 05:44:18 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 03:10:23 client3-1  | {'loss': 1.3019, 'grad_norm': 11.71338176727295, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 05:44:18 server-1   | INFO :      
2025-05-22 03:10:44 client3-1  | {'loss': 1.4009, 'grad_norm': 12.458683013916016, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 03:10:12 client1-1  | {'loss': 1.3993, 'grad_norm': 11.073328971862793, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 03:10:27 client1-1  | {'loss': 1.4303, 'grad_norm': 11.881908416748047, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 03:10:42 client1-1  | {'loss': 1.4008, 'grad_norm': 8.162652015686035, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 03:11:04 client1-1  | {'loss': 1.3223, 'grad_norm': 11.030926704406738, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 03:20:30 client2-1  | {'loss': 1.19, 'grad_norm': 8.324219703674316, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 03:10:59 client3-1  | {'loss': 1.3705, 'grad_norm': 8.624778747558594, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 03:11:19 client1-1  | {'loss': 1.4345, 'grad_norm': 8.781839370727539, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 03:11:34 client1-1  | {'loss': 1.4258, 'grad_norm': 11.349958419799805, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 03:11:49 client1-1  | {'loss': 1.4029, 'grad_norm': 9.380091667175293, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 03:11:14 client3-1  | {'loss': 1.3952, 'grad_norm': 10.315844535827637, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 03:11:29 client3-1  | {'loss': 1.5392, 'grad_norm': 9.96065616607666, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 03:11:50 client3-1  | {'loss': 1.38, 'grad_norm': 10.832935333251953, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 03:12:10 client1-1  | {'loss': 1.2788, 'grad_norm': 9.528754234313965, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 03:12:25 client1-1  | {'loss': 1.4676, 'grad_norm': 12.981376647949219, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 03:12:40 client1-1  | {'loss': 1.4782, 'grad_norm': 13.324024200439453, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 03:12:06 client3-1  | {'loss': 1.383, 'grad_norm': 7.709106922149658, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 05:44:18 server-1   | INFO :      [ROUND 15]
2025-05-22 05:44:18 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 05:56:01 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 03:20:45 client2-1  | {'loss': 1.1169, 'grad_norm': 10.180153846740723, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 03:12:55 client1-1  | {'loss': 1.3429, 'grad_norm': 10.19138240814209, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 05:56:15 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 05:56:45 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 05:56:45 server-1   | INFO :      
2025-05-22 05:56:45 server-1   | INFO :      [ROUND 16]
2025-05-22 03:13:10 client1-1  | {'loss': 1.5577, 'grad_norm': 10.887007713317871, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 03:13:32 client1-1  | {'loss': 1.4408, 'grad_norm': 9.485527992248535, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 03:13:47 client1-1  | {'loss': 1.4766, 'grad_norm': 8.01565933227539, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 03:12:21 client3-1  | {'loss': 1.4395, 'grad_norm': 7.894287109375, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 03:12:36 client3-1  | {'loss': 1.5169, 'grad_norm': 8.753472328186035, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 03:12:57 client3-1  | {'loss': 1.3192, 'grad_norm': 7.579854488372803, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 05:56:45 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 06:08:18 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 06:08:31 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 03:21:00 client2-1  | {'loss': 1.2499, 'grad_norm': 9.299121856689453, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 06:09:03 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 03:14:02 client1-1  | {'loss': 1.5621, 'grad_norm': 13.115364074707031, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 03:14:17 client1-1  | {'loss': 1.5153, 'grad_norm': 9.457926750183105, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 03:14:38 client1-1  | {'loss': 1.5625, 'grad_norm': 12.173873901367188, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 03:14:53 client1-1  | {'loss': 1.531, 'grad_norm': 9.641097068786621, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 03:21:21 client2-1  | {'loss': 1.231, 'grad_norm': 9.9273099899292, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 03:15:08 client1-1  | {'loss': 1.5219, 'grad_norm': 9.302071571350098, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 03:13:12 client3-1  | {'loss': 1.3396, 'grad_norm': 9.2384672164917, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 06:09:03 server-1   | INFO :      
2025-05-22 03:21:36 client2-1  | {'loss': 1.0941, 'grad_norm': 9.16142749786377, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 03:21:51 client2-1  | {'loss': 1.2227, 'grad_norm': 8.644054412841797, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 03:22:06 client2-1  | {'loss': 1.3134, 'grad_norm': 9.912873268127441, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 03:22:27 client2-1  | {'loss': 1.2758, 'grad_norm': 9.53901481628418, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 03:13:28 client3-1  | {'loss': 1.4751, 'grad_norm': 10.475037574768066, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 03:15:23 client1-1  | {'loss': 1.4877, 'grad_norm': 8.8402099609375, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 03:13:43 client3-1  | {'loss': 1.5096, 'grad_norm': 9.72571849822998, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 03:22:42 client2-1  | {'loss': 1.1622, 'grad_norm': 9.890369415283203, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 06:09:03 server-1   | INFO :      [ROUND 17]
2025-05-22 03:15:44 client1-1  | {'loss': 1.3493, 'grad_norm': 9.375235557556152, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 03:13:58 client3-1  | {'loss': 1.4597, 'grad_norm': 8.936503410339355, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 03:14:19 client3-1  | {'loss': 1.4052, 'grad_norm': 9.154509544372559, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 03:14:34 client3-1  | {'loss': 1.6304, 'grad_norm': 13.943283081054688, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 03:22:57 client2-1  | {'loss': 1.2965, 'grad_norm': 8.616532325744629, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 03:14:49 client3-1  | {'loss': 1.4728, 'grad_norm': 9.820291519165039, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 03:15:04 client3-1  | {'loss': 1.3331, 'grad_norm': 8.818780899047852, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 03:15:59 client1-1  | {'loss': 1.2945, 'grad_norm': 7.883138179779053, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 03:23:13 client2-1  | {'loss': 1.3332, 'grad_norm': 11.563921928405762, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 03:23:28 client2-1  | {'loss': 1.2045, 'grad_norm': 9.779545783996582, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 03:23:49 client2-1  | {'loss': 1.0577, 'grad_norm': 8.853344917297363, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 03:24:04 client2-1  | {'loss': 1.203, 'grad_norm': 9.173492431640625, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 06:09:03 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 03:24:19 client2-1  | {'loss': 1.3007, 'grad_norm': 13.412745475769043, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 06:20:34 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 03:16:14 client1-1  | {'loss': 1.0109, 'grad_norm': 6.455909729003906, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 03:24:34 client2-1  | {'loss': 1.3001, 'grad_norm': 10.893522262573242, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 06:20:47 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 06:21:23 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 06:21:23 server-1   | INFO :      
2025-05-22 03:24:55 client2-1  | {'loss': 1.4727, 'grad_norm': 11.651850700378418, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 03:25:11 client2-1  | {'loss': 1.3007, 'grad_norm': 8.364358901977539, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 03:25:26 client2-1  | {'loss': 1.0798, 'grad_norm': 10.605146408081055, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 03:16:14 client1-1  | {'train_runtime': 660.7591, 'train_samples_per_second': 1.211, 'train_steps_per_second': 0.605, 'train_loss': 1.4427056217193603, 'epoch': 1.0}
2025-05-22 03:16:25 client1-1  | INFO :      Sent reply
2025-05-22 03:15:25 client3-1  | {'loss': 1.6298, 'grad_norm': 9.387588500976562, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 03:15:40 client3-1  | {'loss': 1.5506, 'grad_norm': 11.139742851257324, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 06:21:23 server-1   | INFO :      [ROUND 18]
2025-05-22 03:15:54 client3-1  | {'loss': 1.4192, 'grad_norm': 10.449588775634766, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 03:25:41 client2-1  | {'loss': 1.3556, 'grad_norm': 7.899932384490967, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 03:16:09 client3-1  | {'loss': 1.3572, 'grad_norm': 8.14300537109375, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 03:17:01 client1-1  | INFO :      
2025-05-22 03:17:01 client1-1  | INFO :      Received: evaluate message 5df3da5f-866a-45ca-8350-b263927beabd
2025-05-22 03:17:11 client1-1  | {'eval_loss': 1.5228842496871948, 'eval_runtime': 8.8429, 'eval_samples_per_second': 22.617, 'eval_steps_per_second': 2.827, 'epoch': 1.0}
2025-05-22 03:26:02 client2-1  | {'loss': 1.2699, 'grad_norm': 7.759707927703857, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 03:17:11 client1-1  | INFO :      Sent reply
2025-05-22 03:26:17 client2-1  | {'loss': 1.5022, 'grad_norm': 10.47774600982666, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 03:17:21 client1-1  | INFO :      
2025-05-22 03:17:21 client1-1  | INFO :      Received: train message 6f4f91f7-1507-4180-b305-71fc3a4d4a6d
2025-05-22 03:17:52 client1-1  | {'loss': 1.201, 'grad_norm': 9.47472095489502, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 03:26:31 client2-1  | {'loss': 1.2872, 'grad_norm': 10.171001434326172, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 03:26:46 client2-1  | {'loss': 1.4284, 'grad_norm': 9.702286720275879, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 03:27:01 client2-1  | {'loss': 1.5284, 'grad_norm': 9.284719467163086, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 03:27:22 client2-1  | {'loss': 1.4038, 'grad_norm': 10.981888771057129, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 06:21:23 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 06:32:54 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 06:33:08 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 06:33:34 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 03:27:37 client2-1  | {'loss': 1.4588, 'grad_norm': 10.851125717163086, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 06:33:34 server-1   | INFO :      
2025-05-22 03:16:24 client3-1  | {'loss': 0.8728, 'grad_norm': 7.986700057983398, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 03:18:07 client1-1  | {'loss': 1.0339, 'grad_norm': 7.893786430358887, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 03:18:29 client1-1  | {'loss': 1.0513, 'grad_norm': 7.812380790710449, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 03:27:52 client2-1  | {'loss': 1.4637, 'grad_norm': 9.05362606048584, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 03:28:07 client2-1  | {'loss': 1.3684, 'grad_norm': 10.543018341064453, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 03:28:28 client2-1  | {'loss': 0.8382, 'grad_norm': 10.022226333618164, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 03:28:28 client2-1  | {'train_runtime': 666.6282, 'train_samples_per_second': 1.2, 'train_steps_per_second': 0.6, 'train_loss': 1.247869791984558, 'epoch': 1.0}
2025-05-22 06:33:34 server-1   | INFO :      [ROUND 19]
2025-05-22 03:18:44 client1-1  | {'loss': 1.3865, 'grad_norm': 10.533051490783691, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 06:33:34 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 06:45:05 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 06:45:19 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 06:45:51 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 06:45:51 server-1   | INFO :      
2025-05-22 03:18:58 client1-1  | {'loss': 1.289, 'grad_norm': 8.82099723815918, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 03:19:13 client1-1  | {'loss': 1.2102, 'grad_norm': 7.700779438018799, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 03:19:35 client1-1  | {'loss': 1.1613, 'grad_norm': 11.6248140335083, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 06:45:51 server-1   | INFO :      [ROUND 20]
2025-05-22 06:45:51 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 03:28:32 client2-1  | INFO :      Sent reply
2025-05-22 03:29:14 client2-1  | INFO :      
2025-05-22 03:29:14 client2-1  | INFO :      Received: evaluate message a1fb79eb-eb71-43a8-8845-530c5fefd619
2025-05-22 03:29:34 client2-1  | {'eval_loss': 1.4969979524612427, 'eval_runtime': 17.7617, 'eval_samples_per_second': 11.26, 'eval_steps_per_second': 1.408, 'epoch': 1.0}
2025-05-22 06:57:23 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 06:57:37 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 03:29:34 client2-1  | INFO :      Sent reply
2025-05-22 03:29:44 client2-1  | INFO :      
2025-05-22 03:19:50 client1-1  | {'loss': 1.1254, 'grad_norm': 9.404855728149414, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 03:20:05 client1-1  | {'loss': 1.1915, 'grad_norm': 8.763113021850586, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 06:58:08 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 03:16:24 client3-1  | {'train_runtime': 663.0568, 'train_samples_per_second': 1.205, 'train_steps_per_second': 0.603, 'train_loss': 1.4502693724632263, 'epoch': 1.0}
2025-05-22 06:58:08 server-1   | INFO :      
2025-05-22 03:20:20 client1-1  | {'loss': 1.1149, 'grad_norm': 7.552432537078857, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 03:20:42 client1-1  | {'loss': 1.2487, 'grad_norm': 10.580731391906738, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 03:20:57 client1-1  | {'loss': 1.2071, 'grad_norm': 8.867131233215332, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 03:21:12 client1-1  | {'loss': 1.199, 'grad_norm': 10.089376449584961, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 03:21:26 client1-1  | {'loss': 1.2787, 'grad_norm': 10.889470100402832, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 03:29:44 client2-1  | INFO :      Received: train message d1c48cfa-e968-4667-8bb4-67ea3b6754f8
2025-05-22 03:30:04 client2-1  | {'loss': 0.7822, 'grad_norm': 10.745818138122559, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 03:21:48 client1-1  | {'loss': 1.1741, 'grad_norm': 9.59406852722168, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 03:16:32 client3-1  | INFO :      Sent reply
2025-05-22 03:16:58 client3-1  | INFO :      
2025-05-22 03:16:58 client3-1  | INFO :      Received: evaluate message 6573ad40-5e1e-4bd0-ada1-0b51e5296e55
2025-05-22 03:17:02 client3-1  | {'eval_loss': 1.5524135828018188, 'eval_runtime': 2.8659, 'eval_samples_per_second': 69.785, 'eval_steps_per_second': 8.723, 'epoch': 1.0}
2025-05-22 03:17:02 client3-1  | INFO :      Sent reply
2025-05-22 03:30:25 client2-1  | {'loss': 0.7799, 'grad_norm': 6.390065670013428, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 03:17:21 client3-1  | INFO :      
2025-05-22 03:17:21 client3-1  | INFO :      Received: train message 7512f7c3-1b87-49a1-8cb3-2eb714993b01
2025-05-22 06:58:08 server-1   | INFO :      [ROUND 21]
2025-05-22 03:30:40 client2-1  | {'loss': 0.857, 'grad_norm': 7.8386969566345215, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 03:22:03 client1-1  | {'loss': 1.189, 'grad_norm': 8.8623685836792, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 03:17:49 client3-1  | {'loss': 0.9929, 'grad_norm': 8.189539909362793, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 03:18:04 client3-1  | {'loss': 1.2965, 'grad_norm': 7.926100730895996, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 03:18:19 client3-1  | {'loss': 1.1306, 'grad_norm': 9.040075302124023, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 03:30:55 client2-1  | {'loss': 1.0128, 'grad_norm': 10.640257835388184, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 03:18:34 client3-1  | {'loss': 1.2417, 'grad_norm': 9.724592208862305, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 03:18:49 client3-1  | {'loss': 1.0778, 'grad_norm': 10.283856391906738, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 03:31:16 client2-1  | {'loss': 1.0627, 'grad_norm': 7.17971658706665, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 03:19:10 client3-1  | {'loss': 1.0203, 'grad_norm': 7.75405216217041, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 03:19:25 client3-1  | {'loss': 1.2981, 'grad_norm': 8.681190490722656, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 03:19:40 client3-1  | {'loss': 1.2426, 'grad_norm': 7.657099723815918, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 03:31:32 client2-1  | {'loss': 0.9983, 'grad_norm': 8.242337226867676, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 03:19:55 client3-1  | {'loss': 1.5177, 'grad_norm': 8.60974407196045, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 03:20:17 client3-1  | {'loss': 1.3082, 'grad_norm': 9.394125938415527, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 03:20:32 client3-1  | {'loss': 1.1566, 'grad_norm': 7.698667526245117, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 03:20:47 client3-1  | {'loss': 1.1873, 'grad_norm': 10.329465866088867, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 06:58:08 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 03:21:02 client3-1  | {'loss': 1.3305, 'grad_norm': 9.85871696472168, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 03:21:17 client3-1  | {'loss': 1.3149, 'grad_norm': 10.225302696228027, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 03:22:18 client1-1  | {'loss': 1.1865, 'grad_norm': 11.457236289978027, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 07:09:40 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 03:31:47 client2-1  | {'loss': 0.8851, 'grad_norm': 8.75954818725586, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 03:32:01 client2-1  | {'loss': 0.9317, 'grad_norm': 8.160490036010742, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 03:32:22 client2-1  | {'loss': 1.004, 'grad_norm': 6.725818157196045, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 03:32:38 client2-1  | {'loss': 0.961, 'grad_norm': 8.610417366027832, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 03:32:53 client2-1  | {'loss': 1.0074, 'grad_norm': 8.629080772399902, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 03:22:33 client1-1  | {'loss': 1.1859, 'grad_norm': 9.757137298583984, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 03:22:48 client1-1  | {'loss': 1.2113, 'grad_norm': 9.535143852233887, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 03:23:10 client1-1  | {'loss': 1.2042, 'grad_norm': 7.220101833343506, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 07:09:52 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 03:33:07 client2-1  | {'loss': 0.9431, 'grad_norm': 9.213271141052246, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 03:33:29 client2-1  | {'loss': 1.0608, 'grad_norm': 7.422674179077148, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 03:23:25 client1-1  | {'loss': 1.1305, 'grad_norm': 10.093098640441895, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 03:33:44 client2-1  | {'loss': 1.044, 'grad_norm': 10.414329528808594, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 03:23:40 client1-1  | {'loss': 1.2386, 'grad_norm': 9.369654655456543, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 07:10:17 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 03:33:59 client2-1  | {'loss': 0.9407, 'grad_norm': 8.740107536315918, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 03:34:14 client2-1  | {'loss': 1.0705, 'grad_norm': 8.413872718811035, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 03:34:35 client2-1  | {'loss': 1.1855, 'grad_norm': 8.580184936523438, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 03:34:50 client2-1  | {'loss': 1.103, 'grad_norm': 8.329614639282227, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 03:35:05 client2-1  | {'loss': 1.0283, 'grad_norm': 9.3134765625, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 07:10:17 server-1   | INFO :      
2025-05-22 07:10:17 server-1   | INFO :      [ROUND 22]
2025-05-22 03:35:19 client2-1  | {'loss': 1.1554, 'grad_norm': 7.600265979766846, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 03:35:40 client2-1  | {'loss': 1.1863, 'grad_norm': 12.03229808807373, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 03:35:56 client2-1  | {'loss': 1.0615, 'grad_norm': 9.102723121643066, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 07:10:17 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 07:21:43 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 07:21:55 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 07:22:27 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 07:22:27 server-1   | INFO :      
2025-05-22 07:22:27 server-1   | INFO :      [ROUND 23]
2025-05-22 03:21:38 client3-1  | {'loss': 1.0912, 'grad_norm': 9.105813980102539, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 03:21:53 client3-1  | {'loss': 1.1697, 'grad_norm': 7.240048885345459, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 03:22:08 client3-1  | {'loss': 1.177, 'grad_norm': 9.264232635498047, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 03:36:11 client2-1  | {'loss': 0.9318, 'grad_norm': 7.891554355621338, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 03:36:32 client2-1  | {'loss': 1.0803, 'grad_norm': 9.118385314941406, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 03:23:55 client1-1  | {'loss': 1.2736, 'grad_norm': 12.054301261901855, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 03:24:17 client1-1  | {'loss': 1.2397, 'grad_norm': 9.211140632629395, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 03:24:31 client1-1  | {'loss': 1.1313, 'grad_norm': 9.481117248535156, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 03:24:46 client1-1  | {'loss': 1.3141, 'grad_norm': 12.320540428161621, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 03:25:01 client1-1  | {'loss': 1.3305, 'grad_norm': 13.17608642578125, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 03:25:23 client1-1  | {'loss': 1.2241, 'grad_norm': 9.637313842773438, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 03:36:47 client2-1  | {'loss': 1.2067, 'grad_norm': 12.495396614074707, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 03:37:02 client2-1  | {'loss': 1.1686, 'grad_norm': 11.603883743286133, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 03:37:17 client2-1  | {'loss': 1.3816, 'grad_norm': 9.9727201461792, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 03:37:32 client2-1  | {'loss': 1.1962, 'grad_norm': 8.584705352783203, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 07:22:27 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 07:34:04 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 07:34:24 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 03:25:38 client1-1  | {'loss': 1.3865, 'grad_norm': 10.295939445495605, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 03:25:53 client1-1  | {'loss': 1.332, 'grad_norm': 9.16084098815918, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 03:26:14 client1-1  | {'loss': 1.3702, 'grad_norm': 7.9352946281433105, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 03:26:29 client1-1  | {'loss': 1.4729, 'grad_norm': 13.1903715133667, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 03:22:23 client3-1  | {'loss': 1.1056, 'grad_norm': 9.967828750610352, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 03:22:45 client3-1  | {'loss': 1.1814, 'grad_norm': 12.63302993774414, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 03:23:00 client3-1  | {'loss': 1.1967, 'grad_norm': 7.912031173706055, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 03:23:15 client3-1  | {'loss': 1.2115, 'grad_norm': 8.883134841918945, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 03:23:30 client3-1  | {'loss': 1.3501, 'grad_norm': 11.086730003356934, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 03:37:53 client2-1  | {'loss': 0.9958, 'grad_norm': 9.758753776550293, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 03:23:52 client3-1  | {'loss': 1.203, 'grad_norm': 9.779545783996582, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 03:24:07 client3-1  | {'loss': 1.229, 'grad_norm': 7.548896312713623, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 03:24:22 client3-1  | {'loss': 1.2826, 'grad_norm': 8.553627967834473, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 07:34:54 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 03:24:37 client3-1  | {'loss': 1.3723, 'grad_norm': 7.47899055480957, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 03:26:43 client1-1  | {'loss': 1.417, 'grad_norm': 9.982102394104004, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 03:26:58 client1-1  | {'loss': 1.4856, 'grad_norm': 11.952077865600586, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 03:38:08 client2-1  | {'loss': 1.2726, 'grad_norm': 8.154908180236816, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 03:38:23 client2-1  | {'loss': 1.2016, 'grad_norm': 7.638808727264404, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 03:38:38 client2-1  | {'loss': 1.4445, 'grad_norm': 10.553571701049805, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 03:24:58 client3-1  | {'loss': 1.191, 'grad_norm': 7.786512851715088, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 03:39:00 client2-1  | {'loss': 1.2415, 'grad_norm': 10.535612106323242, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 07:34:54 server-1   | INFO :      
2025-05-22 03:27:20 client1-1  | {'loss': 1.4632, 'grad_norm': 9.327486038208008, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 03:27:35 client1-1  | {'loss': 1.4427, 'grad_norm': 9.231648445129395, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 03:27:50 client1-1  | {'loss': 1.4283, 'grad_norm': 8.2473726272583, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 03:28:04 client1-1  | {'loss': 1.2504, 'grad_norm': 9.729308128356934, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 03:28:25 client1-1  | {'loss': 1.1715, 'grad_norm': 7.571108341217041, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 03:28:36 client1-1  | {'loss': 0.8264, 'grad_norm': 7.410821914672852, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 03:28:36 client1-1  | {'train_runtime': 671.5372, 'train_samples_per_second': 1.191, 'train_steps_per_second': 0.596, 'train_loss': 1.244470372200012, 'epoch': 1.0}
2025-05-22 03:28:41 client1-1  | INFO :      Sent reply
2025-05-22 03:29:15 client1-1  | INFO :      
2025-05-22 03:25:13 client3-1  | {'loss': 1.2254, 'grad_norm': 8.333747863769531, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 03:39:15 client2-1  | {'loss': 1.3555, 'grad_norm': 9.980476379394531, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 03:29:15 client1-1  | INFO :      Received: evaluate message caa0bfcd-fc63-4015-b53c-2da378344520
2025-05-22 07:34:54 server-1   | INFO :      [ROUND 24]
2025-05-22 03:25:28 client3-1  | {'loss': 1.3404, 'grad_norm': 10.497883796691895, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 07:34:54 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 07:46:22 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 07:46:40 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 03:39:29 client2-1  | {'loss': 1.4863, 'grad_norm': 9.967082977294922, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 03:39:44 client2-1  | {'loss': 1.3722, 'grad_norm': 10.774121284484863, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 03:40:06 client2-1  | {'loss': 1.4283, 'grad_norm': 9.857935905456543, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 03:25:43 client3-1  | {'loss': 1.3689, 'grad_norm': 9.329981803894043, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 03:26:04 client3-1  | {'loss': 1.366, 'grad_norm': 8.298691749572754, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 03:26:19 client3-1  | {'loss': 1.3026, 'grad_norm': 7.969707012176514, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 03:26:34 client3-1  | {'loss': 1.5374, 'grad_norm': 13.193351745605469, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 07:47:06 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 07:47:06 server-1   | INFO :      
2025-05-22 07:47:06 server-1   | INFO :      [ROUND 25]
2025-05-22 07:47:06 server-1   | INFO :      configure_fit: strategy sampled 3 clients (out of 3)
2025-05-22 07:58:35 server-1   | INFO :      aggregate_fit: received 3 results and 0 failures
2025-05-22 03:40:20 client2-1  | {'loss': 1.4115, 'grad_norm': 8.029757499694824, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 03:40:35 client2-1  | {'loss': 1.3073, 'grad_norm': 10.344003677368164, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 03:40:48 client2-1  | {'loss': 0.7546, 'grad_norm': 8.849863052368164, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 03:29:35 client1-1  | {'eval_loss': 1.5287299156188965, 'eval_runtime': 17.2158, 'eval_samples_per_second': 11.617, 'eval_steps_per_second': 1.452, 'epoch': 1.0}
2025-05-22 03:29:35 client1-1  | INFO :      Sent reply
2025-05-22 03:29:46 client1-1  | INFO :      
2025-05-22 03:40:48 client2-1  | {'train_runtime': 662.3695, 'train_samples_per_second': 1.208, 'train_steps_per_second': 0.604, 'train_loss': 1.1074568367004394, 'epoch': 1.0}
2025-05-22 03:40:58 client2-1  | INFO :      Sent reply
2025-05-22 03:41:29 client2-1  | INFO :      
2025-05-22 07:58:53 server-1   | INFO :      configure_evaluate: strategy sampled 3 clients (out of 3)
2025-05-22 03:29:46 client1-1  | INFO :      Received: train message b014e2d9-a125-4a4f-b8c2-e1808a5cdb88
2025-05-22 03:30:14 client1-1  | {'loss': 0.8694, 'grad_norm': 9.225133895874023, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 03:41:29 client2-1  | INFO :      Received: evaluate message 80224a12-c865-454a-be76-63c83477233a
2025-05-22 03:41:39 client2-1  | {'eval_loss': 1.5082409381866455, 'eval_runtime': 8.8528, 'eval_samples_per_second': 22.592, 'eval_steps_per_second': 2.824, 'epoch': 1.0}
2025-05-22 03:41:39 client2-1  | INFO :      Sent reply
2025-05-22 03:41:49 client2-1  | INFO :      
2025-05-22 03:30:35 client1-1  | {'loss': 0.7715, 'grad_norm': 7.40709924697876, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 03:30:50 client1-1  | {'loss': 0.7967, 'grad_norm': 7.392979145050049, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 03:31:05 client1-1  | {'loss': 1.1053, 'grad_norm': 10.59188175201416, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 03:31:20 client1-1  | {'loss': 1.0232, 'grad_norm': 7.867016792297363, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 03:31:42 client1-1  | {'loss': 0.9816, 'grad_norm': 6.751035213470459, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 03:41:49 client2-1  | INFO :      Received: train message 29582121-69e1-4947-82fe-f42491f4059f
2025-05-22 03:42:10 client2-1  | {'loss': 0.579, 'grad_norm': 10.15245532989502, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 03:31:56 client1-1  | {'loss': 0.9423, 'grad_norm': 11.04062557220459, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 03:26:49 client3-1  | {'loss': 1.3775, 'grad_norm': 9.259941101074219, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 03:32:11 client1-1  | {'loss': 0.9451, 'grad_norm': 8.546830177307129, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 03:27:10 client3-1  | {'loss': 1.2706, 'grad_norm': 8.850354194641113, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 03:42:25 client2-1  | {'loss': 0.6141, 'grad_norm': 7.079106330871582, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 07:59:32 server-1   | INFO :      aggregate_evaluate: received 3 results and 0 failures
2025-05-22 03:27:25 client3-1  | {'loss': 1.5463, 'grad_norm': 9.359512329101562, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 03:27:40 client3-1  | {'loss': 1.479, 'grad_norm': 11.090845108032227, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 03:32:26 client1-1  | {'loss': 0.975, 'grad_norm': 8.260610580444336, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 07:59:32 server-1   | INFO :      
2025-05-22 03:27:55 client3-1  | {'loss': 1.3387, 'grad_norm': 9.525816917419434, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 03:42:40 client2-1  | {'loss': 0.654, 'grad_norm': 6.775204181671143, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 03:42:55 client2-1  | {'loss': 0.7999, 'grad_norm': 10.739690780639648, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 03:32:41 client1-1  | {'loss': 0.914, 'grad_norm': 6.398273944854736, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 03:43:16 client2-1  | {'loss': 0.855, 'grad_norm': 7.002531051635742, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 03:28:16 client3-1  | {'loss': 1.2387, 'grad_norm': 7.608558177947998, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 03:43:31 client2-1  | {'loss': 0.8206, 'grad_norm': 7.025851726531982, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 03:43:46 client2-1  | {'loss': 0.7249, 'grad_norm': 7.495525360107422, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 03:28:30 client3-1  | {'loss': 0.7232, 'grad_norm': 13.399928092956543, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 03:28:30 client3-1  | {'train_runtime': 666.9779, 'train_samples_per_second': 1.198, 'train_steps_per_second': 0.6, 'train_loss': 1.2497881412506104, 'epoch': 1.0}
2025-05-22 03:28:35 client3-1  | INFO :      Sent reply
2025-05-22 07:59:32 server-1   | INFO :      [SUMMARY]
2025-05-22 03:29:13 client3-1  | INFO :      
2025-05-22 07:59:32 server-1   | INFO :      Run finished 25 round(s) in 18433.85s
2025-05-22 03:29:13 client3-1  | INFO :      Received: evaluate message b66f2d13-dc72-4bc5-9d3f-d16dc12d2a78
2025-05-22 03:33:02 client1-1  | {'loss': 1.043, 'grad_norm': 8.913783073425293, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 03:33:17 client1-1  | {'loss': 1.0259, 'grad_norm': 8.704484939575195, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 03:33:32 client1-1  | {'loss': 1.016, 'grad_norm': 9.86728286743164, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 07:59:32 server-1   | INFO :      History (loss, distributed):
2025-05-22 03:44:01 client2-1  | {'loss': 0.7761, 'grad_norm': 7.995180130004883, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 03:33:54 client1-1  | {'loss': 1.0807, 'grad_norm': 11.426761627197266, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 03:34:09 client1-1  | {'loss': 0.9914, 'grad_norm': 10.131898880004883, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 03:34:24 client1-1  | {'loss': 1.0405, 'grad_norm': 8.414070129394531, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 03:29:32 client3-1  | {'eval_loss': 1.5572600364685059, 'eval_runtime': 17.1122, 'eval_samples_per_second': 11.688, 'eval_steps_per_second': 1.461, 'epoch': 1.0}
2025-05-22 03:34:38 client1-1  | {'loss': 1.0551, 'grad_norm': 12.615591049194336, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 03:44:22 client2-1  | {'loss': 0.8451, 'grad_norm': 7.344884395599365, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 03:44:37 client2-1  | {'loss': 0.8112, 'grad_norm': 9.143440246582031, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 03:44:51 client2-1  | {'loss': 0.8312, 'grad_norm': 10.672877311706543, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 03:45:06 client2-1  | {'loss': 0.7997, 'grad_norm': 9.309075355529785, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 03:45:28 client2-1  | {'loss': 0.9108, 'grad_norm': 7.5891337394714355, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 03:45:43 client2-1  | {'loss': 0.8979, 'grad_norm': 9.514679908752441, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 03:45:58 client2-1  | {'loss': 0.8169, 'grad_norm': 8.505941390991211, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 07:59:32 server-1   | INFO :      round 1: 1.5749293176600758
2025-05-22 07:59:32 server-1   | INFO :      round 2: 1.522771888869967
2025-05-22 03:46:13 client2-1  | {'loss': 0.9215, 'grad_norm': 7.724267482757568, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 03:29:32 client3-1  | INFO :      Sent reply
2025-05-22 07:59:32 server-1   | INFO :      round 3: 1.527652765759312
2025-05-22 03:29:44 client3-1  | INFO :      
2025-05-22 03:34:59 client1-1  | {'loss': 1.0362, 'grad_norm': 9.454634666442871, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 03:35:14 client1-1  | {'loss': 1.055, 'grad_norm': 9.252589225769043, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 03:29:44 client3-1  | INFO :      Received: train message b869c092-e017-40a4-859a-7eadd6495d46
2025-05-22 07:59:32 server-1   | INFO :      round 4: 1.541731739330387
2025-05-22 03:30:01 client3-1  | {'loss': 0.7075, 'grad_norm': 10.78114128112793, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 03:35:29 client1-1  | {'loss': 1.0691, 'grad_norm': 6.532131671905518, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 03:30:22 client3-1  | {'loss': 1.0129, 'grad_norm': 6.947569370269775, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 03:46:34 client2-1  | {'loss': 1.0415, 'grad_norm': 8.66726016998291, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 03:46:49 client2-1  | {'loss': 0.9694, 'grad_norm': 8.845479965209961, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 03:47:04 client2-1  | {'loss': 0.8826, 'grad_norm': 10.011902809143066, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 03:47:25 client2-1  | {'loss': 1.0158, 'grad_norm': 7.706692695617676, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 03:47:40 client2-1  | {'loss': 1.0659, 'grad_norm': 12.45691204071045, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 03:47:55 client2-1  | {'loss': 0.94, 'grad_norm': 9.29958438873291, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 07:59:32 server-1   | INFO :      round 5: 1.564621852969837
2025-05-22 07:59:32 server-1   | INFO :      round 6: 1.590900479972104
2025-05-22 03:48:10 client2-1  | {'loss': 0.8524, 'grad_norm': 7.947338581085205, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 07:59:32 server-1   | INFO :      round 7: 1.6226063099810584
2025-05-22 03:48:25 client2-1  | {'loss': 0.9885, 'grad_norm': 9.817882537841797, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 07:59:32 server-1   | INFO :      round 8: 1.655192135572036
2025-05-22 03:30:37 client3-1  | {'loss': 0.8819, 'grad_norm': 7.443437099456787, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 07:59:32 server-1   | INFO :      round 9: 1.6903519144293546
2025-05-22 03:48:46 client2-1  | {'loss': 1.0965, 'grad_norm': 10.988337516784668, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 03:35:44 client1-1  | {'loss': 0.9997, 'grad_norm': 8.576087951660156, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 03:49:01 client2-1  | {'loss': 1.0718, 'grad_norm': 11.290765762329102, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 03:49:16 client2-1  | {'loss': 1.2738, 'grad_norm': 10.801511764526367, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 03:36:05 client1-1  | {'loss': 1.113, 'grad_norm': 7.36740255355835, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 03:36:20 client1-1  | {'loss': 1.1346, 'grad_norm': 11.21074104309082, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 03:36:35 client1-1  | {'loss': 1.1394, 'grad_norm': 9.1912841796875, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 07:59:32 server-1   | INFO :      round 10: 1.7243181870118027
2025-05-22 03:30:52 client3-1  | {'loss': 0.9878, 'grad_norm': 11.207717895507812, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 03:36:50 client1-1  | {'loss': 1.0253, 'grad_norm': 8.856425285339355, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 03:49:31 client2-1  | {'loss': 1.1176, 'grad_norm': 7.859740734100342, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 07:59:32 server-1   | INFO :      round 11: 1.7581702328475566
2025-05-22 07:59:32 server-1   | INFO :      round 12: 1.7941164954498077
2025-05-22 07:59:32 server-1   | INFO :      round 13: 1.8249600193587172
2025-05-22 07:59:32 server-1   | INFO :      round 14: 1.8570891459332421
2025-05-22 07:59:32 server-1   | INFO :      round 15: 1.8875602625655747
2025-05-22 07:59:32 server-1   | INFO :      round 16: 1.9158220472396235
2025-05-22 07:59:32 server-1   | INFO :      round 17: 1.941645612832744
2025-05-22 03:31:07 client3-1  | {'loss': 0.8678, 'grad_norm': 9.369789123535156, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 03:31:22 client3-1  | {'loss': 0.8238, 'grad_norm': 7.365203380584717, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 07:59:32 server-1   | INFO :      round 18: 1.9728958695759253
2025-05-22 07:59:32 server-1   | INFO :      round 19: 1.999544963076656
2025-05-22 07:59:32 server-1   | INFO :      round 20: 2.0250761671120343
2025-05-22 07:59:32 server-1   | INFO :      round 21: 2.048735495287802
2025-05-22 03:37:11 client1-1  | {'loss': 1.2171, 'grad_norm': 12.617518424987793, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 03:37:26 client1-1  | {'loss': 1.2503, 'grad_norm': 11.023992538452148, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 03:37:41 client1-1  | {'loss': 1.1543, 'grad_norm': 7.460464000701904, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 03:37:56 client1-1  | {'loss': 1.2819, 'grad_norm': 10.181855201721191, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 07:59:32 server-1   | INFO :      round 22: 2.0730933506276537
2025-05-22 07:59:32 server-1   | INFO :      round 23: 2.097660274655074
2025-05-22 03:38:11 client1-1  | {'loss': 1.2562, 'grad_norm': 8.580158233642578, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 03:38:32 client1-1  | {'loss': 1.2927, 'grad_norm': 7.997170448303223, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 03:31:44 client3-1  | {'loss': 1.0651, 'grad_norm': 8.813553810119629, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 07:59:32 server-1   | INFO :      round 24: 2.1193735140011523
2025-05-22 03:49:53 client2-1  | {'loss': 0.9436, 'grad_norm': 8.563800811767578, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 03:31:59 client3-1  | {'loss': 1.0037, 'grad_norm': 6.823253154754639, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 03:38:47 client1-1  | {'loss': 1.4056, 'grad_norm': 14.409072875976562, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 03:39:03 client1-1  | {'loss': 1.3246, 'grad_norm': 9.875265121459961, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 03:39:17 client1-1  | {'loss': 1.4462, 'grad_norm': 13.57034969329834, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 03:39:39 client1-1  | {'loss': 1.4247, 'grad_norm': 9.48713493347168, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 07:59:32 server-1   | INFO :      round 25: 2.139343200822241
2025-05-22 07:59:32 server-1   | INFO :      
2025-05-22 03:39:54 client1-1  | {'loss': 1.3976, 'grad_norm': 10.499279975891113, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 03:40:08 client1-1  | {'loss': 1.3632, 'grad_norm': 8.202105522155762, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 03:32:13 client3-1  | {'loss': 1.2669, 'grad_norm': 8.844084739685059, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 03:32:28 client3-1  | {'loss': 1.1067, 'grad_norm': 8.267813682556152, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 03:32:50 client3-1  | {'loss': 0.9699, 'grad_norm': 7.576968193054199, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 03:40:23 client1-1  | {'loss': 1.2085, 'grad_norm': 9.253528594970703, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 03:40:45 client1-1  | {'loss': 1.0909, 'grad_norm': 7.429376125335693, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 03:40:54 client1-1  | {'loss': 0.7251, 'grad_norm': 6.349889755249023, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 03:40:54 client1-1  | {'train_runtime': 663.0025, 'train_samples_per_second': 1.207, 'train_steps_per_second': 0.603, 'train_loss': 1.099700655937195, 'epoch': 1.0}
2025-05-22 03:40:59 client1-1  | INFO :      Sent reply
2025-05-22 03:50:08 client2-1  | {'loss': 1.1883, 'grad_norm': 7.442605018615723, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 03:41:23 client1-1  | INFO :      
2025-05-22 03:33:05 client3-1  | {'loss': 1.0035, 'grad_norm': 9.61677360534668, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 03:33:20 client3-1  | {'loss': 1.1505, 'grad_norm': 8.0586576461792, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 03:41:23 client1-1  | INFO :      Received: evaluate message eda588a8-687d-40df-8d84-6879b00d6c10
2025-05-22 03:41:27 client1-1  | {'eval_loss': 1.5446887016296387, 'eval_runtime': 2.7989, 'eval_samples_per_second': 71.458, 'eval_steps_per_second': 8.932, 'epoch': 1.0}
2025-05-22 03:41:27 client1-1  | INFO :      Sent reply
2025-05-22 03:50:23 client2-1  | {'loss': 1.1417, 'grad_norm': 7.703106880187988, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 03:50:38 client2-1  | {'loss': 1.3639, 'grad_norm': 10.749201774597168, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 03:50:53 client2-1  | {'loss': 1.1929, 'grad_norm': 10.272165298461914, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 03:41:50 client1-1  | INFO :      
2025-05-22 03:41:50 client1-1  | INFO :      Received: train message bec71556-01a2-49f3-8c91-529b9e1f2116
2025-05-22 03:51:14 client2-1  | {'loss': 1.3157, 'grad_norm': 10.09622859954834, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 03:42:15 client1-1  | {'loss': 0.6459, 'grad_norm': 8.018078804016113, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 03:42:30 client1-1  | {'loss': 0.5853, 'grad_norm': 8.008131980895996, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 03:42:51 client1-1  | {'loss': 0.644, 'grad_norm': 6.514519691467285, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 03:43:07 client1-1  | {'loss': 0.9001, 'grad_norm': 9.074320793151855, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 03:33:35 client3-1  | {'loss': 1.1209, 'grad_norm': 9.38469409942627, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 03:43:22 client1-1  | {'loss': 0.8449, 'grad_norm': 7.83074951171875, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 03:33:56 client3-1  | {'loss': 0.923, 'grad_norm': 8.622087478637695, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 03:43:43 client1-1  | {'loss': 0.7917, 'grad_norm': 5.9170308113098145, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 03:43:58 client1-1  | {'loss': 0.746, 'grad_norm': 10.032169342041016, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 03:44:12 client1-1  | {'loss': 0.7586, 'grad_norm': 7.373441219329834, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 03:51:29 client2-1  | {'loss': 1.4598, 'grad_norm': 10.231918334960938, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 03:51:44 client2-1  | {'loss': 1.3512, 'grad_norm': 10.598756790161133, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 03:51:59 client2-1  | {'loss': 1.4057, 'grad_norm': 12.476358413696289, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 03:44:27 client1-1  | {'loss': 0.8152, 'grad_norm': 7.542665004730225, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 03:44:48 client1-1  | {'loss': 0.7734, 'grad_norm': 7.907934665679932, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 03:45:03 client1-1  | {'loss': 0.8955, 'grad_norm': 9.340985298156738, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 03:52:20 client2-1  | {'loss': 1.3727, 'grad_norm': 8.49595832824707, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 03:52:35 client2-1  | {'loss': 1.2281, 'grad_norm': 11.337867736816406, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 03:45:18 client1-1  | {'loss': 0.9053, 'grad_norm': 8.884627342224121, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 03:34:11 client3-1  | {'loss': 1.0059, 'grad_norm': 6.945544242858887, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 03:52:50 client2-1  | {'loss': 0.6324, 'grad_norm': 13.96932315826416, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 03:34:26 client3-1  | {'loss': 1.025, 'grad_norm': 9.420351028442383, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 03:34:41 client3-1  | {'loss': 0.9729, 'grad_norm': 9.637001037597656, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 03:45:33 client1-1  | {'loss': 0.8388, 'grad_norm': 10.22701644897461, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 03:45:55 client1-1  | {'loss': 0.9068, 'grad_norm': 10.536505699157715, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 03:46:10 client1-1  | {'loss': 0.8505, 'grad_norm': 9.290465354919434, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 03:46:24 client1-1  | {'loss': 0.9178, 'grad_norm': 8.64650821685791, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 03:46:39 client1-1  | {'loss': 0.9116, 'grad_norm': 11.639445304870605, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 03:46:54 client1-1  | {'loss': 0.9086, 'grad_norm': 8.925061225891113, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 03:47:15 client1-1  | {'loss': 0.9401, 'grad_norm': 9.669172286987305, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 03:52:50 client2-1  | {'train_runtime': 660.4489, 'train_samples_per_second': 1.211, 'train_steps_per_second': 0.606, 'train_loss': 0.9892451322078705, 'epoch': 1.0}
2025-05-22 03:47:30 client1-1  | {'loss': 0.9139, 'grad_norm': 5.811680793762207, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 03:53:06 client2-1  | INFO :      Sent reply
2025-05-22 03:53:37 client2-1  | INFO :      
2025-05-22 03:53:37 client2-1  | INFO :      Received: evaluate message dde89cb6-6640-4ce3-ae9e-e9f2e2db486c
2025-05-22 03:47:46 client1-1  | {'loss': 0.8897, 'grad_norm': 8.668384552001953, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 03:35:02 client3-1  | {'loss': 1.0414, 'grad_norm': 10.96429443359375, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 03:35:16 client3-1  | {'loss': 1.0428, 'grad_norm': 7.629044532775879, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 03:35:31 client3-1  | {'loss': 1.0783, 'grad_norm': 8.941947937011719, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 03:53:47 client2-1  | {'eval_loss': 1.5293735265731812, 'eval_runtime': 8.6951, 'eval_samples_per_second': 23.001, 'eval_steps_per_second': 2.875, 'epoch': 1.0}
2025-05-22 03:53:47 client2-1  | INFO :      Sent reply
2025-05-22 03:53:58 client2-1  | INFO :      
2025-05-22 03:53:58 client2-1  | INFO :      Received: train message 06f160cd-b84a-4291-827c-016bb9e06dee
2025-05-22 03:48:01 client1-1  | {'loss': 1.0065, 'grad_norm': 8.785676956176758, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 03:48:22 client1-1  | {'loss': 1.0285, 'grad_norm': 10.42609691619873, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 03:35:46 client3-1  | {'loss': 1.2144, 'grad_norm': 9.318751335144043, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 03:48:37 client1-1  | {'loss': 1.0344, 'grad_norm': 9.185033798217773, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 03:36:01 client3-1  | {'loss': 1.084, 'grad_norm': 9.829131126403809, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 03:54:24 client2-1  | {'loss': 0.4297, 'grad_norm': 9.074419975280762, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 03:48:52 client1-1  | {'loss': 0.9378, 'grad_norm': 9.817584991455078, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 03:54:46 client2-1  | {'loss': 0.4363, 'grad_norm': 7.746989727020264, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 03:49:07 client1-1  | {'loss': 1.0956, 'grad_norm': 10.104216575622559, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 03:49:28 client1-1  | {'loss': 1.1463, 'grad_norm': 11.791257858276367, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 03:55:01 client2-1  | {'loss': 0.5315, 'grad_norm': 6.157284259796143, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 03:55:16 client2-1  | {'loss': 0.6606, 'grad_norm': 8.761707305908203, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 03:49:43 client1-1  | {'loss': 1.0753, 'grad_norm': 8.16004753112793, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 03:49:58 client1-1  | {'loss': 1.2133, 'grad_norm': 9.605830192565918, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 03:50:13 client1-1  | {'loss': 1.1882, 'grad_norm': 7.811309337615967, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 03:36:22 client3-1  | {'loss': 1.1169, 'grad_norm': 7.313194274902344, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 03:50:28 client1-1  | {'loss': 1.2322, 'grad_norm': 7.861434459686279, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 03:50:43 client1-1  | {'loss': 1.3671, 'grad_norm': 13.960084915161133, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 03:51:05 client1-1  | {'loss': 1.282, 'grad_norm': 11.738847732543945, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 03:51:19 client1-1  | {'loss': 1.4028, 'grad_norm': 11.931346893310547, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 03:36:37 client3-1  | {'loss': 1.1631, 'grad_norm': 8.921624183654785, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 03:36:52 client3-1  | {'loss': 1.2521, 'grad_norm': 7.75391960144043, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 03:37:07 client3-1  | {'loss': 1.0859, 'grad_norm': 8.102466583251953, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 03:55:31 client2-1  | {'loss': 0.678, 'grad_norm': 6.597926616668701, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 03:37:28 client3-1  | {'loss': 1.1341, 'grad_norm': 8.359895706176758, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 03:55:52 client2-1  | {'loss': 0.6455, 'grad_norm': 6.427516460418701, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 03:37:43 client3-1  | {'loss': 1.2581, 'grad_norm': 10.943068504333496, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 03:56:07 client2-1  | {'loss': 0.5774, 'grad_norm': 8.425508499145508, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 03:56:21 client2-1  | {'loss': 0.649, 'grad_norm': 7.862107276916504, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 03:56:36 client2-1  | {'loss': 0.7139, 'grad_norm': 8.109131813049316, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 03:56:57 client2-1  | {'loss': 0.6818, 'grad_norm': 10.350933074951172, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 03:57:12 client2-1  | {'loss': 0.6996, 'grad_norm': 7.708732604980469, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 03:57:27 client2-1  | {'loss': 0.6602, 'grad_norm': 8.701167106628418, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 03:51:34 client1-1  | {'loss': 1.3668, 'grad_norm': 9.539220809936523, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 03:51:49 client1-1  | {'loss': 1.3768, 'grad_norm': 9.01377010345459, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 03:37:58 client3-1  | {'loss': 1.2863, 'grad_norm': 8.734464645385742, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 03:38:13 client3-1  | {'loss': 1.3053, 'grad_norm': 8.813963890075684, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 03:38:28 client3-1  | {'loss': 1.2287, 'grad_norm': 8.718414306640625, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 03:57:42 client2-1  | {'loss': 0.7621, 'grad_norm': 6.8020477294921875, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 03:57:57 client2-1  | {'loss': 0.7443, 'grad_norm': 8.607756614685059, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 03:58:19 client2-1  | {'loss': 0.6744, 'grad_norm': 7.395013332366943, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 03:58:33 client2-1  | {'loss': 0.8056, 'grad_norm': 7.676489353179932, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 03:38:49 client3-1  | {'loss': 1.4525, 'grad_norm': 12.996430397033691, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 03:39:04 client3-1  | {'loss': 1.3264, 'grad_norm': 9.971996307373047, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 03:52:04 client1-1  | {'loss': 1.3405, 'grad_norm': 9.468134880065918, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 03:52:25 client1-1  | {'loss': 1.1664, 'grad_norm': 8.91683292388916, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 03:52:40 client1-1  | {'loss': 1.0306, 'grad_norm': 8.111359596252441, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 03:52:55 client1-1  | {'loss': 0.6265, 'grad_norm': 6.704277515411377, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 03:58:48 client2-1  | {'loss': 0.9259, 'grad_norm': 9.92092227935791, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 03:52:55 client1-1  | {'train_runtime': 661.8186, 'train_samples_per_second': 1.209, 'train_steps_per_second': 0.604, 'train_loss': 0.982534853219986, 'epoch': 1.0}
2025-05-22 03:53:09 client1-1  | INFO :      Sent reply
2025-05-22 03:53:34 client1-1  | INFO :      
2025-05-22 03:53:34 client1-1  | INFO :      Received: evaluate message e6690809-3e4b-4c7e-8341-e4c3f02a5f77
2025-05-22 03:39:19 client3-1  | {'loss': 1.2376, 'grad_norm': 9.893365859985352, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 03:53:37 client1-1  | {'eval_loss': 1.5682134628295898, 'eval_runtime': 2.7629, 'eval_samples_per_second': 72.389, 'eval_steps_per_second': 9.049, 'epoch': 1.0}
2025-05-22 03:39:34 client3-1  | {'loss': 1.4956, 'grad_norm': 10.509055137634277, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 03:53:37 client1-1  | INFO :      Sent reply
2025-05-22 03:53:53 client1-1  | INFO :      
2025-05-22 03:39:49 client3-1  | {'loss': 1.4617, 'grad_norm': 11.941457748413086, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 03:40:04 client3-1  | {'loss': 1.3002, 'grad_norm': 8.97124195098877, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 03:40:25 client3-1  | {'loss': 1.1542, 'grad_norm': 7.2840189933776855, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 03:40:40 client3-1  | {'loss': 0.6328, 'grad_norm': 8.212138175964355, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 03:40:40 client3-1  | {'train_runtime': 653.2092, 'train_samples_per_second': 1.223, 'train_steps_per_second': 0.612, 'train_loss': 1.1061948943138122, 'epoch': 1.0}
2025-05-22 03:40:43 client3-1  | INFO :      Sent reply
2025-05-22 03:41:30 client3-1  | INFO :      
2025-05-22 03:41:30 client3-1  | INFO :      Received: evaluate message cfc19b7e-01c6-45c0-a666-702cd74fd2cb
2025-05-22 03:41:40 client3-1  | {'eval_loss': 1.572296142578125, 'eval_runtime': 8.2987, 'eval_samples_per_second': 24.1, 'eval_steps_per_second': 3.013, 'epoch': 1.0}
2025-05-22 03:41:40 client3-1  | INFO :      Sent reply
2025-05-22 03:59:03 client2-1  | {'loss': 0.8376, 'grad_norm': 9.022382736206055, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 03:53:53 client1-1  | INFO :      Received: train message 8f0c22b5-8515-470b-aebf-7846981cf5fe
2025-05-22 03:59:18 client2-1  | {'loss': 0.7837, 'grad_norm': 9.84921932220459, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 03:54:08 client1-1  | {'loss': 0.4643, 'grad_norm': 6.051705837249756, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 03:54:28 client1-1  | {'loss': 0.4244, 'grad_norm': 8.715009689331055, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 03:54:44 client1-1  | {'loss': 0.5157, 'grad_norm': 6.233948707580566, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 03:54:59 client1-1  | {'loss': 0.7148, 'grad_norm': 8.375984191894531, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 03:41:48 client3-1  | INFO :      
2025-05-22 03:55:20 client1-1  | {'loss': 0.6842, 'grad_norm': 7.555749893188477, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 03:59:39 client2-1  | {'loss': 0.9242, 'grad_norm': 7.76560115814209, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 03:41:48 client3-1  | INFO :      Received: train message 05ef7c22-6e80-4fc1-8545-d0c4e4238ec8
2025-05-22 03:59:54 client2-1  | {'loss': 0.9482, 'grad_norm': 11.3067045211792, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 03:42:13 client3-1  | {'loss': 0.4973, 'grad_norm': 5.992802143096924, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 03:42:28 client3-1  | {'loss': 0.7796, 'grad_norm': 6.8197832107543945, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 04:00:09 client2-1  | {'loss': 0.8322, 'grad_norm': 9.280844688415527, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 04:00:24 client2-1  | {'loss': 0.7592, 'grad_norm': 7.536642551422119, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 03:42:49 client3-1  | {'loss': 0.6809, 'grad_norm': 6.805571556091309, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 03:43:04 client3-1  | {'loss': 0.7721, 'grad_norm': 11.15544605255127, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 04:00:45 client2-1  | {'loss': 0.876, 'grad_norm': 8.801766395568848, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 04:01:00 client2-1  | {'loss': 1.0044, 'grad_norm': 11.230988502502441, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 03:43:19 client3-1  | {'loss': 0.7179, 'grad_norm': 8.761697769165039, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 03:43:34 client3-1  | {'loss': 0.6731, 'grad_norm': 5.889118671417236, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 03:43:55 client3-1  | {'loss': 0.8859, 'grad_norm': 8.405780792236328, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 04:01:15 client2-1  | {'loss': 1.0036, 'grad_norm': 11.208230972290039, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 03:55:35 client1-1  | {'loss': 0.6479, 'grad_norm': 5.566826343536377, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 04:01:30 client2-1  | {'loss': 1.1676, 'grad_norm': 10.635263442993164, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 04:01:51 client2-1  | {'loss': 1.0428, 'grad_norm': 8.950607299804688, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 04:02:06 client2-1  | {'loss': 0.8682, 'grad_norm': 11.0743408203125, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 03:44:10 client3-1  | {'loss': 0.8368, 'grad_norm': 6.907565593719482, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 04:02:21 client2-1  | {'loss': 1.136, 'grad_norm': 8.328631401062012, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 03:55:50 client1-1  | {'loss': 0.6143, 'grad_norm': 12.753217697143555, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 03:56:05 client1-1  | {'loss': 0.6259, 'grad_norm': 7.656210899353027, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 04:02:37 client2-1  | {'loss': 1.0722, 'grad_norm': 7.854382038116455, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 03:56:26 client1-1  | {'loss': 0.6683, 'grad_norm': 6.845555305480957, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 04:02:58 client2-1  | {'loss': 1.3208, 'grad_norm': 10.758722305297852, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 03:56:41 client1-1  | {'loss': 0.6316, 'grad_norm': 6.207173824310303, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 03:56:55 client1-1  | {'loss': 0.7582, 'grad_norm': 10.347219467163086, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 03:44:25 client3-1  | {'loss': 1.0806, 'grad_norm': 8.3257474899292, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 03:44:39 client3-1  | {'loss': 0.9147, 'grad_norm': 7.489445686340332, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 03:45:01 client3-1  | {'loss': 0.8018, 'grad_norm': 6.916040897369385, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 03:45:16 client3-1  | {'loss': 0.8515, 'grad_norm': 9.576347351074219, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 03:45:31 client3-1  | {'loss': 0.9741, 'grad_norm': 8.441532135009766, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 04:03:13 client2-1  | {'loss': 1.1495, 'grad_norm': 10.746772766113281, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 03:45:46 client3-1  | {'loss': 0.9896, 'grad_norm': 8.587411880493164, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 04:03:28 client2-1  | {'loss': 1.2679, 'grad_norm': 10.978026390075684, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 03:46:01 client3-1  | {'loss': 0.7953, 'grad_norm': 8.05888557434082, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 03:57:11 client1-1  | {'loss': 0.754, 'grad_norm': 8.130359649658203, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 03:57:32 client1-1  | {'loss': 0.7042, 'grad_norm': 8.29338264465332, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 03:57:47 client1-1  | {'loss': 0.7787, 'grad_norm': 11.545439720153809, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 03:58:02 client1-1  | {'loss': 0.7089, 'grad_norm': 10.401914596557617, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 03:46:22 client3-1  | {'loss': 0.8523, 'grad_norm': 6.857376575469971, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 03:46:37 client3-1  | {'loss': 0.8834, 'grad_norm': 8.65489387512207, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 03:46:51 client3-1  | {'loss': 0.8371, 'grad_norm': 9.254340171813965, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 03:47:06 client3-1  | {'loss': 0.9209, 'grad_norm': 11.963465690612793, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 03:47:28 client3-1  | {'loss': 0.9361, 'grad_norm': 7.243463516235352, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 04:03:43 client2-1  | {'loss': 1.4137, 'grad_norm': 11.36778736114502, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 03:47:43 client3-1  | {'loss': 0.9599, 'grad_norm': 8.278401374816895, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 03:47:58 client3-1  | {'loss': 1.0812, 'grad_norm': 9.692119598388672, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 03:48:13 client3-1  | {'loss': 0.9737, 'grad_norm': 9.304946899414062, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 03:58:23 client1-1  | {'loss': 0.7661, 'grad_norm': 7.622344493865967, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 03:58:38 client1-1  | {'loss': 0.7909, 'grad_norm': 11.244771957397461, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 03:58:53 client1-1  | {'loss': 0.8013, 'grad_norm': 9.515597343444824, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 03:59:08 client1-1  | {'loss': 0.8143, 'grad_norm': 9.473420143127441, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 03:59:29 client1-1  | {'loss': 0.8303, 'grad_norm': 6.653379440307617, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 03:48:34 client3-1  | {'loss': 1.0188, 'grad_norm': 7.121095657348633, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 03:48:49 client3-1  | {'loss': 1.0708, 'grad_norm': 9.323005676269531, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 03:59:44 client1-1  | {'loss': 0.8089, 'grad_norm': 10.646256446838379, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 03:59:59 client1-1  | {'loss': 0.925, 'grad_norm': 8.63025188446045, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 04:00:21 client1-1  | {'loss': 0.9225, 'grad_norm': 10.308167457580566, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 04:04:05 client2-1  | {'loss': 1.3328, 'grad_norm': 11.8305025100708, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 04:00:36 client1-1  | {'loss': 0.9486, 'grad_norm': 9.716521263122559, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 04:04:20 client2-1  | {'loss': 1.3762, 'grad_norm': 11.339367866516113, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 03:49:04 client3-1  | {'loss': 1.1639, 'grad_norm': 7.030241966247559, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 04:04:35 client2-1  | {'loss': 1.3545, 'grad_norm': 8.003485679626465, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 04:04:50 client2-1  | {'loss': 1.1857, 'grad_norm': 9.417142868041992, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 04:05:06 client2-1  | {'loss': 0.5893, 'grad_norm': 9.16887092590332, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 04:00:51 client1-1  | {'loss': 0.8639, 'grad_norm': 9.037715911865234, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 04:05:06 client2-1  | {'train_runtime': 663.5887, 'train_samples_per_second': 1.206, 'train_steps_per_second': 0.603, 'train_loss': 0.888047833442688, 'epoch': 1.0}
2025-05-22 04:05:13 client2-1  | INFO :      Sent reply
2025-05-22 04:01:05 client1-1  | {'loss': 0.9977, 'grad_norm': 10.733627319335938, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 03:49:19 client3-1  | {'loss': 1.0038, 'grad_norm': 7.210446357727051, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 04:01:20 client1-1  | {'loss': 1.0635, 'grad_norm': 12.116708755493164, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 04:05:44 client2-1  | INFO :      
2025-05-22 04:05:44 client2-1  | INFO :      Received: evaluate message 958cf254-a381-451d-8f96-f4e219e35347
2025-05-22 04:05:57 client2-1  | {'eval_loss': 1.552109718322754, 'eval_runtime': 6.9059, 'eval_samples_per_second': 28.961, 'eval_steps_per_second': 3.62, 'epoch': 1.0}
2025-05-22 03:49:40 client3-1  | {'loss': 1.065, 'grad_norm': 8.076800346374512, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 03:49:56 client3-1  | {'loss': 1.1852, 'grad_norm': 10.152138710021973, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 03:50:11 client3-1  | {'loss': 1.2124, 'grad_norm': 9.782660484313965, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 03:50:26 client3-1  | {'loss': 1.2301, 'grad_norm': 8.639946937561035, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 03:50:47 client3-1  | {'loss': 1.1798, 'grad_norm': 8.539278030395508, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 04:05:57 client2-1  | INFO :      Sent reply
2025-05-22 04:06:10 client2-1  | INFO :      
2025-05-22 04:01:41 client1-1  | {'loss': 1.0039, 'grad_norm': 8.133163452148438, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 04:06:10 client2-1  | INFO :      Received: train message f7d37b9a-45f4-4005-bd55-3a7a2f0f4955
2025-05-22 04:01:56 client1-1  | {'loss': 1.1427, 'grad_norm': 10.420770645141602, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 03:51:02 client3-1  | {'loss': 1.4242, 'grad_norm': 13.66402816772461, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 04:02:12 client1-1  | {'loss': 1.1299, 'grad_norm': 8.159466743469238, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 04:02:27 client1-1  | {'loss': 1.1648, 'grad_norm': 8.490457534790039, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 03:51:17 client3-1  | {'loss': 1.2858, 'grad_norm': 9.577539443969727, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 03:51:32 client3-1  | {'loss': 1.1992, 'grad_norm': 12.444319725036621, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 04:02:48 client1-1  | {'loss': 1.3206, 'grad_norm': 14.81125259399414, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 03:51:47 client3-1  | {'loss': 1.4798, 'grad_norm': 10.844185829162598, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 04:06:36 client2-1  | {'loss': 0.3249, 'grad_norm': 7.756195545196533, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 04:03:03 client1-1  | {'loss': 1.2194, 'grad_norm': 9.781044006347656, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 04:06:57 client2-1  | {'loss': 0.3272, 'grad_norm': 7.262034893035889, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 04:07:12 client2-1  | {'loss': 0.4329, 'grad_norm': 6.757874011993408, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 03:52:08 client3-1  | {'loss': 1.4326, 'grad_norm': 11.728147506713867, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 03:52:23 client3-1  | {'loss': 1.2549, 'grad_norm': 9.323436737060547, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 04:07:27 client2-1  | {'loss': 0.5027, 'grad_norm': 8.934920310974121, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 04:07:48 client2-1  | {'loss': 0.5431, 'grad_norm': 6.692144870758057, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 04:08:03 client2-1  | {'loss': 0.5205, 'grad_norm': 6.258589267730713, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 03:52:38 client3-1  | {'loss': 1.0721, 'grad_norm': 6.338104724884033, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 04:08:18 client2-1  | {'loss': 0.464, 'grad_norm': 6.357157230377197, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 04:03:18 client1-1  | {'loss': 1.3693, 'grad_norm': 12.423057556152344, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 03:52:53 client3-1  | {'loss': 0.5342, 'grad_norm': 6.115588188171387, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 03:52:53 client3-1  | {'train_runtime': 663.4606, 'train_samples_per_second': 1.204, 'train_steps_per_second': 0.603, 'train_loss': 0.9877115368843079, 'epoch': 1.0}
2025-05-22 03:53:08 client3-1  | INFO :      Sent reply
2025-05-22 04:03:33 client1-1  | {'loss': 1.3568, 'grad_norm': 9.379288673400879, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 03:53:37 client3-1  | INFO :      
2025-05-22 04:08:33 client2-1  | {'loss': 0.525, 'grad_norm': 7.739046573638916, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 04:08:54 client2-1  | {'loss': 0.5773, 'grad_norm': 5.443506717681885, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 04:09:09 client2-1  | {'loss': 0.5863, 'grad_norm': 8.224156379699707, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 03:53:37 client3-1  | INFO :      Received: evaluate message fa0c7d2f-4930-4378-ac46-eea858cb652c
2025-05-22 03:53:46 client3-1  | {'eval_loss': 1.5963102579116821, 'eval_runtime': 6.4262, 'eval_samples_per_second': 31.122, 'eval_steps_per_second': 3.89, 'epoch': 1.0}
2025-05-22 04:09:24 client2-1  | {'loss': 0.5928, 'grad_norm': 8.431000709533691, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 03:53:46 client3-1  | INFO :      Sent reply
2025-05-22 04:09:45 client2-1  | {'loss': 0.5493, 'grad_norm': 9.096073150634766, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 04:03:48 client1-1  | {'loss': 1.3459, 'grad_norm': 9.463068008422852, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 03:53:56 client3-1  | INFO :      
2025-05-22 04:04:03 client1-1  | {'loss': 1.3286, 'grad_norm': 10.43333625793457, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 03:53:56 client3-1  | INFO :      Received: train message 09d90b37-fb5a-42c5-9a5b-55e0fb22265d
2025-05-22 03:54:19 client3-1  | {'loss': 0.3487, 'grad_norm': 5.570772647857666, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 03:54:34 client3-1  | {'loss': 0.5554, 'grad_norm': 7.520483493804932, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 03:54:49 client3-1  | {'loss': 0.544, 'grad_norm': 7.014887809753418, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 04:04:24 client1-1  | {'loss': 1.1409, 'grad_norm': 9.602265357971191, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 03:55:04 client3-1  | {'loss': 0.6228, 'grad_norm': 7.741927146911621, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 04:10:00 client2-1  | {'loss': 0.6428, 'grad_norm': 6.223749160766602, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 04:10:15 client2-1  | {'loss': 0.6316, 'grad_norm': 9.181900024414062, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 04:10:30 client2-1  | {'loss': 0.5711, 'grad_norm': 7.857942581176758, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 04:10:51 client2-1  | {'loss': 0.7069, 'grad_norm': 8.716379165649414, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 04:11:06 client2-1  | {'loss': 0.7909, 'grad_norm': 8.36262321472168, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 04:11:20 client2-1  | {'loss': 0.7172, 'grad_norm': 8.101791381835938, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 04:04:39 client1-1  | {'loss': 0.9657, 'grad_norm': 7.52108097076416, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 04:11:35 client2-1  | {'loss': 0.6898, 'grad_norm': 9.684345245361328, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 03:55:25 client3-1  | {'loss': 0.5754, 'grad_norm': 9.414763450622559, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 03:55:40 client3-1  | {'loss': 0.5357, 'grad_norm': 5.758482456207275, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 03:55:55 client3-1  | {'loss': 0.7183, 'grad_norm': 7.801900386810303, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 03:56:10 client3-1  | {'loss': 0.6847, 'grad_norm': 6.117613315582275, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 04:11:57 client2-1  | {'loss': 0.8131, 'grad_norm': 7.395942211151123, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 03:56:31 client3-1  | {'loss': 0.8991, 'grad_norm': 10.80660629272461, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 04:04:54 client1-1  | {'loss': 0.5448, 'grad_norm': 6.421276569366455, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 04:04:54 client1-1  | {'train_runtime': 658.6593, 'train_samples_per_second': 1.215, 'train_steps_per_second': 0.607, 'train_loss': 0.881550303697586, 'epoch': 1.0}
2025-05-22 04:04:59 client1-1  | INFO :      Sent reply
2025-05-22 04:12:12 client2-1  | {'loss': 0.8537, 'grad_norm': 10.946232795715332, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 04:12:27 client2-1  | {'loss': 0.7579, 'grad_norm': 9.018375396728516, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 04:12:42 client2-1  | {'loss': 0.6997, 'grad_norm': 8.975749969482422, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 04:13:03 client2-1  | {'loss': 0.8, 'grad_norm': 8.765776634216309, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 03:56:46 client3-1  | {'loss': 0.7443, 'grad_norm': 7.3560614585876465, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 04:13:18 client2-1  | {'loss': 0.9238, 'grad_norm': 11.51756763458252, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 04:05:41 client1-1  | INFO :      
2025-05-22 04:05:41 client1-1  | INFO :      Received: evaluate message 1c84100b-18e5-458f-9673-558c55b7840d
2025-05-22 03:57:00 client3-1  | {'loss': 0.6828, 'grad_norm': 7.548398494720459, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 03:57:15 client3-1  | {'loss': 0.7315, 'grad_norm': 9.119965553283691, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 03:57:37 client3-1  | {'loss': 0.8193, 'grad_norm': 7.065521717071533, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 04:05:50 client1-1  | {'eval_loss': 1.594974160194397, 'eval_runtime': 7.135, 'eval_samples_per_second': 28.031, 'eval_steps_per_second': 3.504, 'epoch': 1.0}
2025-05-22 04:05:50 client1-1  | INFO :      Sent reply
2025-05-22 04:06:13 client1-1  | INFO :      
2025-05-22 03:57:52 client3-1  | {'loss': 0.8305, 'grad_norm': 9.888467788696289, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 03:58:07 client3-1  | {'loss': 0.6687, 'grad_norm': 6.8938140869140625, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 03:58:22 client3-1  | {'loss': 0.7331, 'grad_norm': 6.971898078918457, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 03:58:43 client3-1  | {'loss': 0.7699, 'grad_norm': 9.708572387695312, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 03:58:58 client3-1  | {'loss': 0.7188, 'grad_norm': 8.736808776855469, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 03:59:13 client3-1  | {'loss': 0.7914, 'grad_norm': 11.987566947937012, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 03:59:27 client3-1  | {'loss': 0.8155, 'grad_norm': 7.601498126983643, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 03:59:49 client3-1  | {'loss': 0.8571, 'grad_norm': 9.041682243347168, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 04:13:32 client2-1  | {'loss': 0.9042, 'grad_norm': 11.283058166503906, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 04:13:48 client2-1  | {'loss': 1.1131, 'grad_norm': 10.523436546325684, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 04:14:03 client2-1  | {'loss': 0.9764, 'grad_norm': 7.232672691345215, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 04:06:13 client1-1  | INFO :      Received: train message a41d6052-418b-48d0-9c19-d0be6e7d5fa2
2025-05-22 04:14:18 client2-1  | {'loss': 0.8219, 'grad_norm': 9.288153648376465, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 04:06:38 client1-1  | {'loss': 0.3284, 'grad_norm': 6.935393810272217, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 04:14:39 client2-1  | {'loss': 1.0621, 'grad_norm': 7.684340476989746, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 04:00:04 client3-1  | {'loss': 0.9561, 'grad_norm': 8.758439064025879, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 04:14:54 client2-1  | {'loss': 1.0216, 'grad_norm': 8.021944046020508, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 04:07:00 client1-1  | {'loss': 0.2942, 'grad_norm': 6.351428985595703, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 04:07:15 client1-1  | {'loss': 0.4034, 'grad_norm': 6.1376142501831055, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 04:07:36 client1-1  | {'loss': 0.5833, 'grad_norm': 9.2549409866333, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 04:07:51 client1-1  | {'loss': 0.5403, 'grad_norm': 6.956746578216553, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 04:00:19 client3-1  | {'loss': 0.8963, 'grad_norm': 9.649901390075684, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 04:00:34 client3-1  | {'loss': 0.9322, 'grad_norm': 6.746476650238037, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 04:00:55 client3-1  | {'loss': 0.9696, 'grad_norm': 9.165294647216797, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 04:01:10 client3-1  | {'loss': 1.073, 'grad_norm': 7.012413024902344, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 04:01:25 client3-1  | {'loss': 0.9376, 'grad_norm': 7.768415927886963, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 04:15:09 client2-1  | {'loss': 1.2705, 'grad_norm': 10.668883323669434, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 04:08:06 client1-1  | {'loss': 0.5297, 'grad_norm': 5.180670261383057, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 04:15:24 client2-1  | {'loss': 1.1109, 'grad_norm': 9.264616012573242, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 04:15:46 client2-1  | {'loss': 1.2135, 'grad_norm': 11.04280948638916, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 04:16:01 client2-1  | {'loss': 1.3913, 'grad_norm': 10.962921142578125, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 04:01:40 client3-1  | {'loss': 0.9873, 'grad_norm': 8.963191986083984, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 04:16:16 client2-1  | {'loss': 1.3378, 'grad_norm': 11.311413764953613, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 04:16:31 client2-1  | {'loss': 1.3615, 'grad_norm': 10.42158031463623, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 04:16:45 client2-1  | {'loss': 1.3256, 'grad_norm': 8.135130882263184, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 04:17:07 client2-1  | {'loss': 1.0912, 'grad_norm': 9.840749740600586, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 04:17:22 client2-1  | {'loss': 0.4803, 'grad_norm': 8.608205795288086, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 04:17:22 client2-1  | {'train_runtime': 668.8462, 'train_samples_per_second': 1.196, 'train_steps_per_second': 0.598, 'train_loss': 0.8006625753641129, 'epoch': 1.0}
2025-05-22 04:17:29 client2-1  | INFO :      Sent reply
2025-05-22 04:08:20 client1-1  | {'loss': 0.4787, 'grad_norm': 9.27971076965332, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 04:08:41 client1-1  | {'loss': 0.506, 'grad_norm': 6.966333866119385, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 04:08:56 client1-1  | {'loss': 0.5619, 'grad_norm': 6.591030597686768, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 04:02:01 client3-1  | {'loss': 1.1077, 'grad_norm': 9.45578670501709, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 04:09:11 client1-1  | {'loss': 0.5334, 'grad_norm': 6.345959663391113, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 04:18:03 client2-1  | INFO :      
2025-05-22 04:18:03 client2-1  | INFO :      Received: evaluate message cb3d79e7-b56a-4315-a32a-c17a42a2ccff
2025-05-22 04:18:24 client2-1  | {'eval_loss': 1.5811008214950562, 'eval_runtime': 17.4745, 'eval_samples_per_second': 11.445, 'eval_steps_per_second': 1.431, 'epoch': 1.0}
2025-05-22 04:18:24 client2-1  | INFO :      Sent reply
2025-05-22 04:18:33 client2-1  | INFO :      
2025-05-22 04:09:26 client1-1  | {'loss': 0.6204, 'grad_norm': 8.536446571350098, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 04:09:48 client1-1  | {'loss': 0.6369, 'grad_norm': 8.249762535095215, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 04:10:02 client1-1  | {'loss': 0.5846, 'grad_norm': 9.231929779052734, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 04:02:16 client3-1  | {'loss': 1.1624, 'grad_norm': 10.681174278259277, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 04:10:17 client1-1  | {'loss': 0.6618, 'grad_norm': 9.961715698242188, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 04:10:32 client1-1  | {'loss': 0.6151, 'grad_norm': 9.923377990722656, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 04:10:53 client1-1  | {'loss': 0.6604, 'grad_norm': 7.001224994659424, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 04:11:08 client1-1  | {'loss': 0.702, 'grad_norm': 10.417140007019043, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 04:11:23 client1-1  | {'loss': 0.7202, 'grad_norm': 9.218133926391602, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 04:11:38 client1-1  | {'loss': 0.7106, 'grad_norm': 9.199365615844727, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 04:11:59 client1-1  | {'loss': 0.7307, 'grad_norm': 6.288012504577637, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 04:18:33 client2-1  | INFO :      Received: train message b1e42457-f45e-4603-b3d8-808c7a3f1760
2025-05-22 04:18:37 client2-1  | {'loss': 0.2318, 'grad_norm': 5.7832207679748535, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 04:18:49 client2-1  | {'loss': 0.2523, 'grad_norm': 5.128696918487549, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 04:19:03 client2-1  | {'loss': 0.332, 'grad_norm': 5.89923620223999, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 04:19:19 client2-1  | {'loss': 0.398, 'grad_norm': 9.2365083694458, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 04:19:40 client2-1  | {'loss': 0.4411, 'grad_norm': 5.5369157791137695, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 04:19:55 client2-1  | {'loss': 0.4115, 'grad_norm': 4.72033166885376, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 04:20:11 client2-1  | {'loss': 0.3611, 'grad_norm': 6.1155877113342285, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 04:20:26 client2-1  | {'loss': 0.4087, 'grad_norm': 7.210116386413574, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 04:20:46 client2-1  | {'loss': 0.4892, 'grad_norm': 5.259451866149902, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 04:21:01 client2-1  | {'loss': 0.481, 'grad_norm': 7.274785041809082, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 04:21:16 client2-1  | {'loss': 0.4791, 'grad_norm': 6.813736438751221, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 04:02:31 client3-1  | {'loss': 1.1615, 'grad_norm': 8.60757064819336, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 04:02:46 client3-1  | {'loss': 1.1486, 'grad_norm': 9.293461799621582, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 04:21:32 client2-1  | {'loss': 0.4483, 'grad_norm': 10.764159202575684, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 04:21:53 client2-1  | {'loss': 0.561, 'grad_norm': 6.121953010559082, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 04:03:02 client3-1  | {'loss': 1.3663, 'grad_norm': 13.488663673400879, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 04:03:23 client3-1  | {'loss': 1.2521, 'grad_norm': 9.223442077636719, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 04:22:08 client2-1  | {'loss': 0.5268, 'grad_norm': 11.029178619384766, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 04:22:22 client2-1  | {'loss': 0.4761, 'grad_norm': 6.074471950531006, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 04:22:37 client2-1  | {'loss': 0.5911, 'grad_norm': 8.08108139038086, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 04:22:52 client2-1  | {'loss': 0.7127, 'grad_norm': 8.253728866577148, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 04:23:13 client2-1  | {'loss': 0.6111, 'grad_norm': 8.592843055725098, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 04:12:14 client1-1  | {'loss': 0.7168, 'grad_norm': 10.381244659423828, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 04:23:29 client2-1  | {'loss': 0.5926, 'grad_norm': 8.266155242919922, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 04:12:29 client1-1  | {'loss': 0.8163, 'grad_norm': 6.624975681304932, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 04:12:44 client1-1  | {'loss': 0.8163, 'grad_norm': 10.150044441223145, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 04:03:38 client3-1  | {'loss': 1.1805, 'grad_norm': 9.807934761047363, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 04:03:53 client3-1  | {'loss': 1.4494, 'grad_norm': 10.266722679138184, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 04:04:08 client3-1  | {'loss': 1.4159, 'grad_norm': 12.071405410766602, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 04:04:29 client3-1  | {'loss': 1.2361, 'grad_norm': 9.780999183654785, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 04:04:44 client3-1  | {'loss': 1.0155, 'grad_norm': 6.15909481048584, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 04:04:59 client3-1  | {'loss': 0.4969, 'grad_norm': 9.509478569030762, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 04:04:59 client3-1  | {'train_runtime': 661.4096, 'train_samples_per_second': 1.208, 'train_steps_per_second': 0.605, 'train_loss': 0.8848058968782425, 'epoch': 1.0}
2025-05-22 04:13:05 client1-1  | {'loss': 0.847, 'grad_norm': 9.161624908447266, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 04:13:20 client1-1  | {'loss': 0.7751, 'grad_norm': 8.639286041259766, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 04:13:35 client1-1  | {'loss': 0.9113, 'grad_norm': 12.296276092529297, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 04:13:50 client1-1  | {'loss': 0.9854, 'grad_norm': 11.953923225402832, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 04:05:10 client3-1  | INFO :      Sent reply
2025-05-22 04:14:12 client1-1  | {'loss': 0.9346, 'grad_norm': 8.099361419677734, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 04:05:43 client3-1  | INFO :      
2025-05-22 04:05:43 client3-1  | INFO :      Received: evaluate message b3dca9fa-a788-4c50-935c-150fdf74418a
2025-05-22 04:14:27 client1-1  | {'loss': 1.0469, 'grad_norm': 11.242757797241211, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 04:23:44 client2-1  | {'loss': 0.7134, 'grad_norm': 7.461308479309082, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 04:23:59 client2-1  | {'loss': 0.7479, 'grad_norm': 12.222193717956543, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 04:24:21 client2-1  | {'loss': 0.6665, 'grad_norm': 9.608113288879395, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 04:14:42 client1-1  | {'loss': 1.0494, 'grad_norm': 8.318476676940918, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 04:14:57 client1-1  | {'loss': 1.1317, 'grad_norm': 8.278719902038574, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 04:15:19 client1-1  | {'loss': 1.2587, 'grad_norm': 13.82850456237793, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 04:15:34 client1-1  | {'loss': 1.1638, 'grad_norm': 10.367465019226074, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 04:15:49 client1-1  | {'loss': 1.3149, 'grad_norm': 12.297176361083984, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 04:16:04 client1-1  | {'loss': 1.327, 'grad_norm': 9.509035110473633, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 04:16:25 client1-1  | {'loss': 1.3378, 'grad_norm': 12.194419860839844, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 04:24:36 client2-1  | {'loss': 0.6037, 'grad_norm': 8.443495750427246, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 04:24:51 client2-1  | {'loss': 0.7209, 'grad_norm': 8.082681655883789, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 04:25:05 client2-1  | {'loss': 0.877, 'grad_norm': 12.31307601928711, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 04:25:20 client2-1  | {'loss': 0.8374, 'grad_norm': 10.371048927307129, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 04:05:55 client3-1  | {'eval_loss': 1.6256523132324219, 'eval_runtime': 10.3611, 'eval_samples_per_second': 19.303, 'eval_steps_per_second': 2.413, 'epoch': 1.0}
2025-05-22 04:25:41 client2-1  | {'loss': 1.0084, 'grad_norm': 10.442951202392578, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 04:16:40 client1-1  | {'loss': 1.3042, 'grad_norm': 9.006776809692383, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 04:16:55 client1-1  | {'loss': 1.1088, 'grad_norm': 9.485316276550293, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 04:17:10 client1-1  | {'loss': 0.9009, 'grad_norm': 7.031349182128906, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 04:05:55 client3-1  | INFO :      Sent reply
2025-05-22 04:06:13 client3-1  | INFO :      
2025-05-22 04:17:25 client1-1  | {'loss': 0.478, 'grad_norm': 6.9154229164123535, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 04:17:25 client1-1  | {'train_runtime': 667.2321, 'train_samples_per_second': 1.199, 'train_steps_per_second': 0.599, 'train_loss': 0.7906705498695373, 'epoch': 1.0}
2025-05-22 04:06:13 client3-1  | INFO :      Received: train message 27e3821f-0a72-4f74-9dcb-bf395ab652eb
2025-05-22 04:06:33 client3-1  | {'loss': 0.2492, 'grad_norm': 7.779698371887207, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 04:06:55 client3-1  | {'loss': 0.4246, 'grad_norm': 8.42374324798584, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 04:07:10 client3-1  | {'loss': 0.449, 'grad_norm': 7.356472969055176, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 04:07:25 client3-1  | {'loss': 0.4911, 'grad_norm': 7.340628623962402, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 04:07:39 client3-1  | {'loss': 0.4702, 'grad_norm': 8.893315315246582, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 04:17:31 client1-1  | INFO :      Sent reply
2025-05-22 04:18:02 client1-1  | INFO :      
2025-05-22 04:18:02 client1-1  | INFO :      Received: evaluate message ab5cc1e9-effe-4c3b-aeca-ad952834aba4
2025-05-22 04:18:22 client1-1  | {'eval_loss': 1.6277676820755005, 'eval_runtime': 17.327, 'eval_samples_per_second': 11.543, 'eval_steps_per_second': 1.443, 'epoch': 1.0}
2025-05-22 04:25:56 client2-1  | {'loss': 0.894, 'grad_norm': 8.22689151763916, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 04:26:11 client2-1  | {'loss': 0.7805, 'grad_norm': 9.272400856018066, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 04:26:26 client2-1  | {'loss': 1.0093, 'grad_norm': 8.135054588317871, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 04:26:47 client2-1  | {'loss': 0.9586, 'grad_norm': 7.963272571563721, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 04:08:01 client3-1  | {'loss': 0.4236, 'grad_norm': 4.836021900177002, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 04:08:15 client3-1  | {'loss': 0.5708, 'grad_norm': 8.018616676330566, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 04:08:30 client3-1  | {'loss': 0.5552, 'grad_norm': 5.271115779876709, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 04:27:03 client2-1  | {'loss': 1.2182, 'grad_norm': 11.132942199707031, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 04:27:17 client2-1  | {'loss': 1.0692, 'grad_norm': 11.27267074584961, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 04:27:32 client2-1  | {'loss': 1.1845, 'grad_norm': 10.752852439880371, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 04:08:45 client3-1  | {'loss': 0.7641, 'grad_norm': 7.995838642120361, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 04:27:47 client2-1  | {'loss': 1.3563, 'grad_norm': 11.054896354675293, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 04:28:08 client2-1  | {'loss': 1.3417, 'grad_norm': 13.289319038391113, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 04:28:23 client2-1  | {'loss': 1.3216, 'grad_norm': 10.563925743103027, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 04:28:38 client2-1  | {'loss': 1.2997, 'grad_norm': 8.738200187683105, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 04:28:53 client2-1  | {'loss': 1.0345, 'grad_norm': 9.653973579406738, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 04:29:14 client2-1  | {'loss': 0.4284, 'grad_norm': 8.067941665649414, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 04:29:14 client2-1  | {'train_runtime': 640.3218, 'train_samples_per_second': 1.249, 'train_steps_per_second': 0.625, 'train_loss': 0.7219321483373642, 'epoch': 1.0}
2025-05-22 04:09:06 client3-1  | {'loss': 0.6191, 'grad_norm': 8.070552825927734, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 04:09:21 client3-1  | {'loss': 0.5768, 'grad_norm': 6.800901889801025, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 04:29:19 client2-1  | INFO :      Sent reply
2025-05-22 04:09:36 client3-1  | {'loss': 0.619, 'grad_norm': 8.608969688415527, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 04:30:16 client2-1  | INFO :      
2025-05-22 04:18:22 client1-1  | INFO :      Sent reply
2025-05-22 04:30:16 client2-1  | INFO :      Received: evaluate message 492a5591-a4fd-4487-b37d-d05460fc9bea
2025-05-22 04:30:35 client2-1  | {'eval_loss': 1.615279197692871, 'eval_runtime': 17.1136, 'eval_samples_per_second': 11.687, 'eval_steps_per_second': 1.461, 'epoch': 1.0}
2025-05-22 04:30:35 client2-1  | INFO :      Sent reply
2025-05-22 04:18:37 client1-1  | INFO :      
2025-05-22 04:30:47 client2-1  | INFO :      
2025-05-22 04:30:47 client2-1  | INFO :      Received: train message ab513fd0-4a62-4f5b-b1eb-871c170417a6
2025-05-22 04:31:08 client2-1  | {'loss': 0.1662, 'grad_norm': 4.723794460296631, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 04:31:23 client2-1  | {'loss': 0.1744, 'grad_norm': 4.084487438201904, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 04:31:44 client2-1  | {'loss': 0.2521, 'grad_norm': 5.944124698638916, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 04:31:59 client2-1  | {'loss': 0.3236, 'grad_norm': 7.062527179718018, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 04:09:51 client3-1  | {'loss': 0.6947, 'grad_norm': 7.663208961486816, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 04:10:12 client3-1  | {'loss': 0.7137, 'grad_norm': 9.209602355957031, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 04:18:37 client1-1  | INFO :      Received: train message 8ea70d99-c7ca-4b5d-8ec9-cc9bae4492fc
2025-05-22 04:19:01 client1-1  | {'loss': 0.229, 'grad_norm': 4.457108974456787, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 04:19:16 client1-1  | {'loss': 0.2012, 'grad_norm': 4.960719585418701, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 04:32:14 client2-1  | {'loss': 0.3404, 'grad_norm': 5.9271016120910645, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 04:32:29 client2-1  | {'loss': 0.3265, 'grad_norm': 5.2530670166015625, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 04:32:50 client2-1  | {'loss': 0.2962, 'grad_norm': 5.977830410003662, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 04:33:05 client2-1  | {'loss': 0.3404, 'grad_norm': 6.897132873535156, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 04:33:20 client2-1  | {'loss': 0.3999, 'grad_norm': 4.818143367767334, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 04:33:35 client2-1  | {'loss': 0.4016, 'grad_norm': 7.390726089477539, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 04:33:50 client2-1  | {'loss': 0.3866, 'grad_norm': 5.9470133781433105, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 04:34:11 client2-1  | {'loss': 0.3749, 'grad_norm': 7.875614166259766, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 04:34:26 client2-1  | {'loss': 0.4679, 'grad_norm': 6.1321001052856445, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 04:34:41 client2-1  | {'loss': 0.446, 'grad_norm': 8.734416961669922, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 04:19:31 client1-1  | {'loss': 0.2968, 'grad_norm': 5.557839870452881, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 04:19:46 client1-1  | {'loss': 0.4779, 'grad_norm': 9.459136962890625, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 04:20:07 client1-1  | {'loss': 0.4257, 'grad_norm': 6.935723781585693, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 04:35:02 client2-1  | {'loss': 0.4065, 'grad_norm': 6.497779846191406, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 04:20:23 client1-1  | {'loss': 0.4276, 'grad_norm': 3.881159782409668, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 04:20:37 client1-1  | {'loss': 0.385, 'grad_norm': 10.001007080078125, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 04:20:52 client1-1  | {'loss': 0.4035, 'grad_norm': 6.031322002410889, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 04:21:14 client1-1  | {'loss': 0.4757, 'grad_norm': 6.515820503234863, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 04:21:29 client1-1  | {'loss': 0.4291, 'grad_norm': 5.514262676239014, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 04:35:17 client2-1  | {'loss': 0.5131, 'grad_norm': 8.183899879455566, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 04:21:44 client1-1  | {'loss': 0.5192, 'grad_norm': 7.8417463302612305, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 04:35:39 client2-1  | {'loss': 0.5898, 'grad_norm': 8.72472095489502, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 04:35:54 client2-1  | {'loss': 0.5278, 'grad_norm': 8.200457572937012, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 04:22:05 client1-1  | {'loss': 0.5393, 'grad_norm': 7.789904594421387, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 04:22:20 client1-1  | {'loss': 0.4786, 'grad_norm': 8.15429401397705, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 04:22:35 client1-1  | {'loss': 0.5596, 'grad_norm': 9.090570449829102, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 04:22:49 client1-1  | {'loss': 0.5244, 'grad_norm': 8.970486640930176, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 04:23:04 client1-1  | {'loss': 0.5735, 'grad_norm': 10.906453132629395, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 04:10:27 client3-1  | {'loss': 0.5836, 'grad_norm': 7.9109206199646, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 04:23:26 client1-1  | {'loss': 0.5856, 'grad_norm': 9.976820945739746, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 04:23:41 client1-1  | {'loss': 0.6017, 'grad_norm': 8.179910659790039, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 04:36:09 client2-1  | {'loss': 0.5093, 'grad_norm': 8.947510719299316, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 04:36:23 client2-1  | {'loss': 0.6289, 'grad_norm': 7.503927230834961, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 04:36:45 client2-1  | {'loss': 0.653, 'grad_norm': 11.6950101852417, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 04:36:59 client2-1  | {'loss': 0.5951, 'grad_norm': 9.945870399475098, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 04:10:41 client3-1  | {'loss': 0.6332, 'grad_norm': 10.07271957397461, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 04:10:56 client3-1  | {'loss': 0.6502, 'grad_norm': 7.802737712860107, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 04:37:14 client2-1  | {'loss': 0.5279, 'grad_norm': 7.479042053222656, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 04:37:29 client2-1  | {'loss': 0.6658, 'grad_norm': 8.745512962341309, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 04:37:50 client2-1  | {'loss': 0.791, 'grad_norm': 10.931014060974121, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 04:23:57 client1-1  | {'loss': 0.6216, 'grad_norm': 8.87666130065918, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 04:24:12 client1-1  | {'loss': 0.6416, 'grad_norm': 5.367799758911133, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 04:24:33 client1-1  | {'loss': 0.6286, 'grad_norm': 9.485831260681152, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 04:38:05 client2-1  | {'loss': 0.7425, 'grad_norm': 10.481858253479004, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 04:24:48 client1-1  | {'loss': 0.7214, 'grad_norm': 7.08327054977417, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 04:11:17 client3-1  | {'loss': 0.6202, 'grad_norm': 8.575169563293457, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 04:38:20 client2-1  | {'loss': 0.9548, 'grad_norm': 9.3471040725708, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 04:38:35 client2-1  | {'loss': 0.8127, 'grad_norm': 8.08340835571289, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 04:38:56 client2-1  | {'loss': 0.7083, 'grad_norm': 9.7944974899292, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 04:25:03 client1-1  | {'loss': 0.7241, 'grad_norm': 9.84852409362793, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 04:39:11 client2-1  | {'loss': 0.9394, 'grad_norm': 8.10098934173584, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 04:39:26 client2-1  | {'loss': 0.8958, 'grad_norm': 8.097227096557617, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 04:39:41 client2-1  | {'loss': 1.1592, 'grad_norm': 11.22459888458252, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 04:40:03 client2-1  | {'loss': 1.0252, 'grad_norm': 10.430829048156738, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 04:40:18 client2-1  | {'loss': 1.1664, 'grad_norm': 11.213200569152832, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 04:40:33 client2-1  | {'loss': 1.3276, 'grad_norm': 11.963338851928711, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 04:11:32 client3-1  | {'loss': 0.7071, 'grad_norm': 9.42959213256836, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 04:40:48 client2-1  | {'loss': 1.3083, 'grad_norm': 12.598810195922852, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 04:11:48 client3-1  | {'loss': 0.7172, 'grad_norm': 8.601456642150879, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 04:12:03 client3-1  | {'loss': 0.7693, 'grad_norm': 8.552874565124512, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 04:25:18 client1-1  | {'loss': 0.7645, 'grad_norm': 8.671882629394531, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 04:12:24 client3-1  | {'loss': 0.8836, 'grad_norm': 10.486437797546387, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 04:25:39 client1-1  | {'loss': 0.7098, 'grad_norm': 8.956547737121582, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 04:41:09 client2-1  | {'loss': 1.3147, 'grad_norm': 10.896966934204102, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 04:41:24 client2-1  | {'loss': 1.2778, 'grad_norm': 8.724289894104004, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 04:41:39 client2-1  | {'loss': 0.9896, 'grad_norm': 11.195507049560547, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 04:41:54 client2-1  | {'loss': 0.3742, 'grad_norm': 13.371771812438965, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 04:25:54 client1-1  | {'loss': 0.8404, 'grad_norm': 12.396659851074219, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 04:26:09 client1-1  | {'loss': 0.9034, 'grad_norm': 10.909416198730469, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 04:26:23 client1-1  | {'loss': 0.8728, 'grad_norm': 9.937832832336426, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 04:26:45 client1-1  | {'loss': 0.9956, 'grad_norm': 10.189889907836914, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 04:41:54 client2-1  | {'train_runtime': 665.1013, 'train_samples_per_second': 1.203, 'train_steps_per_second': 0.601, 'train_loss': 0.6525375798344613, 'epoch': 1.0}
2025-05-22 04:27:00 client1-1  | {'loss': 0.9709, 'grad_norm': 8.409482955932617, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 04:27:15 client1-1  | {'loss': 1.068, 'grad_norm': 7.876899242401123, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 04:27:30 client1-1  | {'loss': 1.2102, 'grad_norm': 15.515473365783691, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 04:42:04 client2-1  | INFO :      Sent reply
2025-05-22 04:42:33 client2-1  | INFO :      
2025-05-22 04:42:33 client2-1  | INFO :      Received: evaluate message e0b16ab3-05a4-4b11-989f-d650e9c659c5
2025-05-22 04:42:46 client2-1  | {'eval_loss': 1.645483374595642, 'eval_runtime': 11.2894, 'eval_samples_per_second': 17.716, 'eval_steps_per_second': 2.214, 'epoch': 1.0}
2025-05-22 04:27:51 client1-1  | {'loss': 1.1242, 'grad_norm': 10.556466102600098, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 04:42:46 client2-1  | INFO :      Sent reply
2025-05-22 04:42:58 client2-1  | INFO :      
2025-05-22 04:42:58 client2-1  | INFO :      Received: train message f26364c4-0654-4291-9db0-cc10d64a35b9
2025-05-22 04:12:39 client3-1  | {'loss': 0.7847, 'grad_norm': 9.240814208984375, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 04:12:54 client3-1  | {'loss': 0.841, 'grad_norm': 7.635467052459717, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 04:13:15 client3-1  | {'loss': 0.8874, 'grad_norm': 9.13805103302002, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 04:28:06 client1-1  | {'loss': 1.2582, 'grad_norm': 12.549507141113281, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 04:43:15 client2-1  | {'loss': 0.1283, 'grad_norm': 4.054480075836182, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 04:28:21 client1-1  | {'loss': 1.2976, 'grad_norm': 9.764457702636719, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 04:43:36 client2-1  | {'loss': 0.1529, 'grad_norm': 3.0189945697784424, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 04:43:51 client2-1  | {'loss': 0.2079, 'grad_norm': 4.542666912078857, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 04:44:06 client2-1  | {'loss': 0.2692, 'grad_norm': 7.640644073486328, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 04:44:21 client2-1  | {'loss': 0.2796, 'grad_norm': 4.085089206695557, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 04:13:30 client3-1  | {'loss': 0.9897, 'grad_norm': 6.783272743225098, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 04:13:45 client3-1  | {'loss': 0.8581, 'grad_norm': 7.13850736618042, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 04:14:00 client3-1  | {'loss': 0.9177, 'grad_norm': 7.633121967315674, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 04:44:43 client2-1  | {'loss': 0.2644, 'grad_norm': 6.226459503173828, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 04:44:58 client2-1  | {'loss': 0.2569, 'grad_norm': 5.455155849456787, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 04:28:36 client1-1  | {'loss': 1.3059, 'grad_norm': 10.183059692382812, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 04:45:13 client2-1  | {'loss': 0.2782, 'grad_norm': 5.927529335021973, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 04:28:57 client1-1  | {'loss': 1.2971, 'grad_norm': 9.447282791137695, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 04:29:12 client1-1  | {'loss': 1.0777, 'grad_norm': 10.302959442138672, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 04:29:24 client1-1  | {'loss': 0.8498, 'grad_norm': 7.313194751739502, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 04:14:15 client3-1  | {'loss': 1.0262, 'grad_norm': 11.956828117370605, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 04:14:37 client3-1  | {'loss': 1.0886, 'grad_norm': 8.81821060180664, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 04:14:52 client3-1  | {'loss': 1.1066, 'grad_norm': 8.436765670776367, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 04:15:07 client3-1  | {'loss': 1.0988, 'grad_norm': 9.031205177307129, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 04:45:28 client2-1  | {'loss': 0.3277, 'grad_norm': 3.3776068687438965, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 04:45:49 client2-1  | {'loss': 0.3403, 'grad_norm': 7.792661190032959, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 04:46:04 client2-1  | {'loss': 0.3352, 'grad_norm': 7.388329029083252, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 04:46:19 client2-1  | {'loss': 0.2879, 'grad_norm': 7.012866973876953, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 04:46:35 client2-1  | {'loss': 0.3879, 'grad_norm': 6.108580112457275, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 04:46:56 client2-1  | {'loss': 0.3701, 'grad_norm': 7.742166996002197, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 04:15:22 client3-1  | {'loss': 1.3113, 'grad_norm': 13.38213062286377, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 04:15:37 client3-1  | {'loss': 1.2238, 'grad_norm': 10.505243301391602, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 04:15:58 client3-1  | {'loss': 1.1542, 'grad_norm': 11.964238166809082, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 04:29:34 client1-1  | {'loss': 0.4059, 'grad_norm': 5.57700252532959, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 04:29:34 client1-1  | {'train_runtime': 655.4289, 'train_samples_per_second': 1.221, 'train_steps_per_second': 0.61, 'train_loss': 0.7105656433105468, 'epoch': 1.0}
2025-05-22 04:16:13 client3-1  | {'loss': 1.4342, 'grad_norm': 10.840399742126465, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 04:16:28 client3-1  | {'loss': 1.3808, 'grad_norm': 12.352306365966797, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 04:16:43 client3-1  | {'loss': 1.2134, 'grad_norm': 9.305248260498047, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 04:47:11 client2-1  | {'loss': 0.3293, 'grad_norm': 6.755566596984863, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 04:47:26 client2-1  | {'loss': 0.4343, 'grad_norm': 7.478825569152832, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 04:47:41 client2-1  | {'loss': 0.5319, 'grad_norm': 8.294975280761719, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 04:29:44 client1-1  | INFO :      Sent reply
2025-05-22 04:30:18 client1-1  | INFO :      
2025-05-22 04:30:18 client1-1  | INFO :      Received: evaluate message 705dfc55-e965-4a2e-b29d-de87acd5e376
2025-05-22 04:17:05 client3-1  | {'loss': 0.9467, 'grad_norm': 5.648194789886475, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 04:17:19 client3-1  | {'loss': 0.4217, 'grad_norm': 4.993609428405762, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 04:17:19 client3-1  | {'train_runtime': 665.3236, 'train_samples_per_second': 1.201, 'train_steps_per_second': 0.601, 'train_loss': 0.7967568516731263, 'epoch': 1.0}
2025-05-22 04:17:24 client3-1  | INFO :      Sent reply
2025-05-22 04:48:02 client2-1  | {'loss': 0.4672, 'grad_norm': 8.84691047668457, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 04:48:17 client2-1  | {'loss': 0.4495, 'grad_norm': 8.411465644836426, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 04:48:32 client2-1  | {'loss': 0.547, 'grad_norm': 7.419588565826416, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 04:48:47 client2-1  | {'loss': 0.5811, 'grad_norm': 10.734926223754883, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 04:49:09 client2-1  | {'loss': 0.5182, 'grad_norm': 8.305354118347168, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 04:49:24 client2-1  | {'loss': 0.4729, 'grad_norm': 9.692011833190918, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 04:49:39 client2-1  | {'loss': 0.5856, 'grad_norm': 7.333829402923584, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 04:49:54 client2-1  | {'loss': 0.6872, 'grad_norm': 10.951728820800781, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 04:50:15 client2-1  | {'loss': 0.6982, 'grad_norm': 11.52966594696045, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 04:50:30 client2-1  | {'loss': 0.8753, 'grad_norm': 10.626691818237305, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 04:50:45 client2-1  | {'loss': 0.7836, 'grad_norm': 9.345569610595703, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 04:51:00 client2-1  | {'loss': 0.6558, 'grad_norm': 9.171936988830566, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 04:51:15 client2-1  | {'loss': 0.8927, 'grad_norm': 8.287699699401855, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 04:51:36 client2-1  | {'loss': 0.8553, 'grad_norm': 8.206679344177246, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 04:30:38 client1-1  | {'eval_loss': 1.6577072143554688, 'eval_runtime': 18.0531, 'eval_samples_per_second': 11.078, 'eval_steps_per_second': 1.385, 'epoch': 1.0}
2025-05-22 04:30:38 client1-1  | INFO :      Sent reply
2025-05-22 04:30:50 client1-1  | INFO :      
2025-05-22 04:30:50 client1-1  | INFO :      Received: train message cf36dfec-25b6-4a4f-8f5c-767f92c2b324
2025-05-22 04:51:51 client2-1  | {'loss': 1.1267, 'grad_norm': 11.610328674316406, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 04:52:06 client2-1  | {'loss': 0.9832, 'grad_norm': 10.06365966796875, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 04:52:21 client2-1  | {'loss': 1.1285, 'grad_norm': 11.80898380279541, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 04:52:42 client2-1  | {'loss': 1.2928, 'grad_norm': 10.898167610168457, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 04:52:57 client2-1  | {'loss': 1.2769, 'grad_norm': 13.425724029541016, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 04:53:12 client2-1  | {'loss': 1.3094, 'grad_norm': 12.764508247375488, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 04:18:02 client3-1  | INFO :      
2025-05-22 04:53:27 client2-1  | {'loss': 1.2405, 'grad_norm': 8.76724910736084, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 04:31:18 client1-1  | {'loss': 0.1695, 'grad_norm': 3.8266806602478027, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 04:53:49 client2-1  | {'loss': 0.9364, 'grad_norm': 10.283230781555176, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 04:18:02 client3-1  | INFO :      Received: evaluate message 0cc64354-5d56-4000-9014-2b963e0b90b0
2025-05-22 04:31:39 client1-1  | {'loss': 0.1655, 'grad_norm': 5.1630120277404785, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 04:31:54 client1-1  | {'loss': 0.2314, 'grad_norm': 4.095874786376953, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 04:32:09 client1-1  | {'loss': 0.3627, 'grad_norm': 6.629775524139404, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 04:54:04 client2-1  | {'loss': 0.3184, 'grad_norm': 6.5424299240112305, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 04:32:30 client1-1  | {'loss': 0.3333, 'grad_norm': 5.759171009063721, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 04:18:20 client3-1  | {'eval_loss': 1.6589868068695068, 'eval_runtime': 17.0644, 'eval_samples_per_second': 11.72, 'eval_steps_per_second': 1.465, 'epoch': 1.0}
2025-05-22 04:32:45 client1-1  | {'loss': 0.3367, 'grad_norm': 3.9581007957458496, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 04:33:00 client1-1  | {'loss': 0.3206, 'grad_norm': 9.686726570129395, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 04:33:15 client1-1  | {'loss': 0.3224, 'grad_norm': 7.190247058868408, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 04:18:20 client3-1  | INFO :      Sent reply
2025-05-22 04:18:37 client3-1  | INFO :      
2025-05-22 04:18:37 client3-1  | INFO :      Received: train message d0f17e1f-213e-421c-8c16-95cd478c61fb
2025-05-22 04:19:06 client3-1  | {'loss': 0.1758, 'grad_norm': 4.756535053253174, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 04:19:21 client3-1  | {'loss': 0.3118, 'grad_norm': 5.4059648513793945, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 04:33:37 client1-1  | {'loss': 0.3843, 'grad_norm': 5.681447505950928, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 04:33:52 client1-1  | {'loss': 0.3323, 'grad_norm': 6.065004825592041, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 04:34:07 client1-1  | {'loss': 0.4525, 'grad_norm': 8.12384033203125, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 04:54:04 client2-1  | {'train_runtime': 663.7823, 'train_samples_per_second': 1.205, 'train_steps_per_second': 0.603, 'train_loss': 0.5966049680113792, 'epoch': 1.0}
2025-05-22 04:54:11 client2-1  | INFO :      Sent reply
2025-05-22 04:54:39 client2-1  | INFO :      
2025-05-22 04:54:39 client2-1  | INFO :      Received: evaluate message 1f59c57f-0401-4919-a211-4df57a39cab6
2025-05-22 04:19:43 client3-1  | {'loss': 0.3317, 'grad_norm': 7.793742656707764, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 04:19:58 client3-1  | {'loss': 0.3919, 'grad_norm': 6.434417724609375, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 04:20:13 client3-1  | {'loss': 0.392, 'grad_norm': 9.262289047241211, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 04:20:28 client3-1  | {'loss': 0.3509, 'grad_norm': 5.221489906311035, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 04:20:49 client3-1  | {'loss': 0.4769, 'grad_norm': 7.309696674346924, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 04:54:46 client2-1  | {'eval_loss': 1.6795977354049683, 'eval_runtime': 5.059, 'eval_samples_per_second': 39.534, 'eval_steps_per_second': 4.942, 'epoch': 1.0}
2025-05-22 04:21:04 client3-1  | {'loss': 0.4609, 'grad_norm': 5.855710983276367, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 04:54:46 client2-1  | INFO :      Sent reply
2025-05-22 04:21:19 client3-1  | {'loss': 0.6257, 'grad_norm': 8.804306030273438, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 04:34:22 client1-1  | {'loss': 0.4599, 'grad_norm': 7.7280659675598145, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 04:34:43 client1-1  | {'loss': 0.393, 'grad_norm': 7.699485778808594, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 04:34:57 client1-1  | {'loss': 0.4682, 'grad_norm': 9.419119834899902, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 04:21:34 client3-1  | {'loss': 0.5215, 'grad_norm': 6.912844657897949, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 04:35:12 client1-1  | {'loss': 0.4309, 'grad_norm': 14.303106307983398, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 04:35:34 client1-1  | {'loss': 0.468, 'grad_norm': 7.317203998565674, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 04:55:10 client2-1  | INFO :      
2025-05-22 04:55:10 client2-1  | INFO :      Received: train message 99b7b07e-e2aa-46ff-946b-73616c5d6441
2025-05-22 04:55:38 client2-1  | {'loss': 0.1097, 'grad_norm': 2.8568267822265625, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 04:35:49 client1-1  | {'loss': 0.525, 'grad_norm': 8.297375679016113, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 04:36:04 client1-1  | {'loss': 0.5117, 'grad_norm': 8.659406661987305, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 04:36:18 client1-1  | {'loss': 0.5313, 'grad_norm': 7.997132778167725, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 04:36:40 client1-1  | {'loss': 0.5737, 'grad_norm': 5.4249587059021, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 04:21:55 client3-1  | {'loss': 0.4585, 'grad_norm': 6.866522312164307, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 04:22:10 client3-1  | {'loss': 0.5058, 'grad_norm': 8.009133338928223, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 04:22:25 client3-1  | {'loss': 0.5817, 'grad_norm': 6.6524224281311035, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 04:36:54 client1-1  | {'loss': 0.5479, 'grad_norm': 8.015748977661133, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 04:37:09 client1-1  | {'loss': 0.6295, 'grad_norm': 5.608674049377441, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 04:37:24 client1-1  | {'loss': 0.6681, 'grad_norm': 10.016013145446777, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 04:37:46 client1-1  | {'loss': 0.6848, 'grad_norm': 8.854442596435547, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 04:38:00 client1-1  | {'loss': 0.6195, 'grad_norm': 8.821426391601562, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 04:38:15 client1-1  | {'loss': 0.7621, 'grad_norm': 10.097086906433105, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 04:38:30 client1-1  | {'loss': 0.8531, 'grad_norm': 12.651957511901855, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 04:38:51 client1-1  | {'loss': 0.8267, 'grad_norm': 8.948455810546875, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 04:22:40 client3-1  | {'loss': 0.5906, 'grad_norm': 8.861013412475586, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 04:23:01 client3-1  | {'loss': 0.4878, 'grad_norm': 7.047570705413818, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 04:23:16 client3-1  | {'loss': 0.5237, 'grad_norm': 6.096858978271484, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 04:23:31 client3-1  | {'loss': 0.557, 'grad_norm': 7.883681297302246, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 04:23:47 client3-1  | {'loss': 0.5188, 'grad_norm': 9.842528343200684, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 04:24:09 client3-1  | {'loss': 0.6028, 'grad_norm': 9.301025390625, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 04:24:24 client3-1  | {'loss': 0.6106, 'grad_norm': 6.871353626251221, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 04:24:38 client3-1  | {'loss': 0.6679, 'grad_norm': 8.026411056518555, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 04:39:06 client1-1  | {'loss': 0.9361, 'grad_norm': 10.10193157196045, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 04:39:21 client1-1  | {'loss': 0.9242, 'grad_norm': 8.393745422363281, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 04:39:36 client1-1  | {'loss': 1.0216, 'grad_norm': 8.700626373291016, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 04:39:58 client1-1  | {'loss': 1.164, 'grad_norm': 14.685864448547363, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 04:40:13 client1-1  | {'loss': 1.0913, 'grad_norm': 10.606024742126465, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 04:24:53 client3-1  | {'loss': 0.8048, 'grad_norm': 10.705231666564941, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 04:40:28 client1-1  | {'loss': 1.2403, 'grad_norm': 12.464448928833008, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 04:25:14 client3-1  | {'loss': 0.6948, 'grad_norm': 8.910943984985352, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 04:25:29 client3-1  | {'loss': 0.76, 'grad_norm': 7.503702163696289, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 04:40:43 client1-1  | {'loss': 1.2816, 'grad_norm': 9.725188255310059, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 04:55:59 client2-1  | {'loss': 0.1202, 'grad_norm': 2.351612091064453, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 04:41:04 client1-1  | {'loss': 1.2722, 'grad_norm': 10.07214641571045, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 04:41:19 client1-1  | {'loss': 1.2688, 'grad_norm': 9.441168785095215, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 04:25:44 client3-1  | {'loss': 0.8147, 'grad_norm': 8.471817016601562, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 04:41:35 client1-1  | {'loss': 1.051, 'grad_norm': 10.120515823364258, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 04:56:14 client2-1  | {'loss': 0.1796, 'grad_norm': 4.556416034698486, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 04:56:29 client2-1  | {'loss': 0.2452, 'grad_norm': 7.354614734649658, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 04:56:44 client2-1  | {'loss': 0.2117, 'grad_norm': 2.857057809829712, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 04:57:05 client2-1  | {'loss': 0.228, 'grad_norm': 3.8203108310699463, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 04:25:59 client3-1  | {'loss': 0.9119, 'grad_norm': 6.614879608154297, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 04:26:20 client3-1  | {'loss': 0.7859, 'grad_norm': 7.860061168670654, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 04:26:35 client3-1  | {'loss': 0.8433, 'grad_norm': 8.205944061279297, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 04:26:51 client3-1  | {'loss': 0.9675, 'grad_norm': 10.716755867004395, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 04:27:06 client3-1  | {'loss': 1.0351, 'grad_norm': 10.24393081665039, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 04:27:27 client3-1  | {'loss': 1.0565, 'grad_norm': 8.462528228759766, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 04:41:50 client1-1  | {'loss': 0.8008, 'grad_norm': 7.025604724884033, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 04:27:42 client3-1  | {'loss': 1.0593, 'grad_norm': 9.499496459960938, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 04:27:56 client3-1  | {'loss': 1.2714, 'grad_norm': 13.767718315124512, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 04:28:11 client3-1  | {'loss': 1.1919, 'grad_norm': 10.3849515914917, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 04:28:33 client3-1  | {'loss': 1.1267, 'grad_norm': 9.906889915466309, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 04:42:02 client1-1  | {'loss': 0.3543, 'grad_norm': 5.214371681213379, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 04:42:02 client1-1  | {'train_runtime': 665.3319, 'train_samples_per_second': 1.202, 'train_steps_per_second': 0.601, 'train_loss': 0.6442755722999572, 'epoch': 1.0}
2025-05-22 04:42:06 client1-1  | INFO :      Sent reply
2025-05-22 04:42:26 client1-1  | INFO :      
2025-05-22 04:42:26 client1-1  | INFO :      Received: evaluate message e75c485b-755f-4fca-9a85-3ba76a82688a
2025-05-22 04:42:29 client1-1  | {'eval_loss': 1.6944650411605835, 'eval_runtime': 2.7929, 'eval_samples_per_second': 71.611, 'eval_steps_per_second': 8.951, 'epoch': 1.0}
2025-05-22 04:42:29 client1-1  | INFO :      Sent reply
2025-05-22 04:42:59 client1-1  | INFO :      
2025-05-22 04:42:59 client1-1  | INFO :      Received: train message 540a22f9-343b-4c9c-8260-c4c3193554e9
2025-05-22 04:43:27 client1-1  | {'loss': 0.1347, 'grad_norm': 3.4055027961730957, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 04:57:20 client2-1  | {'loss': 0.2282, 'grad_norm': 7.4298834800720215, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 04:57:35 client2-1  | {'loss': 0.2312, 'grad_norm': 6.04530668258667, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 04:43:42 client1-1  | {'loss': 0.1307, 'grad_norm': 2.8213279247283936, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 04:43:57 client1-1  | {'loss': 0.1942, 'grad_norm': 5.77959680557251, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 04:44:18 client1-1  | {'loss': 0.3118, 'grad_norm': 8.437918663024902, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 04:44:34 client1-1  | {'loss': 0.2646, 'grad_norm': 3.789565324783325, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 04:44:49 client1-1  | {'loss': 0.2581, 'grad_norm': 3.568899393081665, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 04:45:10 client1-1  | {'loss': 0.2555, 'grad_norm': 7.643226623535156, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 04:57:49 client2-1  | {'loss': 0.2654, 'grad_norm': 4.902284622192383, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 04:58:11 client2-1  | {'loss': 0.2691, 'grad_norm': 5.178260326385498, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 04:58:26 client2-1  | {'loss': 0.2697, 'grad_norm': 5.548050403594971, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 04:45:25 client1-1  | {'loss': 0.2719, 'grad_norm': 5.892271041870117, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 04:45:40 client1-1  | {'loss': 0.32, 'grad_norm': 5.131961822509766, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 04:45:55 client1-1  | {'loss': 0.2922, 'grad_norm': 4.853964805603027, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 04:46:10 client1-1  | {'loss': 0.3743, 'grad_norm': 8.11082649230957, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 04:46:31 client1-1  | {'loss': 0.3743, 'grad_norm': 7.308194637298584, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 04:28:48 client3-1  | {'loss': 1.4103, 'grad_norm': 10.72800064086914, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 04:29:03 client3-1  | {'loss': 1.3736, 'grad_norm': 11.879199028015137, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 04:29:21 client3-1  | {'loss': 1.178, 'grad_norm': 9.75475025177002, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 04:29:31 client3-1  | {'loss': 0.8985, 'grad_norm': 5.116011619567871, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 04:29:41 client3-1  | {'loss': 0.3654, 'grad_norm': 5.529353618621826, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 04:58:41 client2-1  | {'loss': 0.2457, 'grad_norm': 8.069698333740234, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 04:58:55 client2-1  | {'loss': 0.3255, 'grad_norm': 5.099298000335693, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 04:59:16 client2-1  | {'loss': 0.2969, 'grad_norm': 7.614104747772217, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 04:46:47 client1-1  | {'loss': 0.331, 'grad_norm': 7.31744384765625, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 04:47:02 client1-1  | {'loss': 0.3837, 'grad_norm': 10.087945938110352, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 04:47:17 client1-1  | {'loss': 0.3607, 'grad_norm': 8.423402786254883, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 04:47:38 client1-1  | {'loss': 0.4134, 'grad_norm': 6.751263618469238, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 04:47:53 client1-1  | {'loss': 0.4521, 'grad_norm': 8.200617790222168, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 04:48:08 client1-1  | {'loss': 0.4434, 'grad_norm': 8.779400825500488, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 04:29:41 client3-1  | {'train_runtime': 656.9319, 'train_samples_per_second': 1.216, 'train_steps_per_second': 0.609, 'train_loss': 0.7173448249697685, 'epoch': 1.0}
2025-05-22 04:29:47 client3-1  | INFO :      Sent reply
2025-05-22 04:30:17 client3-1  | INFO :      
2025-05-22 04:48:23 client1-1  | {'loss': 0.4472, 'grad_norm': 7.785075664520264, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 04:30:17 client3-1  | INFO :      Received: evaluate message 7dad9108-fc46-4959-a77c-d5dfa4f4556e
2025-05-22 04:30:36 client3-1  | {'eval_loss': 1.6926274299621582, 'eval_runtime': 17.5493, 'eval_samples_per_second': 11.396, 'eval_steps_per_second': 1.425, 'epoch': 1.0}
2025-05-22 04:48:44 client1-1  | {'loss': 0.4937, 'grad_norm': 6.29317045211792, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 04:48:59 client1-1  | {'loss': 0.4768, 'grad_norm': 7.822013854980469, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 04:49:15 client1-1  | {'loss': 0.546, 'grad_norm': 5.130233287811279, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 04:49:29 client1-1  | {'loss': 0.5683, 'grad_norm': 9.260725975036621, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 04:49:51 client1-1  | {'loss': 0.6173, 'grad_norm': 8.709486961364746, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 04:30:36 client3-1  | INFO :      Sent reply
2025-05-22 04:30:49 client3-1  | INFO :      
2025-05-22 04:30:49 client3-1  | INFO :      Received: train message 49f1d88f-ffe9-4b48-bea3-c54b0bf69f40
2025-05-22 04:31:06 client3-1  | {'loss': 0.136, 'grad_norm': 4.580937385559082, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 04:31:27 client3-1  | {'loss': 0.2284, 'grad_norm': 3.448490858078003, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 04:31:42 client3-1  | {'loss': 0.257, 'grad_norm': 6.958736896514893, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 04:59:31 client2-1  | {'loss': 0.2829, 'grad_norm': 8.06191349029541, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 04:31:57 client3-1  | {'loss': 0.3294, 'grad_norm': 8.72636604309082, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 04:50:06 client1-1  | {'loss': 0.5714, 'grad_norm': 9.219792366027832, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 04:50:21 client1-1  | {'loss': 0.7058, 'grad_norm': 11.077265739440918, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 04:50:35 client1-1  | {'loss': 0.7849, 'grad_norm': 10.496434211730957, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 04:59:46 client2-1  | {'loss': 0.3649, 'grad_norm': 6.243358135223389, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 05:00:07 client2-1  | {'loss': 0.4355, 'grad_norm': 7.271373748779297, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 04:50:57 client1-1  | {'loss': 0.7698, 'grad_norm': 8.322940826416016, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 04:51:12 client1-1  | {'loss': 0.857, 'grad_norm': 10.903475761413574, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 04:51:27 client1-1  | {'loss': 0.8686, 'grad_norm': 9.305428504943848, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 05:00:22 client2-1  | {'loss': 0.3976, 'grad_norm': 7.557873725891113, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 05:00:37 client2-1  | {'loss': 0.3993, 'grad_norm': 8.334031105041504, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 05:00:52 client2-1  | {'loss': 0.4757, 'grad_norm': 5.86543083190918, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 05:01:13 client2-1  | {'loss': 0.53, 'grad_norm': 11.757652282714844, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 04:32:12 client3-1  | {'loss': 0.2874, 'grad_norm': 7.785442352294922, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 04:32:33 client3-1  | {'loss': 0.2739, 'grad_norm': 4.561288356781006, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 04:32:48 client3-1  | {'loss': 0.3628, 'grad_norm': 6.9194655418396, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 04:51:42 client1-1  | {'loss': 0.9661, 'grad_norm': 9.216864585876465, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 04:33:03 client3-1  | {'loss': 0.3914, 'grad_norm': 5.824211120605469, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 05:01:28 client2-1  | {'loss': 0.4578, 'grad_norm': 9.133537292480469, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 05:01:43 client2-1  | {'loss': 0.4002, 'grad_norm': 7.152913570404053, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 05:01:58 client2-1  | {'loss': 0.4976, 'grad_norm': 6.299243927001953, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 04:33:18 client3-1  | {'loss': 0.5255, 'grad_norm': 7.039236545562744, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 04:33:39 client3-1  | {'loss': 0.4099, 'grad_norm': 6.407082557678223, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 04:33:54 client3-1  | {'loss': 0.3688, 'grad_norm': 6.936593055725098, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 05:02:19 client2-1  | {'loss': 0.6445, 'grad_norm': 11.605988502502441, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 05:02:34 client2-1  | {'loss': 0.6262, 'grad_norm': 10.829933166503906, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 05:02:49 client2-1  | {'loss': 0.8173, 'grad_norm': 12.957200050354004, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 05:03:10 client2-1  | {'loss': 0.7146, 'grad_norm': 9.8138427734375, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 05:03:26 client2-1  | {'loss': 0.5961, 'grad_norm': 9.74129581451416, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 05:03:41 client2-1  | {'loss': 0.8471, 'grad_norm': 8.564406394958496, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 05:03:56 client2-1  | {'loss': 0.808, 'grad_norm': 7.92949914932251, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 04:34:09 client3-1  | {'loss': 0.4226, 'grad_norm': 8.035381317138672, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 04:34:24 client3-1  | {'loss': 0.4865, 'grad_norm': 5.828047275543213, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 04:34:45 client3-1  | {'loss': 0.4931, 'grad_norm': 7.226221084594727, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 05:04:17 client2-1  | {'loss': 1.0663, 'grad_norm': 11.469545364379883, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 04:52:03 client1-1  | {'loss': 1.1376, 'grad_norm': 15.395267486572266, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 04:52:18 client1-1  | {'loss': 1.0395, 'grad_norm': 12.032328605651855, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 04:52:33 client1-1  | {'loss': 1.2061, 'grad_norm': 13.061767578125, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 04:35:00 client3-1  | {'loss': 0.3999, 'grad_norm': 6.934537887573242, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 04:35:15 client3-1  | {'loss': 0.4445, 'grad_norm': 6.923514366149902, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 04:35:30 client3-1  | {'loss': 0.4818, 'grad_norm': 7.7454729080200195, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 04:35:51 client3-1  | {'loss': 0.4383, 'grad_norm': 8.804139137268066, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 04:52:48 client1-1  | {'loss': 1.2438, 'grad_norm': 10.54626178741455, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 04:53:09 client1-1  | {'loss': 1.2543, 'grad_norm': 11.464768409729004, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 04:53:24 client1-1  | {'loss': 1.237, 'grad_norm': 9.084656715393066, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 04:53:39 client1-1  | {'loss': 1.018, 'grad_norm': 9.93476390838623, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 04:36:06 client3-1  | {'loss': 0.5364, 'grad_norm': 12.330782890319824, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 04:54:01 client1-1  | {'loss': 0.7493, 'grad_norm': 7.300207614898682, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 04:36:21 client3-1  | {'loss': 0.5392, 'grad_norm': 10.928690910339355, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 04:54:12 client1-1  | {'loss': 0.2975, 'grad_norm': 5.4969892501831055, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 05:04:32 client2-1  | {'loss': 0.9354, 'grad_norm': 10.985308647155762, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 04:54:12 client1-1  | {'train_runtime': 667.2001, 'train_samples_per_second': 1.199, 'train_steps_per_second': 0.6, 'train_loss': 0.5855666297674179, 'epoch': 1.0}
2025-05-22 04:54:18 client1-1  | INFO :      Sent reply
2025-05-22 04:54:47 client1-1  | INFO :      
2025-05-22 04:54:47 client1-1  | INFO :      Received: evaluate message a65fc5e4-2534-4283-a7ba-b69b2815342e
2025-05-22 04:36:35 client3-1  | {'loss': 0.6241, 'grad_norm': 8.412453651428223, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 04:36:56 client3-1  | {'loss': 0.6921, 'grad_norm': 8.99413776397705, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 04:37:11 client3-1  | {'loss': 0.6187, 'grad_norm': 9.05604076385498, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 04:54:56 client1-1  | {'eval_loss': 1.7270015478134155, 'eval_runtime': 6.6965, 'eval_samples_per_second': 29.866, 'eval_steps_per_second': 3.733, 'epoch': 1.0}
2025-05-22 04:54:56 client1-1  | INFO :      Sent reply
2025-05-22 04:55:10 client1-1  | INFO :      
2025-05-22 04:37:26 client3-1  | {'loss': 0.6792, 'grad_norm': 6.904469966888428, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 04:37:41 client3-1  | {'loss': 0.7267, 'grad_norm': 9.239357948303223, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 04:38:02 client3-1  | {'loss': 0.8448, 'grad_norm': 7.691108226776123, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 04:55:10 client1-1  | INFO :      Received: train message 0d18ba10-c98b-4b72-95c4-2f2b9b0918e8
2025-05-22 05:04:46 client2-1  | {'loss': 1.0836, 'grad_norm': 11.544734954833984, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 04:55:36 client1-1  | {'loss': 0.1181, 'grad_norm': 4.7350592613220215, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 05:05:01 client2-1  | {'loss': 1.2492, 'grad_norm': 11.026151657104492, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 05:05:23 client2-1  | {'loss': 1.2727, 'grad_norm': 14.307318687438965, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 04:38:17 client3-1  | {'loss': 0.7006, 'grad_norm': 7.394796371459961, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 05:05:37 client2-1  | {'loss': 1.2976, 'grad_norm': 12.541955947875977, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 04:38:32 client3-1  | {'loss': 0.7809, 'grad_norm': 9.023836135864258, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 05:05:52 client2-1  | {'loss': 1.2259, 'grad_norm': 9.079427719116211, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 05:06:08 client2-1  | {'loss': 0.877, 'grad_norm': 11.148590087890625, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 05:06:22 client2-1  | {'loss': 0.2716, 'grad_norm': 7.361379146575928, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 05:06:22 client2-1  | {'train_runtime': 668.462, 'train_samples_per_second': 1.197, 'train_steps_per_second': 0.598, 'train_loss': 0.5450231832265854, 'epoch': 1.0}
2025-05-22 05:06:27 client2-1  | INFO :      Sent reply
2025-05-22 04:38:47 client3-1  | {'loss': 0.9194, 'grad_norm': 11.353869438171387, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 04:39:08 client3-1  | {'loss': 0.97, 'grad_norm': 9.505247116088867, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 05:06:57 client2-1  | INFO :      
2025-05-22 04:39:23 client3-1  | {'loss': 1.0016, 'grad_norm': 8.55420207977295, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 04:39:38 client3-1  | {'loss': 1.0199, 'grad_norm': 9.92812442779541, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 04:39:53 client3-1  | {'loss': 1.2311, 'grad_norm': 16.121646881103516, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 04:40:08 client3-1  | {'loss': 1.1666, 'grad_norm': 11.134827613830566, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 05:06:57 client2-1  | INFO :      Received: evaluate message 58122f61-148f-4aac-b2c8-f8a9ba14cbab
2025-05-22 05:07:18 client2-1  | {'eval_loss': 1.7109863758087158, 'eval_runtime': 19.7597, 'eval_samples_per_second': 10.122, 'eval_steps_per_second': 1.265, 'epoch': 1.0}
2025-05-22 04:40:30 client3-1  | {'loss': 1.1216, 'grad_norm': 10.074496269226074, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 04:40:45 client3-1  | {'loss': 1.4011, 'grad_norm': 11.728012084960938, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 04:41:00 client3-1  | {'loss': 1.3535, 'grad_norm': 11.735406875610352, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 04:41:15 client3-1  | {'loss': 1.134, 'grad_norm': 8.40196418762207, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 04:41:36 client3-1  | {'loss': 0.8253, 'grad_norm': 5.5638508796691895, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 04:41:51 client3-1  | {'loss': 0.3295, 'grad_norm': 8.780325889587402, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 04:55:51 client1-1  | {'loss': 0.1074, 'grad_norm': 2.661639928817749, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 05:07:18 client2-1  | INFO :      Sent reply
2025-05-22 05:07:29 client2-1  | INFO :      
2025-05-22 05:07:29 client2-1  | INFO :      Received: train message d777ff05-e579-4ef4-9dc6-c679623ae52e
2025-05-22 04:41:51 client3-1  | {'train_runtime': 659.982, 'train_samples_per_second': 1.211, 'train_steps_per_second': 0.606, 'train_loss': 0.6488332509994507, 'epoch': 1.0}
2025-05-22 04:56:12 client1-1  | {'loss': 0.1652, 'grad_norm': 3.7438759803771973, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 04:41:57 client3-1  | INFO :      Sent reply
2025-05-22 04:56:27 client1-1  | {'loss': 0.2476, 'grad_norm': 5.442080974578857, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 04:42:34 client3-1  | INFO :      
2025-05-22 04:42:34 client3-1  | INFO :      Received: evaluate message f124a5d4-7d6a-47e5-88ac-d51ff3bc13a7
2025-05-22 04:42:45 client3-1  | {'eval_loss': 1.73114812374115, 'eval_runtime': 8.4909, 'eval_samples_per_second': 23.555, 'eval_steps_per_second': 2.944, 'epoch': 1.0}
2025-05-22 04:42:45 client3-1  | INFO :      Sent reply
2025-05-22 04:56:41 client1-1  | {'loss': 0.226, 'grad_norm': 4.241157054901123, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 04:56:56 client1-1  | {'loss': 0.2162, 'grad_norm': 2.48429799079895, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 04:57:17 client1-1  | {'loss': 0.2228, 'grad_norm': 7.887765407562256, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 04:57:32 client1-1  | {'loss': 0.2145, 'grad_norm': 4.605785369873047, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 04:42:57 client3-1  | INFO :      
2025-05-22 04:57:47 client1-1  | {'loss': 0.2651, 'grad_norm': 4.862572193145752, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 04:42:57 client3-1  | INFO :      Received: train message ea0f860b-f732-495f-aa0c-bbfb7e761dd3
2025-05-22 05:07:55 client2-1  | {'loss': 0.0901, 'grad_norm': 2.2596499919891357, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 05:08:16 client2-1  | {'loss': 0.112, 'grad_norm': 2.6778881549835205, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 05:08:31 client2-1  | {'loss': 0.1367, 'grad_norm': 2.206834077835083, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 04:43:17 client3-1  | {'loss': 0.1142, 'grad_norm': 3.1480040550231934, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 05:08:46 client2-1  | {'loss': 0.2169, 'grad_norm': 9.08475399017334, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 04:58:02 client1-1  | {'loss': 0.2407, 'grad_norm': 4.203855991363525, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 05:09:01 client2-1  | {'loss': 0.1923, 'grad_norm': 2.932602643966675, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 04:58:17 client1-1  | {'loss': 0.3127, 'grad_norm': 10.335917472839355, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 05:09:22 client2-1  | {'loss': 0.1783, 'grad_norm': 4.693676471710205, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 04:43:32 client3-1  | {'loss': 0.183, 'grad_norm': 3.312933921813965, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 04:43:47 client3-1  | {'loss': 0.2158, 'grad_norm': 5.526208400726318, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 04:44:08 client3-1  | {'loss': 0.2773, 'grad_norm': 7.25538444519043, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 04:44:24 client3-1  | {'loss': 0.2527, 'grad_norm': 5.88923454284668, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 05:09:37 client2-1  | {'loss': 0.1778, 'grad_norm': 4.463837146759033, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 05:09:52 client2-1  | {'loss': 0.1978, 'grad_norm': 4.379647731781006, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 04:44:45 client3-1  | {'loss': 0.2249, 'grad_norm': 4.734879493713379, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 04:45:00 client3-1  | {'loss': 0.3035, 'grad_norm': 7.126043796539307, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 05:10:07 client2-1  | {'loss': 0.2248, 'grad_norm': 2.4444010257720947, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 05:10:28 client2-1  | {'loss': 0.242, 'grad_norm': 6.644176959991455, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 05:10:43 client2-1  | {'loss': 0.2524, 'grad_norm': 7.585147380828857, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 04:45:15 client3-1  | {'loss': 0.3021, 'grad_norm': 4.473586082458496, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 04:45:30 client3-1  | {'loss': 0.4078, 'grad_norm': 10.178101539611816, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 04:58:38 client1-1  | {'loss': 0.3159, 'grad_norm': 5.454643249511719, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 04:45:45 client3-1  | {'loss': 0.3497, 'grad_norm': 6.900212287902832, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 04:58:53 client1-1  | {'loss': 0.2758, 'grad_norm': 5.931385517120361, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 04:46:06 client3-1  | {'loss': 0.3234, 'grad_norm': 6.559354305267334, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 05:10:58 client2-1  | {'loss': 0.205, 'grad_norm': 7.251523494720459, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 05:11:13 client2-1  | {'loss': 0.2706, 'grad_norm': 3.800077438354492, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 05:11:28 client2-1  | {'loss': 0.2546, 'grad_norm': 6.638823986053467, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 04:59:07 client1-1  | {'loss': 0.328, 'grad_norm': 13.202156066894531, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 05:11:50 client2-1  | {'loss': 0.2421, 'grad_norm': 5.799154758453369, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 04:59:28 client1-1  | {'loss': 0.3032, 'grad_norm': 7.186990261077881, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 05:12:04 client2-1  | {'loss': 0.322, 'grad_norm': 7.825409412384033, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 05:12:19 client2-1  | {'loss': 0.3806, 'grad_norm': 7.649064540863037, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 05:12:34 client2-1  | {'loss': 0.3361, 'grad_norm': 7.268486976623535, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 04:59:43 client1-1  | {'loss': 0.3456, 'grad_norm': 7.176638126373291, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 04:59:58 client1-1  | {'loss': 0.4016, 'grad_norm': 10.012768745422363, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 05:00:13 client1-1  | {'loss': 0.3798, 'grad_norm': 8.899625778198242, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 05:00:27 client1-1  | {'loss': 0.3974, 'grad_norm': 9.665694236755371, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 05:00:49 client1-1  | {'loss': 0.4257, 'grad_norm': 6.160409450531006, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 05:01:04 client1-1  | {'loss': 0.4234, 'grad_norm': 7.726772785186768, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 04:46:21 client3-1  | {'loss': 0.3577, 'grad_norm': 7.573545455932617, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 04:46:37 client3-1  | {'loss': 0.4052, 'grad_norm': 4.449696063995361, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 04:46:52 client3-1  | {'loss': 0.4371, 'grad_norm': 7.594057083129883, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 05:01:19 client1-1  | {'loss': 0.5059, 'grad_norm': 5.666257381439209, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 05:01:33 client1-1  | {'loss': 0.5113, 'grad_norm': 8.039546012878418, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 05:01:55 client1-1  | {'loss': 0.5568, 'grad_norm': 9.71020793914795, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 04:47:13 client3-1  | {'loss': 0.3363, 'grad_norm': 6.6693243980407715, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 05:02:09 client1-1  | {'loss': 0.517, 'grad_norm': 8.407526969909668, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 05:02:24 client1-1  | {'loss': 0.6203, 'grad_norm': 10.94188404083252, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 05:02:39 client1-1  | {'loss': 0.7048, 'grad_norm': 10.763846397399902, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 05:03:00 client1-1  | {'loss': 0.7135, 'grad_norm': 8.735297203063965, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 04:47:28 client3-1  | {'loss': 0.3809, 'grad_norm': 7.920199394226074, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 04:47:43 client3-1  | {'loss': 0.3953, 'grad_norm': 7.203114032745361, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 05:03:15 client1-1  | {'loss': 0.8142, 'grad_norm': 10.480391502380371, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 05:03:30 client1-1  | {'loss': 0.8169, 'grad_norm': 8.142288208007812, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 05:03:46 client1-1  | {'loss': 0.9201, 'grad_norm': 8.668365478515625, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 05:04:01 client1-1  | {'loss': 1.0815, 'grad_norm': 15.023870468139648, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 04:47:58 client3-1  | {'loss': 0.378, 'grad_norm': 8.247702598571777, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 04:48:13 client3-1  | {'loss': 0.4535, 'grad_norm': 9.694393157958984, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 04:48:34 client3-1  | {'loss': 0.477, 'grad_norm': 6.585262775421143, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 05:12:55 client2-1  | {'loss': 0.3342, 'grad_norm': 8.371480941772461, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 04:48:49 client3-1  | {'loss': 0.534, 'grad_norm': 7.7423810958862305, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 05:13:11 client2-1  | {'loss': 0.3984, 'grad_norm': 6.347566604614258, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 05:04:15 client1-1  | {'loss': 1.0063, 'grad_norm': 11.08133316040039, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 05:13:26 client2-1  | {'loss': 0.4447, 'grad_norm': 10.73214340209961, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 05:04:36 client1-1  | {'loss': 1.1595, 'grad_norm': 11.803142547607422, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 04:49:05 client3-1  | {'loss': 0.6097, 'grad_norm': 8.049796104431152, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 05:04:51 client1-1  | {'loss': 1.2091, 'grad_norm': 11.11624813079834, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 04:49:20 client3-1  | {'loss': 0.5426, 'grad_norm': 8.548091888427734, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 04:49:41 client3-1  | {'loss': 0.6101, 'grad_norm': 7.3353590965271, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 05:13:41 client2-1  | {'loss': 0.4048, 'grad_norm': 8.966064453125, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 05:13:56 client2-1  | {'loss': 0.3679, 'grad_norm': 7.701961517333984, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 04:49:56 client3-1  | {'loss': 0.6593, 'grad_norm': 8.775073051452637, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 04:50:11 client3-1  | {'loss': 0.7607, 'grad_norm': 6.8944091796875, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 05:05:06 client1-1  | {'loss': 1.2511, 'grad_norm': 11.18882942199707, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 05:05:28 client1-1  | {'loss': 1.2276, 'grad_norm': 10.064642906188965, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 04:50:26 client3-1  | {'loss': 0.6645, 'grad_norm': 7.476442337036133, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 04:50:41 client3-1  | {'loss': 0.7208, 'grad_norm': 7.987079620361328, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 04:51:02 client3-1  | {'loss': 0.8491, 'grad_norm': 11.453786849975586, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 04:51:17 client3-1  | {'loss': 0.9154, 'grad_norm': 9.172768592834473, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 05:14:17 client2-1  | {'loss': 0.4648, 'grad_norm': 7.170557975769043, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 05:14:32 client2-1  | {'loss': 0.5856, 'grad_norm': 10.869139671325684, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 04:51:32 client3-1  | {'loss': 0.9613, 'grad_norm': 9.854178428649902, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 05:05:42 client1-1  | {'loss': 0.9801, 'grad_norm': 10.87218189239502, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 04:51:53 client3-1  | {'loss': 0.9759, 'grad_norm': 9.077741622924805, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 04:52:08 client3-1  | {'loss': 1.1966, 'grad_norm': 12.824397087097168, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 04:52:23 client3-1  | {'loss': 1.1293, 'grad_norm': 11.249066352844238, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 05:05:57 client1-1  | {'loss': 0.7207, 'grad_norm': 7.27606725692749, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 04:52:38 client3-1  | {'loss': 1.0879, 'grad_norm': 10.256782531738281, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 04:52:59 client3-1  | {'loss': 1.3637, 'grad_norm': 12.016186714172363, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 04:53:14 client3-1  | {'loss': 1.3289, 'grad_norm': 12.636433601379395, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 04:53:29 client3-1  | {'loss': 1.1137, 'grad_norm': 9.847490310668945, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 05:06:13 client1-1  | {'loss': 0.2708, 'grad_norm': 5.029637336730957, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 05:06:13 client1-1  | {'train_runtime': 660.5051, 'train_samples_per_second': 1.211, 'train_steps_per_second': 0.606, 'train_loss': 0.5380015397071838, 'epoch': 1.0}
2025-05-22 05:06:26 client1-1  | INFO :      Sent reply
2025-05-22 05:06:57 client1-1  | INFO :      
2025-05-22 05:14:47 client2-1  | {'loss': 0.5746, 'grad_norm': 10.241692543029785, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 05:15:02 client2-1  | {'loss': 0.723, 'grad_norm': 10.14594554901123, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 05:06:57 client1-1  | INFO :      Received: evaluate message 7c2fc996-a507-4222-a069-b42e6a9869ee
2025-05-22 05:07:17 client1-1  | {'eval_loss': 1.7624390125274658, 'eval_runtime': 17.2, 'eval_samples_per_second': 11.628, 'eval_steps_per_second': 1.453, 'epoch': 1.0}
2025-05-22 05:07:17 client1-1  | INFO :      Sent reply
2025-05-22 05:07:30 client1-1  | INFO :      
2025-05-22 05:07:30 client1-1  | INFO :      Received: train message c7f495e6-c333-4f26-a423-5615748ad8e5
2025-05-22 05:07:45 client1-1  | {'loss': 0.0992, 'grad_norm': 3.086531162261963, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 04:53:44 client3-1  | {'loss': 0.798, 'grad_norm': 5.762510299682617, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 04:54:00 client3-1  | {'loss': 0.2825, 'grad_norm': 6.93544340133667, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 05:08:06 client1-1  | {'loss': 0.098, 'grad_norm': 1.7777001857757568, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 04:54:00 client3-1  | {'train_runtime': 661.4682, 'train_samples_per_second': 1.208, 'train_steps_per_second': 0.605, 'train_loss': 0.5919780796766281, 'epoch': 1.0}
2025-05-22 04:54:12 client3-1  | INFO :      Sent reply
2025-05-22 04:54:43 client3-1  | INFO :      
2025-05-22 05:08:21 client1-1  | {'loss': 0.1366, 'grad_norm': 1.8078866004943848, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 04:54:43 client3-1  | INFO :      Received: evaluate message b3033217-4f37-4a61-8348-661fc63a4802
2025-05-22 05:15:23 client2-1  | {'loss': 0.6547, 'grad_norm': 8.735172271728516, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 05:15:39 client2-1  | {'loss': 0.5813, 'grad_norm': 10.300650596618652, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 05:15:54 client2-1  | {'loss': 0.7844, 'grad_norm': 7.136312961578369, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 05:16:08 client2-1  | {'loss': 0.7684, 'grad_norm': 7.230226516723633, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 05:08:36 client1-1  | {'loss': 0.2299, 'grad_norm': 7.680461883544922, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 05:08:51 client1-1  | {'loss': 0.1973, 'grad_norm': 3.5256409645080566, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 05:09:12 client1-1  | {'loss': 0.1953, 'grad_norm': 2.3255462646484375, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 04:54:54 client3-1  | INFO :      Sent reply
2025-05-22 04:54:54 client3-1  | {'eval_loss': 1.7663973569869995, 'eval_runtime': 9.1389, 'eval_samples_per_second': 21.885, 'eval_steps_per_second': 2.736, 'epoch': 1.0}
2025-05-22 05:09:27 client1-1  | {'loss': 0.1834, 'grad_norm': 7.624995708465576, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 04:55:10 client3-1  | INFO :      
2025-05-22 05:16:30 client2-1  | {'loss': 1.0234, 'grad_norm': 11.739313125610352, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 04:55:10 client3-1  | INFO :      Received: train message c528a0c2-a109-4904-aa28-266ea522f3f2
2025-05-22 04:55:33 client3-1  | {'loss': 0.0986, 'grad_norm': 2.158245325088501, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 05:16:45 client2-1  | {'loss': 0.9128, 'grad_norm': 12.03699779510498, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 05:09:42 client1-1  | {'loss': 0.1803, 'grad_norm': 4.949675559997559, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 05:17:00 client2-1  | {'loss': 1.0358, 'grad_norm': 12.090023040771484, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 05:17:14 client2-1  | {'loss': 1.2271, 'grad_norm': 10.37222671508789, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 05:17:36 client2-1  | {'loss': 1.2629, 'grad_norm': 14.550174713134766, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 05:10:04 client1-1  | {'loss': 0.2243, 'grad_norm': 4.217690944671631, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 05:10:19 client1-1  | {'loss': 0.2166, 'grad_norm': 3.6007585525512695, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 04:55:48 client3-1  | {'loss': 0.147, 'grad_norm': 2.7529823780059814, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 04:56:03 client3-1  | {'loss': 0.1968, 'grad_norm': 6.577821731567383, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 04:56:24 client3-1  | {'loss': 0.2413, 'grad_norm': 7.051441669464111, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 05:10:33 client1-1  | {'loss': 0.2732, 'grad_norm': 7.924853801727295, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 04:56:39 client3-1  | {'loss': 0.2041, 'grad_norm': 6.640478610992432, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 05:10:48 client1-1  | {'loss': 0.3056, 'grad_norm': 6.301726341247559, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 04:56:54 client3-1  | {'loss': 0.1824, 'grad_norm': 3.6969516277313232, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 05:11:10 client1-1  | {'loss': 0.2312, 'grad_norm': 5.393591403961182, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 05:11:25 client1-1  | {'loss': 0.2676, 'grad_norm': 7.517149448394775, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 05:11:40 client1-1  | {'loss': 0.2464, 'grad_norm': 6.823383331298828, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 05:11:55 client1-1  | {'loss': 0.2908, 'grad_norm': 6.087268829345703, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 05:12:16 client1-1  | {'loss': 0.3446, 'grad_norm': 8.393874168395996, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 05:12:31 client1-1  | {'loss': 0.3459, 'grad_norm': 8.666267395019531, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 05:17:51 client2-1  | {'loss': 1.2448, 'grad_norm': 11.054750442504883, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 05:12:46 client1-1  | {'loss': 0.3437, 'grad_norm': 6.692462921142578, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 04:57:15 client3-1  | {'loss': 0.2391, 'grad_norm': 5.752933025360107, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 05:18:06 client2-1  | {'loss': 1.2138, 'grad_norm': 8.296917915344238, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 05:18:22 client2-1  | {'loss': 0.8346, 'grad_norm': 10.084211349487305, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 05:18:42 client2-1  | {'loss': 0.2536, 'grad_norm': 7.641740322113037, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 05:13:01 client1-1  | {'loss': 0.3582, 'grad_norm': 3.882755994796753, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 05:13:23 client1-1  | {'loss': 0.3585, 'grad_norm': 7.120036602020264, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 05:13:38 client1-1  | {'loss': 0.4358, 'grad_norm': 5.906087875366211, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 05:18:42 client2-1  | {'train_runtime': 668.6214, 'train_samples_per_second': 1.196, 'train_steps_per_second': 0.598, 'train_loss': 0.5031987695395946, 'epoch': 1.0}
2025-05-22 05:13:53 client1-1  | {'loss': 0.4384, 'grad_norm': 9.208498001098633, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 05:14:08 client1-1  | {'loss': 0.473, 'grad_norm': 7.826634407043457, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 05:14:23 client1-1  | {'loss': 0.4378, 'grad_norm': 8.770362854003906, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 04:57:29 client3-1  | {'loss': 0.271, 'grad_norm': 5.24810266494751, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 04:57:44 client3-1  | {'loss': 0.3559, 'grad_norm': 9.886265754699707, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 04:57:59 client3-1  | {'loss': 0.2949, 'grad_norm': 4.254630088806152, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 04:58:21 client3-1  | {'loss': 0.2588, 'grad_norm': 6.085628986358643, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 05:18:49 client2-1  | INFO :      Sent reply
2025-05-22 05:19:24 client2-1  | INFO :      
2025-05-22 05:19:24 client2-1  | INFO :      Received: evaluate message f55e22d9-f12e-4b88-87bf-10b966b17eda
2025-05-22 05:19:39 client2-1  | {'eval_loss': 1.7457776069641113, 'eval_runtime': 11.41, 'eval_samples_per_second': 17.528, 'eval_steps_per_second': 2.191, 'epoch': 1.0}
2025-05-22 05:19:39 client2-1  | INFO :      Sent reply
2025-05-22 05:19:55 client2-1  | INFO :      
2025-05-22 05:19:55 client2-1  | INFO :      Received: train message dfc6be73-254e-4ddc-a8f9-e693c466b45f
2025-05-22 05:20:19 client2-1  | {'loss': 0.0887, 'grad_norm': 1.8855854272842407, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 05:20:34 client2-1  | {'loss': 0.1179, 'grad_norm': 2.8799445629119873, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 05:14:44 client1-1  | {'loss': 0.5616, 'grad_norm': 10.306356430053711, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 05:14:59 client1-1  | {'loss': 0.6454, 'grad_norm': 10.7792387008667, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 05:20:49 client2-1  | {'loss': 0.1377, 'grad_norm': 3.115878105163574, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 05:15:14 client1-1  | {'loss': 0.6364, 'grad_norm': 7.931114196777344, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 05:21:04 client2-1  | {'loss': 0.1806, 'grad_norm': 9.68755054473877, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 05:15:29 client1-1  | {'loss': 0.746, 'grad_norm': 10.355125427246094, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 04:58:36 client3-1  | {'loss': 0.2959, 'grad_norm': 6.1194939613342285, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 05:15:51 client1-1  | {'loss': 0.7546, 'grad_norm': 7.607539176940918, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 04:58:50 client3-1  | {'loss': 0.351, 'grad_norm': 6.270841121673584, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 05:16:06 client1-1  | {'loss': 0.8466, 'grad_norm': 8.119630813598633, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 04:59:05 client3-1  | {'loss': 0.3712, 'grad_norm': 10.14863395690918, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 05:16:21 client1-1  | {'loss': 1.0476, 'grad_norm': 15.176194190979004, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 05:16:35 client1-1  | {'loss': 0.9644, 'grad_norm': 10.950445175170898, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 05:16:57 client1-1  | {'loss': 1.1498, 'grad_norm': 14.442083358764648, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 04:59:26 client3-1  | {'loss': 0.2775, 'grad_norm': 6.308438301086426, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 04:59:41 client3-1  | {'loss': 0.3076, 'grad_norm': 6.494106769561768, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 04:59:56 client3-1  | {'loss': 0.339, 'grad_norm': 8.007779121398926, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 05:21:25 client2-1  | {'loss': 0.1804, 'grad_norm': 5.643167018890381, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 05:21:40 client2-1  | {'loss': 0.1654, 'grad_norm': 3.5055530071258545, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 05:17:11 client1-1  | {'loss': 1.2069, 'grad_norm': 9.761313438415527, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 05:17:26 client1-1  | {'loss': 1.2022, 'grad_norm': 10.863670349121094, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 05:21:54 client2-1  | {'loss': 0.1422, 'grad_norm': 3.6890060901641846, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 05:22:10 client2-1  | {'loss': 0.1806, 'grad_norm': 5.6764044761657715, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 05:17:41 client1-1  | {'loss': 1.2092, 'grad_norm': 9.826408386230469, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 05:18:03 client1-1  | {'loss': 0.9702, 'grad_norm': 10.819573402404785, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 05:18:18 client1-1  | {'loss': 0.6659, 'grad_norm': 7.389080047607422, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 05:22:31 client2-1  | {'loss': 0.2117, 'grad_norm': 3.7645726203918457, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 05:22:47 client2-1  | {'loss': 0.2064, 'grad_norm': 5.037339210510254, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 05:23:01 client2-1  | {'loss': 0.1945, 'grad_norm': 6.1634931564331055, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 05:23:16 client2-1  | {'loss': 0.1774, 'grad_norm': 6.1258344650268555, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 05:23:38 client2-1  | {'loss': 0.2379, 'grad_norm': 3.3513450622558594, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 05:23:53 client2-1  | {'loss': 0.2086, 'grad_norm': 4.964372634887695, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 05:24:08 client2-1  | {'loss': 0.1998, 'grad_norm': 3.770850658416748, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 05:24:23 client2-1  | {'loss': 0.2841, 'grad_norm': 5.780647277832031, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 05:00:10 client3-1  | {'loss': 0.3245, 'grad_norm': 8.660459518432617, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 05:00:31 client3-1  | {'loss': 0.3848, 'grad_norm': 8.725113868713379, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 05:24:38 client2-1  | {'loss': 0.3116, 'grad_norm': 7.284841060638428, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 05:18:34 client1-1  | {'loss': 0.2565, 'grad_norm': 5.309234142303467, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 05:00:46 client3-1  | {'loss': 0.3903, 'grad_norm': 5.5403900146484375, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 05:01:01 client3-1  | {'loss': 0.4624, 'grad_norm': 7.065725326538086, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 05:18:34 client1-1  | {'train_runtime': 663.0211, 'train_samples_per_second': 1.207, 'train_steps_per_second': 0.603, 'train_loss': 0.49437604382634165, 'epoch': 1.0}
2025-05-22 05:01:16 client3-1  | {'loss': 0.5458, 'grad_norm': 9.596452713012695, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 05:24:58 client2-1  | {'loss': 0.2858, 'grad_norm': 6.304993152618408, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 05:25:14 client2-1  | {'loss': 0.2785, 'grad_norm': 7.693700313568115, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 05:18:42 client1-1  | INFO :      Sent reply
2025-05-22 05:19:20 client1-1  | INFO :      
2025-05-22 05:19:20 client1-1  | INFO :      Received: evaluate message 6133e30c-ae28-4d45-b7fb-bc6ee57ff97e
2025-05-22 05:19:30 client1-1  | {'eval_loss': 1.7966009378433228, 'eval_runtime': 8.5575, 'eval_samples_per_second': 23.371, 'eval_steps_per_second': 2.921, 'epoch': 1.0}
2025-05-22 05:25:29 client2-1  | {'loss': 0.3569, 'grad_norm': 5.356331825256348, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 05:19:30 client1-1  | INFO :      Sent reply
2025-05-22 05:01:37 client3-1  | {'loss': 0.4743, 'grad_norm': 9.30215072631836, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 05:25:44 client2-1  | {'loss': 0.3802, 'grad_norm': 10.866341590881348, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 05:26:05 client2-1  | {'loss': 0.3508, 'grad_norm': 9.072970390319824, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 05:19:56 client1-1  | INFO :      
2025-05-22 05:19:56 client1-1  | INFO :      Received: train message 661e51d4-8190-4392-a0c2-bf0d12032287
2025-05-22 05:20:24 client1-1  | {'loss': 0.0917, 'grad_norm': 3.668105363845825, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 05:26:20 client2-1  | {'loss': 0.305, 'grad_norm': 6.7865447998046875, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 05:20:39 client1-1  | {'loss': 0.0914, 'grad_norm': 1.5761626958847046, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 05:26:35 client2-1  | {'loss': 0.4037, 'grad_norm': 6.941814422607422, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 05:20:54 client1-1  | {'loss': 0.1208, 'grad_norm': 1.937540888786316, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 05:26:50 client2-1  | {'loss': 0.5215, 'grad_norm': 11.14174747467041, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 05:01:52 client3-1  | {'loss': 0.5328, 'grad_norm': 7.267536163330078, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 05:27:11 client2-1  | {'loss': 0.4991, 'grad_norm': 10.647700309753418, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 05:02:07 client3-1  | {'loss': 0.6003, 'grad_norm': 6.895804405212402, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 05:21:09 client1-1  | {'loss': 0.1944, 'grad_norm': 7.284475803375244, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 05:27:26 client2-1  | {'loss': 0.6661, 'grad_norm': 10.915584564208984, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 05:21:30 client1-1  | {'loss': 0.196, 'grad_norm': 5.366128444671631, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 05:27:41 client2-1  | {'loss': 0.601, 'grad_norm': 8.74622917175293, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 05:02:22 client3-1  | {'loss': 0.6952, 'grad_norm': 6.4605937004089355, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 05:27:56 client2-1  | {'loss': 0.5143, 'grad_norm': 8.902698516845703, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 05:02:37 client3-1  | {'loss': 0.5761, 'grad_norm': 8.067702293395996, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 05:21:45 client1-1  | {'loss': 0.1627, 'grad_norm': 1.6611248254776, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 05:28:18 client2-1  | {'loss': 0.7294, 'grad_norm': 8.30864429473877, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 05:22:00 client1-1  | {'loss': 0.1664, 'grad_norm': 6.070773601531982, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 05:28:33 client2-1  | {'loss': 0.7118, 'grad_norm': 6.9500508308410645, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 05:22:21 client1-1  | {'loss': 0.1636, 'grad_norm': 3.5946145057678223, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 05:02:58 client3-1  | {'loss': 0.6679, 'grad_norm': 8.388466835021973, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 05:28:48 client2-1  | {'loss': 0.9743, 'grad_norm': 11.242156982421875, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 05:29:03 client2-1  | {'loss': 0.8712, 'grad_norm': 10.645400047302246, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 05:03:13 client3-1  | {'loss': 0.8008, 'grad_norm': 10.525113105773926, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 05:03:28 client3-1  | {'loss': 0.8616, 'grad_norm': 9.054672241210938, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 05:03:43 client3-1  | {'loss': 0.9091, 'grad_norm': 8.92676830291748, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 05:04:05 client3-1  | {'loss': 0.9334, 'grad_norm': 10.201530456542969, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 05:04:20 client3-1  | {'loss': 1.1712, 'grad_norm': 13.153429985046387, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 05:04:34 client3-1  | {'loss': 1.0977, 'grad_norm': 11.356996536254883, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 05:04:49 client3-1  | {'loss': 1.0611, 'grad_norm': 10.494823455810547, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 05:29:25 client2-1  | {'loss': 1.0043, 'grad_norm': 12.867603302001953, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 05:29:40 client2-1  | {'loss': 1.2062, 'grad_norm': 11.624452590942383, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 05:29:55 client2-1  | {'loss': 1.237, 'grad_norm': 14.62277603149414, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 05:30:10 client2-1  | {'loss': 1.2293, 'grad_norm': 12.450138092041016, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 05:30:31 client2-1  | {'loss': 1.1925, 'grad_norm': 9.75722599029541, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 05:05:10 client3-1  | {'loss': 1.3485, 'grad_norm': 12.18636703491211, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 05:05:25 client3-1  | {'loss': 1.3155, 'grad_norm': 14.13520622253418, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 05:30:46 client2-1  | {'loss': 0.7785, 'grad_norm': 10.741737365722656, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 05:31:01 client2-1  | {'loss': 0.2286, 'grad_norm': 10.937873840332031, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 05:31:01 client2-1  | {'train_runtime': 664.1215, 'train_samples_per_second': 1.205, 'train_steps_per_second': 0.602, 'train_loss': 0.46378732919692994, 'epoch': 1.0}
2025-05-22 05:05:40 client3-1  | {'loss': 1.0634, 'grad_norm': 10.12693977355957, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 05:31:10 client2-1  | INFO :      Sent reply
2025-05-22 05:31:45 client2-1  | INFO :      
2025-05-22 05:22:36 client1-1  | {'loss': 0.2051, 'grad_norm': 3.301563024520874, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 05:31:45 client2-1  | INFO :      Received: evaluate message adde2ece-3c4f-4c39-991c-2cd0a0ad8a1a
2025-05-22 05:22:52 client1-1  | {'loss': 0.2008, 'grad_norm': 3.0517418384552, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 05:23:07 client1-1  | {'loss': 0.2188, 'grad_norm': 6.58121395111084, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 05:05:55 client3-1  | {'loss': 0.7326, 'grad_norm': 5.3906049728393555, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 05:06:17 client3-1  | {'loss': 0.2559, 'grad_norm': 5.069115161895752, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 05:06:17 client3-1  | {'train_runtime': 663.0993, 'train_samples_per_second': 1.205, 'train_steps_per_second': 0.603, 'train_loss': 0.54093217253685, 'epoch': 1.0}
2025-05-22 05:06:23 client3-1  | INFO :      Sent reply
2025-05-22 05:31:57 client2-1  | {'eval_loss': 1.7765334844589233, 'eval_runtime': 10.8329, 'eval_samples_per_second': 18.462, 'eval_steps_per_second': 2.308, 'epoch': 1.0}
2025-05-22 05:31:57 client2-1  | INFO :      Sent reply
2025-05-22 05:23:28 client1-1  | {'loss': 0.2631, 'grad_norm': 7.162094593048096, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 05:06:55 client3-1  | INFO :      
2025-05-22 05:23:43 client1-1  | {'loss': 0.199, 'grad_norm': 6.202008247375488, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 05:06:55 client3-1  | INFO :      Received: evaluate message db02955a-6f49-4140-b3a6-2df5b5aafaa0
2025-05-22 05:07:14 client3-1  | {'eval_loss': 1.8011282682418823, 'eval_runtime': 16.7529, 'eval_samples_per_second': 11.938, 'eval_steps_per_second': 1.492, 'epoch': 1.0}
2025-05-22 05:07:14 client3-1  | INFO :      Sent reply
2025-05-22 05:07:30 client3-1  | INFO :      
2025-05-22 05:07:30 client3-1  | INFO :      Received: train message e8c9b2c0-5653-4aae-a823-049601e02772
2025-05-22 05:07:57 client3-1  | {'loss': 0.0923, 'grad_norm': 1.4688433408737183, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 05:08:19 client3-1  | {'loss': 0.1263, 'grad_norm': 2.087080478668213, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 05:08:33 client3-1  | {'loss': 0.1374, 'grad_norm': 3.5875420570373535, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 05:32:16 client2-1  | INFO :      
2025-05-22 05:32:16 client2-1  | INFO :      Received: train message 8184743a-58c0-4823-8c91-9510699ff210
2025-05-22 05:32:40 client2-1  | {'loss': 0.0756, 'grad_norm': 3.0782060623168945, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 05:32:55 client2-1  | {'loss': 0.1038, 'grad_norm': 2.5789918899536133, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 05:08:48 client3-1  | {'loss': 0.1974, 'grad_norm': 6.3636345863342285, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 05:09:03 client3-1  | {'loss': 0.1624, 'grad_norm': 4.788581371307373, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 05:09:24 client3-1  | {'loss': 0.1657, 'grad_norm': 3.1412925720214844, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 05:33:10 client2-1  | {'loss': 0.1187, 'grad_norm': 2.3087828159332275, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 05:33:25 client2-1  | {'loss': 0.1725, 'grad_norm': 7.342723369598389, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 05:33:40 client2-1  | {'loss': 0.1452, 'grad_norm': 3.46854829788208, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 05:34:02 client2-1  | {'loss': 0.1494, 'grad_norm': 2.011333703994751, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 05:34:17 client2-1  | {'loss': 0.1378, 'grad_norm': 2.14292311668396, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 05:34:32 client2-1  | {'loss': 0.1577, 'grad_norm': 3.179187297821045, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 05:34:54 client2-1  | {'loss': 0.172, 'grad_norm': 1.735749363899231, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 05:35:09 client2-1  | {'loss': 0.1904, 'grad_norm': 5.357004642486572, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 05:35:24 client2-1  | {'loss': 0.1789, 'grad_norm': 4.767383098602295, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 05:23:58 client1-1  | {'loss': 0.2455, 'grad_norm': 8.915221214294434, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 05:35:39 client2-1  | {'loss': 0.1876, 'grad_norm': 6.630819797515869, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 05:36:00 client2-1  | {'loss': 0.2038, 'grad_norm': 5.584622383117676, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 05:09:39 client3-1  | {'loss': 0.2016, 'grad_norm': 5.5567522048950195, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 05:36:15 client2-1  | {'loss': 0.1909, 'grad_norm': 4.881948947906494, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 05:09:54 client3-1  | {'loss': 0.2107, 'grad_norm': 4.163984298706055, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 05:10:10 client3-1  | {'loss': 0.2925, 'grad_norm': 6.146585941314697, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 05:10:24 client3-1  | {'loss': 0.2308, 'grad_norm': 4.86386775970459, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 05:10:45 client3-1  | {'loss': 0.2239, 'grad_norm': 6.483721733093262, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 05:36:30 client2-1  | {'loss': 0.1795, 'grad_norm': 3.694000482559204, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 05:11:00 client3-1  | {'loss': 0.2542, 'grad_norm': 5.95599889755249, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 05:11:16 client3-1  | {'loss': 0.2978, 'grad_norm': 5.120607376098633, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 05:11:31 client3-1  | {'loss': 0.3144, 'grad_norm': 7.678761005401611, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 05:11:52 client3-1  | {'loss': 0.2406, 'grad_norm': 5.46548318862915, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 05:36:45 client2-1  | {'loss': 0.227, 'grad_norm': 4.948665618896484, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 05:37:00 client2-1  | {'loss': 0.276, 'grad_norm': 6.569566249847412, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 05:37:22 client2-1  | {'loss': 0.2522, 'grad_norm': 10.522361755371094, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 05:37:37 client2-1  | {'loss': 0.2572, 'grad_norm': 7.852035045623779, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 05:24:19 client1-1  | {'loss': 0.2273, 'grad_norm': 5.328709125518799, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 05:24:35 client1-1  | {'loss': 0.2536, 'grad_norm': 5.7166008949279785, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 05:24:49 client1-1  | {'loss': 0.2925, 'grad_norm': 7.042250156402588, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 05:25:04 client1-1  | {'loss': 0.3031, 'grad_norm': 8.172155380249023, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 05:37:52 client2-1  | {'loss': 0.3162, 'grad_norm': 5.198862552642822, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 05:38:07 client2-1  | {'loss': 0.344, 'grad_norm': 15.168790817260742, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 05:38:29 client2-1  | {'loss': 0.3106, 'grad_norm': 7.499308109283447, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 05:38:44 client2-1  | {'loss': 0.274, 'grad_norm': 6.544581413269043, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 05:25:25 client1-1  | {'loss': 0.2799, 'grad_norm': 8.097129821777344, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 05:25:41 client1-1  | {'loss': 0.3334, 'grad_norm': 5.249616622924805, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 05:12:07 client3-1  | {'loss': 0.2757, 'grad_norm': 5.795166492462158, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 05:25:56 client1-1  | {'loss': 0.3261, 'grad_norm': 8.143362045288086, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 05:12:21 client3-1  | {'loss': 0.3051, 'grad_norm': 6.869374752044678, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 05:26:11 client1-1  | {'loss': 0.385, 'grad_norm': 5.506783485412598, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 05:26:32 client1-1  | {'loss': 0.3947, 'grad_norm': 10.673257827758789, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 05:26:47 client1-1  | {'loss': 0.4431, 'grad_norm': 9.07734203338623, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 05:38:59 client2-1  | {'loss': 0.3544, 'grad_norm': 6.4005889892578125, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 05:39:14 client2-1  | {'loss': 0.4651, 'grad_norm': 10.489666938781738, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 05:39:36 client2-1  | {'loss': 0.4675, 'grad_norm': 12.054019927978516, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 05:12:36 client3-1  | {'loss': 0.2517, 'grad_norm': 7.109192371368408, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 05:39:51 client2-1  | {'loss': 0.6097, 'grad_norm': 9.75922966003418, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 05:12:58 client3-1  | {'loss': 0.343, 'grad_norm': 9.131159782409668, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 05:13:13 client3-1  | {'loss': 0.3369, 'grad_norm': 6.013991832733154, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 05:27:02 client1-1  | {'loss': 0.4, 'grad_norm': 8.310027122497559, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 05:13:29 client3-1  | {'loss': 0.4007, 'grad_norm': 7.6200852394104, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 05:27:16 client1-1  | {'loss': 0.5158, 'grad_norm': 10.130699157714844, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 05:40:06 client2-1  | {'loss': 0.5438, 'grad_norm': 9.32760238647461, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 05:27:38 client1-1  | {'loss': 0.5812, 'grad_norm': 10.395931243896484, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 05:13:43 client3-1  | {'loss': 0.4579, 'grad_norm': 9.257394790649414, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 05:40:21 client2-1  | {'loss': 0.4827, 'grad_norm': 9.453634262084961, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 05:14:05 client3-1  | {'loss': 0.4039, 'grad_norm': 9.90195083618164, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 05:14:20 client3-1  | {'loss': 0.5003, 'grad_norm': 6.76301383972168, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 05:14:35 client3-1  | {'loss': 0.5156, 'grad_norm': 7.756994724273682, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 05:14:50 client3-1  | {'loss': 0.6345, 'grad_norm': 7.537145614624023, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 05:27:53 client1-1  | {'loss': 0.5954, 'grad_norm': 6.911996364593506, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 05:15:11 client3-1  | {'loss': 0.5557, 'grad_norm': 8.442279815673828, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 05:15:26 client3-1  | {'loss': 0.6036, 'grad_norm': 8.01703929901123, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 05:15:42 client3-1  | {'loss': 0.7351, 'grad_norm': 11.223470687866211, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 05:40:43 client2-1  | {'loss': 0.6878, 'grad_norm': 8.064767837524414, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 05:40:57 client2-1  | {'loss': 0.6625, 'grad_norm': 8.721282005310059, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 05:15:56 client3-1  | {'loss': 0.8313, 'grad_norm': 9.947918891906738, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 05:16:18 client3-1  | {'loss': 0.869, 'grad_norm': 8.630753517150879, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 05:16:32 client3-1  | {'loss': 0.885, 'grad_norm': 9.831742286682129, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 05:16:48 client3-1  | {'loss': 1.124, 'grad_norm': 17.18484878540039, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 05:17:02 client3-1  | {'loss': 1.0589, 'grad_norm': 11.190184593200684, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 05:17:23 client3-1  | {'loss': 1.04, 'grad_norm': 11.21828556060791, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 05:17:38 client3-1  | {'loss': 1.3066, 'grad_norm': 11.13542652130127, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 05:41:12 client2-1  | {'loss': 0.9144, 'grad_norm': 11.19610595703125, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 05:17:53 client3-1  | {'loss': 1.2638, 'grad_norm': 12.858222007751465, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 05:18:08 client3-1  | {'loss': 1.0677, 'grad_norm': 9.217935562133789, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 05:41:27 client2-1  | {'loss': 0.8337, 'grad_norm': 9.852996826171875, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 05:28:08 client1-1  | {'loss': 0.6905, 'grad_norm': 10.2609224319458, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 05:18:24 client3-1  | {'loss': 0.6922, 'grad_norm': 5.101726531982422, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 05:28:23 client1-1  | {'loss': 0.7095, 'grad_norm': 8.300525665283203, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 05:41:42 client2-1  | {'loss': 0.9773, 'grad_norm': 12.394532203674316, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 05:18:39 client3-1  | {'loss': 0.2108, 'grad_norm': 4.498414993286133, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 05:18:39 client3-1  | {'train_runtime': 664.3794, 'train_samples_per_second': 1.203, 'train_steps_per_second': 0.602, 'train_loss': 0.49542709469795226, 'epoch': 1.0}
2025-05-22 05:28:38 client1-1  | {'loss': 0.796, 'grad_norm': 8.56478214263916, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 05:29:00 client1-1  | {'loss': 1.0004, 'grad_norm': 15.321700096130371, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 05:29:15 client1-1  | {'loss': 0.9432, 'grad_norm': 11.033970832824707, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 05:29:30 client1-1  | {'loss': 1.1105, 'grad_norm': 12.223381996154785, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 05:29:45 client1-1  | {'loss': 1.1534, 'grad_norm': 10.859797477722168, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 05:30:07 client1-1  | {'loss': 1.1847, 'grad_norm': 11.07524299621582, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 05:30:22 client1-1  | {'loss': 1.1867, 'grad_norm': 11.317185401916504, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 05:18:50 client3-1  | INFO :      Sent reply
2025-05-22 05:19:24 client3-1  | INFO :      
2025-05-22 05:19:24 client3-1  | INFO :      Received: evaluate message f8aa7cbe-63b8-4b9d-abaa-3f5980d15718
2025-05-22 05:19:37 client3-1  | {'eval_loss': 1.8400168418884277, 'eval_runtime': 12.2007, 'eval_samples_per_second': 16.392, 'eval_steps_per_second': 2.049, 'epoch': 1.0}
2025-05-22 05:42:03 client2-1  | {'loss': 1.1746, 'grad_norm': 11.260597229003906, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 05:42:18 client2-1  | {'loss': 1.1811, 'grad_norm': 12.099925994873047, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 05:42:33 client2-1  | {'loss': 1.2081, 'grad_norm': 11.875715255737305, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 05:42:49 client2-1  | {'loss': 1.1406, 'grad_norm': 9.083294868469238, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 05:19:37 client3-1  | INFO :      Sent reply
2025-05-22 05:19:54 client3-1  | INFO :      
2025-05-22 05:19:54 client3-1  | INFO :      Received: train message 7fc8e6a7-0b3a-49cd-8988-49c7c8d6a1ec
2025-05-22 05:20:14 client3-1  | {'loss': 0.0757, 'grad_norm': 2.7961013317108154, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 05:30:37 client1-1  | {'loss': 0.9108, 'grad_norm': 10.319443702697754, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 05:20:29 client3-1  | {'loss': 0.1204, 'grad_norm': 5.206008434295654, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 05:20:50 client3-1  | {'loss': 0.1291, 'grad_norm': 3.9410860538482666, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 05:21:06 client3-1  | {'loss': 0.1631, 'grad_norm': 5.301543712615967, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 05:21:20 client3-1  | {'loss': 0.1611, 'grad_norm': 4.6500959396362305, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 05:21:42 client3-1  | {'loss': 0.1615, 'grad_norm': 2.5560550689697266, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 05:21:57 client3-1  | {'loss': 0.1792, 'grad_norm': 5.444363117218018, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 05:22:12 client3-1  | {'loss': 0.1935, 'grad_norm': 3.925172805786133, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 05:22:27 client3-1  | {'loss': 0.2549, 'grad_norm': 5.200564384460449, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 05:22:42 client3-1  | {'loss': 0.2183, 'grad_norm': 4.612524509429932, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 05:23:03 client3-1  | {'loss': 0.1919, 'grad_norm': 5.589804649353027, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 05:23:18 client3-1  | {'loss': 0.2124, 'grad_norm': 5.481765270233154, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 05:43:10 client2-1  | {'loss': 0.7352, 'grad_norm': 8.389641761779785, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 05:43:23 client2-1  | {'loss': 0.2075, 'grad_norm': 5.010609149932861, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 05:23:33 client3-1  | {'loss': 0.2553, 'grad_norm': 3.5109732151031494, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 05:23:48 client3-1  | {'loss': 0.2564, 'grad_norm': 8.642254829406738, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 05:24:03 client3-1  | {'loss': 0.2067, 'grad_norm': 4.957677841186523, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 05:24:25 client3-1  | {'loss': 0.253, 'grad_norm': 7.284719944000244, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 05:43:23 client2-1  | {'train_runtime': 664.9261, 'train_samples_per_second': 1.203, 'train_steps_per_second': 0.602, 'train_loss': 0.4316835978627205, 'epoch': 1.0}
2025-05-22 05:43:35 client2-1  | INFO :      Sent reply
2025-05-22 05:44:03 client2-1  | INFO :      
2025-05-22 05:44:03 client2-1  | INFO :      Received: evaluate message 583c05ed-9519-4452-b464-967b93dd20bc
2025-05-22 05:30:58 client1-1  | {'loss': 0.6114, 'grad_norm': 6.576050758361816, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 05:24:40 client3-1  | {'loss': 0.2588, 'grad_norm': 7.061029434204102, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 05:31:10 client1-1  | {'loss': 0.2188, 'grad_norm': 3.334944725036621, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 05:24:54 client3-1  | {'loss': 0.2446, 'grad_norm': 8.139397621154785, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 05:31:10 client1-1  | {'train_runtime': 667.8355, 'train_samples_per_second': 1.198, 'train_steps_per_second': 0.599, 'train_loss': 0.4591572332382202, 'epoch': 1.0}
2025-05-22 05:44:06 client2-1  | {'eval_loss': 1.8089643716812134, 'eval_runtime': 2.8144, 'eval_samples_per_second': 71.064, 'eval_steps_per_second': 8.883, 'epoch': 1.0}
2025-05-22 05:31:15 client1-1  | INFO :      Sent reply
2025-05-22 05:25:16 client3-1  | {'loss': 0.2871, 'grad_norm': 7.376899242401123, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 05:31:45 client1-1  | INFO :      
2025-05-22 05:44:06 client2-1  | INFO :      Sent reply
2025-05-22 05:44:31 client2-1  | INFO :      
2025-05-22 05:44:31 client2-1  | INFO :      Received: train message 187ba859-85e6-4a67-993a-4a9374aa40d2
2025-05-22 05:31:45 client1-1  | INFO :      Received: evaluate message b9aae902-5b28-4bd9-85c0-538d649e7b78
2025-05-22 05:31:55 client1-1  | {'eval_loss': 1.8285675048828125, 'eval_runtime': 9.0257, 'eval_samples_per_second': 22.159, 'eval_steps_per_second': 2.77, 'epoch': 1.0}
2025-05-22 05:31:55 client1-1  | INFO :      Sent reply
2025-05-22 05:44:54 client2-1  | {'loss': 0.0734, 'grad_norm': 1.4440325498580933, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 05:45:16 client2-1  | {'loss': 0.1029, 'grad_norm': 1.7326269149780273, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 05:45:31 client2-1  | {'loss': 0.1051, 'grad_norm': 2.378401756286621, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 05:45:46 client2-1  | {'loss': 0.154, 'grad_norm': 6.920111656188965, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 05:46:01 client2-1  | {'loss': 0.1289, 'grad_norm': 4.2336249351501465, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 05:25:31 client3-1  | {'loss': 0.283, 'grad_norm': 5.4880690574646, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 05:25:46 client3-1  | {'loss': 0.3322, 'grad_norm': 6.819952964782715, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 05:26:01 client3-1  | {'loss': 0.4115, 'grad_norm': 8.61508560180664, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 05:26:22 client3-1  | {'loss': 0.3589, 'grad_norm': 9.039374351501465, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 05:26:37 client3-1  | {'loss': 0.4342, 'grad_norm': 6.850017070770264, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 05:26:52 client3-1  | {'loss': 0.4587, 'grad_norm': 17.807275772094727, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 05:27:07 client3-1  | {'loss': 0.5805, 'grad_norm': 5.856924533843994, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 05:32:12 client1-1  | INFO :      
2025-05-22 05:32:12 client1-1  | INFO :      Received: train message 1f6938f8-0e3e-4aaf-93c9-6762dc48857a
2025-05-22 05:46:23 client2-1  | {'loss': 0.148, 'grad_norm': 2.201619863510132, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 05:32:20 client1-1  | {'loss': 0.0842, 'grad_norm': 2.2063984870910645, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 05:32:35 client1-1  | {'loss': 0.0863, 'grad_norm': 1.725261926651001, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 05:32:51 client1-1  | {'loss': 0.1081, 'grad_norm': 1.20148503780365, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 05:33:06 client1-1  | {'loss': 0.1571, 'grad_norm': 7.547023773193359, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 05:27:21 client3-1  | {'loss': 0.4711, 'grad_norm': 8.44080638885498, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 05:33:27 client1-1  | {'loss': 0.1714, 'grad_norm': 3.0180575847625732, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 05:46:38 client2-1  | {'loss': 0.124, 'grad_norm': 4.868530750274658, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 05:46:53 client2-1  | {'loss': 0.1508, 'grad_norm': 6.189438819885254, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 05:27:43 client3-1  | {'loss': 0.5556, 'grad_norm': 7.587978839874268, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 05:47:15 client2-1  | {'loss': 0.1612, 'grad_norm': 3.384460926055908, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 05:33:43 client1-1  | {'loss': 0.1605, 'grad_norm': 2.6158697605133057, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 05:33:58 client1-1  | {'loss': 0.1646, 'grad_norm': 6.1517744064331055, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 05:34:19 client1-1  | {'loss': 0.1467, 'grad_norm': 3.1475415229797363, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 05:27:58 client3-1  | {'loss': 0.6809, 'grad_norm': 11.63809585571289, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 05:47:30 client2-1  | {'loss': 0.1787, 'grad_norm': 4.917234897613525, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 05:34:34 client1-1  | {'loss': 0.1787, 'grad_norm': 3.4023942947387695, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 05:34:49 client1-1  | {'loss': 0.1882, 'grad_norm': 3.6845908164978027, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 05:35:04 client1-1  | {'loss': 0.1807, 'grad_norm': 5.175287246704102, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 05:47:45 client2-1  | {'loss': 0.171, 'grad_norm': 5.084619045257568, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 05:48:00 client2-1  | {'loss': 0.1494, 'grad_norm': 4.974992275238037, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 05:48:21 client2-1  | {'loss': 0.174, 'grad_norm': 3.675577402114868, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 05:35:26 client1-1  | {'loss': 0.2116, 'grad_norm': 4.918083190917969, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 05:35:41 client1-1  | {'loss': 0.1861, 'grad_norm': 5.449312686920166, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 05:35:56 client1-1  | {'loss': 0.2101, 'grad_norm': 6.7794575691223145, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 05:36:11 client1-1  | {'loss': 0.196, 'grad_norm': 6.0055317878723145, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 05:36:33 client1-1  | {'loss': 0.2261, 'grad_norm': 6.3236308097839355, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 05:36:48 client1-1  | {'loss': 0.2732, 'grad_norm': 8.007185935974121, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 05:37:03 client1-1  | {'loss': 0.2576, 'grad_norm': 7.399059772491455, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 05:48:36 client2-1  | {'loss': 0.1549, 'grad_norm': 3.8858137130737305, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 05:48:51 client2-1  | {'loss': 0.1509, 'grad_norm': 3.869291067123413, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 05:28:13 client3-1  | {'loss': 0.7729, 'grad_norm': 8.957314491271973, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 05:49:07 client2-1  | {'loss': 0.2072, 'grad_norm': 4.633965492248535, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 05:28:28 client3-1  | {'loss': 0.8057, 'grad_norm': 9.12126350402832, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 05:28:50 client3-1  | {'loss': 0.8408, 'grad_norm': 10.75485610961914, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 05:37:18 client1-1  | {'loss': 0.2565, 'grad_norm': 6.293979644775391, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 05:49:28 client2-1  | {'loss': 0.2476, 'grad_norm': 6.197800636291504, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 05:49:43 client2-1  | {'loss': 0.2124, 'grad_norm': 6.581047058105469, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 05:49:58 client2-1  | {'loss': 0.217, 'grad_norm': 5.263008117675781, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 05:37:39 client1-1  | {'loss': 0.2841, 'grad_norm': 4.846541881561279, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 05:37:54 client1-1  | {'loss': 0.2626, 'grad_norm': 6.163407802581787, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 05:38:10 client1-1  | {'loss': 0.3234, 'grad_norm': 4.41080379486084, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 05:38:25 client1-1  | {'loss': 0.3562, 'grad_norm': 8.51064395904541, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 05:38:46 client1-1  | {'loss': 0.3818, 'grad_norm': 7.326564788818359, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 05:50:13 client2-1  | {'loss': 0.2706, 'grad_norm': 4.938085556030273, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 05:39:02 client1-1  | {'loss': 0.3366, 'grad_norm': 7.884145259857178, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 05:50:34 client2-1  | {'loss': 0.3074, 'grad_norm': 10.131842613220215, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 05:39:17 client1-1  | {'loss': 0.4509, 'grad_norm': 10.154763221740723, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 05:39:32 client1-1  | {'loss': 0.5444, 'grad_norm': 11.015024185180664, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 05:50:49 client2-1  | {'loss': 0.2838, 'grad_norm': 8.469059944152832, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 05:29:05 client3-1  | {'loss': 1.0683, 'grad_norm': 13.340453147888184, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 05:39:53 client1-1  | {'loss': 0.5671, 'grad_norm': 8.020066261291504, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 05:40:08 client1-1  | {'loss': 0.6301, 'grad_norm': 10.331440925598145, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 05:40:24 client1-1  | {'loss': 0.624, 'grad_norm': 7.286037921905518, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 05:40:45 client1-1  | {'loss': 0.7549, 'grad_norm': 8.346342086791992, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 05:41:00 client1-1  | {'loss': 0.9523, 'grad_norm': 15.573951721191406, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 05:29:20 client3-1  | {'loss': 1.022, 'grad_norm': 12.5792236328125, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 05:29:35 client3-1  | {'loss': 0.9883, 'grad_norm': 12.426209449768066, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 05:29:50 client3-1  | {'loss': 1.2779, 'grad_norm': 12.101119041442871, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 05:41:15 client1-1  | {'loss': 0.894, 'grad_norm': 11.082822799682617, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 05:41:30 client1-1  | {'loss': 1.0746, 'grad_norm': 13.610858917236328, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 05:41:44 client1-1  | {'loss': 1.1265, 'grad_norm': 12.39188003540039, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 05:30:11 client3-1  | {'loss': 1.2774, 'grad_norm': 14.414868354797363, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 05:30:27 client3-1  | {'loss': 1.0237, 'grad_norm': 10.344625473022461, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 05:30:42 client3-1  | {'loss': 0.6353, 'grad_norm': 4.707003116607666, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 05:30:57 client3-1  | {'loss': 0.196, 'grad_norm': 6.5023369789123535, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 05:30:57 client3-1  | {'train_runtime': 661.3533, 'train_samples_per_second': 1.208, 'train_steps_per_second': 0.605, 'train_loss': 0.45745126485824583, 'epoch': 1.0}
2025-05-22 05:51:03 client2-1  | {'loss': 0.2314, 'grad_norm': 6.371586322784424, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 05:51:18 client2-1  | {'loss': 0.3111, 'grad_norm': 7.650511741638184, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 05:51:40 client2-1  | {'loss': 0.4171, 'grad_norm': 10.372193336486816, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 05:51:55 client2-1  | {'loss': 0.4125, 'grad_norm': 10.987614631652832, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 05:52:10 client2-1  | {'loss': 0.5599, 'grad_norm': 8.562186241149902, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 05:52:25 client2-1  | {'loss': 0.4844, 'grad_norm': 9.326458930969238, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 05:31:10 client3-1  | INFO :      Sent reply
2025-05-22 05:31:52 client3-1  | INFO :      
2025-05-22 05:31:52 client3-1  | INFO :      Received: evaluate message 0fc308bb-2616-442b-bdbc-e4c0fe71c58d
2025-05-22 05:42:06 client1-1  | {'loss': 1.1655, 'grad_norm': 12.242875099182129, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 05:32:01 client3-1  | {'eval_loss': 1.869823932647705, 'eval_runtime': 5.0717, 'eval_samples_per_second': 39.434, 'eval_steps_per_second': 4.929, 'epoch': 1.0}
2025-05-22 05:42:21 client1-1  | {'loss': 1.1807, 'grad_norm': 14.379851341247559, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 05:32:01 client3-1  | INFO :      Sent reply
2025-05-22 05:52:46 client2-1  | {'loss': 0.4396, 'grad_norm': 8.500349998474121, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 05:32:16 client3-1  | INFO :      
2025-05-22 05:42:36 client1-1  | {'loss': 0.899, 'grad_norm': 10.906754493713379, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 05:42:51 client1-1  | {'loss': 0.5828, 'grad_norm': 6.443727970123291, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 05:43:12 client1-1  | {'loss': 0.1871, 'grad_norm': 3.7967915534973145, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 05:32:16 client3-1  | INFO :      Received: train message 838740f6-b993-44f7-b9b0-2af955f6b6ac
2025-05-22 05:53:01 client2-1  | {'loss': 0.6157, 'grad_norm': 8.19160270690918, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 05:43:12 client1-1  | {'train_runtime': 658.4096, 'train_samples_per_second': 1.215, 'train_steps_per_second': 0.608, 'train_loss': 0.4255593812465668, 'epoch': 1.0}
2025-05-22 05:43:18 client1-1  | INFO :      Sent reply
2025-05-22 05:44:10 client1-1  | INFO :      
2025-05-22 05:44:10 client1-1  | INFO :      Received: evaluate message 5012ea8b-da6d-4b23-b94e-0ce6e8309866
2025-05-22 05:32:45 client3-1  | {'loss': 0.0775, 'grad_norm': 3.7255263328552246, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 05:33:00 client3-1  | {'loss': 0.1125, 'grad_norm': 2.388827085494995, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 05:53:15 client2-1  | {'loss': 0.6253, 'grad_norm': 7.249048233032227, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 05:44:18 client1-1  | {'eval_loss': 1.8602691888809204, 'eval_runtime': 6.6515, 'eval_samples_per_second': 30.068, 'eval_steps_per_second': 3.759, 'epoch': 1.0}
2025-05-22 05:44:18 client1-1  | INFO :      Sent reply
2025-05-22 05:44:33 client1-1  | INFO :      
2025-05-22 05:44:33 client1-1  | INFO :      Received: train message 9c7f3006-58a8-45ab-8061-00af69f06921
2025-05-22 05:53:30 client2-1  | {'loss': 0.8757, 'grad_norm': 11.840152740478516, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 05:44:59 client1-1  | {'loss': 0.0826, 'grad_norm': 2.641535758972168, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 05:33:15 client3-1  | {'loss': 0.1203, 'grad_norm': 3.631244421005249, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 05:33:30 client3-1  | {'loss': 0.1471, 'grad_norm': 4.791589260101318, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 05:53:51 client2-1  | {'loss': 0.8, 'grad_norm': 10.268826484680176, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 05:54:06 client2-1  | {'loss': 0.9434, 'grad_norm': 11.79434585571289, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 05:54:21 client2-1  | {'loss': 1.137, 'grad_norm': 12.007218360900879, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 05:54:36 client2-1  | {'loss': 1.1693, 'grad_norm': 13.571601867675781, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 05:33:52 client3-1  | {'loss': 0.1323, 'grad_norm': 4.421576976776123, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 05:54:58 client2-1  | {'loss': 1.186, 'grad_norm': 13.223588943481445, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 05:34:07 client3-1  | {'loss': 0.1418, 'grad_norm': 2.4419877529144287, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 05:55:12 client2-1  | {'loss': 1.1345, 'grad_norm': 7.982375144958496, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 05:45:14 client1-1  | {'loss': 0.0821, 'grad_norm': 1.228361964225769, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 05:55:27 client2-1  | {'loss': 0.6894, 'grad_norm': 8.35472583770752, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 05:34:22 client3-1  | {'loss': 0.1594, 'grad_norm': 4.162899494171143, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 05:45:29 client1-1  | {'loss': 0.0963, 'grad_norm': 3.325251340866089, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 05:45:50 client1-1  | {'loss': 0.1409, 'grad_norm': 5.460318565368652, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 05:46:05 client1-1  | {'loss': 0.167, 'grad_norm': 3.534489631652832, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 05:46:21 client1-1  | {'loss': 0.1398, 'grad_norm': 1.7419673204421997, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 05:55:42 client2-1  | {'loss': 0.1745, 'grad_norm': 4.939911842346191, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 05:34:37 client3-1  | {'loss': 0.1754, 'grad_norm': 2.9098269939422607, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 05:34:59 client3-1  | {'loss': 0.2227, 'grad_norm': 6.158157825469971, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 05:35:14 client3-1  | {'loss': 0.1912, 'grad_norm': 3.6140425205230713, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 05:35:29 client3-1  | {'loss': 0.1663, 'grad_norm': 3.7970030307769775, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 05:46:42 client1-1  | {'loss': 0.1361, 'grad_norm': 5.12596321105957, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 05:55:42 client2-1  | {'train_runtime': 668.5196, 'train_samples_per_second': 1.197, 'train_steps_per_second': 0.598, 'train_loss': 0.40201160207390785, 'epoch': 1.0}
2025-05-22 05:46:58 client1-1  | {'loss': 0.1351, 'grad_norm': 6.276141166687012, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 05:55:58 client2-1  | INFO :      Sent reply
2025-05-22 05:35:44 client3-1  | {'loss': 0.1919, 'grad_norm': 7.045007705688477, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 05:47:13 client1-1  | {'loss': 0.1615, 'grad_norm': 3.220033884048462, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 05:36:05 client3-1  | {'loss': 0.2394, 'grad_norm': 4.445573329925537, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 05:56:33 client2-1  | INFO :      
2025-05-22 05:47:28 client1-1  | {'loss': 0.1684, 'grad_norm': 3.677767276763916, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 05:56:33 client2-1  | INFO :      Received: evaluate message 37f9074e-f81d-407f-9d56-0f9a1a86d756
2025-05-22 05:47:49 client1-1  | {'loss': 0.1757, 'grad_norm': 4.9744696617126465, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 05:56:45 client2-1  | {'eval_loss': 1.836209774017334, 'eval_runtime': 8.7677, 'eval_samples_per_second': 22.811, 'eval_steps_per_second': 2.851, 'epoch': 1.0}
2025-05-22 05:36:20 client3-1  | {'loss': 0.2313, 'grad_norm': 7.636104583740234, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 05:56:45 client2-1  | INFO :      Sent reply
2025-05-22 05:56:58 client2-1  | INFO :      
2025-05-22 05:56:58 client2-1  | INFO :      Received: train message 76b7220f-abf5-4773-b8f6-c64cadecc35f
2025-05-22 05:57:17 client2-1  | {'loss': 0.0715, 'grad_norm': 1.229149580001831, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 05:57:33 client2-1  | {'loss': 0.0943, 'grad_norm': 1.559661626815796, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 05:48:04 client1-1  | {'loss': 0.201, 'grad_norm': 6.643405437469482, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 05:57:47 client2-1  | {'loss': 0.1045, 'grad_norm': 1.667609453201294, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 05:58:09 client2-1  | {'loss': 0.1445, 'grad_norm': 4.216660022735596, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 05:58:24 client2-1  | {'loss': 0.1245, 'grad_norm': 2.1510963439941406, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 05:58:39 client2-1  | {'loss': 0.1294, 'grad_norm': 2.639542579650879, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 05:58:54 client2-1  | {'loss': 0.1272, 'grad_norm': 4.844154357910156, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 05:48:19 client1-1  | {'loss': 0.1685, 'grad_norm': 4.934872627258301, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 05:48:34 client1-1  | {'loss': 0.1815, 'grad_norm': 7.6584601402282715, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 05:59:09 client2-1  | {'loss': 0.1262, 'grad_norm': 3.155456781387329, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 05:48:56 client1-1  | {'loss': 0.1803, 'grad_norm': 3.766364097595215, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 05:59:30 client2-1  | {'loss': 0.155, 'grad_norm': 2.680971384048462, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 05:59:45 client2-1  | {'loss': 0.1452, 'grad_norm': 4.191189765930176, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 05:49:11 client1-1  | {'loss': 0.1895, 'grad_norm': 4.701844215393066, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 05:49:26 client1-1  | {'loss': 0.2375, 'grad_norm': 7.394964218139648, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 05:49:41 client1-1  | {'loss': 0.2221, 'grad_norm': 8.450105667114258, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 05:36:35 client3-1  | {'loss': 0.1681, 'grad_norm': 5.20272159576416, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 05:49:56 client1-1  | {'loss': 0.2242, 'grad_norm': 6.195847034454346, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 05:50:17 client1-1  | {'loss': 0.2635, 'grad_norm': 3.9066238403320312, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 05:50:32 client1-1  | {'loss': 0.2282, 'grad_norm': 5.852987289428711, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 05:50:46 client1-1  | {'loss': 0.2991, 'grad_norm': 4.27701997756958, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 05:36:50 client3-1  | {'loss': 0.2108, 'grad_norm': 5.359312057495117, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 05:37:12 client3-1  | {'loss': 0.2296, 'grad_norm': 6.9448981285095215, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 05:51:01 client1-1  | {'loss': 0.3023, 'grad_norm': 8.113530158996582, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 05:37:27 client3-1  | {'loss': 0.2073, 'grad_norm': 7.463619709014893, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 05:51:23 client1-1  | {'loss': 0.3515, 'grad_norm': 7.100587368011475, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 05:37:42 client3-1  | {'loss': 0.2613, 'grad_norm': 7.7772369384765625, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 05:37:57 client3-1  | {'loss': 0.2565, 'grad_norm': 3.863614559173584, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 05:51:38 client1-1  | {'loss': 0.3019, 'grad_norm': 7.545953750610352, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 05:51:53 client1-1  | {'loss': 0.4133, 'grad_norm': 9.799402236938477, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 05:38:12 client3-1  | {'loss': 0.3012, 'grad_norm': 6.755588531494141, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 05:38:34 client3-1  | {'loss': 0.3605, 'grad_norm': 9.667908668518066, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 05:38:49 client3-1  | {'loss': 0.3197, 'grad_norm': 8.350208282470703, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 05:39:04 client3-1  | {'loss': 0.3831, 'grad_norm': 6.3767170906066895, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 06:00:00 client2-1  | {'loss': 0.1457, 'grad_norm': 5.012102127075195, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 05:39:19 client3-1  | {'loss': 0.4017, 'grad_norm': 7.437414169311523, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 05:39:34 client3-1  | {'loss': 0.5171, 'grad_norm': 7.136834621429443, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 05:39:56 client3-1  | {'loss': 0.4277, 'grad_norm': 6.3906731605529785, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 05:40:11 client3-1  | {'loss': 0.5091, 'grad_norm': 7.228767395019531, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 05:52:08 client1-1  | {'loss': 0.4747, 'grad_norm': 9.664716720581055, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 05:52:29 client1-1  | {'loss': 0.5022, 'grad_norm': 7.411978721618652, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 05:52:43 client1-1  | {'loss': 0.5912, 'grad_norm': 10.913069725036621, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 05:40:26 client3-1  | {'loss': 0.6218, 'grad_norm': 10.512524604797363, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 06:00:15 client2-1  | {'loss': 0.1365, 'grad_norm': 5.376976013183594, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 05:40:41 client3-1  | {'loss': 0.7089, 'grad_norm': 9.154668807983398, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 06:00:36 client2-1  | {'loss': 0.1699, 'grad_norm': 3.450819492340088, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 06:00:52 client2-1  | {'loss': 0.1544, 'grad_norm': 5.137948036193848, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 06:01:07 client2-1  | {'loss': 0.1496, 'grad_norm': 4.5255255699157715, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 06:01:22 client2-1  | {'loss': 0.1913, 'grad_norm': 8.186057090759277, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 05:52:58 client1-1  | {'loss': 0.6019, 'grad_norm': 7.774210453033447, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 06:01:43 client2-1  | {'loss': 0.24, 'grad_norm': 6.633387565612793, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 05:41:02 client3-1  | {'loss': 0.7689, 'grad_norm': 9.267901420593262, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 05:41:17 client3-1  | {'loss': 0.8056, 'grad_norm': 9.217621803283691, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 05:41:32 client3-1  | {'loss': 1.033, 'grad_norm': 15.55218505859375, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 05:41:47 client3-1  | {'loss': 1.0159, 'grad_norm': 12.03923511505127, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 05:53:13 client1-1  | {'loss': 0.6963, 'grad_norm': 8.271027565002441, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 05:53:34 client1-1  | {'loss': 0.9241, 'grad_norm': 15.233670234680176, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 05:53:49 client1-1  | {'loss': 0.8606, 'grad_norm': 13.5728120803833, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 06:01:58 client2-1  | {'loss': 0.185, 'grad_norm': 6.059177875518799, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 06:02:12 client2-1  | {'loss': 0.1864, 'grad_norm': 6.512365818023682, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 06:02:27 client2-1  | {'loss': 0.2235, 'grad_norm': 5.2823710441589355, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 05:54:04 client1-1  | {'loss': 1.0373, 'grad_norm': 12.884114265441895, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 05:54:19 client1-1  | {'loss': 1.1326, 'grad_norm': 10.80851936340332, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 06:02:49 client2-1  | {'loss': 0.2593, 'grad_norm': 9.876103401184082, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 06:03:04 client2-1  | {'loss': 0.2419, 'grad_norm': 8.085646629333496, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 06:03:19 client2-1  | {'loss': 0.2079, 'grad_norm': 5.5631914138793945, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 06:03:34 client2-1  | {'loss': 0.2695, 'grad_norm': 5.022731304168701, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 05:54:40 client1-1  | {'loss': 1.1306, 'grad_norm': 12.093538284301758, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 05:54:55 client1-1  | {'loss': 1.1459, 'grad_norm': 10.545608520507812, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 05:55:10 client1-1  | {'loss': 0.8721, 'grad_norm': 11.221148490905762, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 05:55:25 client1-1  | {'loss': 0.541, 'grad_norm': 7.460446834564209, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 05:55:46 client1-1  | {'loss': 0.1749, 'grad_norm': 3.971848487854004, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 05:42:08 client3-1  | {'loss': 0.964, 'grad_norm': 11.060426712036133, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 05:42:23 client3-1  | {'loss': 1.2784, 'grad_norm': 12.577972412109375, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 05:42:38 client3-1  | {'loss': 1.2503, 'grad_norm': 14.5093355178833, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 05:55:46 client1-1  | {'train_runtime': 669.3669, 'train_samples_per_second': 1.195, 'train_steps_per_second': 0.598, 'train_loss': 0.39837400034070014, 'epoch': 1.0}
2025-05-22 05:42:54 client3-1  | {'loss': 1.0073, 'grad_norm': 9.367899894714355, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 06:03:55 client2-1  | {'loss': 0.3663, 'grad_norm': 12.008861541748047, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 05:55:53 client1-1  | INFO :      Sent reply
2025-05-22 05:56:27 client1-1  | INFO :      
2025-05-22 06:04:10 client2-1  | {'loss': 0.3738, 'grad_norm': 10.441866874694824, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 05:56:27 client1-1  | INFO :      Received: evaluate message 1392ed31-7a42-49fe-8c81-363fe57974c2
2025-05-22 06:04:25 client2-1  | {'loss': 0.5123, 'grad_norm': 9.656394958496094, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 05:56:32 client1-1  | {'eval_loss': 1.893699049949646, 'eval_runtime': 2.9164, 'eval_samples_per_second': 68.577, 'eval_steps_per_second': 8.572, 'epoch': 1.0}
2025-05-22 05:43:15 client3-1  | {'loss': 0.6087, 'grad_norm': 4.793176651000977, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 06:04:39 client2-1  | {'loss': 0.4441, 'grad_norm': 8.564485549926758, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 05:43:25 client3-1  | {'loss': 0.212, 'grad_norm': 4.719455242156982, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 06:05:01 client2-1  | {'loss': 0.4364, 'grad_norm': 9.888808250427246, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 06:05:16 client2-1  | {'loss': 0.5677, 'grad_norm': 8.304403305053711, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 05:56:32 client1-1  | INFO :      Sent reply
2025-05-22 05:43:25 client3-1  | {'train_runtime': 661.9695, 'train_samples_per_second': 1.207, 'train_steps_per_second': 0.604, 'train_loss': 0.42844354316592215, 'epoch': 1.0}
2025-05-22 05:43:33 client3-1  | INFO :      Sent reply
2025-05-22 05:44:08 client3-1  | INFO :      
2025-05-22 05:44:08 client3-1  | INFO :      Received: evaluate message 8b95a75d-f4fa-472a-83b9-3f5b66e179cf
2025-05-22 06:05:31 client2-1  | {'loss': 0.576, 'grad_norm': 7.331787586212158, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 06:05:46 client2-1  | {'loss': 0.851, 'grad_norm': 13.331385612487793, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 05:44:16 client3-1  | {'eval_loss': 1.9020788669586182, 'eval_runtime': 6.7961, 'eval_samples_per_second': 29.429, 'eval_steps_per_second': 3.679, 'epoch': 1.0}
2025-05-22 06:06:08 client2-1  | {'loss': 0.7686, 'grad_norm': 10.88973331451416, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 05:44:16 client3-1  | INFO :      Sent reply
2025-05-22 05:44:31 client3-1  | INFO :      
2025-05-22 05:44:31 client3-1  | INFO :      Received: train message 2c322fa3-d1ab-46d6-9b7e-4ca139f1a088
2025-05-22 05:44:56 client3-1  | {'loss': 0.0707, 'grad_norm': 1.4221376180648804, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 06:06:23 client2-1  | {'loss': 0.9085, 'grad_norm': 13.320169448852539, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 06:06:37 client2-1  | {'loss': 1.1145, 'grad_norm': 12.824273109436035, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 06:06:59 client2-1  | {'loss': 1.1347, 'grad_norm': 15.078856468200684, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 06:07:14 client2-1  | {'loss': 1.1704, 'grad_norm': 13.181315422058105, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 05:56:59 client1-1  | INFO :      
2025-05-22 06:07:28 client2-1  | {'loss': 1.0904, 'grad_norm': 8.82640266418457, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 06:07:43 client2-1  | {'loss': 0.6437, 'grad_norm': 7.454989433288574, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 06:08:05 client2-1  | {'loss': 0.1904, 'grad_norm': 6.4904937744140625, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 06:08:05 client2-1  | {'train_runtime': 665.7999, 'train_samples_per_second': 1.202, 'train_steps_per_second': 0.601, 'train_loss': 0.37829416409134864, 'epoch': 1.0}
2025-05-22 05:45:11 client3-1  | {'loss': 0.1061, 'grad_norm': 2.384519577026367, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 05:45:33 client3-1  | {'loss': 0.1159, 'grad_norm': 2.4909682273864746, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 05:56:59 client1-1  | INFO :      Received: train message 4a2fb6c3-65c0-491a-9222-57cfb234ed8c
2025-05-22 05:57:28 client1-1  | {'loss': 0.0856, 'grad_norm': 2.7501704692840576, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 05:57:42 client1-1  | {'loss': 0.0803, 'grad_norm': 1.1392284631729126, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 05:45:48 client3-1  | {'loss': 0.1409, 'grad_norm': 6.604940891265869, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 06:08:13 client2-1  | INFO :      Sent reply
2025-05-22 05:46:03 client3-1  | {'loss': 0.1326, 'grad_norm': 3.588496446609497, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 06:08:44 client2-1  | INFO :      
2025-05-22 05:46:19 client3-1  | {'loss': 0.135, 'grad_norm': 3.2171497344970703, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 05:58:04 client1-1  | {'loss': 0.1059, 'grad_norm': 3.4662437438964844, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 05:58:19 client1-1  | {'loss': 0.1231, 'grad_norm': 3.3743629455566406, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 05:58:34 client1-1  | {'loss': 0.1296, 'grad_norm': 2.44201397895813, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 05:58:49 client1-1  | {'loss': 0.1285, 'grad_norm': 1.839066505432129, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 05:59:10 client1-1  | {'loss': 0.1181, 'grad_norm': 3.8414366245269775, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 05:46:47 client3-1  | {'loss': 0.1368, 'grad_norm': 2.9093685150146484, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 05:47:02 client3-1  | {'loss': 0.1526, 'grad_norm': 4.175441741943359, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 05:47:18 client3-1  | {'loss': 0.1751, 'grad_norm': 4.301878929138184, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 05:47:33 client3-1  | {'loss': 0.1638, 'grad_norm': 3.3887746334075928, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 06:08:44 client2-1  | INFO :      Received: evaluate message 974cc407-ae64-4b01-becd-e1e42b3afb39
2025-05-22 06:08:50 client2-1  | {'eval_loss': 1.8565609455108643, 'eval_runtime': 4.8132, 'eval_samples_per_second': 41.553, 'eval_steps_per_second': 5.194, 'epoch': 1.0}
2025-05-22 05:47:54 client3-1  | {'loss': 0.1529, 'grad_norm': 4.383516788482666, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 05:48:09 client3-1  | {'loss': 0.1794, 'grad_norm': 6.811252117156982, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 05:48:24 client3-1  | {'loss': 0.2066, 'grad_norm': 3.885585308074951, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 05:59:25 client1-1  | {'loss': 0.1235, 'grad_norm': 4.263813018798828, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 05:59:40 client1-1  | {'loss': 0.1384, 'grad_norm': 2.8258163928985596, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 05:59:55 client1-1  | {'loss': 0.1528, 'grad_norm': 2.9467220306396484, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 06:00:17 client1-1  | {'loss': 0.1617, 'grad_norm': 7.347083568572998, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 06:00:32 client1-1  | {'loss': 0.1797, 'grad_norm': 6.062231540679932, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 06:00:47 client1-1  | {'loss': 0.1465, 'grad_norm': 6.6568098068237305, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 06:01:02 client1-1  | {'loss': 0.1763, 'grad_norm': 7.277304649353027, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 06:01:23 client1-1  | {'loss': 0.1566, 'grad_norm': 3.1349687576293945, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 06:01:38 client1-1  | {'loss': 0.1801, 'grad_norm': 5.224621772766113, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 06:01:53 client1-1  | {'loss': 0.2128, 'grad_norm': 7.992141246795654, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 05:48:39 client3-1  | {'loss': 0.201, 'grad_norm': 7.580385684967041, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 05:48:54 client3-1  | {'loss': 0.1511, 'grad_norm': 4.844973087310791, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 05:49:16 client3-1  | {'loss': 0.1841, 'grad_norm': 5.409647464752197, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 05:49:31 client3-1  | {'loss': 0.2105, 'grad_norm': 6.643136978149414, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 05:49:46 client3-1  | {'loss': 0.1919, 'grad_norm': 7.318399429321289, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 06:02:08 client1-1  | {'loss': 0.2121, 'grad_norm': 8.068190574645996, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 05:50:01 client3-1  | {'loss': 0.2346, 'grad_norm': 6.638387203216553, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 05:50:22 client3-1  | {'loss': 0.2243, 'grad_norm': 4.299036502838135, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 06:08:50 client2-1  | INFO :      Sent reply
2025-05-22 05:50:37 client3-1  | {'loss': 0.2534, 'grad_norm': 6.332674026489258, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 05:50:51 client3-1  | {'loss': 0.3102, 'grad_norm': 6.717747688293457, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 05:51:06 client3-1  | {'loss': 0.2725, 'grad_norm': 8.48893928527832, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 06:02:29 client1-1  | {'loss': 0.1969, 'grad_norm': 5.184321403503418, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 06:09:13 client2-1  | INFO :      
2025-05-22 06:09:13 client2-1  | INFO :      Received: train message bf9ec99e-c27f-406c-8451-83372c8dfc3c
2025-05-22 06:09:28 client2-1  | {'loss': 0.0707, 'grad_norm': 0.9237715601921082, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 06:09:42 client2-1  | {'loss': 0.0968, 'grad_norm': 1.4868853092193604, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 06:09:58 client2-1  | {'loss': 0.0994, 'grad_norm': 1.2689995765686035, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 06:10:13 client2-1  | {'loss': 0.1317, 'grad_norm': 6.271261215209961, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 06:10:34 client2-1  | {'loss': 0.1153, 'grad_norm': 1.3233879804611206, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 05:51:27 client3-1  | {'loss': 0.3347, 'grad_norm': 6.001270771026611, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 05:51:43 client3-1  | {'loss': 0.379, 'grad_norm': 7.712735176086426, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 06:10:49 client2-1  | {'loss': 0.1252, 'grad_norm': 1.5442756414413452, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 06:11:04 client2-1  | {'loss': 0.1126, 'grad_norm': 2.975071668624878, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 06:11:19 client2-1  | {'loss': 0.1293, 'grad_norm': 4.244347095489502, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 06:11:40 client2-1  | {'loss': 0.1283, 'grad_norm': 2.909088373184204, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 06:11:55 client2-1  | {'loss': 0.1595, 'grad_norm': 4.054991245269775, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 06:12:10 client2-1  | {'loss': 0.1509, 'grad_norm': 5.4207987785339355, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 06:12:25 client2-1  | {'loss': 0.1342, 'grad_norm': 5.081669807434082, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 05:51:58 client3-1  | {'loss': 0.4711, 'grad_norm': 6.315836429595947, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 05:52:12 client3-1  | {'loss': 0.3965, 'grad_norm': 6.8831586837768555, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 05:52:33 client3-1  | {'loss': 0.4455, 'grad_norm': 6.817192077636719, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 06:12:47 client2-1  | {'loss': 0.1628, 'grad_norm': 3.809445858001709, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 05:52:48 client3-1  | {'loss': 0.5837, 'grad_norm': 11.095609664916992, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 06:13:02 client2-1  | {'loss': 0.1407, 'grad_norm': 4.824986934661865, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 05:53:03 client3-1  | {'loss': 0.678, 'grad_norm': 9.870247840881348, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 06:02:44 client1-1  | {'loss': 0.2073, 'grad_norm': 3.556187629699707, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 06:02:59 client1-1  | {'loss': 0.2162, 'grad_norm': 6.566462993621826, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 06:03:14 client1-1  | {'loss': 0.2585, 'grad_norm': 2.8791921138763428, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 05:53:18 client3-1  | {'loss': 0.7147, 'grad_norm': 10.39492416381836, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 06:03:35 client1-1  | {'loss': 0.2549, 'grad_norm': 6.897986888885498, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 06:13:17 client2-1  | {'loss': 0.1357, 'grad_norm': 3.858170986175537, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 06:13:32 client2-1  | {'loss': 0.1604, 'grad_norm': 3.9472506046295166, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 05:53:39 client3-1  | {'loss': 0.7537, 'grad_norm': 10.784229278564453, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 06:13:53 client2-1  | {'loss': 0.2013, 'grad_norm': 5.292265892028809, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 06:03:50 client1-1  | {'loss': 0.3025, 'grad_norm': 5.9796833992004395, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 06:14:08 client2-1  | {'loss': 0.1727, 'grad_norm': 5.156271934509277, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 06:14:22 client2-1  | {'loss': 0.1825, 'grad_norm': 6.514620304107666, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 06:14:37 client2-1  | {'loss': 0.2174, 'grad_norm': 4.633056163787842, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 06:04:05 client1-1  | {'loss': 0.258, 'grad_norm': 8.33013916015625, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 06:04:20 client1-1  | {'loss': 0.3759, 'grad_norm': 10.144474029541016, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 06:04:41 client1-1  | {'loss': 0.4195, 'grad_norm': 8.847845077514648, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 06:14:58 client2-1  | {'loss': 0.2354, 'grad_norm': 8.655458450317383, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 06:04:56 client1-1  | {'loss': 0.4651, 'grad_norm': 6.4235124588012695, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 05:53:54 client3-1  | {'loss': 0.9791, 'grad_norm': 13.728705406188965, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 05:54:09 client3-1  | {'loss': 0.9426, 'grad_norm': 11.78983211517334, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 05:54:24 client3-1  | {'loss': 0.942, 'grad_norm': 11.192292213439941, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 05:54:45 client3-1  | {'loss': 1.247, 'grad_norm': 12.615943908691406, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 05:55:00 client3-1  | {'loss': 1.2233, 'grad_norm': 13.622318267822266, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 05:55:15 client3-1  | {'loss': 0.9897, 'grad_norm': 9.519478797912598, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 06:05:11 client1-1  | {'loss': 0.5237, 'grad_norm': 11.42409610748291, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 05:55:36 client3-1  | {'loss': 0.5686, 'grad_norm': 3.8224642276763916, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 06:15:14 client2-1  | {'loss': 0.2128, 'grad_norm': 7.545621871948242, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 05:55:51 client3-1  | {'loss': 0.1739, 'grad_norm': 4.557636737823486, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 06:15:29 client2-1  | {'loss': 0.1987, 'grad_norm': 4.596913814544678, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 06:05:27 client1-1  | {'loss': 0.5298, 'grad_norm': 7.8006768226623535, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 05:55:51 client3-1  | {'train_runtime': 675.661, 'train_samples_per_second': 1.183, 'train_steps_per_second': 0.592, 'train_loss': 0.3981353202462196, 'epoch': 1.0}
2025-05-22 06:05:48 client1-1  | {'loss': 0.6475, 'grad_norm': 8.894437789916992, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 06:06:03 client1-1  | {'loss': 0.8516, 'grad_norm': 15.055408477783203, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 06:15:44 client2-1  | {'loss': 0.2467, 'grad_norm': 7.727019786834717, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 06:06:18 client1-1  | {'loss': 0.8156, 'grad_norm': 11.456549644470215, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 06:16:05 client2-1  | {'loss': 0.3313, 'grad_norm': 10.062307357788086, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 06:06:33 client1-1  | {'loss': 0.9756, 'grad_norm': 14.378544807434082, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 06:16:20 client2-1  | {'loss': 0.3226, 'grad_norm': 8.95328140258789, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 06:16:35 client2-1  | {'loss': 0.4709, 'grad_norm': 9.130743026733398, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 06:16:50 client2-1  | {'loss': 0.408, 'grad_norm': 7.307629108428955, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 05:55:58 client3-1  | INFO :      Sent reply
2025-05-22 06:17:11 client2-1  | {'loss': 0.3787, 'grad_norm': 9.542258262634277, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 06:17:26 client2-1  | {'loss': 0.5248, 'grad_norm': 7.717253684997559, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 06:17:41 client2-1  | {'loss': 0.5422, 'grad_norm': 6.7775163650512695, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 06:06:54 client1-1  | {'loss': 1.0564, 'grad_norm': 10.73395824432373, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 06:07:09 client1-1  | {'loss': 1.1163, 'grad_norm': 12.117247581481934, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 05:56:33 client3-1  | INFO :      
2025-05-22 06:17:56 client2-1  | {'loss': 0.8114, 'grad_norm': 11.088730812072754, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 06:18:17 client2-1  | {'loss': 0.7475, 'grad_norm': 11.046916961669922, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 06:18:33 client2-1  | {'loss': 0.8716, 'grad_norm': 12.718427658081055, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 06:18:47 client2-1  | {'loss': 1.0751, 'grad_norm': 12.387441635131836, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 06:07:24 client1-1  | {'loss': 1.1147, 'grad_norm': 11.068132400512695, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 06:19:02 client2-1  | {'loss': 1.1295, 'grad_norm': 13.46657657623291, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 05:56:33 client3-1  | INFO :      Received: evaluate message 08c72064-76bf-47ed-b4fc-30bf3f44868d
2025-05-22 05:56:43 client3-1  | {'eval_loss': 1.9328172206878662, 'eval_runtime': 8.6967, 'eval_samples_per_second': 22.997, 'eval_steps_per_second': 2.875, 'epoch': 1.0}
2025-05-22 05:56:43 client3-1  | INFO :      Sent reply
2025-05-22 05:56:59 client3-1  | INFO :      
2025-05-22 05:56:59 client3-1  | INFO :      Received: train message c9821d76-4b32-4987-8e10-e12599a555c5
2025-05-22 05:57:22 client3-1  | {'loss': 0.0693, 'grad_norm': 1.00927734375, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 05:57:37 client3-1  | {'loss': 0.0963, 'grad_norm': 2.399411916732788, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 06:07:38 client1-1  | {'loss': 0.8422, 'grad_norm': 11.041709899902344, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 06:08:00 client1-1  | {'loss': 0.5033, 'grad_norm': 6.418447494506836, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 06:08:11 client1-1  | {'loss': 0.1529, 'grad_norm': 3.5303540229797363, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 05:57:52 client3-1  | {'loss': 0.1172, 'grad_norm': 3.230483055114746, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 06:19:24 client2-1  | {'loss': 1.1216, 'grad_norm': 12.293609619140625, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 06:19:39 client2-1  | {'loss': 1.0671, 'grad_norm': 8.457253456115723, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 06:08:11 client1-1  | {'train_runtime': 665.1885, 'train_samples_per_second': 1.203, 'train_steps_per_second': 0.601, 'train_loss': 0.36740123242139816, 'epoch': 1.0}
2025-05-22 06:08:16 client1-1  | INFO :      Sent reply
2025-05-22 06:08:47 client1-1  | INFO :      
2025-05-22 06:08:47 client1-1  | INFO :      Received: evaluate message bdc6cc8a-c6de-43aa-adee-52b199d9cc33
2025-05-22 05:58:07 client3-1  | {'loss': 0.1257, 'grad_norm': 3.7672715187072754, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 05:58:22 client3-1  | {'loss': 0.1203, 'grad_norm': 3.8200907707214355, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 06:09:01 client1-1  | {'eval_loss': 1.926072359085083, 'eval_runtime': 12.9973, 'eval_samples_per_second': 15.388, 'eval_steps_per_second': 1.923, 'epoch': 1.0}
2025-05-22 05:58:43 client3-1  | {'loss': 0.1081, 'grad_norm': 3.2328081130981445, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 05:58:59 client3-1  | {'loss': 0.11, 'grad_norm': 2.835909605026245, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 06:19:54 client2-1  | {'loss': 0.6151, 'grad_norm': 8.968958854675293, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 05:59:13 client3-1  | {'loss': 0.1476, 'grad_norm': 4.254583358764648, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 05:59:34 client3-1  | {'loss': 0.1587, 'grad_norm': 4.890394687652588, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 05:59:49 client3-1  | {'loss': 0.1622, 'grad_norm': 3.7396533489227295, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 06:00:04 client3-1  | {'loss': 0.1249, 'grad_norm': 3.5748260021209717, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 06:00:20 client3-1  | {'loss': 0.1822, 'grad_norm': 6.374608039855957, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 06:09:01 client1-1  | INFO :      Sent reply
2025-05-22 06:00:35 client3-1  | {'loss': 0.1932, 'grad_norm': 3.998861074447632, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 06:20:09 client2-1  | {'loss': 0.1676, 'grad_norm': 4.259069442749023, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 06:20:09 client2-1  | {'train_runtime': 653.1756, 'train_samples_per_second': 1.225, 'train_steps_per_second': 0.612, 'train_loss': 0.3576509211957455, 'epoch': 1.0}
2025-05-22 06:09:17 client1-1  | INFO :      
2025-05-22 06:09:17 client1-1  | INFO :      Received: train message 964d59bc-3a70-4e24-b9cd-ced45af9b19e
2025-05-22 06:09:40 client1-1  | {'loss': 0.0804, 'grad_norm': 4.608794212341309, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 06:20:22 client2-1  | INFO :      Sent reply
2025-05-22 06:21:03 client2-1  | INFO :      
2025-05-22 06:21:03 client2-1  | INFO :      Received: evaluate message a9833a92-5e16-46e9-b369-261d0ba8524a
2025-05-22 06:21:18 client2-1  | {'eval_loss': 1.8848626613616943, 'eval_runtime': 12.2338, 'eval_samples_per_second': 16.348, 'eval_steps_per_second': 2.044, 'epoch': 1.0}
2025-05-22 06:21:18 client2-1  | INFO :      Sent reply
2025-05-22 06:21:38 client2-1  | INFO :      
2025-05-22 06:09:55 client1-1  | {'loss': 0.0797, 'grad_norm': 2.207132577896118, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 06:10:10 client1-1  | {'loss': 0.0938, 'grad_norm': 0.9484527111053467, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 06:10:25 client1-1  | {'loss': 0.1165, 'grad_norm': 3.0755348205566406, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 06:21:38 client2-1  | INFO :      Received: train message f7677d45-94fc-4f07-9808-0b5e9a69779e
2025-05-22 06:10:46 client1-1  | {'loss': 0.1247, 'grad_norm': 3.5665431022644043, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 06:00:56 client3-1  | {'loss': 0.2005, 'grad_norm': 7.862910747528076, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 06:01:12 client3-1  | {'loss': 0.1446, 'grad_norm': 3.314770221710205, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 06:01:26 client3-1  | {'loss': 0.157, 'grad_norm': 4.054225921630859, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 06:22:03 client2-1  | {'loss': 0.066, 'grad_norm': 1.45323646068573, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 06:01:41 client3-1  | {'loss': 0.1912, 'grad_norm': 5.623352527618408, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 06:11:01 client1-1  | {'loss': 0.1047, 'grad_norm': 1.6362946033477783, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 06:11:16 client1-1  | {'loss': 0.1018, 'grad_norm': 4.869603157043457, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 06:11:31 client1-1  | {'loss': 0.1197, 'grad_norm': 4.048529148101807, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 06:22:18 client2-1  | {'loss': 0.0894, 'grad_norm': 1.679370641708374, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 06:22:33 client2-1  | {'loss': 0.098, 'grad_norm': 1.271599292755127, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 06:22:54 client2-1  | {'loss': 0.116, 'grad_norm': 4.82480525970459, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 06:02:02 client3-1  | {'loss': 0.1716, 'grad_norm': 5.329412460327148, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 06:02:17 client3-1  | {'loss': 0.2055, 'grad_norm': 6.320137023925781, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 06:23:09 client2-1  | {'loss': 0.1028, 'grad_norm': 3.2026824951171875, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 06:02:32 client3-1  | {'loss': 0.1995, 'grad_norm': 3.142115592956543, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 06:23:24 client2-1  | {'loss': 0.1033, 'grad_norm': 3.392143487930298, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 06:02:47 client3-1  | {'loss': 0.2306, 'grad_norm': 4.693204402923584, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 06:23:45 client2-1  | {'loss': 0.1078, 'grad_norm': 1.8733407258987427, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 06:24:00 client2-1  | {'loss': 0.1096, 'grad_norm': 2.9043314456939697, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 06:24:15 client2-1  | {'loss': 0.1346, 'grad_norm': 2.0772054195404053, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 06:24:29 client2-1  | {'loss': 0.14, 'grad_norm': 1.6789379119873047, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 06:24:51 client2-1  | {'loss': 0.1268, 'grad_norm': 3.2283756732940674, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 06:25:05 client2-1  | {'loss': 0.1255, 'grad_norm': 5.807010650634766, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 06:25:20 client2-1  | {'loss': 0.1419, 'grad_norm': 4.0287556648254395, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 06:25:35 client2-1  | {'loss': 0.1317, 'grad_norm': 5.628425121307373, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 06:25:57 client2-1  | {'loss': 0.1269, 'grad_norm': 3.001840114593506, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 06:03:08 client3-1  | {'loss': 0.2733, 'grad_norm': 6.769019603729248, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 06:26:11 client2-1  | {'loss': 0.1515, 'grad_norm': 4.108627796173096, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 06:11:52 client1-1  | {'loss': 0.1271, 'grad_norm': 4.364659786224365, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 06:12:07 client1-1  | {'loss': 0.1422, 'grad_norm': 4.672332286834717, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 06:12:22 client1-1  | {'loss': 0.146, 'grad_norm': 6.068037033081055, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 06:03:23 client3-1  | {'loss': 0.243, 'grad_norm': 6.888025283813477, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 06:12:37 client1-1  | {'loss': 0.1968, 'grad_norm': 4.612060070037842, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 06:12:59 client1-1  | {'loss': 0.1246, 'grad_norm': 5.217129230499268, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 06:13:14 client1-1  | {'loss': 0.1455, 'grad_norm': 6.799831867218018, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 06:26:26 client2-1  | {'loss': 0.1778, 'grad_norm': 5.052412986755371, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 06:13:29 client1-1  | {'loss': 0.132, 'grad_norm': 3.815147638320923, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 06:26:41 client2-1  | {'loss': 0.1491, 'grad_norm': 5.884657859802246, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 06:13:44 client1-1  | {'loss': 0.1506, 'grad_norm': 5.274124622344971, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 06:03:38 client3-1  | {'loss': 0.299, 'grad_norm': 5.524945259094238, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 06:14:05 client1-1  | {'loss': 0.1961, 'grad_norm': 4.816097259521484, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 06:14:20 client1-1  | {'loss': 0.1846, 'grad_norm': 6.651968479156494, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 06:14:34 client1-1  | {'loss': 0.1816, 'grad_norm': 6.884551048278809, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 06:27:02 client2-1  | {'loss': 0.1663, 'grad_norm': 6.287968635559082, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 06:27:17 client2-1  | {'loss': 0.1922, 'grad_norm': 4.490238189697266, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 06:27:32 client2-1  | {'loss': 0.2068, 'grad_norm': 8.152297019958496, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 06:27:54 client2-1  | {'loss': 0.1961, 'grad_norm': 6.144148349761963, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 06:28:09 client2-1  | {'loss': 0.1743, 'grad_norm': 6.020839691162109, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 06:28:30 client2-1  | {'loss': 0.2238, 'grad_norm': 5.427340507507324, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 06:28:45 client2-1  | {'loss': 0.2993, 'grad_norm': 8.715088844299316, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 06:14:49 client1-1  | {'loss': 0.1915, 'grad_norm': 3.1119065284729004, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 06:03:53 client3-1  | {'loss': 0.3152, 'grad_norm': 6.314139366149902, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 06:29:00 client2-1  | {'loss': 0.3095, 'grad_norm': 9.763825416564941, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 06:04:14 client3-1  | {'loss': 0.4226, 'grad_norm': 5.606735706329346, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 06:29:15 client2-1  | {'loss': 0.4189, 'grad_norm': 9.888229370117188, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 06:29:36 client2-1  | {'loss': 0.366, 'grad_norm': 7.716578483581543, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 06:29:51 client2-1  | {'loss': 0.3446, 'grad_norm': 8.193410873413086, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 06:30:06 client2-1  | {'loss': 0.4922, 'grad_norm': 6.748517036437988, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 06:30:21 client2-1  | {'loss': 0.4903, 'grad_norm': 6.519869327545166, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 06:30:42 client2-1  | {'loss': 0.7572, 'grad_norm': 12.919182777404785, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 06:30:57 client2-1  | {'loss': 0.7177, 'grad_norm': 11.079374313354492, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 06:31:12 client2-1  | {'loss': 0.8287, 'grad_norm': 11.395074844360352, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 06:15:11 client1-1  | {'loss': 0.1906, 'grad_norm': 6.450791358947754, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 06:15:26 client1-1  | {'loss': 0.2332, 'grad_norm': 2.665100336074829, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 06:31:26 client2-1  | {'loss': 1.0523, 'grad_norm': 11.733358383178711, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 06:31:47 client2-1  | {'loss': 1.0881, 'grad_norm': 13.8770751953125, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 06:32:02 client2-1  | {'loss': 1.1015, 'grad_norm': 12.469860076904297, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 06:32:17 client2-1  | {'loss': 1.0457, 'grad_norm': 8.950218200683594, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 06:15:41 client1-1  | {'loss': 0.2186, 'grad_norm': 5.849566459655762, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 06:04:29 client3-1  | {'loss': 0.3547, 'grad_norm': 6.7495503425598145, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 06:15:56 client1-1  | {'loss': 0.2809, 'grad_norm': 6.685614109039307, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 06:04:44 client3-1  | {'loss': 0.4013, 'grad_norm': 7.172666072845459, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 06:16:17 client1-1  | {'loss': 0.2505, 'grad_norm': 7.684652805328369, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 06:04:59 client3-1  | {'loss': 0.5379, 'grad_norm': 11.978804588317871, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 06:05:14 client3-1  | {'loss': 0.6148, 'grad_norm': 9.971548080444336, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 06:05:36 client3-1  | {'loss': 0.6695, 'grad_norm': 10.422968864440918, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 06:05:50 client3-1  | {'loss': 0.7273, 'grad_norm': 8.852034568786621, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 06:16:32 client1-1  | {'loss': 0.3317, 'grad_norm': 9.296402931213379, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 06:16:47 client1-1  | {'loss': 0.3757, 'grad_norm': 9.939470291137695, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 06:32:31 client2-1  | {'loss': 0.5912, 'grad_norm': 9.20544719696045, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 06:32:41 client2-1  | {'loss': 0.1399, 'grad_norm': 3.601484537124634, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 06:32:41 client2-1  | {'train_runtime': 657.92, 'train_samples_per_second': 1.216, 'train_steps_per_second': 0.608, 'train_loss': 0.3350346949696541, 'epoch': 1.0}
2025-05-22 06:32:52 client2-1  | INFO :      Sent reply
2025-05-22 06:33:18 client2-1  | INFO :      
2025-05-22 06:33:18 client2-1  | INFO :      Received: evaluate message 0c9794cf-4294-452e-83cf-cacd6c8da997
2025-05-22 06:33:22 client2-1  | {'eval_loss': 1.9185378551483154, 'eval_runtime': 2.8804, 'eval_samples_per_second': 69.435, 'eval_steps_per_second': 8.679, 'epoch': 1.0}
2025-05-22 06:17:02 client1-1  | {'loss': 0.4298, 'grad_norm': 7.101562023162842, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 06:17:23 client1-1  | {'loss': 0.495, 'grad_norm': 10.368650436401367, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 06:17:38 client1-1  | {'loss': 0.511, 'grad_norm': 7.877834320068359, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 06:33:22 client2-1  | INFO :      Sent reply
2025-05-22 06:33:49 client2-1  | INFO :      
2025-05-22 06:33:49 client2-1  | INFO :      Received: train message e5ad3ea9-c291-4d51-84ec-2b1c3e837ca1
2025-05-22 06:17:53 client1-1  | {'loss': 0.6212, 'grad_norm': 7.795220851898193, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 06:18:08 client1-1  | {'loss': 0.8458, 'grad_norm': 13.93818187713623, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 06:18:30 client1-1  | {'loss': 0.7786, 'grad_norm': 10.612749099731445, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 06:06:05 client3-1  | {'loss': 0.9336, 'grad_norm': 13.569219589233398, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 06:06:20 client3-1  | {'loss': 0.9279, 'grad_norm': 12.706621170043945, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 06:18:45 client1-1  | {'loss': 0.9621, 'grad_norm': 13.078727722167969, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 06:06:35 client3-1  | {'loss': 0.9317, 'grad_norm': 11.373651504516602, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 06:06:56 client3-1  | {'loss': 1.2207, 'grad_norm': 12.55438232421875, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 06:07:11 client3-1  | {'loss': 1.2293, 'grad_norm': 14.455373764038086, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 06:34:16 client2-1  | {'loss': 0.0665, 'grad_norm': 1.0393915176391602, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 06:34:37 client2-1  | {'loss': 0.0943, 'grad_norm': 1.4925537109375, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 06:34:52 client2-1  | {'loss': 0.0909, 'grad_norm': 0.9039816856384277, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 06:19:00 client1-1  | {'loss': 1.0323, 'grad_norm': 10.200685501098633, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 06:19:21 client1-1  | {'loss': 1.1031, 'grad_norm': 12.446222305297852, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 06:19:36 client1-1  | {'loss': 1.101, 'grad_norm': 11.3439359664917, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 06:35:07 client2-1  | {'loss': 0.1158, 'grad_norm': 5.44063663482666, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 06:35:22 client2-1  | {'loss': 0.0994, 'grad_norm': 2.873441457748413, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 06:35:44 client2-1  | {'loss': 0.1069, 'grad_norm': 1.5078383684158325, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 06:07:26 client3-1  | {'loss': 0.9364, 'grad_norm': 9.289056777954102, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 06:07:41 client3-1  | {'loss': 0.5175, 'grad_norm': 4.846354961395264, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 06:07:56 client3-1  | {'loss': 0.1552, 'grad_norm': 4.41901159286499, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 06:19:52 client1-1  | {'loss': 0.8078, 'grad_norm': 11.445941925048828, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 06:35:59 client2-1  | {'loss': 0.0984, 'grad_norm': 1.3116225004196167, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 06:20:06 client1-1  | {'loss': 0.4597, 'grad_norm': 5.592678546905518, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 06:07:56 client3-1  | {'train_runtime': 654.8624, 'train_samples_per_second': 1.22, 'train_steps_per_second': 0.611, 'train_loss': 0.37318330615758893, 'epoch': 1.0}
2025-05-22 06:20:25 client1-1  | {'loss': 0.1522, 'grad_norm': 3.5072689056396484, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 06:20:25 client1-1  | {'train_runtime': 666.3124, 'train_samples_per_second': 1.201, 'train_steps_per_second': 0.6, 'train_loss': 0.3480119416117668, 'epoch': 1.0}
2025-05-22 06:20:31 client1-1  | INFO :      Sent reply
2025-05-22 06:21:04 client1-1  | INFO :      
2025-05-22 06:21:04 client1-1  | INFO :      Received: evaluate message 46e48057-1df4-43f7-9432-44fde7e93fd5
2025-05-22 06:21:23 client1-1  | {'eval_loss': 1.9455243349075317, 'eval_runtime': 12.8105, 'eval_samples_per_second': 15.612, 'eval_steps_per_second': 1.952, 'epoch': 1.0}
2025-05-22 06:36:13 client2-1  | {'loss': 0.0939, 'grad_norm': 1.8365013599395752, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 06:36:29 client2-1  | {'loss': 0.1194, 'grad_norm': 1.8099805116653442, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 06:36:50 client2-1  | {'loss': 0.1045, 'grad_norm': 1.238948941230774, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 06:37:05 client2-1  | {'loss': 0.1103, 'grad_norm': 4.670640468597412, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 06:08:09 client3-1  | INFO :      Sent reply
2025-05-22 06:08:49 client3-1  | INFO :      
2025-05-22 06:08:49 client3-1  | INFO :      Received: evaluate message 00ebdf24-dada-4073-b356-01e524f2604a
2025-05-22 06:37:20 client2-1  | {'loss': 0.1138, 'grad_norm': 6.232029914855957, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 06:21:23 client1-1  | INFO :      Sent reply
2025-05-22 06:37:35 client2-1  | {'loss': 0.1339, 'grad_norm': 3.7831788063049316, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 06:21:35 client1-1  | INFO :      
2025-05-22 06:21:35 client1-1  | INFO :      Received: train message 64d01727-2371-4b4f-a102-0213ebf617ff
2025-05-22 06:21:41 client1-1  | {'loss': 0.0856, 'grad_norm': 3.917518138885498, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 06:09:03 client3-1  | {'eval_loss': 1.9648818969726562, 'eval_runtime': 11.6425, 'eval_samples_per_second': 17.178, 'eval_steps_per_second': 2.147, 'epoch': 1.0}
2025-05-22 06:09:03 client3-1  | INFO :      Sent reply
2025-05-22 06:21:54 client1-1  | {'loss': 0.0836, 'grad_norm': 2.5906810760498047, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 06:09:18 client3-1  | INFO :      
2025-05-22 06:09:18 client3-1  | INFO :      Received: train message 04b1b19a-ad1e-4439-b30e-75f972e569fe
2025-05-22 06:22:08 client1-1  | {'loss': 0.0989, 'grad_norm': 2.397735595703125, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 06:09:45 client3-1  | {'loss': 0.0668, 'grad_norm': 0.9126263856887817, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 06:10:00 client3-1  | {'loss': 0.0941, 'grad_norm': 1.6364604234695435, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 06:22:29 client1-1  | {'loss': 0.1081, 'grad_norm': 4.565269947052002, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 06:22:44 client1-1  | {'loss': 0.1251, 'grad_norm': 4.332365989685059, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 06:22:59 client1-1  | {'loss': 0.108, 'grad_norm': 2.0756452083587646, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 06:37:56 client2-1  | {'loss': 0.1271, 'grad_norm': 4.258545875549316, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 06:10:22 client3-1  | {'loss': 0.0908, 'grad_norm': 2.3159830570220947, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 06:23:14 client1-1  | {'loss': 0.1195, 'grad_norm': 6.001596927642822, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 06:23:35 client1-1  | {'loss': 0.1188, 'grad_norm': 4.256376266479492, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 06:23:50 client1-1  | {'loss': 0.1363, 'grad_norm': 2.1808738708496094, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 06:38:11 client2-1  | {'loss': 0.1175, 'grad_norm': 2.6236135959625244, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 06:24:05 client1-1  | {'loss': 0.1332, 'grad_norm': 2.232323408126831, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 06:38:26 client2-1  | {'loss': 0.1477, 'grad_norm': 4.663196563720703, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 06:24:20 client1-1  | {'loss': 0.1474, 'grad_norm': 5.732273101806641, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 06:38:41 client2-1  | {'loss': 0.1775, 'grad_norm': 3.591888904571533, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 06:24:41 client1-1  | {'loss': 0.1755, 'grad_norm': 4.702775478363037, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 06:39:03 client2-1  | {'loss': 0.1325, 'grad_norm': 4.737395286560059, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 06:24:56 client1-1  | {'loss': 0.1227, 'grad_norm': 6.403285503387451, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 06:39:17 client2-1  | {'loss': 0.1633, 'grad_norm': 7.1140289306640625, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 06:10:37 client3-1  | {'loss': 0.1152, 'grad_norm': 4.640754222869873, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 06:10:52 client3-1  | {'loss': 0.1126, 'grad_norm': 3.4191677570343018, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 06:25:11 client1-1  | {'loss': 0.1589, 'grad_norm': 6.127834796905518, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 06:25:26 client1-1  | {'loss': 0.1381, 'grad_norm': 4.591503143310547, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 06:25:47 client1-1  | {'loss': 0.1461, 'grad_norm': 3.8241071701049805, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 06:26:02 client1-1  | {'loss': 0.1815, 'grad_norm': 5.095833778381348, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 06:39:32 client2-1  | {'loss': 0.1902, 'grad_norm': 4.263838768005371, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 06:11:13 client3-1  | {'loss': 0.108, 'grad_norm': 2.755758047103882, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 06:26:17 client1-1  | {'loss': 0.1681, 'grad_norm': 6.386252403259277, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 06:26:31 client1-1  | {'loss': 0.1728, 'grad_norm': 6.753461837768555, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 06:26:52 client1-1  | {'loss': 0.1768, 'grad_norm': 3.1075878143310547, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 06:27:07 client1-1  | {'loss': 0.1825, 'grad_norm': 5.595042705535889, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 06:27:22 client1-1  | {'loss': 0.2065, 'grad_norm': 2.6613821983337402, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 06:27:43 client1-1  | {'loss': 0.2094, 'grad_norm': 6.775543689727783, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 06:11:28 client3-1  | {'loss': 0.1115, 'grad_norm': 2.6152091026306152, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 06:11:43 client3-1  | {'loss': 0.1382, 'grad_norm': 4.47352933883667, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 06:39:47 client2-1  | {'loss': 0.2059, 'grad_norm': 8.007332801818848, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 06:40:09 client2-1  | {'loss': 0.1895, 'grad_norm': 5.521965980529785, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 06:40:24 client2-1  | {'loss': 0.1754, 'grad_norm': 4.8925042152404785, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 06:11:58 client3-1  | {'loss': 0.1511, 'grad_norm': 3.892935037612915, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 06:12:19 client3-1  | {'loss': 0.1511, 'grad_norm': 3.005002737045288, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 06:12:34 client3-1  | {'loss': 0.1231, 'grad_norm': 3.3135924339294434, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 06:12:49 client3-1  | {'loss': 0.1459, 'grad_norm': 6.13319206237793, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 06:13:05 client3-1  | {'loss': 0.1765, 'grad_norm': 2.7000672817230225, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 06:40:39 client2-1  | {'loss': 0.2031, 'grad_norm': 7.483854293823242, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 06:40:54 client2-1  | {'loss': 0.2757, 'grad_norm': 8.730989456176758, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 06:41:10 client2-1  | {'loss': 0.263, 'grad_norm': 10.392388343811035, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 06:27:59 client1-1  | {'loss': 0.2325, 'grad_norm': 5.9490814208984375, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 06:13:19 client3-1  | {'loss': 0.1754, 'grad_norm': 5.749657154083252, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 06:13:41 client3-1  | {'loss': 0.1305, 'grad_norm': 4.834171295166016, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 06:13:55 client3-1  | {'loss': 0.1544, 'grad_norm': 6.124148368835449, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 06:14:10 client3-1  | {'loss': 0.1623, 'grad_norm': 5.2799177169799805, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 06:41:31 client2-1  | {'loss': 0.3719, 'grad_norm': 7.53256368637085, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 06:41:46 client2-1  | {'loss': 0.3283, 'grad_norm': 9.383866310119629, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 06:42:01 client2-1  | {'loss': 0.3287, 'grad_norm': 8.186320304870605, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 06:42:16 client2-1  | {'loss': 0.4436, 'grad_norm': 7.0083160400390625, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 06:14:25 client3-1  | {'loss': 0.155, 'grad_norm': 4.5355143547058105, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 06:14:46 client3-1  | {'loss': 0.1931, 'grad_norm': 6.807397842407227, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 06:42:37 client2-1  | {'loss': 0.4504, 'grad_norm': 5.908132553100586, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 06:15:01 client3-1  | {'loss': 0.1775, 'grad_norm': 3.4759085178375244, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 06:42:52 client2-1  | {'loss': 0.7109, 'grad_norm': 12.151199340820312, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 06:43:07 client2-1  | {'loss': 0.6604, 'grad_norm': 10.729043006896973, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 06:43:22 client2-1  | {'loss': 0.8113, 'grad_norm': 12.226868629455566, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 06:43:43 client2-1  | {'loss': 1.0005, 'grad_norm': 12.995059967041016, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 06:15:16 client3-1  | {'loss': 0.2039, 'grad_norm': 4.969823360443115, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 06:15:31 client3-1  | {'loss': 0.2462, 'grad_norm': 5.9133148193359375, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 06:15:53 client3-1  | {'loss': 0.2243, 'grad_norm': 6.4326276779174805, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 06:16:08 client3-1  | {'loss': 0.273, 'grad_norm': 6.9835100173950195, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 06:28:14 client1-1  | {'loss': 0.2178, 'grad_norm': 7.316773414611816, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 06:28:35 client1-1  | {'loss': 0.2992, 'grad_norm': 8.81279182434082, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 06:28:50 client1-1  | {'loss': 0.3566, 'grad_norm': 9.969097137451172, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 06:29:05 client1-1  | {'loss': 0.3794, 'grad_norm': 6.597748756408691, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 06:16:22 client3-1  | {'loss': 0.3, 'grad_norm': 6.931957721710205, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 06:16:37 client3-1  | {'loss': 0.3821, 'grad_norm': 6.559968948364258, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 06:16:52 client3-1  | {'loss': 0.3131, 'grad_norm': 6.289062976837158, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 06:43:58 client2-1  | {'loss': 1.0946, 'grad_norm': 14.065828323364258, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 06:44:13 client2-1  | {'loss': 1.0809, 'grad_norm': 12.575867652893066, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 06:44:28 client2-1  | {'loss': 1.0186, 'grad_norm': 8.261584281921387, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 06:29:20 client1-1  | {'loss': 0.4323, 'grad_norm': 8.667099952697754, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 06:44:50 client2-1  | {'loss': 0.5458, 'grad_norm': 7.340454578399658, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 06:44:58 client2-1  | {'loss': 0.1338, 'grad_norm': 5.347833156585693, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 06:44:58 client2-1  | {'train_runtime': 663.8998, 'train_samples_per_second': 1.205, 'train_steps_per_second': 0.603, 'train_loss': 0.31740578457713126, 'epoch': 1.0}
2025-05-22 06:45:03 client2-1  | INFO :      Sent reply
2025-05-22 06:45:36 client2-1  | INFO :      
2025-05-22 06:17:14 client3-1  | {'loss': 0.3791, 'grad_norm': 7.208826065063477, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 06:17:28 client3-1  | {'loss': 0.5041, 'grad_norm': 9.358522415161133, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 06:17:43 client3-1  | {'loss': 0.5683, 'grad_norm': 9.760602951049805, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 06:17:58 client3-1  | {'loss': 0.6356, 'grad_norm': 9.982373237609863, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 06:45:36 client2-1  | INFO :      Received: evaluate message f91e99d0-dab5-4999-921f-6eaf13077007
2025-05-22 06:45:49 client2-1  | {'eval_loss': 1.946010708808899, 'eval_runtime': 12.0386, 'eval_samples_per_second': 16.613, 'eval_steps_per_second': 2.077, 'epoch': 1.0}
2025-05-22 06:29:41 client1-1  | {'loss': 0.4582, 'grad_norm': 7.365363597869873, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 06:29:56 client1-1  | {'loss': 0.5756, 'grad_norm': 8.32249641418457, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 06:45:49 client2-1  | INFO :      Sent reply
2025-05-22 06:30:11 client1-1  | {'loss': 0.792, 'grad_norm': 14.24357795715332, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 06:18:20 client3-1  | {'loss': 0.6654, 'grad_norm': 10.683938026428223, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 06:18:35 client3-1  | {'loss': 0.9163, 'grad_norm': 17.368629455566406, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 06:18:50 client3-1  | {'loss': 0.8731, 'grad_norm': 12.195405006408691, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 06:19:05 client3-1  | {'loss': 0.9116, 'grad_norm': 11.707575798034668, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 06:30:32 client1-1  | {'loss': 0.771, 'grad_norm': 11.798343658447266, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 06:19:26 client3-1  | {'loss': 1.2041, 'grad_norm': 13.620373725891113, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 06:19:41 client3-1  | {'loss': 1.2062, 'grad_norm': 14.273131370544434, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 06:19:57 client3-1  | {'loss': 0.9312, 'grad_norm': 9.234468460083008, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 06:46:02 client2-1  | INFO :      
2025-05-22 06:46:02 client2-1  | INFO :      Received: train message 7f975c13-c29a-4186-9eb9-0c3e9a4b308e
2025-05-22 06:46:15 client2-1  | {'loss': 0.063, 'grad_norm': 1.38773512840271, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 06:30:47 client1-1  | {'loss': 0.9233, 'grad_norm': 13.324997901916504, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 06:20:11 client3-1  | {'loss': 0.485, 'grad_norm': 3.924532413482666, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 06:20:27 client3-1  | {'loss': 0.1473, 'grad_norm': 2.930445909500122, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 06:46:30 client2-1  | {'loss': 0.0895, 'grad_norm': 1.3854557275772095, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 06:46:45 client2-1  | {'loss': 0.0993, 'grad_norm': 1.0413897037506104, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 06:20:27 client3-1  | {'train_runtime': 663.7204, 'train_samples_per_second': 1.204, 'train_steps_per_second': 0.603, 'train_loss': 0.35257944613695147, 'epoch': 1.0}
2025-05-22 06:47:00 client2-1  | {'loss': 0.1051, 'grad_norm': 5.226200103759766, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 06:47:21 client2-1  | {'loss': 0.0975, 'grad_norm': 1.5461275577545166, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 06:47:36 client2-1  | {'loss': 0.0985, 'grad_norm': 2.507791757583618, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 06:47:51 client2-1  | {'loss': 0.1004, 'grad_norm': 2.058835506439209, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 06:48:06 client2-1  | {'loss': 0.0974, 'grad_norm': 3.380389928817749, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 06:48:27 client2-1  | {'loss': 0.1155, 'grad_norm': 2.399165153503418, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 06:48:42 client2-1  | {'loss': 0.1374, 'grad_norm': 3.699780225753784, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 06:48:57 client2-1  | {'loss': 0.1261, 'grad_norm': 5.426634788513184, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 06:49:12 client2-1  | {'loss': 0.1123, 'grad_norm': 5.751729965209961, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 06:20:33 client3-1  | INFO :      Sent reply
2025-05-22 06:21:03 client3-1  | INFO :      
2025-05-22 06:21:03 client3-1  | INFO :      Received: evaluate message 4be7d3ec-15f7-4843-84c5-91afeba4a3c0
2025-05-22 06:31:02 client1-1  | {'loss': 0.9984, 'grad_norm': 10.873223304748535, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 06:21:20 client3-1  | {'eval_loss': 1.9946027994155884, 'eval_runtime': 15.9507, 'eval_samples_per_second': 12.539, 'eval_steps_per_second': 1.567, 'epoch': 1.0}
2025-05-22 06:21:20 client3-1  | INFO :      Sent reply
2025-05-22 06:21:37 client3-1  | INFO :      
2025-05-22 06:31:17 client1-1  | {'loss': 1.0595, 'grad_norm': 14.387168884277344, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 06:49:27 client2-1  | {'loss': 0.1363, 'grad_norm': 3.7567994594573975, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 06:21:37 client3-1  | INFO :      Received: train message 2192f6ba-1aeb-439d-9463-3255469748f5
2025-05-22 06:49:48 client2-1  | {'loss': 0.1128, 'grad_norm': 6.523350715637207, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 06:22:12 client3-1  | {'loss': 0.0682, 'grad_norm': 0.8908225893974304, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 06:31:38 client1-1  | {'loss': 1.1023, 'grad_norm': 11.235929489135742, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 06:31:52 client1-1  | {'loss': 0.7882, 'grad_norm': 11.177204132080078, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 06:32:07 client1-1  | {'loss': 0.4268, 'grad_norm': 5.141506195068359, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 06:32:22 client1-1  | {'loss': 0.1484, 'grad_norm': 3.2766458988189697, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 06:22:27 client3-1  | {'loss': 0.0877, 'grad_norm': 1.0600433349609375, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 06:50:03 client2-1  | {'loss': 0.1119, 'grad_norm': 3.9596762657165527, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 06:50:18 client2-1  | {'loss': 0.1383, 'grad_norm': 2.9681971073150635, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 06:50:33 client2-1  | {'loss': 0.1471, 'grad_norm': 4.034238338470459, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 06:22:42 client3-1  | {'loss': 0.0969, 'grad_norm': 4.684484958648682, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 06:50:55 client2-1  | {'loss': 0.1275, 'grad_norm': 3.9545111656188965, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 06:51:10 client2-1  | {'loss': 0.1522, 'grad_norm': 6.061551570892334, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 06:51:25 client2-1  | {'loss': 0.172, 'grad_norm': 3.0270872116088867, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 06:22:57 client3-1  | {'loss': 0.1003, 'grad_norm': 3.6501855850219727, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 06:51:39 client2-1  | {'loss': 0.1763, 'grad_norm': 7.833501815795898, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 06:32:22 client1-1  | {'train_runtime': 646.3663, 'train_samples_per_second': 1.238, 'train_steps_per_second': 0.619, 'train_loss': 0.331631513684988, 'epoch': 1.0}
2025-05-22 06:52:01 client2-1  | {'loss': 0.1728, 'grad_norm': 6.112832546234131, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 06:23:18 client3-1  | {'loss': 0.1172, 'grad_norm': 2.661212921142578, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 06:52:15 client2-1  | {'loss': 0.1626, 'grad_norm': 3.5786495208740234, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 06:32:35 client1-1  | INFO :      Sent reply
2025-05-22 06:52:31 client2-1  | {'loss': 0.2013, 'grad_norm': 4.781879901885986, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 06:23:33 client3-1  | {'loss': 0.1089, 'grad_norm': 2.9677422046661377, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 06:52:46 client2-1  | {'loss': 0.2548, 'grad_norm': 11.02985954284668, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 06:33:25 client1-1  | INFO :      
2025-05-22 06:33:25 client1-1  | INFO :      Received: evaluate message df5b0cd4-ff68-4885-b0c6-8c741c16de5e
2025-05-22 06:33:34 client1-1  | {'eval_loss': 1.9769054651260376, 'eval_runtime': 6.9134, 'eval_samples_per_second': 28.929, 'eval_steps_per_second': 3.616, 'epoch': 1.0}
2025-05-22 06:33:34 client1-1  | INFO :      Sent reply
2025-05-22 06:33:45 client1-1  | INFO :      
2025-05-22 06:33:45 client1-1  | INFO :      Received: train message 0f3d766d-1a8f-4f6b-b65e-38d5daef3a5a
2025-05-22 06:53:07 client2-1  | {'loss': 0.2425, 'grad_norm': 9.526047706604004, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 06:53:22 client2-1  | {'loss': 0.3602, 'grad_norm': 11.224032402038574, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 06:53:37 client2-1  | {'loss': 0.3048, 'grad_norm': 9.49181079864502, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 06:23:48 client3-1  | {'loss': 0.1003, 'grad_norm': 1.8336482048034668, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 06:53:58 client2-1  | {'loss': 0.2932, 'grad_norm': 7.645559310913086, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 06:24:03 client3-1  | {'loss': 0.1348, 'grad_norm': 1.2049379348754883, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 06:24:24 client3-1  | {'loss': 0.1418, 'grad_norm': 6.351388454437256, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 06:24:39 client3-1  | {'loss': 0.1207, 'grad_norm': 2.2459511756896973, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 06:54:13 client2-1  | {'loss': 0.4232, 'grad_norm': 7.502864360809326, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 06:54:28 client2-1  | {'loss': 0.4496, 'grad_norm': 7.001331806182861, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 06:54:43 client2-1  | {'loss': 0.668, 'grad_norm': 13.781847953796387, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 06:34:05 client1-1  | {'loss': 0.0799, 'grad_norm': 3.9425060749053955, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 06:34:20 client1-1  | {'loss': 0.0743, 'grad_norm': 1.502819299697876, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 06:34:35 client1-1  | {'loss': 0.0809, 'grad_norm': 2.0838892459869385, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 06:54:58 client2-1  | {'loss': 0.6411, 'grad_norm': 12.152669906616211, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 06:55:19 client2-1  | {'loss': 0.7761, 'grad_norm': 11.261005401611328, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 06:55:34 client2-1  | {'loss': 0.9774, 'grad_norm': 11.92074966430664, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 06:24:53 client3-1  | {'loss': 0.1134, 'grad_norm': 4.103229522705078, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 06:55:49 client2-1  | {'loss': 1.056, 'grad_norm': 13.733968734741211, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 06:34:50 client1-1  | {'loss': 0.1007, 'grad_norm': 3.8481125831604004, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 06:25:08 client3-1  | {'loss': 0.1573, 'grad_norm': 5.337866306304932, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 06:56:04 client2-1  | {'loss': 1.0638, 'grad_norm': 13.041638374328613, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 06:56:25 client2-1  | {'loss': 0.9926, 'grad_norm': 9.092253684997559, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 06:56:40 client2-1  | {'loss': 0.5293, 'grad_norm': 7.405531406402588, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 06:56:55 client2-1  | {'loss': 0.1443, 'grad_norm': 6.4371819496154785, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 06:56:55 client2-1  | {'train_runtime': 651.6207, 'train_samples_per_second': 1.228, 'train_steps_per_second': 0.614, 'train_loss': 0.30575634524226186, 'epoch': 1.0}
2025-05-22 06:57:03 client2-1  | INFO :      Sent reply
2025-05-22 06:57:53 client2-1  | INFO :      
2025-05-22 06:57:53 client2-1  | INFO :      Received: evaluate message f763202a-7a73-404c-8d70-cd8224251562
2025-05-22 06:58:07 client2-1  | {'eval_loss': 1.9689234495162964, 'eval_runtime': 11.9199, 'eval_samples_per_second': 16.779, 'eval_steps_per_second': 2.097, 'epoch': 1.0}
2025-05-22 06:58:07 client2-1  | INFO :      Sent reply
2025-05-22 06:25:23 client3-1  | {'loss': 0.1692, 'grad_norm': 4.165003299713135, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 06:25:44 client3-1  | {'loss': 0.1469, 'grad_norm': 6.813187122344971, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 06:25:59 client3-1  | {'loss': 0.1158, 'grad_norm': 3.8161239624023438, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 06:58:17 client2-1  | INFO :      
2025-05-22 06:58:17 client2-1  | INFO :      Received: train message b75e96c5-b11d-4324-b099-a8985f53ffcc
2025-05-22 06:58:21 client2-1  | {'loss': 0.0716, 'grad_norm': 1.2261263132095337, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 06:58:38 client2-1  | {'loss': 0.0805, 'grad_norm': 1.3735030889511108, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 06:35:12 client1-1  | {'loss': 0.1122, 'grad_norm': 3.820451259613037, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 06:58:53 client2-1  | {'loss': 0.0923, 'grad_norm': 1.3643063306808472, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 06:35:27 client1-1  | {'loss': 0.1, 'grad_norm': 1.7776433229446411, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 06:59:07 client2-1  | {'loss': 0.1195, 'grad_norm': 5.022498607635498, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 06:35:42 client1-1  | {'loss': 0.0986, 'grad_norm': 5.143739700317383, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 06:35:57 client1-1  | {'loss': 0.1022, 'grad_norm': 4.068648338317871, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 06:36:18 client1-1  | {'loss': 0.1254, 'grad_norm': 2.1600115299224854, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 06:36:33 client1-1  | {'loss': 0.1258, 'grad_norm': 2.007117509841919, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 06:36:48 client1-1  | {'loss': 0.1173, 'grad_norm': 4.403459072113037, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 06:37:09 client1-1  | {'loss': 0.1702, 'grad_norm': 4.275918006896973, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 06:37:24 client1-1  | {'loss': 0.1242, 'grad_norm': 4.807855606079102, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 06:26:14 client3-1  | {'loss': 0.1317, 'grad_norm': 4.173330307006836, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 06:26:35 client3-1  | {'loss': 0.15, 'grad_norm': 5.205256938934326, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 06:26:50 client3-1  | {'loss': 0.151, 'grad_norm': 6.76203727722168, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 06:37:39 client1-1  | {'loss': 0.1417, 'grad_norm': 8.028302192687988, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 06:37:54 client1-1  | {'loss': 0.1331, 'grad_norm': 4.870343208312988, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 06:38:16 client1-1  | {'loss': 0.1282, 'grad_norm': 4.087520122528076, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 06:27:05 client3-1  | {'loss': 0.1637, 'grad_norm': 5.569991588592529, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 06:27:20 client3-1  | {'loss': 0.1686, 'grad_norm': 4.045218467712402, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 06:27:34 client3-1  | {'loss': 0.193, 'grad_norm': 4.857397556304932, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 06:27:56 client3-1  | {'loss': 0.2172, 'grad_norm': 5.599689960479736, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 06:38:31 client1-1  | {'loss': 0.1667, 'grad_norm': 4.883421897888184, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 06:38:46 client1-1  | {'loss': 0.1574, 'grad_norm': 6.183576583862305, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 06:28:11 client3-1  | {'loss': 0.204, 'grad_norm': 6.792900085449219, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 06:28:26 client3-1  | {'loss': 0.245, 'grad_norm': 5.868009090423584, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 06:28:41 client3-1  | {'loss': 0.2654, 'grad_norm': 5.444089412689209, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 06:29:02 client3-1  | {'loss': 0.3488, 'grad_norm': 6.215831756591797, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 06:29:17 client3-1  | {'loss': 0.2767, 'grad_norm': 5.468923568725586, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 06:29:32 client3-1  | {'loss': 0.3241, 'grad_norm': 6.644925117492676, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 06:29:46 client3-1  | {'loss': 0.4471, 'grad_norm': 10.807637214660645, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 06:30:08 client3-1  | {'loss': 0.5266, 'grad_norm': 9.241719245910645, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 06:30:23 client3-1  | {'loss': 0.5862, 'grad_norm': 8.141477584838867, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 06:39:01 client1-1  | {'loss': 0.1568, 'grad_norm': 3.4155824184417725, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 06:30:37 client3-1  | {'loss': 0.6358, 'grad_norm': 9.604458808898926, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 06:39:22 client1-1  | {'loss': 0.176, 'grad_norm': 3.075749397277832, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 06:30:52 client3-1  | {'loss': 0.8805, 'grad_norm': 14.637904167175293, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 06:39:37 client1-1  | {'loss': 0.1528, 'grad_norm': 4.873651027679443, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 06:39:52 client1-1  | {'loss': 0.2015, 'grad_norm': 3.655130624771118, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 06:40:07 client1-1  | {'loss': 0.1853, 'grad_norm': 5.125992298126221, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 06:40:28 client1-1  | {'loss': 0.2277, 'grad_norm': 5.551694393157959, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 06:40:44 client1-1  | {'loss': 0.2043, 'grad_norm': 6.058793544769287, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 06:31:14 client3-1  | {'loss': 0.8464, 'grad_norm': 12.244933128356934, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 06:40:59 client1-1  | {'loss': 0.2757, 'grad_norm': 9.266609191894531, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 06:59:22 client2-1  | {'loss': 0.0997, 'grad_norm': 3.130093812942505, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 06:41:14 client1-1  | {'loss': 0.3148, 'grad_norm': 9.407157897949219, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 06:59:44 client2-1  | {'loss': 0.1006, 'grad_norm': 2.290367841720581, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 06:41:36 client1-1  | {'loss': 0.3459, 'grad_norm': 7.408252239227295, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 06:59:59 client2-1  | {'loss': 0.0878, 'grad_norm': 2.3241822719573975, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 06:31:28 client3-1  | {'loss': 0.8704, 'grad_norm': 13.458778381347656, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 07:00:14 client2-1  | {'loss': 0.1059, 'grad_norm': 5.482810020446777, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 06:31:43 client3-1  | {'loss': 1.1778, 'grad_norm': 13.568845748901367, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 07:00:29 client2-1  | {'loss': 0.1073, 'grad_norm': 1.9574339389801025, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 07:00:50 client2-1  | {'loss': 0.1158, 'grad_norm': 1.246671199798584, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 07:01:05 client2-1  | {'loss': 0.1133, 'grad_norm': 3.2511003017425537, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 06:41:51 client1-1  | {'loss': 0.412, 'grad_norm': 8.804993629455566, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 06:42:06 client1-1  | {'loss': 0.4195, 'grad_norm': 8.222468376159668, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 07:01:19 client2-1  | {'loss': 0.1077, 'grad_norm': 3.0226306915283203, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 06:42:21 client1-1  | {'loss': 0.5319, 'grad_norm': 9.112422943115234, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 06:42:42 client1-1  | {'loss': 0.7377, 'grad_norm': 16.51698112487793, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 06:31:58 client3-1  | {'loss': 1.1753, 'grad_norm': 13.600544929504395, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 06:42:57 client1-1  | {'loss': 0.708, 'grad_norm': 10.648018836975098, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 06:43:12 client1-1  | {'loss': 0.9003, 'grad_norm': 12.937834739685059, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 06:32:19 client3-1  | {'loss': 0.8823, 'grad_norm': 9.822354316711426, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 07:01:34 client2-1  | {'loss': 0.1224, 'grad_norm': 2.9298832416534424, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 07:01:56 client2-1  | {'loss': 0.1142, 'grad_norm': 4.085808277130127, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 07:02:11 client2-1  | {'loss': 0.116, 'grad_norm': 2.6892824172973633, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 07:02:26 client2-1  | {'loss': 0.1314, 'grad_norm': 4.260375022888184, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 07:02:41 client2-1  | {'loss': 0.1613, 'grad_norm': 3.8086800575256348, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 07:03:02 client2-1  | {'loss': 0.1216, 'grad_norm': 3.3802003860473633, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 07:03:17 client2-1  | {'loss': 0.1472, 'grad_norm': 5.2065582275390625, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 07:03:32 client2-1  | {'loss': 0.1561, 'grad_norm': 3.3909356594085693, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 07:03:47 client2-1  | {'loss': 0.171, 'grad_norm': 9.170427322387695, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 06:43:27 client1-1  | {'loss': 0.9941, 'grad_norm': 11.33905029296875, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 07:04:08 client2-1  | {'loss': 0.1578, 'grad_norm': 5.389729976654053, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 07:04:23 client2-1  | {'loss': 0.1433, 'grad_norm': 5.393271446228027, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 07:04:38 client2-1  | {'loss': 0.1711, 'grad_norm': 5.2787251472473145, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 06:32:33 client3-1  | {'loss': 0.4659, 'grad_norm': 4.229822158813477, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 06:32:43 client3-1  | {'loss': 0.1385, 'grad_norm': 5.965422630310059, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 06:32:43 client3-1  | {'train_runtime': 662.4429, 'train_samples_per_second': 1.206, 'train_steps_per_second': 0.604, 'train_loss': 0.3312928983569145, 'epoch': 1.0}
2025-05-22 06:43:48 client1-1  | {'loss': 1.034, 'grad_norm': 11.486390113830566, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 06:44:03 client1-1  | {'loss': 1.0593, 'grad_norm': 12.201170921325684, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 06:32:51 client3-1  | INFO :      Sent reply
2025-05-22 06:33:23 client3-1  | INFO :      
2025-05-22 06:33:23 client3-1  | INFO :      Received: evaluate message c1e47fd7-2607-42e8-a6b3-038d140c1f7e
2025-05-22 06:33:31 client3-1  | {'eval_loss': 2.023294687271118, 'eval_runtime': 7.0941, 'eval_samples_per_second': 28.193, 'eval_steps_per_second': 3.524, 'epoch': 1.0}
2025-05-22 06:33:31 client3-1  | INFO :      Sent reply
2025-05-22 06:33:44 client3-1  | INFO :      
2025-05-22 06:33:44 client3-1  | INFO :      Received: train message ec160222-cbda-47d9-9eae-e9db177804a7
2025-05-22 07:04:53 client2-1  | {'loss': 0.2256, 'grad_norm': 8.829963684082031, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 07:05:15 client2-1  | {'loss': 0.2242, 'grad_norm': 8.135505676269531, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 07:05:30 client2-1  | {'loss': 0.3169, 'grad_norm': 7.756574630737305, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 06:34:04 client3-1  | {'loss': 0.0621, 'grad_norm': 0.7699510455131531, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 06:34:18 client3-1  | {'loss': 0.0865, 'grad_norm': 1.0196508169174194, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 06:34:39 client3-1  | {'loss': 0.0936, 'grad_norm': 3.187278985977173, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 06:34:55 client3-1  | {'loss': 0.1125, 'grad_norm': 4.165902137756348, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 07:05:45 client2-1  | {'loss': 0.2562, 'grad_norm': 7.509163856506348, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 07:06:00 client2-1  | {'loss': 0.2718, 'grad_norm': 7.464780330657959, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 07:06:21 client2-1  | {'loss': 0.3849, 'grad_norm': 6.811270236968994, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 07:06:35 client2-1  | {'loss': 0.3881, 'grad_norm': 4.88615083694458, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 06:35:10 client3-1  | {'loss': 0.1019, 'grad_norm': 4.133751392364502, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 06:35:25 client3-1  | {'loss': 0.0982, 'grad_norm': 3.2730934619903564, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 06:35:46 client3-1  | {'loss': 0.1018, 'grad_norm': 1.6497141122817993, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 06:44:18 client1-1  | {'loss': 0.7803, 'grad_norm': 10.804056167602539, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 06:36:01 client3-1  | {'loss': 0.1152, 'grad_norm': 1.2875251770019531, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 06:44:40 client1-1  | {'loss': 0.4142, 'grad_norm': 4.796019554138184, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 06:36:16 client3-1  | {'loss': 0.1437, 'grad_norm': 4.4158616065979, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 07:06:50 client2-1  | {'loss': 0.6511, 'grad_norm': 11.123754501342773, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 07:07:12 client2-1  | {'loss': 0.6, 'grad_norm': 11.42301082611084, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 07:07:27 client2-1  | {'loss': 0.7406, 'grad_norm': 11.324339866638184, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 06:36:31 client3-1  | {'loss': 0.1431, 'grad_norm': 2.970900774002075, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 07:07:43 client2-1  | {'loss': 0.9496, 'grad_norm': 12.58951187133789, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 06:36:52 client3-1  | {'loss': 0.1118, 'grad_norm': 2.754863739013672, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 07:07:57 client2-1  | {'loss': 1.0242, 'grad_norm': 14.097946166992188, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 07:08:19 client2-1  | {'loss': 1.0517, 'grad_norm': 13.4607515335083, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 07:08:34 client2-1  | {'loss': 0.9765, 'grad_norm': 8.909745216369629, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 06:44:55 client1-1  | {'loss': 0.1356, 'grad_norm': 3.9791154861450195, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 06:44:55 client1-1  | {'train_runtime': 667.339, 'train_samples_per_second': 1.199, 'train_steps_per_second': 0.599, 'train_loss': 0.3126705911755562, 'epoch': 1.0}
2025-05-22 06:45:02 client1-1  | INFO :      Sent reply
2025-05-22 06:45:36 client1-1  | INFO :      
2025-05-22 07:08:48 client2-1  | {'loss': 0.4821, 'grad_norm': 7.881934642791748, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 07:09:03 client2-1  | {'loss': 0.122, 'grad_norm': 2.947826623916626, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 06:45:36 client1-1  | INFO :      Received: evaluate message 68ae675c-23e5-4d6b-b528-70a7eda0bf3c
2025-05-22 06:45:51 client1-1  | {'eval_loss': 2.004207134246826, 'eval_runtime': 10.8155, 'eval_samples_per_second': 18.492, 'eval_steps_per_second': 2.312, 'epoch': 1.0}
2025-05-22 07:09:03 client2-1  | {'train_runtime': 645.0122, 'train_samples_per_second': 1.24, 'train_steps_per_second': 0.62, 'train_loss': 0.28952796295285227, 'epoch': 1.0}
2025-05-22 07:09:15 client2-1  | INFO :      Sent reply
2025-05-22 07:10:07 client2-1  | INFO :      
2025-05-22 07:10:07 client2-1  | INFO :      Received: evaluate message 4dac17be-46b3-4cc6-8a51-bf36dd857783
2025-05-22 07:10:14 client2-1  | {'eval_loss': 1.993241310119629, 'eval_runtime': 4.8046, 'eval_samples_per_second': 41.627, 'eval_steps_per_second': 5.203, 'epoch': 1.0}
2025-05-22 07:10:14 client2-1  | INFO :      Sent reply
2025-05-22 07:10:26 client2-1  | INFO :      
2025-05-22 07:10:26 client2-1  | INFO :      Received: train message 27e1c2ee-1a5b-42ba-95a4-33bdf137737c
2025-05-22 06:45:51 client1-1  | INFO :      Sent reply
2025-05-22 06:46:05 client1-1  | INFO :      
2025-05-22 07:10:32 client2-1  | {'loss': 0.0662, 'grad_norm': 1.2566828727722168, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 07:10:45 client2-1  | {'loss': 0.0777, 'grad_norm': 1.333946943283081, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 07:11:00 client2-1  | {'loss': 0.104, 'grad_norm': 6.007990837097168, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 07:11:21 client2-1  | {'loss': 0.0998, 'grad_norm': 4.533570766448975, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 06:37:07 client3-1  | {'loss': 0.1486, 'grad_norm': 3.3371646404266357, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 06:37:22 client3-1  | {'loss': 0.1542, 'grad_norm': 2.569871664047241, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 07:11:36 client2-1  | {'loss': 0.0815, 'grad_norm': 1.9144160747528076, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 06:37:37 client3-1  | {'loss': 0.1457, 'grad_norm': 5.089168071746826, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 07:11:51 client2-1  | {'loss': 0.0872, 'grad_norm': 2.003298759460449, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 06:37:59 client3-1  | {'loss': 0.1156, 'grad_norm': 4.296638488769531, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 07:12:06 client2-1  | {'loss': 0.0833, 'grad_norm': 1.1640541553497314, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 06:38:14 client3-1  | {'loss': 0.1268, 'grad_norm': 3.385488748550415, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 07:12:28 client2-1  | {'loss': 0.0882, 'grad_norm': 2.686250686645508, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 07:12:42 client2-1  | {'loss': 0.0985, 'grad_norm': 3.3188464641571045, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 07:12:57 client2-1  | {'loss': 0.1148, 'grad_norm': 1.0667558908462524, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 07:13:12 client2-1  | {'loss': 0.108, 'grad_norm': 2.8711421489715576, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 06:46:05 client1-1  | INFO :      Received: train message e1dc3aa3-1e48-44de-a071-6be3d9741f26
2025-05-22 06:46:28 client1-1  | {'loss': 0.0734, 'grad_norm': 2.7415339946746826, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 07:13:27 client2-1  | {'loss': 0.1096, 'grad_norm': 7.400356292724609, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 07:13:48 client2-1  | {'loss': 0.1208, 'grad_norm': 1.8281666040420532, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 07:14:03 client2-1  | {'loss': 0.1021, 'grad_norm': 3.9638125896453857, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 07:14:18 client2-1  | {'loss': 0.1095, 'grad_norm': 2.861651659011841, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 06:46:50 client1-1  | {'loss': 0.0766, 'grad_norm': 0.8772932887077332, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 06:38:29 client3-1  | {'loss': 0.1376, 'grad_norm': 5.40131139755249, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 06:47:04 client1-1  | {'loss': 0.0852, 'grad_norm': 0.8033598065376282, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 06:38:44 client3-1  | {'loss': 0.1352, 'grad_norm': 5.669196128845215, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 07:14:39 client2-1  | {'loss': 0.1302, 'grad_norm': 3.5071892738342285, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 06:39:05 client3-1  | {'loss': 0.1609, 'grad_norm': 4.904013156890869, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 07:14:54 client2-1  | {'loss': 0.1435, 'grad_norm': 6.028521537780762, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 06:47:19 client1-1  | {'loss': 0.1014, 'grad_norm': 6.420638084411621, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 07:15:09 client2-1  | {'loss': 0.1212, 'grad_norm': 6.6251726150512695, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 07:15:24 client2-1  | {'loss': 0.125, 'grad_norm': 5.149297714233398, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 07:15:39 client2-1  | {'loss': 0.1485, 'grad_norm': 3.543884515762329, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 07:16:00 client2-1  | {'loss': 0.1469, 'grad_norm': 5.886498928070068, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 06:47:41 client1-1  | {'loss': 0.0925, 'grad_norm': 2.7926933765411377, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 06:47:56 client1-1  | {'loss': 0.0974, 'grad_norm': 3.208324909210205, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 06:48:11 client1-1  | {'loss': 0.0993, 'grad_norm': 4.383832931518555, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 06:48:26 client1-1  | {'loss': 0.1035, 'grad_norm': 3.7234325408935547, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 06:48:47 client1-1  | {'loss': 0.1112, 'grad_norm': 1.9368969202041626, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 06:49:02 client1-1  | {'loss': 0.1215, 'grad_norm': 2.2982988357543945, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 06:49:17 client1-1  | {'loss': 0.1368, 'grad_norm': 5.745497703552246, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 06:49:32 client1-1  | {'loss': 0.1399, 'grad_norm': 4.778243541717529, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 06:49:53 client1-1  | {'loss': 0.1122, 'grad_norm': 3.315983295440674, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 06:50:08 client1-1  | {'loss': 0.1304, 'grad_norm': 5.391865253448486, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 06:50:23 client1-1  | {'loss': 0.1222, 'grad_norm': 4.147049903869629, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 06:50:39 client1-1  | {'loss': 0.1403, 'grad_norm': 3.718886613845825, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 06:51:00 client1-1  | {'loss': 0.1499, 'grad_norm': 6.121119976043701, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 06:51:15 client1-1  | {'loss': 0.153, 'grad_norm': 5.304345607757568, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 06:51:30 client1-1  | {'loss': 0.1496, 'grad_norm': 4.526241302490234, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 06:51:51 client1-1  | {'loss': 0.1583, 'grad_norm': 2.3453261852264404, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 06:52:06 client1-1  | {'loss': 0.1498, 'grad_norm': 4.798218727111816, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 06:52:21 client1-1  | {'loss': 0.1852, 'grad_norm': 2.7951924800872803, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 06:39:20 client3-1  | {'loss': 0.146, 'grad_norm': 4.819221496582031, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 06:52:36 client1-1  | {'loss': 0.1591, 'grad_norm': 4.967062950134277, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 06:39:35 client3-1  | {'loss': 0.1695, 'grad_norm': 4.216567516326904, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 06:52:57 client1-1  | {'loss': 0.1916, 'grad_norm': 4.306003570556641, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 06:53:12 client1-1  | {'loss': 0.1792, 'grad_norm': 6.454172134399414, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 06:53:27 client1-1  | {'loss': 0.2341, 'grad_norm': 7.32219934463501, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 06:53:42 client1-1  | {'loss': 0.2781, 'grad_norm': 9.473636627197266, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 06:53:57 client1-1  | {'loss': 0.3194, 'grad_norm': 6.226039886474609, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 06:39:50 client3-1  | {'loss': 0.1831, 'grad_norm': 5.225793361663818, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 06:54:18 client1-1  | {'loss': 0.3685, 'grad_norm': 9.803304672241211, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 06:54:33 client1-1  | {'loss': 0.3882, 'grad_norm': 7.614130020141602, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 06:54:48 client1-1  | {'loss': 0.4922, 'grad_norm': 8.358795166015625, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 06:55:03 client1-1  | {'loss': 0.7166, 'grad_norm': 15.939777374267578, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 06:55:24 client1-1  | {'loss': 0.6674, 'grad_norm': 11.412304878234863, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 06:40:11 client3-1  | {'loss': 0.1772, 'grad_norm': 6.471144676208496, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 06:40:26 client3-1  | {'loss': 0.2241, 'grad_norm': 5.550633907318115, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 06:40:41 client3-1  | {'loss': 0.2393, 'grad_norm': 5.113531112670898, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 06:55:39 client1-1  | {'loss': 0.8571, 'grad_norm': 13.245280265808105, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 06:55:54 client1-1  | {'loss': 0.9572, 'grad_norm': 10.740671157836914, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 06:56:16 client1-1  | {'loss': 1.0242, 'grad_norm': 13.073539733886719, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 07:16:15 client2-1  | {'loss': 0.1399, 'grad_norm': 4.7973151206970215, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 06:56:31 client1-1  | {'loss': 1.025, 'grad_norm': 12.832931518554688, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 07:16:30 client2-1  | {'loss': 0.1325, 'grad_norm': 4.9217000007629395, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 07:16:51 client2-1  | {'loss': 0.1636, 'grad_norm': 4.90371561050415, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 07:17:06 client2-1  | {'loss': 0.2124, 'grad_norm': 7.685180187225342, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 07:17:21 client2-1  | {'loss': 0.2193, 'grad_norm': 7.935803413391113, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 07:17:36 client2-1  | {'loss': 0.2851, 'grad_norm': 15.186993598937988, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 06:56:46 client1-1  | {'loss': 0.7484, 'grad_norm': 11.168556213378906, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 06:57:00 client1-1  | {'loss': 0.3771, 'grad_norm': 4.372001647949219, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 06:57:12 client1-1  | {'loss': 0.1323, 'grad_norm': 5.587610244750977, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 06:40:57 client3-1  | {'loss': 0.3218, 'grad_norm': 4.263974666595459, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 06:57:12 client1-1  | {'train_runtime': 664.7303, 'train_samples_per_second': 1.203, 'train_steps_per_second': 0.602, 'train_loss': 0.2951332253217697, 'epoch': 1.0}
2025-05-22 06:57:23 client1-1  | INFO :      Sent reply
2025-05-22 07:17:51 client2-1  | {'loss': 0.2364, 'grad_norm': 6.32357120513916, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 06:57:51 client1-1  | INFO :      
2025-05-22 06:41:19 client3-1  | {'loss': 0.2496, 'grad_norm': 5.209494590759277, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 06:41:34 client3-1  | {'loss': 0.2995, 'grad_norm': 7.3509111404418945, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 07:18:12 client2-1  | {'loss': 0.2548, 'grad_norm': 8.827876091003418, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 07:18:27 client2-1  | {'loss': 0.3506, 'grad_norm': 7.367650032043457, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 07:18:42 client2-1  | {'loss': 0.3597, 'grad_norm': 5.53801965713501, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 07:19:04 client2-1  | {'loss': 0.597, 'grad_norm': 10.90183162689209, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 06:41:49 client3-1  | {'loss': 0.3968, 'grad_norm': 10.300527572631836, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 06:57:51 client1-1  | INFO :      Received: evaluate message ca89840d-5455-4239-8cbd-dec5c1906e40
2025-05-22 06:42:03 client3-1  | {'loss': 0.4838, 'grad_norm': 9.358771324157715, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 06:58:03 client1-1  | {'eval_loss': 2.0318551063537598, 'eval_runtime': 10.025, 'eval_samples_per_second': 19.95, 'eval_steps_per_second': 2.494, 'epoch': 1.0}
2025-05-22 06:58:03 client1-1  | INFO :      Sent reply
2025-05-22 06:58:20 client1-1  | INFO :      
2025-05-22 06:58:20 client1-1  | INFO :      Received: train message 0e1a5080-e082-4639-b728-129e5b6ab97a
2025-05-22 06:58:43 client1-1  | {'loss': 0.0958, 'grad_norm': 5.442732810974121, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 06:59:05 client1-1  | {'loss': 0.0721, 'grad_norm': 0.7521932125091553, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 06:59:20 client1-1  | {'loss': 0.0721, 'grad_norm': 0.7640865445137024, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 06:59:34 client1-1  | {'loss': 0.0845, 'grad_norm': 3.4376258850097656, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 06:59:56 client1-1  | {'loss': 0.0908, 'grad_norm': 3.048405408859253, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 07:19:18 client2-1  | {'loss': 0.5592, 'grad_norm': 10.306498527526855, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 07:19:33 client2-1  | {'loss': 0.7155, 'grad_norm': 13.323932647705078, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 07:19:48 client2-1  | {'loss': 0.9247, 'grad_norm': 12.573517799377441, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 07:20:09 client2-1  | {'loss': 0.976, 'grad_norm': 14.075220108032227, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 06:42:18 client3-1  | {'loss': 0.5259, 'grad_norm': 7.994049072265625, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 07:20:24 client2-1  | {'loss': 1.0022, 'grad_norm': 13.035728454589844, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 07:20:39 client2-1  | {'loss': 0.9127, 'grad_norm': 8.985203742980957, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 07:20:54 client2-1  | {'loss': 0.437, 'grad_norm': 7.402209281921387, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 07:00:11 client1-1  | {'loss': 0.0972, 'grad_norm': 1.3526142835617065, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 07:00:26 client1-1  | {'loss': 0.0893, 'grad_norm': 2.9566218852996826, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 06:42:39 client3-1  | {'loss': 0.6056, 'grad_norm': 10.638684272766113, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 06:42:54 client3-1  | {'loss': 0.8456, 'grad_norm': 13.784486770629883, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 06:43:09 client3-1  | {'loss': 0.8048, 'grad_norm': 11.328437805175781, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 07:00:41 client1-1  | {'loss': 0.0841, 'grad_norm': 2.2846667766571045, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 06:43:24 client3-1  | {'loss': 0.8291, 'grad_norm': 12.274078369140625, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 07:01:02 client1-1  | {'loss': 0.1019, 'grad_norm': 1.6259766817092896, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 06:43:46 client3-1  | {'loss': 1.1547, 'grad_norm': 15.1571626663208, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 07:21:09 client2-1  | {'loss': 0.1268, 'grad_norm': 4.237460613250732, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 07:01:17 client1-1  | {'loss': 0.1175, 'grad_norm': 4.565552711486816, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 07:01:32 client1-1  | {'loss': 0.1426, 'grad_norm': 5.267065525054932, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 06:44:00 client3-1  | {'loss': 1.1543, 'grad_norm': 15.814881324768066, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 07:01:47 client1-1  | {'loss': 0.1441, 'grad_norm': 5.069190979003906, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 06:44:15 client3-1  | {'loss': 0.8709, 'grad_norm': 10.014392852783203, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 07:02:08 client1-1  | {'loss': 0.0984, 'grad_norm': 3.798017740249634, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 07:21:09 client2-1  | {'train_runtime': 641.998, 'train_samples_per_second': 1.246, 'train_steps_per_second': 0.623, 'train_loss': 0.2717978847026825, 'epoch': 1.0}
2025-05-22 06:44:30 client3-1  | {'loss': 0.4282, 'grad_norm': 3.72912859916687, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 06:44:46 client3-1  | {'loss': 0.1181, 'grad_norm': 2.0181033611297607, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 06:44:46 client3-1  | {'train_runtime': 658.6905, 'train_samples_per_second': 1.213, 'train_steps_per_second': 0.607, 'train_loss': 0.3130776922404766, 'epoch': 1.0}
2025-05-22 06:44:58 client3-1  | INFO :      Sent reply
2025-05-22 06:45:33 client3-1  | INFO :      
2025-05-22 07:02:23 client1-1  | {'loss': 0.1155, 'grad_norm': 5.615623950958252, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 07:02:39 client1-1  | {'loss': 0.109, 'grad_norm': 3.709066152572632, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 07:03:00 client1-1  | {'loss': 0.1073, 'grad_norm': 4.6916937828063965, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 07:03:15 client1-1  | {'loss': 0.153, 'grad_norm': 6.209461212158203, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 07:03:30 client1-1  | {'loss': 0.1412, 'grad_norm': 4.7405781745910645, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 07:03:44 client1-1  | {'loss': 0.1456, 'grad_norm': 5.074603080749512, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 07:04:06 client1-1  | {'loss': 0.1452, 'grad_norm': 2.5863113403320312, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 07:04:21 client1-1  | {'loss': 0.1495, 'grad_norm': 3.9179468154907227, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 07:04:36 client1-1  | {'loss': 0.1585, 'grad_norm': 2.7359941005706787, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 06:45:33 client3-1  | INFO :      Received: evaluate message b3904f87-027d-4e64-8fae-95f8880927a7
2025-05-22 06:45:43 client3-1  | {'eval_loss': 2.0484659671783447, 'eval_runtime': 8.8785, 'eval_samples_per_second': 22.526, 'eval_steps_per_second': 2.816, 'epoch': 1.0}
2025-05-22 06:45:43 client3-1  | INFO :      Sent reply
2025-05-22 06:46:05 client3-1  | INFO :      
2025-05-22 07:04:51 client1-1  | {'loss': 0.1571, 'grad_norm': 5.6345977783203125, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 06:46:05 client3-1  | INFO :      Received: train message 02ada6fa-92bf-4599-afee-71c5bf092539
2025-05-22 07:21:22 client2-1  | INFO :      Sent reply
2025-05-22 06:46:33 client3-1  | {'loss': 0.0682, 'grad_norm': 0.8788249492645264, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 07:22:08 client2-1  | INFO :      
2025-05-22 07:05:12 client1-1  | {'loss': 0.1879, 'grad_norm': 6.161528587341309, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 07:05:27 client1-1  | {'loss': 0.1872, 'grad_norm': 6.2641215324401855, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 07:05:42 client1-1  | {'loss': 0.2289, 'grad_norm': 9.148701667785645, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 07:05:57 client1-1  | {'loss': 0.263, 'grad_norm': 10.122794151306152, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 07:22:08 client2-1  | INFO :      Received: evaluate message b6173556-e25d-406d-a7e4-cf1aa3b2ce20
2025-05-22 07:22:22 client2-1  | {'eval_loss': 2.013524055480957, 'eval_runtime': 12.3203, 'eval_samples_per_second': 16.233, 'eval_steps_per_second': 2.029, 'epoch': 1.0}
2025-05-22 07:22:22 client2-1  | INFO :      Sent reply
2025-05-22 06:46:48 client3-1  | {'loss': 0.0787, 'grad_norm': 0.824163019657135, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 07:22:37 client2-1  | INFO :      
2025-05-22 07:22:37 client2-1  | INFO :      Received: train message abae0363-7950-4e22-9e01-f8d1683abe85
2025-05-22 07:23:00 client2-1  | {'loss': 0.0654, 'grad_norm': 0.8441533446311951, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 07:23:21 client2-1  | {'loss': 0.0823, 'grad_norm': 2.000992774963379, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 07:23:36 client2-1  | {'loss': 0.0876, 'grad_norm': 0.926508903503418, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 07:23:51 client2-1  | {'loss': 0.0916, 'grad_norm': 2.8912289142608643, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 06:47:09 client3-1  | {'loss': 0.0869, 'grad_norm': 2.2573678493499756, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 06:47:24 client3-1  | {'loss': 0.1017, 'grad_norm': 3.3327150344848633, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 07:24:06 client2-1  | {'loss': 0.0965, 'grad_norm': 1.6229522228240967, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 06:47:39 client3-1  | {'loss': 0.0977, 'grad_norm': 2.1966867446899414, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 06:47:54 client3-1  | {'loss': 0.0928, 'grad_norm': 2.645946741104126, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 06:48:15 client3-1  | {'loss': 0.0914, 'grad_norm': 2.500225305557251, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 06:48:30 client3-1  | {'loss': 0.1127, 'grad_norm': 4.598086357116699, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 06:48:45 client3-1  | {'loss': 0.1119, 'grad_norm': 2.7806546688079834, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 07:06:18 client1-1  | {'loss': 0.2793, 'grad_norm': 5.031518936157227, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 07:06:33 client1-1  | {'loss': 0.3397, 'grad_norm': 9.352770805358887, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 07:06:48 client1-1  | {'loss': 0.3638, 'grad_norm': 6.211507320404053, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 07:07:03 client1-1  | {'loss': 0.4544, 'grad_norm': 6.626021862030029, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 06:49:00 client3-1  | {'loss': 0.1139, 'grad_norm': 2.262200117111206, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 06:49:21 client3-1  | {'loss': 0.1039, 'grad_norm': 2.62404727935791, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 06:49:36 client3-1  | {'loss': 0.1399, 'grad_norm': 2.7577502727508545, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 06:49:51 client3-1  | {'loss': 0.1608, 'grad_norm': 2.9384961128234863, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 07:07:25 client1-1  | {'loss': 0.6738, 'grad_norm': 15.9182767868042, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 07:07:40 client1-1  | {'loss': 0.6296, 'grad_norm': 12.297551155090332, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 07:07:55 client1-1  | {'loss': 0.8337, 'grad_norm': 17.204816818237305, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 06:50:06 client3-1  | {'loss': 0.1454, 'grad_norm': 3.9943432807922363, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 06:50:28 client3-1  | {'loss': 0.1025, 'grad_norm': 1.9183275699615479, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 06:50:43 client3-1  | {'loss': 0.1232, 'grad_norm': 4.89478063583374, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 07:08:10 client1-1  | {'loss': 0.9167, 'grad_norm': 11.794707298278809, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 07:08:31 client1-1  | {'loss': 0.9979, 'grad_norm': 11.07382869720459, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 07:08:46 client1-1  | {'loss': 0.9892, 'grad_norm': 11.911251068115234, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 07:09:00 client1-1  | {'loss': 0.7062, 'grad_norm': 10.503101348876953, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 06:50:58 client3-1  | {'loss': 0.1297, 'grad_norm': 4.553686618804932, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 06:51:13 client3-1  | {'loss': 0.1193, 'grad_norm': 3.741676092147827, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 06:51:34 client3-1  | {'loss': 0.1456, 'grad_norm': 4.424720764160156, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 07:24:21 client2-1  | {'loss': 0.082, 'grad_norm': 4.879134654998779, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 07:09:15 client1-1  | {'loss': 0.3694, 'grad_norm': 3.8488643169403076, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 07:24:43 client2-1  | {'loss': 0.0837, 'grad_norm': 1.074894905090332, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 07:09:29 client1-1  | {'loss': 0.1192, 'grad_norm': 2.9437448978424072, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 07:24:58 client2-1  | {'loss': 0.0875, 'grad_norm': 6.022839546203613, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 06:51:49 client3-1  | {'loss': 0.1353, 'grad_norm': 3.28096079826355, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 06:52:03 client3-1  | {'loss': 0.1658, 'grad_norm': 2.999375343322754, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 06:52:18 client3-1  | {'loss': 0.1719, 'grad_norm': 3.5441699028015137, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 06:52:40 client3-1  | {'loss': 0.1638, 'grad_norm': 6.357863426208496, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 06:52:55 client3-1  | {'loss': 0.1997, 'grad_norm': 5.176941394805908, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 06:53:10 client3-1  | {'loss': 0.2179, 'grad_norm': 4.797230243682861, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 07:25:13 client2-1  | {'loss': 0.105, 'grad_norm': 2.1641860008239746, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 07:25:27 client2-1  | {'loss': 0.112, 'grad_norm': 1.149096131324768, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 07:25:42 client2-1  | {'loss': 0.0938, 'grad_norm': 1.9470444917678833, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 06:53:25 client3-1  | {'loss': 0.2879, 'grad_norm': 5.241410732269287, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 06:53:40 client3-1  | {'loss': 0.2327, 'grad_norm': 5.768718719482422, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 07:26:04 client2-1  | {'loss': 0.0906, 'grad_norm': 2.8783247470855713, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 07:26:19 client2-1  | {'loss': 0.1001, 'grad_norm': 1.183703899383545, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 07:26:34 client2-1  | {'loss': 0.0967, 'grad_norm': 3.8198485374450684, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 07:26:49 client2-1  | {'loss': 0.111, 'grad_norm': 5.463479995727539, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 06:54:01 client3-1  | {'loss': 0.2813, 'grad_norm': 6.455408573150635, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 07:27:04 client2-1  | {'loss': 0.1072, 'grad_norm': 3.8985064029693604, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 06:54:16 client3-1  | {'loss': 0.3837, 'grad_norm': 12.90966796875, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 07:27:26 client2-1  | {'loss': 0.1469, 'grad_norm': 6.134184837341309, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 06:54:30 client3-1  | {'loss': 0.448, 'grad_norm': 9.427650451660156, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 07:09:29 client1-1  | {'train_runtime': 666.838, 'train_samples_per_second': 1.2, 'train_steps_per_second': 0.6, 'train_loss': 0.2803023953735828, 'epoch': 1.0}
2025-05-22 07:09:37 client1-1  | INFO :      Sent reply
2025-05-22 07:10:01 client1-1  | INFO :      
2025-05-22 07:10:01 client1-1  | INFO :      Received: evaluate message 89f7df39-f1b1-4217-8ede-46e29af40e92
2025-05-22 06:54:45 client3-1  | {'loss': 0.4993, 'grad_norm': 8.814554214477539, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 06:55:07 client3-1  | {'loss': 0.5893, 'grad_norm': 10.448225021362305, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 06:55:22 client3-1  | {'loss': 0.7956, 'grad_norm': 20.77946662902832, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 06:55:37 client3-1  | {'loss': 0.7631, 'grad_norm': 11.79336929321289, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 06:55:52 client3-1  | {'loss': 0.8207, 'grad_norm': 11.922952651977539, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 07:27:40 client2-1  | {'loss': 0.1234, 'grad_norm': 3.68690824508667, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 07:27:56 client2-1  | {'loss': 0.1279, 'grad_norm': 5.265401363372803, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 07:28:11 client2-1  | {'loss': 0.1428, 'grad_norm': 4.435470104217529, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 07:10:07 client1-1  | {'eval_loss': 2.0567004680633545, 'eval_runtime': 2.8974, 'eval_samples_per_second': 69.027, 'eval_steps_per_second': 8.628, 'epoch': 1.0}
2025-05-22 07:28:26 client2-1  | {'loss': 0.144, 'grad_norm': 5.836230754852295, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 06:56:13 client3-1  | {'loss': 1.1462, 'grad_norm': 14.59061336517334, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 06:56:28 client3-1  | {'loss': 1.1158, 'grad_norm': 15.014299392700195, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 06:56:43 client3-1  | {'loss': 0.8535, 'grad_norm': 10.567630767822266, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 07:28:48 client2-1  | {'loss': 0.1433, 'grad_norm': 4.404320240020752, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 06:56:58 client3-1  | {'loss': 0.3907, 'grad_norm': 4.368500232696533, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 07:29:03 client2-1  | {'loss': 0.1241, 'grad_norm': 3.1276931762695312, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 07:10:07 client1-1  | INFO :      Sent reply
2025-05-22 07:29:18 client2-1  | {'loss': 0.1504, 'grad_norm': 4.012713432312012, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 07:10:29 client1-1  | INFO :      
2025-05-22 06:57:14 client3-1  | {'loss': 0.1105, 'grad_norm': 1.6760404109954834, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 07:10:29 client1-1  | INFO :      Received: train message d8b3a3cc-8367-4053-b13b-37e5b3250334
2025-05-22 07:11:04 client1-1  | {'loss': 0.0786, 'grad_norm': 2.1639087200164795, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 07:11:19 client1-1  | {'loss': 0.0771, 'grad_norm': 12.8038969039917, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 07:11:34 client1-1  | {'loss': 0.0782, 'grad_norm': 1.3425695896148682, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 07:11:49 client1-1  | {'loss': 0.0991, 'grad_norm': 2.9127471446990967, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 07:12:11 client1-1  | {'loss': 0.0968, 'grad_norm': 1.6161551475524902, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 07:29:34 client2-1  | {'loss': 0.2057, 'grad_norm': 9.296791076660156, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 07:29:55 client2-1  | {'loss': 0.1988, 'grad_norm': 8.000293731689453, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 07:30:10 client2-1  | {'loss': 0.2704, 'grad_norm': 8.895686149597168, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 07:12:25 client1-1  | {'loss': 0.0954, 'grad_norm': 3.149174928665161, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 07:12:40 client1-1  | {'loss': 0.0919, 'grad_norm': 4.734501838684082, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 06:57:14 client3-1  | {'train_runtime': 662.0646, 'train_samples_per_second': 1.207, 'train_steps_per_second': 0.604, 'train_loss': 0.29747429087758065, 'epoch': 1.0}
2025-05-22 06:57:20 client3-1  | INFO :      Sent reply
2025-05-22 06:57:53 client3-1  | INFO :      
2025-05-22 07:12:55 client1-1  | {'loss': 0.0905, 'grad_norm': 4.364308834075928, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 07:13:10 client1-1  | {'loss': 0.1057, 'grad_norm': 1.3229103088378906, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 07:13:31 client1-1  | {'loss': 0.1101, 'grad_norm': 1.913000464439392, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 07:30:25 client2-1  | {'loss': 0.2142, 'grad_norm': 4.923002243041992, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 07:30:40 client2-1  | {'loss': 0.2327, 'grad_norm': 7.857441425323486, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 07:31:02 client2-1  | {'loss': 0.327, 'grad_norm': 6.57431697845459, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 06:57:53 client3-1  | INFO :      Received: evaluate message c4fac5a5-377b-4beb-b1e3-b3feb52901a9
2025-05-22 07:31:17 client2-1  | {'loss': 0.3441, 'grad_norm': 5.274596691131592, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 07:13:46 client1-1  | {'loss': 0.1139, 'grad_norm': 2.209643602371216, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 07:14:01 client1-1  | {'loss': 0.1348, 'grad_norm': 3.570319414138794, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 07:14:16 client1-1  | {'loss': 0.091, 'grad_norm': 3.6882753372192383, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 07:14:37 client1-1  | {'loss': 0.1182, 'grad_norm': 4.798910140991211, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 06:58:08 client3-1  | {'eval_loss': 2.0744993686676025, 'eval_runtime': 11.8482, 'eval_samples_per_second': 16.88, 'eval_steps_per_second': 2.11, 'epoch': 1.0}
2025-05-22 06:58:08 client3-1  | INFO :      Sent reply
2025-05-22 06:58:22 client3-1  | INFO :      
2025-05-22 06:58:22 client3-1  | INFO :      Received: train message 411591c2-1029-4bff-a2c4-4e36da00e970
2025-05-22 06:58:48 client3-1  | {'loss': 0.0621, 'grad_norm': 1.0518909692764282, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 06:59:03 client3-1  | {'loss': 0.0788, 'grad_norm': 0.9931359887123108, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 07:14:52 client1-1  | {'loss': 0.1095, 'grad_norm': 5.6204023361206055, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 06:59:24 client3-1  | {'loss': 0.0851, 'grad_norm': 1.8828370571136475, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 06:59:39 client3-1  | {'loss': 0.0953, 'grad_norm': 3.2205922603607178, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 07:00:01 client3-1  | {'loss': 0.0901, 'grad_norm': 2.808681011199951, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 07:31:32 client2-1  | {'loss': 0.5642, 'grad_norm': 9.796257019042969, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 07:31:47 client2-1  | {'loss': 0.5465, 'grad_norm': 9.730367660522461, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 07:32:09 client2-1  | {'loss': 0.6852, 'grad_norm': 12.006762504577637, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 07:32:24 client2-1  | {'loss': 0.8856, 'grad_norm': 14.071224212646484, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 07:32:39 client2-1  | {'loss': 0.9682, 'grad_norm': 12.697954177856445, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 07:33:00 client2-1  | {'loss': 0.9845, 'grad_norm': 12.171420097351074, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 07:15:07 client1-1  | {'loss': 0.1164, 'grad_norm': 3.6496191024780273, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 07:15:28 client1-1  | {'loss': 0.1377, 'grad_norm': 3.9132697582244873, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 07:33:15 client2-1  | {'loss': 0.9142, 'grad_norm': 9.84298038482666, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 07:15:43 client1-1  | {'loss': 0.1287, 'grad_norm': 3.966517448425293, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 07:33:30 client2-1  | {'loss': 0.4333, 'grad_norm': 6.059850692749023, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 07:33:45 client2-1  | {'loss': 0.1109, 'grad_norm': 2.746366024017334, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 07:33:45 client2-1  | {'train_runtime': 666.1603, 'train_samples_per_second': 1.201, 'train_steps_per_second': 0.6, 'train_loss': 0.26203365370631215, 'epoch': 1.0}
2025-05-22 07:33:58 client2-1  | INFO :      Sent reply
2025-05-22 07:34:40 client2-1  | INFO :      
2025-05-22 07:34:40 client2-1  | INFO :      Received: evaluate message aaf62d56-c376-41c3-b8da-282ae897cbda
2025-05-22 07:34:54 client2-1  | {'eval_loss': 2.042037010192871, 'eval_runtime': 10.1352, 'eval_samples_per_second': 19.733, 'eval_steps_per_second': 2.467, 'epoch': 1.0}
2025-05-22 07:15:58 client1-1  | {'loss': 0.1354, 'grad_norm': 3.5171000957489014, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 07:34:54 client2-1  | INFO :      Sent reply
2025-05-22 07:16:13 client1-1  | {'loss': 0.1369, 'grad_norm': 2.5576772689819336, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 07:16:27 client1-1  | {'loss': 0.1376, 'grad_norm': 4.020046710968018, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 07:34:59 client2-1  | INFO :      
2025-05-22 07:16:49 client1-1  | {'loss': 0.1573, 'grad_norm': 3.043065309524536, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 07:17:04 client1-1  | {'loss': 0.1397, 'grad_norm': 5.087213039398193, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 07:17:19 client1-1  | {'loss': 0.1599, 'grad_norm': 4.156978607177734, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 07:17:34 client1-1  | {'loss': 0.1794, 'grad_norm': 5.977221965789795, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 07:17:49 client1-1  | {'loss': 0.2054, 'grad_norm': 7.700526237487793, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 07:34:59 client2-1  | INFO :      Received: train message 70b3760d-5307-47e3-9aef-1bcd77b4abe8
2025-05-22 07:18:10 client1-1  | {'loss': 0.2488, 'grad_norm': 8.424904823303223, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 07:18:25 client1-1  | {'loss': 0.2821, 'grad_norm': 7.0424675941467285, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 07:00:16 client3-1  | {'loss': 0.1009, 'grad_norm': 2.230011463165283, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 07:18:39 client1-1  | {'loss': 0.3228, 'grad_norm': 8.562788963317871, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 07:18:54 client1-1  | {'loss': 0.3255, 'grad_norm': 7.089035987854004, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 07:00:31 client3-1  | {'loss': 0.0947, 'grad_norm': 3.2152440547943115, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 07:35:13 client2-1  | {'loss': 0.0623, 'grad_norm': 0.9166600704193115, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 07:35:27 client2-1  | {'loss': 0.0808, 'grad_norm': 1.3310692310333252, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 07:35:42 client2-1  | {'loss': 0.0792, 'grad_norm': 0.9476821422576904, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 07:35:58 client2-1  | {'loss': 0.1022, 'grad_norm': 6.62150764465332, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 07:19:09 client1-1  | {'loss': 0.425, 'grad_norm': 8.301833152770996, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 07:36:19 client2-1  | {'loss': 0.0856, 'grad_norm': 1.1289783716201782, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 07:19:31 client1-1  | {'loss': 0.6216, 'grad_norm': 15.238786697387695, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 07:36:34 client2-1  | {'loss': 0.0897, 'grad_norm': 1.3057879209518433, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 07:00:52 client3-1  | {'loss': 0.1001, 'grad_norm': 2.3683245182037354, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 07:01:07 client3-1  | {'loss': 0.1124, 'grad_norm': 2.5425946712493896, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 07:01:22 client3-1  | {'loss': 0.1126, 'grad_norm': 3.3260180950164795, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 07:19:46 client1-1  | {'loss': 0.6043, 'grad_norm': 10.703095436096191, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 07:20:00 client1-1  | {'loss': 0.8027, 'grad_norm': 13.393303871154785, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 07:20:22 client1-1  | {'loss': 0.8691, 'grad_norm': 9.653230667114258, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 07:01:37 client3-1  | {'loss': 0.1021, 'grad_norm': 2.929579734802246, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 07:01:58 client3-1  | {'loss': 0.1446, 'grad_norm': 5.998452186584473, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 07:36:49 client2-1  | {'loss': 0.0852, 'grad_norm': 1.5318372249603271, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 07:37:04 client2-1  | {'loss': 0.0915, 'grad_norm': 1.5315808057785034, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 07:37:25 client2-1  | {'loss': 0.0891, 'grad_norm': 2.42539381980896, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 07:02:13 client3-1  | {'loss': 0.1394, 'grad_norm': 2.499004364013672, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 07:02:28 client3-1  | {'loss': 0.1286, 'grad_norm': 5.431504249572754, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 07:02:44 client3-1  | {'loss': 0.1153, 'grad_norm': 3.901500701904297, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 07:03:05 client3-1  | {'loss': 0.1141, 'grad_norm': 3.7480478286743164, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 07:03:20 client3-1  | {'loss': 0.1143, 'grad_norm': 3.3641629219055176, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 07:03:34 client3-1  | {'loss': 0.127, 'grad_norm': 3.668400764465332, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 07:20:37 client1-1  | {'loss': 0.9561, 'grad_norm': 13.671292304992676, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 07:20:52 client1-1  | {'loss': 1.0028, 'grad_norm': 10.523880958557129, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 07:21:06 client1-1  | {'loss': 0.6976, 'grad_norm': 10.393267631530762, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 07:21:25 client1-1  | {'loss': 0.3523, 'grad_norm': 4.912082672119141, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 07:21:35 client1-1  | {'loss': 0.0998, 'grad_norm': 2.1469812393188477, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 07:21:35 client1-1  | {'train_runtime': 662.5824, 'train_samples_per_second': 1.207, 'train_steps_per_second': 0.604, 'train_loss': 0.26839301973581314, 'epoch': 1.0}
2025-05-22 07:21:40 client1-1  | INFO :      Sent reply
2025-05-22 07:22:13 client1-1  | INFO :      
2025-05-22 07:22:13 client1-1  | INFO :      Received: evaluate message 673e207d-5afc-4d8d-a90b-591b4e969844
2025-05-22 07:22:27 client1-1  | {'eval_loss': 2.081977605819702, 'eval_runtime': 10.3004, 'eval_samples_per_second': 19.417, 'eval_steps_per_second': 2.427, 'epoch': 1.0}
2025-05-22 07:22:27 client1-1  | INFO :      Sent reply
2025-05-22 07:22:36 client1-1  | INFO :      
2025-05-22 07:22:36 client1-1  | INFO :      Received: train message 98e98c95-013e-4263-b99d-9d2ae601a882
2025-05-22 07:37:40 client2-1  | {'loss': 0.0924, 'grad_norm': 2.1822447776794434, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 07:37:56 client2-1  | {'loss': 0.0929, 'grad_norm': 2.349700450897217, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 07:38:17 client2-1  | {'loss': 0.0921, 'grad_norm': 3.074568033218384, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 07:23:04 client1-1  | {'loss': 0.0858, 'grad_norm': 3.881466865539551, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 07:23:19 client1-1  | {'loss': 0.0733, 'grad_norm': 2.023775577545166, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 07:23:34 client1-1  | {'loss': 0.0746, 'grad_norm': 2.9481613636016846, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 07:38:33 client2-1  | {'loss': 0.1102, 'grad_norm': 3.105417490005493, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 07:38:47 client2-1  | {'loss': 0.1078, 'grad_norm': 2.843452215194702, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 07:39:03 client2-1  | {'loss': 0.0997, 'grad_norm': 3.257359027862549, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 07:39:24 client2-1  | {'loss': 0.1159, 'grad_norm': 3.8374385833740234, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 07:23:49 client1-1  | {'loss': 0.084, 'grad_norm': 3.236051321029663, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 07:39:39 client2-1  | {'loss': 0.1197, 'grad_norm': 3.4343910217285156, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 07:39:54 client2-1  | {'loss': 0.1052, 'grad_norm': 3.616631269454956, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 07:40:09 client2-1  | {'loss': 0.1263, 'grad_norm': 5.063717842102051, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 07:03:49 client3-1  | {'loss': 0.1409, 'grad_norm': 4.747628688812256, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 07:24:04 client1-1  | {'loss': 0.0907, 'grad_norm': 1.437869668006897, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 07:40:30 client2-1  | {'loss': 0.1319, 'grad_norm': 3.78181791305542, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 07:40:45 client2-1  | {'loss': 0.1345, 'grad_norm': 6.616753101348877, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 07:41:00 client2-1  | {'loss': 0.1308, 'grad_norm': 5.458312511444092, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 07:41:15 client2-1  | {'loss': 0.1206, 'grad_norm': 6.976205825805664, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 07:41:37 client2-1  | {'loss': 0.1339, 'grad_norm': 5.347524166107178, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 07:24:26 client1-1  | {'loss': 0.0991, 'grad_norm': 2.6890525817871094, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 07:24:41 client1-1  | {'loss': 0.0973, 'grad_norm': 6.456381320953369, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 07:41:52 client2-1  | {'loss': 0.1939, 'grad_norm': 9.45706844329834, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 07:24:56 client1-1  | {'loss': 0.0779, 'grad_norm': 4.044044017791748, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 07:42:07 client2-1  | {'loss': 0.1894, 'grad_norm': 6.780142307281494, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 07:25:11 client1-1  | {'loss': 0.0948, 'grad_norm': 1.6378334760665894, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 07:25:32 client1-1  | {'loss': 0.1075, 'grad_norm': 1.9408576488494873, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 07:25:47 client1-1  | {'loss': 0.1136, 'grad_norm': 4.026901721954346, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 07:42:28 client2-1  | {'loss': 0.2427, 'grad_norm': 8.232633590698242, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 07:26:02 client1-1  | {'loss': 0.1163, 'grad_norm': 3.660167932510376, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 07:42:43 client2-1  | {'loss': 0.1922, 'grad_norm': 5.057186126708984, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 07:26:17 client1-1  | {'loss': 0.0865, 'grad_norm': 1.8394830226898193, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 07:04:11 client3-1  | {'loss': 0.1249, 'grad_norm': 4.927654266357422, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 07:42:58 client2-1  | {'loss': 0.2064, 'grad_norm': 7.272641658782959, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 07:04:25 client3-1  | {'loss': 0.1585, 'grad_norm': 4.729084014892578, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 07:43:13 client2-1  | {'loss': 0.2981, 'grad_norm': 5.276307106018066, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 07:04:40 client3-1  | {'loss': 0.1568, 'grad_norm': 4.1197829246521, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 07:04:55 client3-1  | {'loss': 0.1555, 'grad_norm': 5.603517055511475, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 07:05:17 client3-1  | {'loss': 0.2142, 'grad_norm': 4.6212286949157715, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 07:26:39 client1-1  | {'loss': 0.1035, 'grad_norm': 4.726457595825195, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 07:43:34 client2-1  | {'loss': 0.3137, 'grad_norm': 4.900173187255859, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 07:43:49 client2-1  | {'loss': 0.51, 'grad_norm': 10.274613380432129, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 07:44:04 client2-1  | {'loss': 0.5016, 'grad_norm': 11.634087562561035, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 07:26:54 client1-1  | {'loss': 0.1013, 'grad_norm': 3.219398260116577, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 07:27:09 client1-1  | {'loss': 0.1015, 'grad_norm': 3.2294235229492188, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 07:05:32 client3-1  | {'loss': 0.2099, 'grad_norm': 4.716984272003174, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 07:44:19 client2-1  | {'loss': 0.6539, 'grad_norm': 12.444652557373047, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 07:05:47 client3-1  | {'loss': 0.2682, 'grad_norm': 5.264278888702393, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 07:44:40 client2-1  | {'loss': 0.8656, 'grad_norm': 14.075194358825684, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 07:44:55 client2-1  | {'loss': 0.9567, 'grad_norm': 12.959992408752441, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 07:45:10 client2-1  | {'loss': 0.9728, 'grad_norm': 12.889115333557129, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 07:45:25 client2-1  | {'loss': 0.8846, 'grad_norm': 8.696545600891113, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 07:45:46 client2-1  | {'loss': 0.4035, 'grad_norm': 6.406924724578857, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 07:46:01 client2-1  | {'loss': 0.1068, 'grad_norm': 2.434995412826538, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 07:46:01 client2-1  | {'train_runtime': 660.9603, 'train_samples_per_second': 1.21, 'train_steps_per_second': 0.605, 'train_loss': 0.2492756086587906, 'epoch': 1.0}
2025-05-22 07:46:07 client2-1  | INFO :      Sent reply
2025-05-22 07:46:53 client2-1  | INFO :      
2025-05-22 07:46:53 client2-1  | INFO :      Received: evaluate message e18716bf-156d-44dd-a137-21a0e87bda2c
2025-05-22 07:06:02 client3-1  | {'loss': 0.2222, 'grad_norm': 5.715450286865234, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 07:06:23 client3-1  | {'loss': 0.2549, 'grad_norm': 5.1868510246276855, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 07:47:06 client2-1  | {'eval_loss': 2.064049482345581, 'eval_runtime': 11.2688, 'eval_samples_per_second': 17.748, 'eval_steps_per_second': 2.219, 'epoch': 1.0}
2025-05-22 07:47:06 client2-1  | INFO :      Sent reply
2025-05-22 07:47:14 client2-1  | INFO :      
2025-05-22 07:47:14 client2-1  | INFO :      Received: train message 829404b6-3423-48f5-8775-241059035acc
2025-05-22 07:47:41 client2-1  | {'loss': 0.0688, 'grad_norm': 3.03823184967041, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 07:48:02 client2-1  | {'loss': 0.0841, 'grad_norm': 1.4910974502563477, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 07:48:17 client2-1  | {'loss': 0.0788, 'grad_norm': 1.5540448427200317, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 07:48:32 client2-1  | {'loss': 0.0908, 'grad_norm': 2.658198595046997, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 07:48:54 client2-1  | {'loss': 0.0777, 'grad_norm': 1.1474707126617432, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 07:49:09 client2-1  | {'loss': 0.0835, 'grad_norm': 1.2151861190795898, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 07:27:30 client1-1  | {'loss': 0.1137, 'grad_norm': 2.3358092308044434, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 07:27:45 client1-1  | {'loss': 0.1481, 'grad_norm': 4.66009521484375, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 07:28:01 client1-1  | {'loss': 0.1373, 'grad_norm': 4.933675289154053, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 07:49:24 client2-1  | {'loss': 0.0851, 'grad_norm': 2.221437931060791, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 07:49:39 client2-1  | {'loss': 0.0811, 'grad_norm': 2.638382911682129, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 07:50:00 client2-1  | {'loss': 0.0944, 'grad_norm': 1.6063705682754517, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 07:28:16 client1-1  | {'loss': 0.1574, 'grad_norm': 2.5760796070098877, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 07:28:37 client1-1  | {'loss': 0.1327, 'grad_norm': 4.702146530151367, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 07:28:53 client1-1  | {'loss': 0.1427, 'grad_norm': 3.2880516052246094, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 07:29:08 client1-1  | {'loss': 0.1412, 'grad_norm': 6.356640815734863, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 07:50:15 client2-1  | {'loss': 0.0937, 'grad_norm': 1.9914103746414185, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 07:50:30 client2-1  | {'loss': 0.0959, 'grad_norm': 3.181442975997925, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 07:29:23 client1-1  | {'loss': 0.1614, 'grad_norm': 3.874696969985962, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 07:29:39 client1-1  | {'loss': 0.1618, 'grad_norm': 4.739041328430176, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 07:30:00 client1-1  | {'loss': 0.1962, 'grad_norm': 7.396239757537842, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 07:30:15 client1-1  | {'loss': 0.2202, 'grad_norm': 8.530735969543457, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 07:50:45 client2-1  | {'loss': 0.0976, 'grad_norm': 4.048214435577393, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 07:30:31 client1-1  | {'loss': 0.2462, 'grad_norm': 4.733026504516602, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 07:51:06 client2-1  | {'loss': 0.1098, 'grad_norm': 3.300510883331299, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 07:51:21 client2-1  | {'loss': 0.1037, 'grad_norm': 6.8456711769104, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 07:51:37 client2-1  | {'loss': 0.1074, 'grad_norm': 5.039357662200928, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 07:06:38 client3-1  | {'loss': 0.3418, 'grad_norm': 9.852235794067383, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 07:51:52 client2-1  | {'loss': 0.1031, 'grad_norm': 3.6042280197143555, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 07:52:13 client2-1  | {'loss': 0.1163, 'grad_norm': 5.505136013031006, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 07:52:28 client2-1  | {'loss': 0.1106, 'grad_norm': 2.1235315799713135, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 07:52:43 client2-1  | {'loss': 0.1355, 'grad_norm': 4.659862995147705, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 07:52:58 client2-1  | {'loss': 0.136, 'grad_norm': 3.3867292404174805, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 07:53:19 client2-1  | {'loss': 0.1349, 'grad_norm': 4.228806972503662, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 07:06:52 client3-1  | {'loss': 0.4144, 'grad_norm': 7.55625581741333, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 07:53:34 client2-1  | {'loss': 0.1289, 'grad_norm': 4.546628952026367, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 07:53:49 client2-1  | {'loss': 0.1173, 'grad_norm': 2.6715359687805176, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 07:54:05 client2-1  | {'loss': 0.1348, 'grad_norm': 4.624117374420166, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 07:54:26 client2-1  | {'loss': 0.1714, 'grad_norm': 7.582322597503662, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 07:54:41 client2-1  | {'loss': 0.1606, 'grad_norm': 8.564263343811035, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 07:54:56 client2-1  | {'loss': 0.2353, 'grad_norm': 6.907037258148193, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 07:55:11 client2-1  | {'loss': 0.1935, 'grad_norm': 6.693508625030518, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 07:55:32 client2-1  | {'loss': 0.2198, 'grad_norm': 7.557880401611328, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 07:55:47 client2-1  | {'loss': 0.2716, 'grad_norm': 5.458315849304199, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 07:56:02 client2-1  | {'loss': 0.297, 'grad_norm': 4.863077640533447, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 07:07:08 client3-1  | {'loss': 0.447, 'grad_norm': 8.088006019592285, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 07:07:23 client3-1  | {'loss': 0.5235, 'grad_norm': 9.137057304382324, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 07:07:44 client3-1  | {'loss': 0.7722, 'grad_norm': 14.270865440368652, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 07:30:52 client1-1  | {'loss': 0.2906, 'grad_norm': 9.399985313415527, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 07:31:07 client1-1  | {'loss': 0.2903, 'grad_norm': 7.24807071685791, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 07:31:22 client1-1  | {'loss': 0.3975, 'grad_norm': 6.683894634246826, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 07:31:37 client1-1  | {'loss': 0.5881, 'grad_norm': 14.120477676391602, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 07:07:59 client3-1  | {'loss': 0.7393, 'grad_norm': 11.645800590515137, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 07:08:14 client3-1  | {'loss': 0.7799, 'grad_norm': 12.627436637878418, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 07:08:29 client3-1  | {'loss': 1.0998, 'grad_norm': 13.272078514099121, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 07:56:17 client2-1  | {'loss': 0.4856, 'grad_norm': 9.558428764343262, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 07:08:50 client3-1  | {'loss': 1.1217, 'grad_norm': 15.531597137451172, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 07:09:05 client3-1  | {'loss': 0.798, 'grad_norm': 9.924776077270508, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 07:09:17 client3-1  | {'loss': 0.3822, 'grad_norm': 4.035944938659668, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 07:09:28 client3-1  | {'loss': 0.1047, 'grad_norm': 1.5977593660354614, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 07:56:38 client2-1  | {'loss': 0.4741, 'grad_norm': 11.392525672912598, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 07:09:28 client3-1  | {'train_runtime': 661.1411, 'train_samples_per_second': 1.209, 'train_steps_per_second': 0.605, 'train_loss': 0.2836980517208576, 'epoch': 1.0}
2025-05-22 07:56:53 client2-1  | {'loss': 0.658, 'grad_norm': 11.390883445739746, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 07:09:38 client3-1  | INFO :      Sent reply
2025-05-22 07:10:10 client3-1  | INFO :      
2025-05-22 07:10:10 client3-1  | INFO :      Received: evaluate message 743093eb-cdd9-49e1-8351-00f7f2125288
2025-05-22 07:10:17 client3-1  | {'eval_loss': 2.0963122844696045, 'eval_runtime': 4.6146, 'eval_samples_per_second': 43.341, 'eval_steps_per_second': 5.418, 'epoch': 1.0}
2025-05-22 07:10:17 client3-1  | INFO :      Sent reply
2025-05-22 07:10:30 client3-1  | INFO :      
2025-05-22 07:10:30 client3-1  | INFO :      Received: train message eb55cd11-3ec8-4da1-af9a-63c144b11edd
2025-05-22 07:31:59 client1-1  | {'loss': 0.5771, 'grad_norm': 11.365909576416016, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 07:32:14 client1-1  | {'loss': 0.7651, 'grad_norm': 13.66795539855957, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 07:32:29 client1-1  | {'loss': 0.8668, 'grad_norm': 11.18563461303711, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 07:57:08 client2-1  | {'loss': 0.8162, 'grad_norm': 14.136236190795898, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 07:32:44 client1-1  | {'loss': 0.9369, 'grad_norm': 13.5095796585083, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 07:10:55 client3-1  | {'loss': 0.0717, 'grad_norm': 0.8525540828704834, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 07:11:10 client3-1  | {'loss': 0.0713, 'grad_norm': 0.7804903984069824, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 07:11:31 client3-1  | {'loss': 0.0922, 'grad_norm': 2.6082825660705566, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 07:11:46 client3-1  | {'loss': 0.0902, 'grad_norm': 3.3757104873657227, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 07:12:01 client3-1  | {'loss': 0.0911, 'grad_norm': 1.8755425214767456, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 07:57:23 client2-1  | {'loss': 0.9039, 'grad_norm': 12.214133262634277, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 07:12:23 client3-1  | {'loss': 0.0858, 'grad_norm': 5.986299991607666, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 07:57:44 client2-1  | {'loss': 0.9332, 'grad_norm': 12.361834526062012, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 07:12:37 client3-1  | {'loss': 0.0851, 'grad_norm': 1.54244065284729, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 07:12:52 client3-1  | {'loss': 0.1047, 'grad_norm': 3.1436233520507812, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 07:13:07 client3-1  | {'loss': 0.113, 'grad_norm': 3.5798895359039307, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 07:32:58 client1-1  | {'loss': 0.9585, 'grad_norm': 11.237947463989258, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 07:33:20 client1-1  | {'loss': 0.6617, 'grad_norm': 10.847888946533203, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 07:33:35 client1-1  | {'loss': 0.312, 'grad_norm': 3.4808506965637207, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 07:13:23 client3-1  | {'loss': 0.1121, 'grad_norm': 3.9172353744506836, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 07:13:44 client3-1  | {'loss': 0.0997, 'grad_norm': 6.788630485534668, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 07:13:58 client3-1  | {'loss': 0.1176, 'grad_norm': 2.5363776683807373, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 07:57:59 client2-1  | {'loss': 0.8527, 'grad_norm': 8.599742889404297, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 07:58:15 client2-1  | {'loss': 0.3865, 'grad_norm': 7.877455234527588, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 07:58:29 client2-1  | {'loss': 0.0995, 'grad_norm': 4.337421417236328, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 07:58:29 client2-1  | {'train_runtime': 672.7474, 'train_samples_per_second': 1.189, 'train_steps_per_second': 0.595, 'train_loss': 0.24071417346596719, 'epoch': 1.0}
2025-05-22 07:14:13 client3-1  | {'loss': 0.1306, 'grad_norm': 2.8248181343078613, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 07:14:28 client3-1  | {'loss': 0.1285, 'grad_norm': 7.808896064758301, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 07:33:50 client1-1  | {'loss': 0.1143, 'grad_norm': 3.248556613922119, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 07:14:49 client3-1  | {'loss': 0.109, 'grad_norm': 3.2250781059265137, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 07:15:04 client3-1  | {'loss': 0.1079, 'grad_norm': 3.5542831420898438, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 07:15:19 client3-1  | {'loss': 0.1433, 'grad_norm': 4.076724529266357, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 07:58:34 client2-1  | INFO :      Sent reply
2025-05-22 07:59:10 client2-1  | INFO :      
2025-05-22 07:15:40 client3-1  | {'loss': 0.1047, 'grad_norm': 4.667629718780518, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 07:59:10 client2-1  | INFO :      Received: evaluate message e91611ef-da6a-418d-b743-02239e018f77
2025-05-22 07:59:32 client2-1  | INFO :      Sent reply
2025-05-22 07:59:32 client2-1  | {'eval_loss': 2.079895257949829, 'eval_runtime': 17.6403, 'eval_samples_per_second': 11.338, 'eval_steps_per_second': 1.417, 'epoch': 1.0}
2025-05-22 07:59:33 client2-1  | INFO :      
2025-05-22 07:59:33 client2-1  | INFO :      Received: reconnect message adc52c2b-4c5d-4102-b47c-2c58fe8f74a3
2025-05-22 07:33:50 client1-1  | {'train_runtime': 673.0094, 'train_samples_per_second': 1.189, 'train_steps_per_second': 0.594, 'train_loss': 0.2556374804675579, 'epoch': 1.0}
2025-05-22 07:33:57 client1-1  | INFO :      Sent reply
2025-05-22 07:34:36 client1-1  | INFO :      
2025-05-22 07:34:36 client1-1  | INFO :      Received: evaluate message d54d14ea-2952-46c1-85b6-a0212233fb9a
2025-05-22 07:34:51 client1-1  | {'eval_loss': 2.1027040481567383, 'eval_runtime': 12.1289, 'eval_samples_per_second': 16.49, 'eval_steps_per_second': 2.061, 'epoch': 1.0}
2025-05-22 07:59:33 client2-1  | INFO :      Disconnect and shut down
2025-05-22 07:15:55 client3-1  | {'loss': 0.1267, 'grad_norm': 5.011608600616455, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 07:16:10 client3-1  | {'loss': 0.1321, 'grad_norm': 3.525444984436035, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 07:16:25 client3-1  | {'loss': 0.1301, 'grad_norm': 4.466250896453857, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 07:16:40 client3-1  | {'loss': 0.1459, 'grad_norm': 3.1361467838287354, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 07:34:51 client1-1  | INFO :      Sent reply
2025-05-22 07:35:01 client1-1  | INFO :      
2025-05-22 07:35:01 client1-1  | INFO :      Received: train message 4f91d137-6139-4824-9181-9aed45599482
2025-05-22 07:35:32 client1-1  | {'loss': 0.0848, 'grad_norm': 3.745859384536743, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 07:17:01 client3-1  | {'loss': 0.1636, 'grad_norm': 5.355643272399902, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 07:17:16 client3-1  | {'loss': 0.18, 'grad_norm': 4.884034633636475, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 07:17:31 client3-1  | {'loss': 0.2074, 'grad_norm': 4.154361248016357, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 07:17:46 client3-1  | {'loss': 0.2448, 'grad_norm': 5.0093183517456055, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 07:35:47 client1-1  | {'loss': 0.0738, 'grad_norm': 2.2994871139526367, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 07:36:02 client1-1  | {'loss': 0.073, 'grad_norm': 3.004747152328491, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 07:18:08 client3-1  | {'loss': 0.1985, 'grad_norm': 4.601447582244873, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 07:36:18 client1-1  | {'loss': 0.0865, 'grad_norm': 1.7943590879440308, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 07:36:39 client1-1  | {'loss': 0.101, 'grad_norm': 2.151110887527466, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 07:36:54 client1-1  | {'loss': 0.0894, 'grad_norm': 2.0839054584503174, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 07:18:23 client3-1  | {'loss': 0.219, 'grad_norm': 3.8604915142059326, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 07:37:09 client1-1  | {'loss': 0.0833, 'grad_norm': 2.8521838188171387, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 07:18:37 client3-1  | {'loss': 0.3048, 'grad_norm': 8.411504745483398, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 07:37:30 client1-1  | {'loss': 0.0764, 'grad_norm': 3.6801962852478027, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 07:37:45 client1-1  | {'loss': 0.0978, 'grad_norm': 2.5693957805633545, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 07:38:00 client1-1  | {'loss': 0.1077, 'grad_norm': 2.4364864826202393, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 07:38:15 client1-1  | {'loss': 0.1235, 'grad_norm': 4.329591751098633, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 07:38:31 client1-1  | {'loss': 0.1564, 'grad_norm': 4.230819225311279, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 07:38:52 client1-1  | {'loss': 0.0917, 'grad_norm': 2.355760097503662, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 07:18:58 client3-1  | {'loss': 0.4023, 'grad_norm': 8.274662971496582, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 07:19:14 client3-1  | {'loss': 0.436, 'grad_norm': 8.545401573181152, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 07:19:29 client3-1  | {'loss': 0.514, 'grad_norm': 10.239995002746582, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 07:19:44 client3-1  | {'loss': 0.7391, 'grad_norm': 13.49683952331543, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 07:39:07 client1-1  | {'loss': 0.0945, 'grad_norm': 4.2306036949157715, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 07:20:05 client3-1  | {'loss': 0.7174, 'grad_norm': 11.409329414367676, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 07:20:20 client3-1  | {'loss': 0.7575, 'grad_norm': 12.534031867980957, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 07:20:35 client3-1  | {'loss': 1.0725, 'grad_norm': 14.910455703735352, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 07:20:56 client3-1  | {'loss': 1.0933, 'grad_norm': 14.792901039123535, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 07:21:11 client3-1  | {'loss': 0.7844, 'grad_norm': 8.793769836425781, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 07:39:22 client1-1  | {'loss': 0.1109, 'grad_norm': 2.5750880241394043, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 07:39:37 client1-1  | {'loss': 0.1002, 'grad_norm': 3.135392665863037, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 07:39:59 client1-1  | {'loss': 0.1345, 'grad_norm': 4.673603057861328, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 07:21:23 client3-1  | {'loss': 0.3504, 'grad_norm': 3.854869842529297, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 07:21:33 client3-1  | {'loss': 0.1019, 'grad_norm': 1.575938105583191, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 07:21:33 client3-1  | {'train_runtime': 658.2025, 'train_samples_per_second': 1.214, 'train_steps_per_second': 0.608, 'train_loss': 0.27200026392936705, 'epoch': 1.0}
2025-05-22 07:21:40 client3-1  | INFO :      Sent reply
2025-05-22 07:40:14 client1-1  | {'loss': 0.1286, 'grad_norm': 5.89917516708374, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 07:40:29 client1-1  | {'loss': 0.1328, 'grad_norm': 4.787228107452393, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 07:40:43 client1-1  | {'loss': 0.145, 'grad_norm': 2.355438470840454, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 07:22:11 client3-1  | INFO :      
2025-05-22 07:22:11 client3-1  | INFO :      Received: evaluate message f3613476-cc11-4263-92c0-0d382d0455e7
2025-05-22 07:22:24 client3-1  | INFO :      Sent reply
2025-05-22 07:22:24 client3-1  | {'eval_loss': 2.1238291263580322, 'eval_runtime': 11.9407, 'eval_samples_per_second': 16.749, 'eval_steps_per_second': 2.094, 'epoch': 1.0}
2025-05-22 07:22:37 client3-1  | INFO :      
2025-05-22 07:22:37 client3-1  | INFO :      Received: train message a02b1514-7426-42c3-b365-57ebdd24fc9d
2025-05-22 07:23:02 client3-1  | {'loss': 0.0664, 'grad_norm': 0.9426733255386353, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 07:23:17 client3-1  | {'loss': 0.0815, 'grad_norm': 0.8898429274559021, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 07:23:39 client3-1  | {'loss': 0.0848, 'grad_norm': 2.2742087841033936, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 07:23:54 client3-1  | {'loss': 0.097, 'grad_norm': 7.457859516143799, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 07:24:09 client3-1  | {'loss': 0.0924, 'grad_norm': 1.8495930433273315, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 07:24:24 client3-1  | {'loss': 0.0957, 'grad_norm': 2.3235552310943604, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 07:41:05 client1-1  | {'loss': 0.1363, 'grad_norm': 5.207432746887207, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 07:24:45 client3-1  | {'loss': 0.092, 'grad_norm': 1.7926992177963257, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 07:41:20 client1-1  | {'loss': 0.1467, 'grad_norm': 2.1625750064849854, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 07:41:35 client1-1  | {'loss': 0.1505, 'grad_norm': 3.752868413925171, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 07:41:50 client1-1  | {'loss': 0.1455, 'grad_norm': 6.090478420257568, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 07:25:00 client3-1  | {'loss': 0.1026, 'grad_norm': 2.639763593673706, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 07:25:15 client3-1  | {'loss': 0.118, 'grad_norm': 4.693831920623779, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 07:25:30 client3-1  | {'loss': 0.1247, 'grad_norm': 4.917109489440918, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 07:25:51 client3-1  | {'loss': 0.0986, 'grad_norm': 3.2647764682769775, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 07:26:06 client3-1  | {'loss': 0.103, 'grad_norm': 4.821170806884766, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 07:26:22 client3-1  | {'loss': 0.1279, 'grad_norm': 3.4526357650756836, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 07:26:37 client3-1  | {'loss': 0.1214, 'grad_norm': 6.059462070465088, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 07:26:59 client3-1  | {'loss': 0.0997, 'grad_norm': 1.969813585281372, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 07:27:14 client3-1  | {'loss': 0.1062, 'grad_norm': 4.890697956085205, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 07:42:12 client1-1  | {'loss': 0.1435, 'grad_norm': 4.989233016967773, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 07:42:26 client1-1  | {'loss': 0.1825, 'grad_norm': 5.775928497314453, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 07:27:29 client3-1  | {'loss': 0.113, 'grad_norm': 3.9037466049194336, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 07:27:43 client3-1  | {'loss': 0.1129, 'grad_norm': 5.661653995513916, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 07:42:41 client1-1  | {'loss': 0.2149, 'grad_norm': 8.265088081359863, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 07:28:05 client3-1  | {'loss': 0.147, 'grad_norm': 6.291367053985596, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 07:28:20 client3-1  | {'loss': 0.1357, 'grad_norm': 3.920250654220581, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 07:42:56 client1-1  | {'loss': 0.2281, 'grad_norm': 4.42309045791626, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 07:43:17 client1-1  | {'loss': 0.2799, 'grad_norm': 9.04538345336914, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 07:43:32 client1-1  | {'loss': 0.2774, 'grad_norm': 6.13120174407959, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 07:43:47 client1-1  | {'loss': 0.3688, 'grad_norm': 7.028044700622559, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 07:44:09 client1-1  | {'loss': 0.5631, 'grad_norm': 13.858957290649414, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 07:44:24 client1-1  | {'loss': 0.5518, 'grad_norm': 10.045926094055176, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 07:44:39 client1-1  | {'loss': 0.7266, 'grad_norm': 13.168835639953613, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 07:44:53 client1-1  | {'loss': 0.8069, 'grad_norm': 11.315131187438965, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 07:45:15 client1-1  | {'loss': 0.9438, 'grad_norm': 13.624375343322754, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 07:45:30 client1-1  | {'loss': 0.9666, 'grad_norm': 14.495441436767578, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 07:28:35 client3-1  | {'loss': 0.1415, 'grad_norm': 5.793766498565674, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 07:28:51 client3-1  | {'loss': 0.1421, 'grad_norm': 5.253199577331543, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 07:29:06 client3-1  | {'loss': 0.1427, 'grad_norm': 5.505960941314697, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 07:45:44 client1-1  | {'loss': 0.6483, 'grad_norm': 10.850749969482422, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 07:45:59 client1-1  | {'loss': 0.2933, 'grad_norm': 4.059253692626953, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 07:46:15 client1-1  | {'loss': 0.0989, 'grad_norm': 1.3319600820541382, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 07:29:28 client3-1  | {'loss': 0.1775, 'grad_norm': 4.434099197387695, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 07:29:43 client3-1  | {'loss': 0.1874, 'grad_norm': 2.663037061691284, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 07:29:58 client3-1  | {'loss': 0.2337, 'grad_norm': 4.883182525634766, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 07:30:13 client3-1  | {'loss': 0.1782, 'grad_norm': 5.104021072387695, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 07:30:28 client3-1  | {'loss': 0.2255, 'grad_norm': 4.134666442871094, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 07:46:15 client1-1  | {'train_runtime': 671.9252, 'train_samples_per_second': 1.191, 'train_steps_per_second': 0.595, 'train_loss': 0.24912528306245804, 'epoch': 1.0}
2025-05-22 07:30:50 client3-1  | {'loss': 0.312, 'grad_norm': 8.799809455871582, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 07:46:20 client1-1  | INFO :      Sent reply
2025-05-22 07:46:46 client1-1  | INFO :      
2025-05-22 07:31:05 client3-1  | {'loss': 0.3583, 'grad_norm': 8.794312477111816, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 07:31:20 client3-1  | {'loss': 0.3951, 'grad_norm': 7.77509880065918, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 07:31:35 client3-1  | {'loss': 0.4961, 'grad_norm': 9.414205551147461, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 07:46:46 client1-1  | INFO :      Received: evaluate message 47bde569-1eab-42b5-a70d-2914de587f92
2025-05-22 07:46:49 client1-1  | {'eval_loss': 2.1238274574279785, 'eval_runtime': 2.9145, 'eval_samples_per_second': 68.622, 'eval_steps_per_second': 8.578, 'epoch': 1.0}
2025-05-22 07:46:49 client1-1  | INFO :      Sent reply
2025-05-22 07:47:14 client1-1  | INFO :      
2025-05-22 07:31:56 client3-1  | {'loss': 0.7056, 'grad_norm': 13.984588623046875, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 07:32:12 client3-1  | {'loss': 0.6891, 'grad_norm': 12.255769729614258, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 07:47:14 client1-1  | INFO :      Received: train message 13db6dfc-56a3-49f3-9a67-871a43bc3a06
2025-05-22 07:47:36 client1-1  | {'loss': 0.0739, 'grad_norm': 1.5385037660598755, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 07:47:51 client1-1  | {'loss': 0.0669, 'grad_norm': 1.0013853311538696, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 07:48:12 client1-1  | {'loss': 0.0713, 'grad_norm': 1.5133253335952759, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 07:48:27 client1-1  | {'loss': 0.0844, 'grad_norm': 1.7946126461029053, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 07:48:42 client1-1  | {'loss': 0.0809, 'grad_norm': 1.0329827070236206, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 07:48:57 client1-1  | {'loss': 0.0793, 'grad_norm': 0.978653073310852, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 07:32:26 client3-1  | {'loss': 0.7474, 'grad_norm': 12.448272705078125, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 07:32:41 client3-1  | {'loss': 1.0666, 'grad_norm': 13.534666061401367, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 07:33:03 client3-1  | {'loss': 1.0521, 'grad_norm': 13.360203742980957, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 07:49:19 client1-1  | {'loss': 0.0679, 'grad_norm': 4.382340908050537, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 07:49:34 client1-1  | {'loss': 0.0773, 'grad_norm': 2.102363348007202, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 07:33:18 client3-1  | {'loss': 0.7702, 'grad_norm': 10.072970390319824, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 07:33:33 client3-1  | {'loss': 0.3189, 'grad_norm': 3.5437228679656982, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 07:33:47 client3-1  | {'loss': 0.0951, 'grad_norm': 4.116556167602539, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 07:33:47 client3-1  | {'train_runtime': 667.0174, 'train_samples_per_second': 1.198, 'train_steps_per_second': 0.6, 'train_loss': 0.26388434663414956, 'epoch': 1.0}
2025-05-22 07:33:53 client3-1  | INFO :      Sent reply
2025-05-22 07:34:37 client3-1  | INFO :      
2025-05-22 07:34:37 client3-1  | INFO :      Received: evaluate message a55dafa0-c31d-4b61-88a0-aa157307f537
2025-05-22 07:34:50 client3-1  | INFO :      Sent reply
2025-05-22 07:34:50 client3-1  | {'eval_loss': 2.1482903957366943, 'eval_runtime': 12.0585, 'eval_samples_per_second': 16.586, 'eval_steps_per_second': 2.073, 'epoch': 1.0}
2025-05-22 07:35:02 client3-1  | INFO :      
2025-05-22 07:35:02 client3-1  | INFO :      Received: train message cc62761b-9e91-4854-ba95-261e6f62b583
2025-05-22 07:35:29 client3-1  | {'loss': 0.0686, 'grad_norm': 1.2565730810165405, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 07:49:48 client1-1  | {'loss': 0.0994, 'grad_norm': 3.445725679397583, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 07:35:44 client3-1  | {'loss': 0.0836, 'grad_norm': 1.04780113697052, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 07:36:00 client3-1  | {'loss': 0.0813, 'grad_norm': 3.5474600791931152, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 07:36:15 client3-1  | {'loss': 0.0821, 'grad_norm': 2.068312644958496, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 07:50:03 client1-1  | {'loss': 0.1038, 'grad_norm': 3.430140733718872, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 07:50:24 client1-1  | {'loss': 0.101, 'grad_norm': 2.5792486667633057, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 07:50:39 client1-1  | {'loss': 0.1123, 'grad_norm': 3.2411720752716064, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 07:50:54 client1-1  | {'loss': 0.0912, 'grad_norm': 3.1045122146606445, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 07:51:09 client1-1  | {'loss': 0.1023, 'grad_norm': 4.538293361663818, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 07:51:31 client1-1  | {'loss': 0.1112, 'grad_norm': 4.711655139923096, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 07:51:46 client1-1  | {'loss': 0.1133, 'grad_norm': 5.410832405090332, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 07:52:01 client1-1  | {'loss': 0.1245, 'grad_norm': 2.8390374183654785, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 07:52:16 client1-1  | {'loss': 0.1436, 'grad_norm': 4.761054039001465, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 07:36:36 client3-1  | {'loss': 0.0858, 'grad_norm': 2.608219623565674, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 07:36:51 client3-1  | {'loss': 0.084, 'grad_norm': 3.067641258239746, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 07:37:06 client3-1  | {'loss': 0.0903, 'grad_norm': 3.045417308807373, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 07:37:21 client3-1  | {'loss': 0.0994, 'grad_norm': 2.7905588150024414, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 07:52:31 client1-1  | {'loss': 0.1381, 'grad_norm': 3.6798458099365234, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 07:52:53 client1-1  | {'loss': 0.1359, 'grad_norm': 2.3813652992248535, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 07:53:07 client1-1  | {'loss': 0.1213, 'grad_norm': 3.303826093673706, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 07:37:43 client3-1  | {'loss': 0.1201, 'grad_norm': 5.038957595825195, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 07:37:58 client3-1  | {'loss': 0.1061, 'grad_norm': 3.0844061374664307, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 07:38:13 client3-1  | {'loss': 0.0944, 'grad_norm': 6.561346530914307, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 07:38:28 client3-1  | {'loss': 0.1096, 'grad_norm': 6.00033712387085, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 07:38:49 client3-1  | {'loss': 0.131, 'grad_norm': 2.157649517059326, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 07:39:05 client3-1  | {'loss': 0.1074, 'grad_norm': 3.7448270320892334, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 07:39:20 client3-1  | {'loss': 0.097, 'grad_norm': 3.7517776489257812, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 07:53:22 client1-1  | {'loss': 0.1429, 'grad_norm': 2.8529598712921143, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 07:53:37 client1-1  | {'loss': 0.1298, 'grad_norm': 3.9355556964874268, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 07:39:35 client3-1  | {'loss': 0.1013, 'grad_norm': 4.674567699432373, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 07:53:59 client1-1  | {'loss': 0.1479, 'grad_norm': 3.5047361850738525, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 07:54:14 client1-1  | {'loss': 0.1314, 'grad_norm': 5.880014896392822, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 07:54:29 client1-1  | {'loss': 0.1665, 'grad_norm': 5.526462554931641, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 07:39:50 client3-1  | {'loss': 0.1127, 'grad_norm': 5.448947906494141, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 07:40:11 client3-1  | {'loss': 0.1016, 'grad_norm': 3.8195581436157227, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 07:40:26 client3-1  | {'loss': 0.1332, 'grad_norm': 7.9033002853393555, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 07:40:41 client3-1  | {'loss': 0.1203, 'grad_norm': 2.7741446495056152, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 07:40:56 client3-1  | {'loss': 0.1291, 'grad_norm': 4.630163669586182, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 07:41:17 client3-1  | {'loss': 0.1467, 'grad_norm': 3.3780081272125244, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 07:54:44 client1-1  | {'loss': 0.1886, 'grad_norm': 7.614164352416992, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 07:55:05 client1-1  | {'loss': 0.2252, 'grad_norm': 5.3691558837890625, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 07:41:32 client3-1  | {'loss': 0.1433, 'grad_norm': 5.806152820587158, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 07:41:47 client3-1  | {'loss': 0.1784, 'grad_norm': 3.7715094089508057, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 07:55:20 client1-1  | {'loss': 0.256, 'grad_norm': 8.384313583374023, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 07:55:35 client1-1  | {'loss': 0.2586, 'grad_norm': 5.389086723327637, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 07:55:50 client1-1  | {'loss': 0.363, 'grad_norm': 6.131762981414795, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 07:56:12 client1-1  | {'loss': 0.5159, 'grad_norm': 13.24190902709961, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 07:56:27 client1-1  | {'loss': 0.5275, 'grad_norm': 12.280648231506348, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 07:56:42 client1-1  | {'loss': 0.7206, 'grad_norm': 13.962628364562988, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 07:56:56 client1-1  | {'loss': 0.7962, 'grad_norm': 9.306147575378418, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 07:57:18 client1-1  | {'loss': 0.8978, 'grad_norm': 13.337922096252441, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 07:57:33 client1-1  | {'loss': 0.9304, 'grad_norm': 12.284440994262695, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 07:42:02 client3-1  | {'loss': 0.1647, 'grad_norm': 2.5658786296844482, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 07:42:24 client3-1  | {'loss': 0.2045, 'grad_norm': 3.834282636642456, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 07:57:47 client1-1  | {'loss': 0.6171, 'grad_norm': 11.290998458862305, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 07:58:02 client1-1  | {'loss': 0.2814, 'grad_norm': 4.46183443069458, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 07:58:24 client1-1  | {'loss': 0.1027, 'grad_norm': 1.831472635269165, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 07:58:24 client1-1  | {'train_runtime': 667.6387, 'train_samples_per_second': 1.198, 'train_steps_per_second': 0.599, 'train_loss': 0.23748375713825226, 'epoch': 1.0}
2025-05-22 07:58:29 client1-1  | INFO :      Sent reply
2025-05-22 07:59:10 client1-1  | INFO :      
2025-05-22 07:59:10 client1-1  | INFO :      Received: evaluate message a7fb6e9a-389b-41c8-bf7c-cd76ee9e8638
2025-05-22 07:42:39 client3-1  | {'loss': 0.1643, 'grad_norm': 3.675826072692871, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 07:59:30 client1-1  | {'eval_loss': 2.1488289833068848, 'eval_runtime': 17.8913, 'eval_samples_per_second': 11.179, 'eval_steps_per_second': 1.397, 'epoch': 1.0}
2025-05-22 07:42:53 client3-1  | {'loss': 0.1833, 'grad_norm': 3.979642868041992, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 07:59:30 client1-1  | INFO :      Sent reply
2025-05-22 07:43:15 client3-1  | {'loss': 0.2784, 'grad_norm': 9.46834945678711, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 07:43:30 client3-1  | {'loss': 0.3217, 'grad_norm': 7.558413028717041, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 07:43:51 client3-1  | {'loss': 0.3598, 'grad_norm': 6.166291236877441, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 07:59:32 client1-1  | INFO :      
2025-05-22 07:59:32 client1-1  | INFO :      Received: reconnect message c69e0c6d-c25c-4b8c-8b96-673c76d8b747
2025-05-22 07:44:07 client3-1  | {'loss': 0.4529, 'grad_norm': 10.00800895690918, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 07:59:33 client1-1  | INFO :      Disconnect and shut down
2025-05-22 07:44:22 client3-1  | {'loss': 0.6597, 'grad_norm': 15.122766494750977, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 07:44:36 client3-1  | {'loss': 0.6713, 'grad_norm': 12.407623291015625, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 07:44:51 client3-1  | {'loss': 0.707, 'grad_norm': 14.511786460876465, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 07:45:12 client3-1  | {'loss': 1.0368, 'grad_norm': 13.422893524169922, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 07:45:27 client3-1  | {'loss': 1.0435, 'grad_norm': 13.861502647399902, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 07:45:42 client3-1  | {'loss': 0.7296, 'grad_norm': 10.923638343811035, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 07:45:57 client3-1  | {'loss': 0.2998, 'grad_norm': 2.439666271209717, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 07:46:09 client3-1  | {'loss': 0.092, 'grad_norm': 3.949831247329712, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 07:46:09 client3-1  | {'train_runtime': 661.6982, 'train_samples_per_second': 1.207, 'train_steps_per_second': 0.605, 'train_loss': 0.2494061754643917, 'epoch': 1.0}
2025-05-22 07:46:18 client3-1  | INFO :      Sent reply
2025-05-22 07:46:54 client3-1  | INFO :      
2025-05-22 07:46:54 client3-1  | INFO :      Received: evaluate message 0e3dc703-1b2d-4a01-96ba-27825208a1a0
2025-05-22 07:47:05 client3-1  | {'eval_loss': 2.1702945232391357, 'eval_runtime': 8.5532, 'eval_samples_per_second': 23.383, 'eval_steps_per_second': 2.923, 'epoch': 1.0}
2025-05-22 07:47:05 client3-1  | INFO :      Sent reply
2025-05-22 07:47:15 client3-1  | INFO :      
2025-05-22 07:47:15 client3-1  | INFO :      Received: train message 85ca024f-3846-43d8-8272-500516b4ff61
2025-05-22 07:47:38 client3-1  | {'loss': 0.0699, 'grad_norm': 0.8747960925102234, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-22 07:47:53 client3-1  | {'loss': 0.0846, 'grad_norm': 0.864631175994873, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-22 07:48:08 client3-1  | {'loss': 0.0752, 'grad_norm': 3.155841112136841, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-22 07:48:29 client3-1  | {'loss': 0.0821, 'grad_norm': 1.8718498945236206, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-22 07:48:44 client3-1  | {'loss': 0.0866, 'grad_norm': 2.05220890045166, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-22 07:48:59 client3-1  | {'loss': 0.0994, 'grad_norm': 2.2033560276031494, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-22 07:49:14 client3-1  | {'loss': 0.0823, 'grad_norm': 2.091434955596924, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-22 07:49:29 client3-1  | {'loss': 0.0925, 'grad_norm': 2.228917360305786, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-22 07:49:50 client3-1  | {'loss': 0.1063, 'grad_norm': 5.958146572113037, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-22 07:50:05 client3-1  | {'loss': 0.0937, 'grad_norm': 7.228482723236084, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-22 07:50:20 client3-1  | {'loss': 0.092, 'grad_norm': 8.82247543334961, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-22 07:50:35 client3-1  | {'loss': 0.1187, 'grad_norm': 3.3685216903686523, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-22 07:50:56 client3-1  | {'loss': 0.1167, 'grad_norm': 2.4516077041625977, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-22 07:51:11 client3-1  | {'loss': 0.1013, 'grad_norm': 5.5640716552734375, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-22 07:51:27 client3-1  | {'loss': 0.0888, 'grad_norm': 1.5221261978149414, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-22 07:51:42 client3-1  | {'loss': 0.0951, 'grad_norm': 2.1985697746276855, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-22 07:52:03 client3-1  | {'loss': 0.11, 'grad_norm': 3.4313337802886963, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-22 07:52:18 client3-1  | {'loss': 0.111, 'grad_norm': 3.8957712650299072, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-22 07:52:33 client3-1  | {'loss': 0.1244, 'grad_norm': 5.178338050842285, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-22 07:52:48 client3-1  | {'loss': 0.1192, 'grad_norm': 2.993269681930542, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-22 07:53:03 client3-1  | {'loss': 0.1166, 'grad_norm': 4.1675004959106445, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-22 07:53:24 client3-1  | {'loss': 0.1423, 'grad_norm': 4.74765682220459, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-22 07:53:39 client3-1  | {'loss': 0.1194, 'grad_norm': 5.851467609405518, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-22 07:53:54 client3-1  | {'loss': 0.1501, 'grad_norm': 2.6592447757720947, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-22 07:54:09 client3-1  | {'loss': 0.1554, 'grad_norm': 3.1800408363342285, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-22 07:54:31 client3-1  | {'loss': 0.1864, 'grad_norm': 4.747984886169434, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-22 07:54:46 client3-1  | {'loss': 0.1506, 'grad_norm': 3.544271469116211, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-22 07:55:01 client3-1  | {'loss': 0.1765, 'grad_norm': 3.6268980503082275, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-22 07:55:16 client3-1  | {'loss': 0.2357, 'grad_norm': 6.930050373077393, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-22 07:55:37 client3-1  | {'loss': 0.2962, 'grad_norm': 7.081830024719238, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-22 07:55:52 client3-1  | {'loss': 0.3368, 'grad_norm': 8.135110855102539, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-22 07:56:07 client3-1  | {'loss': 0.428, 'grad_norm': 8.842721939086914, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-22 07:56:22 client3-1  | {'loss': 0.609, 'grad_norm': 15.399591445922852, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-22 07:56:44 client3-1  | {'loss': 0.6235, 'grad_norm': 12.293780326843262, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-22 07:56:58 client3-1  | {'loss': 0.6805, 'grad_norm': 14.562294006347656, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-22 07:57:13 client3-1  | {'loss': 0.9893, 'grad_norm': 13.298550605773926, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-22 07:57:28 client3-1  | {'loss': 1.0321, 'grad_norm': 14.705201148986816, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-22 07:57:49 client3-1  | {'loss': 0.702, 'grad_norm': 8.857583999633789, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-22 07:58:04 client3-1  | {'loss': 0.2751, 'grad_norm': 2.400322914123535, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-22 07:58:20 client3-1  | {'loss': 0.0816, 'grad_norm': 4.511188507080078, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-22 07:58:20 client3-1  | {'train_runtime': 661.8405, 'train_samples_per_second': 1.207, 'train_steps_per_second': 0.604, 'train_loss': 0.23592295482754708, 'epoch': 1.0}
2025-05-22 07:58:32 client3-1  | INFO :      Sent reply
2025-05-22 07:59:10 client3-1  | INFO :      
2025-05-22 07:59:10 client3-1  | INFO :      Received: evaluate message fb100f22-c93c-44ae-a489-98f2cb9fffee
2025-05-22 07:59:31 client3-1  | {'eval_loss': 2.1893553733825684, 'eval_runtime': 17.5491, 'eval_samples_per_second': 11.397, 'eval_steps_per_second': 1.425, 'epoch': 1.0}
2025-05-22 07:59:31 client3-1  | INFO :      Sent reply
2025-05-22 07:59:32 client3-1  | INFO :      
2025-05-22 07:59:32 client3-1  | INFO :      Received: reconnect message 47248d7e-9b14-423d-a8fc-9f511cb4860d
2025-05-22 07:59:33 client3-1  | INFO :      Disconnect and shut down
