2025-05-19 21:39:00 server-1   | WARNING :   DEPRECATED FEATURE: flwr.server.start_server() is deprecated.
2025-05-19 21:40:12 client1-1  | 
Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]
Generating train split:  83%|████████▎ | 100000/120000 [00:00<00:00, 990991.94 examples/s]
Generating train split: 100%|██████████| 120000/120000 [00:00<00:00, 1053798.89 examples/s]
2025-05-19 21:39:00 server-1   | Instead, use the `flower-superlink` CLI command to start a SuperLink as shown below:
2025-05-19 21:40:12 client1-1  | 
Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]
Generating test split: 100%|██████████| 7600/7600 [00:00<00:00, 1031108.21 examples/s]
2025-05-19 21:41:07 client2-1  | 
Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]
Generating train split: 100%|██████████| 120000/120000 [00:00<00:00, 1096308.83 examples/s]
Generating train split: 100%|██████████| 120000/120000 [00:00<00:00, 1093372.38 examples/s]
2025-05-19 21:41:07 client2-1  | 
Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]
Generating test split: 100%|██████████| 7600/7600 [00:00<00:00, 958611.57 examples/s]
2025-05-19 21:41:09 client2-1  | 
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 1348.46 examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 1342.68 examples/s]
2025-05-19 21:40:14 client1-1  | 
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 1341.73 examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 1335.13 examples/s]
2025-05-19 21:39:00 server-1   | 
2025-05-19 21:39:00 server-1   | $ flower-superlink --insecure
2025-05-19 21:39:00 server-1   | 
2025-05-19 21:39:00 server-1   | To view usage and all available options, run:
2025-05-19 21:39:00 server-1   | 
2025-05-19 21:39:00 server-1   | $ flower-superlink --help
2025-05-19 21:39:00 server-1   | 
2025-05-19 21:39:00 server-1   | Using `start_server()` is deprecated.
2025-05-19 21:39:00 server-1   | 
2025-05-19 21:39:00 server-1   |             This is a deprecated feature. It will be removed
2025-05-19 21:39:00 server-1   |             entirely in future versions of Flower.
2025-05-19 21:39:00 server-1   |         
2025-05-19 21:39:00 server-1   | INFO :      Starting Flower server, config: num_rounds=5, no round_timeout
2025-05-19 21:41:09 client2-1  | 
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]
Map:  34%|███▍      | 338/1000 [00:00<00:00, 3343.68 examples/s]
Map:  70%|███████   | 705/1000 [00:00<00:00, 3520.11 examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 3155.02 examples/s]
2025-05-19 21:41:09 client2-1  | /app/client.py:49: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-05-19 21:41:09 client2-1  |   trainer = Trainer(
2025-05-19 21:40:15 client1-1  | 
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]
Map:  18%|█▊        | 182/1000 [00:00<00:00, 1791.76 examples/s]
Map:  37%|███▋      | 366/1000 [00:00<00:00, 1813.35 examples/s]
Map:  59%|█████▉    | 593/1000 [00:00<00:00, 2018.56 examples/s]
Map:  80%|████████  | 800/1000 [00:00<00:00, 2035.71 examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 1882.16 examples/s]
2025-05-19 21:41:10 client2-1  | WARNING :   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
2025-05-19 21:41:10 client2-1  | Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
2025-05-19 21:39:00 server-1   | INFO :      Flower ECE: gRPC server running (5 rounds), SSL is disabled
2025-05-19 21:39:00 server-1   | INFO :      [INIT]
2025-05-19 21:39:00 server-1   | INFO :      Requesting initial parameters from one random client
2025-05-19 21:41:10 client2-1  | flwr.client.start_client(
2025-05-19 21:41:10 client2-1  | server_address='<IP>:<PORT>',
2025-05-19 21:40:20 server-1   | INFO :      Received initial parameters from one random client
2025-05-19 21:40:20 server-1   | INFO :      Starting evaluation of initial global parameters
2025-05-19 21:40:20 server-1   | INFO :      Evaluation returned no results (`None`)
2025-05-19 21:40:15 client1-1  | /app/client.py:49: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-05-19 21:40:20 server-1   | INFO :      
2025-05-19 21:40:15 client1-1  |   trainer = Trainer(
2025-05-19 21:40:20 server-1   | INFO :      [ROUND 1]
2025-05-19 21:41:10 server-1   | INFO :      configure_fit: strategy sampled 2 clients (out of 2)
2025-05-19 21:48:54 server-1   | INFO :      aggregate_fit: received 2 results and 0 failures
2025-05-19 21:48:59 server-1   | WARNING :   No fit_metrics_aggregation_fn provided
2025-05-19 21:48:59 server-1   | INFO :      configure_evaluate: strategy sampled 2 clients (out of 2)
2025-05-19 21:49:18 server-1   | INFO :      aggregate_evaluate: received 2 results and 0 failures
2025-05-19 21:41:10 client2-1  | client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
2025-05-19 21:40:16 client1-1  | WARNING :   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
2025-05-19 21:41:10 client2-1  | )
2025-05-19 21:49:18 server-1   | WARNING :   No evaluate_metrics_aggregation_fn provided
2025-05-19 21:41:10 client2-1  | Using `start_numpy_client()` is deprecated.
2025-05-19 21:49:18 server-1   | INFO :      
2025-05-19 21:41:10 client2-1  | 
2025-05-19 21:41:10 client2-1  |             This is a deprecated feature. It will be removed
2025-05-19 21:49:18 server-1   | INFO :      [ROUND 2]
2025-05-19 21:49:18 server-1   | INFO :      configure_fit: strategy sampled 2 clients (out of 2)
2025-05-19 21:56:49 server-1   | INFO :      aggregate_fit: received 2 results and 0 failures
2025-05-19 21:40:16 client1-1  | Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
2025-05-19 21:56:54 server-1   | INFO :      configure_evaluate: strategy sampled 2 clients (out of 2)
2025-05-19 21:40:16 client1-1  | flwr.client.start_client(
2025-05-19 21:40:16 client1-1  | server_address='<IP>:<PORT>',
2025-05-19 21:40:16 client1-1  | client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
2025-05-19 21:40:16 client1-1  | )
2025-05-19 21:40:16 client1-1  | Using `start_numpy_client()` is deprecated.
2025-05-19 21:41:10 client2-1  |             entirely in future versions of Flower.
2025-05-19 21:57:09 server-1   | INFO :      aggregate_evaluate: received 2 results and 0 failures
2025-05-19 21:41:10 client2-1  |         
2025-05-19 21:41:10 client2-1  | WARNING :   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
2025-05-19 21:41:10 client2-1  | Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:
2025-05-19 21:41:10 client2-1  | 
2025-05-19 21:41:10 client2-1  | $ flower-supernode --insecure --superlink='<IP>:<PORT>'
2025-05-19 21:57:09 server-1   | INFO :      
2025-05-19 21:57:09 server-1   | INFO :      [ROUND 3]
2025-05-19 21:57:09 server-1   | INFO :      configure_fit: strategy sampled 2 clients (out of 2)
2025-05-19 21:41:10 client2-1  | 
2025-05-19 21:41:10 client2-1  | To view all available options, run:
2025-05-19 21:40:16 client1-1  | 
2025-05-19 21:40:16 client1-1  |             This is a deprecated feature. It will be removed
2025-05-19 21:40:16 client1-1  |             entirely in future versions of Flower.
2025-05-19 22:04:34 server-1   | INFO :      aggregate_fit: received 2 results and 0 failures
2025-05-19 21:40:16 client1-1  |         
2025-05-19 21:41:10 client2-1  | 
2025-05-19 21:41:10 client2-1  | $ flower-supernode --help
2025-05-19 21:41:10 client2-1  | 
2025-05-19 21:41:10 client2-1  | Using `start_client()` is deprecated.
2025-05-19 21:41:10 client2-1  | 
2025-05-19 21:40:16 client1-1  | WARNING :   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
2025-05-19 21:40:16 client1-1  | Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:
2025-05-19 22:04:40 server-1   | INFO :      configure_evaluate: strategy sampled 2 clients (out of 2)
2025-05-19 22:04:58 server-1   | INFO :      aggregate_evaluate: received 2 results and 0 failures
2025-05-19 22:04:58 server-1   | INFO :      
2025-05-19 21:41:10 client2-1  |             This is a deprecated feature. It will be removed
2025-05-19 21:40:16 client1-1  | 
2025-05-19 21:41:10 client2-1  |             entirely in future versions of Flower.
2025-05-19 21:41:10 client2-1  |         
2025-05-19 21:41:17 client2-1  | INFO :      
2025-05-19 21:41:17 client2-1  | INFO :      Received: train message c12235d9-3e3e-48c1-b0c7-6c41cfee9af1
2025-05-19 21:41:34 client2-1  | {'loss': 2.601, 'grad_norm': 12.700850486755371, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-19 21:41:44 client2-1  | {'loss': 1.701, 'grad_norm': 15.263579368591309, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-19 21:41:58 client2-1  | {'loss': 1.5413, 'grad_norm': 14.924647331237793, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-19 21:42:08 client2-1  | {'loss': 1.5084, 'grad_norm': 11.737829208374023, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-19 21:42:18 client2-1  | {'loss': 1.4867, 'grad_norm': 13.93914794921875, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-19 21:42:28 client2-1  | {'loss': 1.4997, 'grad_norm': 14.920110702514648, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-19 21:42:41 client2-1  | {'loss': 1.4803, 'grad_norm': 14.05017375946045, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-19 21:42:51 client2-1  | {'loss': 1.6589, 'grad_norm': 11.854897499084473, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-19 21:43:01 client2-1  | {'loss': 1.4721, 'grad_norm': 16.295398712158203, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-19 21:43:15 client2-1  | {'loss': 1.5535, 'grad_norm': 17.57485580444336, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-19 21:43:25 client2-1  | {'loss': 1.4841, 'grad_norm': 12.247942924499512, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-19 22:04:58 server-1   | INFO :      [ROUND 4]
2025-05-19 21:43:35 client2-1  | {'loss': 1.5989, 'grad_norm': 13.974462509155273, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-19 22:04:58 server-1   | INFO :      configure_fit: strategy sampled 2 clients (out of 2)
2025-05-19 21:43:45 client2-1  | {'loss': 1.4312, 'grad_norm': 14.314990043640137, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-19 22:12:25 server-1   | INFO :      aggregate_fit: received 2 results and 0 failures
2025-05-19 21:40:16 client1-1  | $ flower-supernode --insecure --superlink='<IP>:<PORT>'
2025-05-19 22:12:30 server-1   | INFO :      configure_evaluate: strategy sampled 2 clients (out of 2)
2025-05-19 21:43:59 client2-1  | {'loss': 1.4187, 'grad_norm': 13.82353401184082, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-19 22:12:49 server-1   | INFO :      aggregate_evaluate: received 2 results and 0 failures
2025-05-19 22:12:49 server-1   | INFO :      
2025-05-19 22:12:49 server-1   | INFO :      [ROUND 5]
2025-05-19 21:44:09 client2-1  | {'loss': 1.4701, 'grad_norm': 13.539532661437988, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-19 22:12:49 server-1   | INFO :      configure_fit: strategy sampled 2 clients (out of 2)
2025-05-19 21:40:16 client1-1  | 
2025-05-19 21:44:18 client2-1  | {'loss': 1.3575, 'grad_norm': 10.871011734008789, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-19 21:44:32 client2-1  | {'loss': 1.4066, 'grad_norm': 12.065603256225586, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-19 21:44:42 client2-1  | {'loss': 1.412, 'grad_norm': 13.48873233795166, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-19 21:40:16 client1-1  | To view all available options, run:
2025-05-19 21:40:16 client1-1  | 
2025-05-19 21:40:16 client1-1  | $ flower-supernode --help
2025-05-19 21:44:52 client2-1  | {'loss': 1.3088, 'grad_norm': 11.071293830871582, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-19 21:45:06 client2-1  | {'loss': 1.6416, 'grad_norm': 11.690345764160156, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-19 21:40:16 client1-1  | 
2025-05-19 21:40:16 client1-1  | Using `start_client()` is deprecated.
2025-05-19 21:40:16 client1-1  | 
2025-05-19 21:40:16 client1-1  |             This is a deprecated feature. It will be removed
2025-05-19 21:40:16 client1-1  |             entirely in future versions of Flower.
2025-05-19 21:40:16 client1-1  |         
2025-05-19 21:45:16 client2-1  | {'loss': 1.287, 'grad_norm': 11.70107364654541, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-19 21:45:26 client2-1  | {'loss': 1.2886, 'grad_norm': 17.37563705444336, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-19 21:45:36 client2-1  | {'loss': 1.3883, 'grad_norm': 13.114779472351074, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-19 21:45:50 client2-1  | {'loss': 1.6138, 'grad_norm': 9.251484870910645, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-19 21:46:00 client2-1  | {'loss': 1.3731, 'grad_norm': 11.324997901916504, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-19 22:20:20 server-1   | INFO :      aggregate_fit: received 2 results and 0 failures
2025-05-19 22:20:25 server-1   | INFO :      configure_evaluate: strategy sampled 2 clients (out of 2)
2025-05-19 21:40:16 client1-1  | INFO :      
2025-05-19 21:40:16 client1-1  | INFO :      Received: get_parameters message 66e4b841-ce39-4060-b173-84f457b03a06
2025-05-19 21:40:19 client1-1  | INFO :      Sent reply
2025-05-19 22:20:46 server-1   | INFO :      aggregate_evaluate: received 2 results and 0 failures
2025-05-19 21:46:10 client2-1  | {'loss': 1.5071, 'grad_norm': 13.083330154418945, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-19 22:20:46 server-1   | INFO :      
2025-05-19 21:41:17 client1-1  | INFO :      
2025-05-19 21:46:20 client2-1  | {'loss': 1.3798, 'grad_norm': 13.587925910949707, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-19 21:41:17 client1-1  | INFO :      Received: train message debb1802-df9d-4e62-9ea1-cb44ac55e47d
2025-05-19 21:46:34 client2-1  | {'loss': 1.346, 'grad_norm': 10.428629875183105, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-19 21:41:36 client1-1  | {'loss': 3.0779, 'grad_norm': 23.870946884155273, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-19 21:46:44 client2-1  | {'loss': 1.3275, 'grad_norm': 9.480512619018555, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-19 22:20:46 server-1   | INFO :      [SUMMARY]
2025-05-19 21:41:47 client1-1  | {'loss': 1.6398, 'grad_norm': 16.393983840942383, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-19 21:46:54 client2-1  | {'loss': 1.3643, 'grad_norm': 13.955072402954102, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-19 21:42:01 client1-1  | {'loss': 1.6488, 'grad_norm': 14.47984504699707, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-19 21:47:07 client2-1  | {'loss': 1.3997, 'grad_norm': 9.311558723449707, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-19 21:42:11 client1-1  | {'loss': 1.6039, 'grad_norm': 16.12891960144043, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-19 21:42:25 client1-1  | {'loss': 1.594, 'grad_norm': 14.733625411987305, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-19 21:47:17 client2-1  | {'loss': 1.4925, 'grad_norm': 11.113691329956055, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-19 21:42:35 client1-1  | {'loss': 1.479, 'grad_norm': 18.79583740234375, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-19 21:42:44 client1-1  | {'loss': 1.5072, 'grad_norm': 16.48334312438965, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-19 21:47:27 client2-1  | {'loss': 1.592, 'grad_norm': 10.390338897705078, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-19 21:42:58 client1-1  | {'loss': 1.5028, 'grad_norm': 15.15711498260498, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-19 22:20:46 server-1   | INFO :      Run finished 5 round(s) in 2426.24s
2025-05-19 21:43:08 client1-1  | {'loss': 1.5129, 'grad_norm': 10.253802299499512, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-19 21:43:18 client1-1  | {'loss': 1.5075, 'grad_norm': 11.58635139465332, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-19 21:43:28 client1-1  | {'loss': 1.3813, 'grad_norm': 11.765666961669922, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-19 22:20:46 server-1   | INFO :      History (loss, distributed):
2025-05-19 22:20:46 server-1   | INFO :      round 1: 1.312696397304535
2025-05-19 22:20:46 server-1   | INFO :      round 2: 1.3364108204841614
2025-05-19 21:47:37 client2-1  | {'loss': 1.5369, 'grad_norm': 13.552906036376953, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-19 22:20:46 server-1   | INFO :      round 3: 1.3725641369819641
2025-05-19 21:43:42 client1-1  | {'loss': 1.3413, 'grad_norm': 8.577851295471191, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-19 21:43:51 client1-1  | {'loss': 1.4302, 'grad_norm': 14.374579429626465, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-19 21:44:02 client1-1  | {'loss': 1.4745, 'grad_norm': 10.165772438049316, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-19 21:44:15 client1-1  | {'loss': 1.5905, 'grad_norm': 13.09705638885498, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-19 21:44:25 client1-1  | {'loss': 1.4071, 'grad_norm': 11.210378646850586, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-19 22:20:46 server-1   | INFO :      round 4: 1.4089081287384033
2025-05-19 22:20:46 server-1   | INFO :      round 5: 1.4513224363327026
2025-05-19 22:20:46 server-1   | INFO :      
2025-05-19 21:44:35 client1-1  | {'loss': 1.4304, 'grad_norm': 11.469685554504395, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-19 21:47:51 client2-1  | {'loss': 1.2543, 'grad_norm': 11.043596267700195, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-19 21:44:45 client1-1  | {'loss': 1.3735, 'grad_norm': 16.789493560791016, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-19 21:44:59 client1-1  | {'loss': 1.3679, 'grad_norm': 12.699308395385742, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-19 21:45:09 client1-1  | {'loss': 1.442, 'grad_norm': 14.695151329040527, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-19 21:45:19 client1-1  | {'loss': 1.5491, 'grad_norm': 12.430862426757812, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-19 21:48:01 client2-1  | {'loss': 1.2883, 'grad_norm': 10.747010231018066, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-19 21:48:10 client2-1  | {'loss': 1.3394, 'grad_norm': 14.550005912780762, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-19 21:48:24 client2-1  | {'loss': 1.3901, 'grad_norm': 15.557666778564453, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-19 21:48:34 client2-1  | {'loss': 1.4073, 'grad_norm': 14.270679473876953, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-19 21:45:33 client1-1  | {'loss': 1.5661, 'grad_norm': 15.29328441619873, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-19 21:45:43 client1-1  | {'loss': 1.3717, 'grad_norm': 10.572358131408691, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-19 21:45:53 client1-1  | {'loss': 1.4105, 'grad_norm': 12.154624938964844, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-19 21:46:03 client1-1  | {'loss': 1.4397, 'grad_norm': 14.039730072021484, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-19 21:46:17 client1-1  | {'loss': 1.4951, 'grad_norm': 10.834545135498047, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-19 21:46:27 client1-1  | {'loss': 1.4216, 'grad_norm': 10.978960990905762, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-19 21:48:44 client2-1  | {'loss': 1.4331, 'grad_norm': 13.249505043029785, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-19 21:48:44 client2-1  | {'train_runtime': 445.575, 'train_samples_per_second': 1.795, 'train_steps_per_second': 0.898, 'train_loss': 1.4760309290885925, 'epoch': 1.0}
2025-05-19 21:46:37 client1-1  | {'loss': 1.3306, 'grad_norm': 9.797501564025879, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-19 21:46:47 client1-1  | {'loss': 1.4985, 'grad_norm': 14.400670051574707, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-19 21:47:00 client1-1  | {'loss': 1.4055, 'grad_norm': 12.422646522521973, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-19 21:47:10 client1-1  | {'loss': 1.4726, 'grad_norm': 14.53523063659668, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-19 21:48:52 client2-1  | INFO :      Sent reply
2025-05-19 21:49:04 client2-1  | INFO :      
2025-05-19 21:47:20 client1-1  | {'loss': 1.3556, 'grad_norm': 11.540557861328125, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-19 21:49:04 client2-1  | INFO :      Received: evaluate message dcb6e2df-fad7-4383-ae10-4560b030e2bd
2025-05-19 21:49:18 client2-1  | {'eval_loss': 1.2957048416137695, 'eval_runtime': 11.4907, 'eval_samples_per_second': 17.405, 'eval_steps_per_second': 2.176, 'epoch': 1.0}
2025-05-19 21:49:18 client2-1  | INFO :      Sent reply
2025-05-19 21:49:22 client2-1  | INFO :      
2025-05-19 21:47:30 client1-1  | {'loss': 1.4986, 'grad_norm': 12.841272354125977, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-19 21:47:44 client1-1  | {'loss': 1.4343, 'grad_norm': 9.683223724365234, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-19 21:47:54 client1-1  | {'loss': 1.2494, 'grad_norm': 10.82675838470459, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-19 21:48:03 client1-1  | {'loss': 1.2167, 'grad_norm': 9.784420013427734, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-19 21:48:13 client1-1  | {'loss': 1.2218, 'grad_norm': 12.026585578918457, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-19 21:48:27 client1-1  | {'loss': 1.3837, 'grad_norm': 8.442797660827637, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-19 21:48:36 client1-1  | {'loss': 1.3134, 'grad_norm': 10.266639709472656, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-19 21:48:46 client1-1  | {'loss': 1.308, 'grad_norm': 11.753752708435059, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-19 21:49:22 client2-1  | INFO :      Received: train message 0a394a7a-0ee9-4770-8e61-f8b226e0dc90
2025-05-19 21:49:37 client2-1  | {'loss': 0.8169, 'grad_norm': 9.148890495300293, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-19 21:48:46 client1-1  | {'train_runtime': 448.235, 'train_samples_per_second': 1.785, 'train_steps_per_second': 0.892, 'train_loss': 1.4813659501075744, 'epoch': 1.0}
2025-05-19 21:49:50 client2-1  | {'loss': 1.0207, 'grad_norm': 10.021646499633789, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-19 21:48:53 client1-1  | INFO :      Sent reply
2025-05-19 21:49:05 client1-1  | INFO :      
2025-05-19 21:49:05 client1-1  | INFO :      Received: evaluate message bc5a3658-c40b-4762-8b93-6fa39e11802d
2025-05-19 21:50:00 client2-1  | {'loss': 1.0093, 'grad_norm': 13.605888366699219, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-19 21:50:10 client2-1  | {'loss': 0.9907, 'grad_norm': 9.3651704788208, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-19 21:50:20 client2-1  | {'loss': 0.9801, 'grad_norm': 11.05280876159668, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-19 21:50:33 client2-1  | {'loss': 1.0073, 'grad_norm': 11.444302558898926, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-19 21:50:43 client2-1  | {'loss': 1.0411, 'grad_norm': 11.465323448181152, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-19 21:49:17 client1-1  | {'eval_loss': 1.3296879529953003, 'eval_runtime': 9.4837, 'eval_samples_per_second': 21.089, 'eval_steps_per_second': 2.636, 'epoch': 1.0}
2025-05-19 21:49:17 client1-1  | INFO :      Sent reply
2025-05-19 21:49:22 client1-1  | INFO :      
2025-05-19 21:49:22 client1-1  | INFO :      Received: train message 922e67a2-64ff-4411-a75a-e4bbfc636ec8
2025-05-19 21:49:34 client1-1  | {'loss': 0.9666, 'grad_norm': 18.40605926513672, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-19 21:50:53 client2-1  | {'loss': 1.1974, 'grad_norm': 11.063536643981934, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-19 21:51:03 client2-1  | {'loss': 1.0706, 'grad_norm': 12.20649242401123, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-19 21:51:16 client2-1  | {'loss': 1.0939, 'grad_norm': 12.82288646697998, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-19 21:51:26 client2-1  | {'loss': 1.0776, 'grad_norm': 10.486796379089355, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-19 21:49:48 client1-1  | {'loss': 1.0433, 'grad_norm': 11.83352279663086, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-19 21:49:58 client1-1  | {'loss': 1.0591, 'grad_norm': 10.472614288330078, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-19 21:50:07 client1-1  | {'loss': 1.0561, 'grad_norm': 11.22593879699707, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-19 21:51:40 client2-1  | {'loss': 1.1745, 'grad_norm': 11.80184555053711, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-19 21:51:50 client2-1  | {'loss': 1.0292, 'grad_norm': 11.449085235595703, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-19 21:52:04 client2-1  | {'loss': 1.0372, 'grad_norm': 13.903372764587402, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-19 21:50:17 client1-1  | {'loss': 1.1076, 'grad_norm': 10.336087226867676, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-19 21:52:18 client2-1  | {'loss': 1.113, 'grad_norm': 10.999345779418945, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-19 21:50:31 client1-1  | {'loss': 1.0482, 'grad_norm': 13.612870216369629, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-19 21:52:28 client2-1  | {'loss': 1.0203, 'grad_norm': 9.980940818786621, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-19 21:50:41 client1-1  | {'loss': 1.0534, 'grad_norm': 13.236595153808594, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-19 21:50:51 client1-1  | {'loss': 1.0477, 'grad_norm': 12.70201587677002, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-19 21:51:00 client1-1  | {'loss': 1.05, 'grad_norm': 10.141843795776367, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-19 21:51:14 client1-1  | {'loss': 1.0819, 'grad_norm': 9.887101173400879, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-19 21:51:24 client1-1  | {'loss': 1.0038, 'grad_norm': 8.649333000183105, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-19 21:52:42 client2-1  | {'loss': 1.0657, 'grad_norm': 10.661231994628906, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-19 21:52:52 client2-1  | {'loss': 1.0936, 'grad_norm': 12.393813133239746, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-19 21:53:02 client2-1  | {'loss': 1.0281, 'grad_norm': 10.617676734924316, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-19 21:53:16 client2-1  | {'loss': 1.3161, 'grad_norm': 9.173596382141113, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-19 21:51:33 client1-1  | {'loss': 0.9968, 'grad_norm': 8.578398704528809, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-19 21:51:47 client1-1  | {'loss': 1.0548, 'grad_norm': 12.002747535705566, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-19 21:51:57 client1-1  | {'loss': 1.1133, 'grad_norm': 8.040560722351074, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-19 21:53:25 client2-1  | {'loss': 1.0057, 'grad_norm': 11.037248611450195, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-19 21:53:35 client2-1  | {'loss': 1.0362, 'grad_norm': 11.103860855102539, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-19 21:53:45 client2-1  | {'loss': 1.1123, 'grad_norm': 11.225512504577637, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-19 21:52:07 client1-1  | {'loss': 1.1854, 'grad_norm': 10.142541885375977, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-19 21:53:58 client2-1  | {'loss': 1.3076, 'grad_norm': 9.476460456848145, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-19 21:52:21 client1-1  | {'loss': 1.0802, 'grad_norm': 10.740087509155273, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-19 21:52:31 client1-1  | {'loss': 1.104, 'grad_norm': 9.443574905395508, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-19 21:52:44 client1-1  | {'loss': 1.0354, 'grad_norm': 12.900503158569336, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-19 21:52:54 client1-1  | {'loss': 1.0372, 'grad_norm': 10.811965942382812, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-19 21:53:04 client1-1  | {'loss': 1.1297, 'grad_norm': 11.317669868469238, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-19 21:53:18 client1-1  | {'loss': 1.2108, 'grad_norm': 11.01292610168457, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-19 21:53:28 client1-1  | {'loss': 1.2602, 'grad_norm': 16.72793960571289, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-19 21:53:37 client1-1  | {'loss': 1.1062, 'grad_norm': 13.33255386352539, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-19 21:53:47 client1-1  | {'loss': 1.1419, 'grad_norm': 13.109825134277344, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-19 21:54:01 client1-1  | {'loss': 1.1731, 'grad_norm': 11.867020606994629, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-19 21:54:10 client1-1  | {'loss': 1.2368, 'grad_norm': 10.367876052856445, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-19 21:54:20 client1-1  | {'loss': 1.1745, 'grad_norm': 11.419368743896484, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-19 21:54:34 client1-1  | {'loss': 1.1025, 'grad_norm': 9.124959945678711, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-19 21:54:08 client2-1  | {'loss': 1.1002, 'grad_norm': 10.445063591003418, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-19 21:54:18 client2-1  | {'loss': 1.2723, 'grad_norm': 12.930829048156738, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-19 21:54:43 client1-1  | {'loss': 1.2521, 'grad_norm': 12.488058090209961, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-19 21:54:27 client2-1  | {'loss': 1.1594, 'grad_norm': 11.111831665039062, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-19 21:54:53 client1-1  | {'loss': 1.2078, 'grad_norm': 12.34030532836914, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-19 21:55:03 client1-1  | {'loss': 1.2969, 'grad_norm': 14.692469596862793, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-19 21:55:17 client1-1  | {'loss': 1.1752, 'grad_norm': 10.896025657653809, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-19 21:55:26 client1-1  | {'loss': 1.3086, 'grad_norm': 11.42797565460205, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-19 21:55:36 client1-1  | {'loss': 1.2976, 'grad_norm': 10.175338745117188, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-19 21:55:49 client1-1  | {'loss': 1.1398, 'grad_norm': 11.134923934936523, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-19 21:55:59 client1-1  | {'loss': 1.11, 'grad_norm': 9.285240173339844, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-19 21:56:09 client1-1  | {'loss': 1.0879, 'grad_norm': 11.13304615020752, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-19 21:54:41 client2-1  | {'loss': 1.1143, 'grad_norm': 9.424970626831055, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-19 21:54:51 client2-1  | {'loss': 1.1413, 'grad_norm': 10.92104434967041, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-19 21:55:00 client2-1  | {'loss': 1.1574, 'grad_norm': 13.99210262298584, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-19 21:55:10 client2-1  | {'loss': 1.2016, 'grad_norm': 9.174077987670898, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-19 21:56:19 client1-1  | {'loss': 1.2411, 'grad_norm': 8.078911781311035, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-19 21:56:32 client1-1  | {'loss': 1.0191, 'grad_norm': 8.9845609664917, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-19 21:56:42 client1-1  | {'loss': 0.7626, 'grad_norm': 8.423916816711426, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-19 21:55:24 client2-1  | {'loss': 1.3334, 'grad_norm': 11.26921558380127, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-19 21:55:33 client2-1  | {'loss': 1.4088, 'grad_norm': 11.80623722076416, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-19 21:55:43 client2-1  | {'loss': 1.4047, 'grad_norm': 13.111936569213867, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-19 21:56:42 client1-1  | {'train_runtime': 438.3782, 'train_samples_per_second': 1.825, 'train_steps_per_second': 0.912, 'train_loss': 1.1139904296398162, 'epoch': 1.0}
2025-05-19 21:56:45 client1-1  | INFO :      Sent reply
2025-05-19 21:57:00 client1-1  | INFO :      
2025-05-19 21:55:57 client2-1  | {'loss': 1.1555, 'grad_norm': 10.67598819732666, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-19 21:57:00 client1-1  | INFO :      Received: evaluate message 2e346774-ec0c-437c-8e2e-44c7b0597614
2025-05-19 21:56:06 client2-1  | {'loss': 1.1765, 'grad_norm': 9.604667663574219, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-19 21:56:16 client2-1  | {'loss': 1.2066, 'grad_norm': 13.42385196685791, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-19 21:57:09 client1-1  | {'eval_loss': 1.3568447828292847, 'eval_runtime': 6.9984, 'eval_samples_per_second': 28.578, 'eval_steps_per_second': 3.572, 'epoch': 1.0}
2025-05-19 21:57:09 client1-1  | INFO :      Sent reply
2025-05-19 21:57:13 client1-1  | INFO :      
2025-05-19 21:56:26 client2-1  | {'loss': 1.2385, 'grad_norm': 14.328103065490723, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-19 21:56:39 client2-1  | {'loss': 1.144, 'grad_norm': 11.361928939819336, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-19 21:56:45 client2-1  | {'loss': 0.8552, 'grad_norm': 8.67873477935791, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-19 21:57:13 client1-1  | INFO :      Received: train message 0da98364-d53b-4fa2-9306-ccbb39b81598
2025-05-19 21:57:27 client1-1  | {'loss': 0.6145, 'grad_norm': 15.786859512329102, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-19 21:57:41 client1-1  | {'loss': 0.6959, 'grad_norm': 10.106876373291016, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-19 21:56:45 client2-1  | {'train_runtime': 439.6118, 'train_samples_per_second': 1.82, 'train_steps_per_second': 0.91, 'train_loss': 1.1178684043884277, 'epoch': 1.0}
2025-05-19 21:57:51 client1-1  | {'loss': 0.7279, 'grad_norm': 10.011662483215332, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-19 21:56:48 client2-1  | INFO :      Sent reply
2025-05-19 21:56:59 client2-1  | INFO :      
2025-05-19 21:58:00 client1-1  | {'loss': 0.7686, 'grad_norm': 11.032716751098633, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-19 21:58:10 client1-1  | {'loss': 0.8205, 'grad_norm': 21.166017532348633, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-19 21:58:24 client1-1  | {'loss': 0.7591, 'grad_norm': 12.441256523132324, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-19 21:56:59 client2-1  | INFO :      Received: evaluate message ea4e7c94-9686-45b0-a7dd-9d08dc955be9
2025-05-19 21:57:07 client2-1  | {'eval_loss': 1.315976858139038, 'eval_runtime': 6.9868, 'eval_samples_per_second': 28.626, 'eval_steps_per_second': 3.578, 'epoch': 1.0}
2025-05-19 21:57:07 client2-1  | INFO :      Sent reply
2025-05-19 21:57:14 client2-1  | INFO :      
2025-05-19 21:57:14 client2-1  | INFO :      Received: train message 1c6b448a-d6e0-4740-9b65-d5680c246bc6
2025-05-19 21:57:25 client2-1  | {'loss': 0.4966, 'grad_norm': 8.323256492614746, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-19 21:58:33 client1-1  | {'loss': 0.7783, 'grad_norm': 12.853046417236328, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-19 21:58:43 client1-1  | {'loss': 0.7648, 'grad_norm': 11.462417602539062, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-19 21:58:53 client1-1  | {'loss': 0.7767, 'grad_norm': 9.158198356628418, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-19 21:59:06 client1-1  | {'loss': 0.8466, 'grad_norm': 9.176456451416016, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-19 21:59:16 client1-1  | {'loss': 0.7643, 'grad_norm': 8.783072471618652, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-19 21:59:26 client1-1  | {'loss': 0.7449, 'grad_norm': 7.557943820953369, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-19 21:57:38 client2-1  | {'loss': 0.6726, 'grad_norm': 12.173890113830566, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-19 21:57:48 client2-1  | {'loss': 0.6887, 'grad_norm': 11.783048629760742, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-19 21:59:35 client1-1  | {'loss': 0.8015, 'grad_norm': 11.98046588897705, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-19 21:59:49 client1-1  | {'loss': 0.8581, 'grad_norm': 6.967286109924316, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-19 21:57:58 client2-1  | {'loss': 0.6687, 'grad_norm': 9.960758209228516, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-19 21:58:08 client2-1  | {'loss': 0.7065, 'grad_norm': 9.68499755859375, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-19 21:58:21 client2-1  | {'loss': 0.7045, 'grad_norm': 10.126258850097656, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-19 21:58:31 client2-1  | {'loss': 0.8068, 'grad_norm': 11.002570152282715, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-19 21:58:41 client2-1  | {'loss': 0.9051, 'grad_norm': 9.315770149230957, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-19 21:58:54 client2-1  | {'loss': 0.8137, 'grad_norm': 11.523633003234863, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-19 21:59:59 client1-1  | {'loss': 0.9145, 'grad_norm': 10.219565391540527, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-19 22:00:08 client1-1  | {'loss': 0.8499, 'grad_norm': 9.852681159973145, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-19 21:59:04 client2-1  | {'loss': 0.829, 'grad_norm': 12.63362979888916, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-19 22:00:18 client1-1  | {'loss': 0.8838, 'grad_norm': 8.584291458129883, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-19 22:00:32 client1-1  | {'loss': 0.8177, 'grad_norm': 11.70569133758545, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-19 22:00:41 client1-1  | {'loss': 0.8143, 'grad_norm': 11.285833358764648, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-19 22:00:51 client1-1  | {'loss': 0.9332, 'grad_norm': 11.754698753356934, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-19 21:59:14 client2-1  | {'loss': 0.8248, 'grad_norm': 10.225377082824707, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-19 22:01:01 client1-1  | {'loss': 1.0026, 'grad_norm': 11.853936195373535, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-19 21:59:23 client2-1  | {'loss': 0.9099, 'grad_norm': 11.281805038452148, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-19 21:59:37 client2-1  | {'loss': 0.7942, 'grad_norm': 11.917525291442871, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-19 21:59:47 client2-1  | {'loss': 0.7821, 'grad_norm': 12.603915214538574, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-19 22:01:15 client1-1  | {'loss': 1.0533, 'grad_norm': 11.916986465454102, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-19 22:01:24 client1-1  | {'loss': 0.9412, 'grad_norm': 8.40044116973877, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-19 22:01:34 client1-1  | {'loss': 0.9636, 'grad_norm': 10.388983726501465, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-19 22:01:47 client1-1  | {'loss': 1.0012, 'grad_norm': 11.34060287475586, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-19 21:59:56 client2-1  | {'loss': 0.8967, 'grad_norm': 12.197171211242676, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-19 22:01:57 client1-1  | {'loss': 1.0391, 'grad_norm': 9.108601570129395, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-19 22:00:06 client2-1  | {'loss': 0.8183, 'grad_norm': 9.737065315246582, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-19 22:02:07 client1-1  | {'loss': 1.037, 'grad_norm': 10.658895492553711, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-19 22:02:16 client1-1  | {'loss': 0.9553, 'grad_norm': 8.9606351852417, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-19 22:02:30 client1-1  | {'loss': 1.1122, 'grad_norm': 12.83343505859375, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-19 22:00:20 client2-1  | {'loss': 0.8353, 'grad_norm': 9.494439125061035, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-19 22:02:40 client1-1  | {'loss': 1.0874, 'grad_norm': 10.598103523254395, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-19 22:00:29 client2-1  | {'loss': 0.8755, 'grad_norm': 10.710211753845215, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-19 22:02:50 client1-1  | {'loss': 1.1806, 'grad_norm': 14.09510326385498, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-19 22:02:59 client1-1  | {'loss': 1.0666, 'grad_norm': 11.242688179016113, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-19 22:03:13 client1-1  | {'loss': 1.2011, 'grad_norm': 10.936363220214844, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-19 22:00:39 client2-1  | {'loss': 0.8216, 'grad_norm': 9.999065399169922, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-19 22:00:49 client2-1  | {'loss': 1.0794, 'grad_norm': 8.519927024841309, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-19 22:01:02 client2-1  | {'loss': 0.8318, 'grad_norm': 9.933632850646973, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-19 22:03:23 client1-1  | {'loss': 1.193, 'grad_norm': 9.44682788848877, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-19 22:03:32 client1-1  | {'loss': 1.0887, 'grad_norm': 12.26136302947998, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-19 22:01:13 client2-1  | {'loss': 0.8331, 'grad_norm': 10.820300102233887, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-19 22:03:42 client1-1  | {'loss': 1.0707, 'grad_norm': 11.82306957244873, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-19 22:01:22 client2-1  | {'loss': 0.9145, 'grad_norm': 9.267352104187012, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-19 22:01:32 client2-1  | {'loss': 1.0996, 'grad_norm': 9.102652549743652, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-19 22:01:45 client2-1  | {'loss': 0.9561, 'grad_norm': 9.807397842407227, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-19 22:01:55 client2-1  | {'loss': 1.0913, 'grad_norm': 12.861555099487305, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-19 22:02:04 client2-1  | {'loss': 0.9999, 'grad_norm': 10.960318565368652, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-19 22:02:14 client2-1  | {'loss': 0.9782, 'grad_norm': 9.684760093688965, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-19 22:02:28 client2-1  | {'loss': 0.9979, 'grad_norm': 7.925026893615723, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-19 22:02:37 client2-1  | {'loss': 1.0328, 'grad_norm': 13.45937728881836, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-19 22:03:56 client1-1  | {'loss': 1.026, 'grad_norm': 11.667793273925781, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-19 22:04:05 client1-1  | {'loss': 1.1868, 'grad_norm': 8.273405075073242, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-19 22:04:15 client1-1  | {'loss': 0.907, 'grad_norm': 9.857008934020996, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-19 22:04:25 client1-1  | {'loss': 0.5986, 'grad_norm': 8.146554946899414, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-19 22:04:25 client1-1  | {'train_runtime': 427.9884, 'train_samples_per_second': 1.869, 'train_steps_per_second': 0.935, 'train_loss': 0.9161746180057526, 'epoch': 1.0}
2025-05-19 22:04:33 client1-1  | INFO :      Sent reply
2025-05-19 22:04:45 client1-1  | INFO :      
2025-05-19 22:04:45 client1-1  | INFO :      Received: evaluate message c4fd520d-2e54-4c1e-9810-efe681f2962d
2025-05-19 22:04:58 client1-1  | {'eval_loss': 1.3952716588974, 'eval_runtime': 11.5444, 'eval_samples_per_second': 17.324, 'eval_steps_per_second': 2.166, 'epoch': 1.0}
2025-05-19 22:04:58 client1-1  | INFO :      Sent reply
2025-05-19 22:05:02 client1-1  | INFO :      
2025-05-19 22:02:47 client2-1  | {'loss': 1.0904, 'grad_norm': 9.600123405456543, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-19 22:02:57 client2-1  | {'loss': 1.2111, 'grad_norm': 11.176173210144043, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-19 22:05:02 client1-1  | INFO :      Received: train message 91df5604-3f7f-4d08-ac07-946fc835a012
2025-05-19 22:05:22 client1-1  | {'loss': 0.4024, 'grad_norm': 12.820623397827148, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-19 22:05:31 client1-1  | {'loss': 0.4433, 'grad_norm': 13.069499015808105, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-19 22:05:41 client1-1  | {'loss': 0.505, 'grad_norm': 8.495305061340332, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-19 22:03:11 client2-1  | {'loss': 1.33, 'grad_norm': 10.596264839172363, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-19 22:03:21 client2-1  | {'loss': 1.3275, 'grad_norm': 14.350841522216797, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-19 22:03:30 client2-1  | {'loss': 1.0913, 'grad_norm': 11.2418212890625, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-19 22:05:51 client1-1  | {'loss': 0.541, 'grad_norm': 10.471700668334961, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-19 22:03:44 client2-1  | {'loss': 1.1338, 'grad_norm': 9.051799774169922, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-19 22:06:05 client1-1  | {'loss': 0.6123, 'grad_norm': 12.428766250610352, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-19 22:03:54 client2-1  | {'loss': 1.1555, 'grad_norm': 13.556404113769531, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-19 22:06:15 client1-1  | {'loss': 0.5465, 'grad_norm': 10.06138801574707, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-19 22:06:25 client1-1  | {'loss': 0.5744, 'grad_norm': 12.082083702087402, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-19 22:04:03 client2-1  | {'loss': 1.1679, 'grad_norm': 12.837728500366211, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-19 22:04:17 client2-1  | {'loss': 1.0084, 'grad_norm': 12.307862281799316, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-19 22:04:27 client2-1  | {'loss': 0.6458, 'grad_norm': 8.399918556213379, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-19 22:04:27 client2-1  | {'train_runtime': 432.1543, 'train_samples_per_second': 1.851, 'train_steps_per_second': 0.926, 'train_loss': 0.9206824195384979, 'epoch': 1.0}
2025-05-19 22:04:34 client2-1  | INFO :      Sent reply
2025-05-19 22:04:45 client2-1  | INFO :      
2025-05-19 22:04:45 client2-1  | INFO :      Received: evaluate message 3b435e19-a4fa-40b6-8f53-6e70f0c5c2e2
2025-05-19 22:06:38 client1-1  | {'loss': 0.5534, 'grad_norm': 9.81873893737793, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-19 22:06:48 client1-1  | {'loss': 0.6027, 'grad_norm': 10.560687065124512, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-19 22:04:57 client2-1  | {'eval_loss': 1.3498566150665283, 'eval_runtime': 11.494, 'eval_samples_per_second': 17.4, 'eval_steps_per_second': 2.175, 'epoch': 1.0}
2025-05-19 22:04:57 client2-1  | INFO :      Sent reply
2025-05-19 22:05:02 client2-1  | INFO :      
2025-05-19 22:05:02 client2-1  | INFO :      Received: train message 49f8c0fb-cc43-4e86-bb8a-e9cccb546a1e
2025-05-19 22:05:15 client2-1  | {'loss': 0.3173, 'grad_norm': 6.691844463348389, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-19 22:05:29 client2-1  | {'loss': 0.4571, 'grad_norm': 10.8958101272583, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-19 22:05:39 client2-1  | {'loss': 0.4691, 'grad_norm': 9.034096717834473, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-19 22:05:48 client2-1  | {'loss': 0.4673, 'grad_norm': 6.611781120300293, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-19 22:05:58 client2-1  | {'loss': 0.5203, 'grad_norm': 8.947614669799805, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-19 22:06:58 client1-1  | {'loss': 0.6377, 'grad_norm': 9.310453414916992, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-19 22:07:08 client1-1  | {'loss': 0.5733, 'grad_norm': 7.601502895355225, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-19 22:07:21 client1-1  | {'loss': 0.5517, 'grad_norm': 7.485018253326416, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-19 22:06:12 client2-1  | {'loss': 0.5303, 'grad_norm': 8.585323333740234, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-19 22:06:22 client2-1  | {'loss': 0.6061, 'grad_norm': 10.98798942565918, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-19 22:07:31 client1-1  | {'loss': 0.6136, 'grad_norm': 11.293865203857422, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-19 22:07:41 client1-1  | {'loss': 0.6784, 'grad_norm': 6.672890663146973, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-19 22:07:50 client1-1  | {'loss': 0.7135, 'grad_norm': 9.543757438659668, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-19 22:06:31 client2-1  | {'loss': 0.6734, 'grad_norm': 9.655182838439941, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-19 22:08:04 client1-1  | {'loss': 0.6648, 'grad_norm': 9.329462051391602, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-19 22:06:41 client2-1  | {'loss': 0.6196, 'grad_norm': 10.448259353637695, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-19 22:06:55 client2-1  | {'loss': 0.6108, 'grad_norm': 11.224895477294922, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-19 22:08:14 client1-1  | {'loss': 0.6845, 'grad_norm': 8.021354675292969, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-19 22:07:05 client2-1  | {'loss': 0.611, 'grad_norm': 9.05972957611084, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-19 22:07:15 client2-1  | {'loss': 0.6891, 'grad_norm': 10.2525634765625, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-19 22:08:24 client1-1  | {'loss': 0.6298, 'grad_norm': 11.461196899414062, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-19 22:08:33 client1-1  | {'loss': 0.6651, 'grad_norm': 9.522793769836426, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-19 22:08:47 client1-1  | {'loss': 0.7668, 'grad_norm': 12.025917053222656, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-19 22:07:28 client2-1  | {'loss': 0.6065, 'grad_norm': 10.730223655700684, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-19 22:07:38 client2-1  | {'loss': 0.609, 'grad_norm': 11.49425983428955, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-19 22:08:56 client1-1  | {'loss': 0.8243, 'grad_norm': 11.686386108398438, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-19 22:09:06 client1-1  | {'loss': 0.9007, 'grad_norm': 12.390223503112793, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-19 22:09:20 client1-1  | {'loss': 0.7592, 'grad_norm': 9.113480567932129, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-19 22:09:29 client1-1  | {'loss': 0.8287, 'grad_norm': 9.952770233154297, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-19 22:09:39 client1-1  | {'loss': 0.8556, 'grad_norm': 12.57077693939209, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-19 22:09:49 client1-1  | {'loss': 0.9097, 'grad_norm': 10.477749824523926, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-19 22:07:48 client2-1  | {'loss': 0.6987, 'grad_norm': 10.858344078063965, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-19 22:08:02 client2-1  | {'loss': 0.6416, 'grad_norm': 10.919306755065918, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-19 22:08:11 client2-1  | {'loss': 0.6523, 'grad_norm': 9.597764015197754, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-19 22:08:21 client2-1  | {'loss': 0.7122, 'grad_norm': 10.325018882751465, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-19 22:08:31 client2-1  | {'loss': 0.6787, 'grad_norm': 10.122397422790527, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-19 22:08:44 client2-1  | {'loss': 0.894, 'grad_norm': 8.02126407623291, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-19 22:10:02 client1-1  | {'loss': 0.899, 'grad_norm': 11.00040340423584, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-19 22:10:12 client1-1  | {'loss': 0.8563, 'grad_norm': 8.750011444091797, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-19 22:10:22 client1-1  | {'loss': 1.0035, 'grad_norm': 14.162145614624023, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-19 22:08:54 client2-1  | {'loss': 0.6894, 'grad_norm': 10.970135688781738, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-19 22:10:32 client1-1  | {'loss': 0.9829, 'grad_norm': 11.0617036819458, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-19 22:10:45 client1-1  | {'loss': 1.0739, 'grad_norm': 12.648807525634766, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-19 22:09:04 client2-1  | {'loss': 0.6833, 'grad_norm': 15.25362777709961, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-19 22:10:55 client1-1  | {'loss': 1.0074, 'grad_norm': 10.777449607849121, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-19 22:11:05 client1-1  | {'loss': 1.1356, 'grad_norm': 10.578815460205078, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-19 22:11:15 client1-1  | {'loss': 1.1591, 'grad_norm': 10.355609893798828, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-19 22:11:28 client1-1  | {'loss': 1.028, 'grad_norm': 12.185575485229492, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-19 22:11:38 client1-1  | {'loss': 1.0156, 'grad_norm': 10.737515449523926, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-19 22:09:13 client2-1  | {'loss': 0.7735, 'grad_norm': 8.779211044311523, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-19 22:09:27 client2-1  | {'loss': 0.9367, 'grad_norm': 8.897405624389648, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-19 22:11:48 client1-1  | {'loss': 1.0019, 'grad_norm': 12.441594123840332, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-19 22:09:36 client2-1  | {'loss': 0.8118, 'grad_norm': 10.182997703552246, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-19 22:11:57 client1-1  | {'loss': 1.1335, 'grad_norm': 9.054261207580566, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-19 22:12:11 client1-1  | {'loss': 0.8125, 'grad_norm': 8.417426109313965, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-19 22:09:46 client2-1  | {'loss': 0.9566, 'grad_norm': 14.38769817352295, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-19 22:09:56 client2-1  | {'loss': 0.8907, 'grad_norm': 9.91710090637207, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-19 22:10:09 client2-1  | {'loss': 0.8623, 'grad_norm': 10.040773391723633, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-19 22:10:19 client2-1  | {'loss': 0.8975, 'grad_norm': 7.483434200286865, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-19 22:12:21 client1-1  | {'loss': 0.488, 'grad_norm': 8.469572067260742, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-19 22:12:21 client1-1  | {'train_runtime': 434.7125, 'train_samples_per_second': 1.84, 'train_steps_per_second': 0.92, 'train_loss': 0.7658849942684174, 'epoch': 1.0}
2025-05-19 22:10:29 client2-1  | {'loss': 0.912, 'grad_norm': 14.630880355834961, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-19 22:10:39 client2-1  | {'loss': 0.9926, 'grad_norm': 8.749459266662598, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-19 22:10:52 client2-1  | {'loss': 1.1097, 'grad_norm': 11.290421485900879, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-19 22:12:25 client1-1  | INFO :      Sent reply
2025-05-19 22:12:37 client1-1  | INFO :      
2025-05-19 22:12:37 client1-1  | INFO :      Received: evaluate message 9594e6cb-25e7-4060-9658-24c50c75620a
2025-05-19 22:12:48 client1-1  | {'eval_loss': 1.4300217628479004, 'eval_runtime': 10.9733, 'eval_samples_per_second': 18.226, 'eval_steps_per_second': 2.278, 'epoch': 1.0}
2025-05-19 22:11:02 client2-1  | {'loss': 1.2564, 'grad_norm': 10.388688087463379, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-19 22:11:12 client2-1  | {'loss': 1.2606, 'grad_norm': 14.205547332763672, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-19 22:11:22 client2-1  | {'loss': 1.0515, 'grad_norm': 14.999049186706543, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-19 22:11:35 client2-1  | {'loss': 1.1035, 'grad_norm': 10.290188789367676, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-19 22:11:45 client2-1  | {'loss': 1.1202, 'grad_norm': 13.725208282470703, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-19 22:11:55 client2-1  | {'loss': 1.1176, 'grad_norm': 12.894729614257812, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-19 22:12:04 client2-1  | {'loss': 0.9293, 'grad_norm': 11.836440086364746, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-19 22:12:18 client2-1  | {'loss': 0.54, 'grad_norm': 7.207558631896973, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-19 22:12:18 client2-1  | {'train_runtime': 434.2579, 'train_samples_per_second': 1.842, 'train_steps_per_second': 0.921, 'train_loss': 0.7739799404144287, 'epoch': 1.0}
2025-05-19 22:12:23 client2-1  | INFO :      Sent reply
2025-05-19 22:12:48 client1-1  | INFO :      Sent reply
2025-05-19 22:12:54 client1-1  | INFO :      
2025-05-19 22:12:36 client2-1  | INFO :      
2025-05-19 22:12:36 client2-1  | INFO :      Received: evaluate message b0f2df33-184c-4bfe-bd2a-e1bdc5158b4c
2025-05-19 22:12:54 client1-1  | INFO :      Received: train message 5fd56678-b554-4fd1-9986-66620d4ff283
2025-05-19 22:12:49 client2-1  | {'eval_loss': 1.3877944946289062, 'eval_runtime': 11.3907, 'eval_samples_per_second': 17.558, 'eval_steps_per_second': 2.195, 'epoch': 1.0}
2025-05-19 22:13:11 client1-1  | {'loss': 0.2538, 'grad_norm': 9.854759216308594, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-19 22:13:21 client1-1  | {'loss': 0.3044, 'grad_norm': 11.631836891174316, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-19 22:13:31 client1-1  | {'loss': 0.3601, 'grad_norm': 7.820141792297363, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-19 22:13:40 client1-1  | {'loss': 0.3703, 'grad_norm': 7.012182235717773, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-19 22:12:49 client2-1  | INFO :      Sent reply
2025-05-19 22:13:54 client1-1  | {'loss': 0.4636, 'grad_norm': 15.805635452270508, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-19 22:14:04 client1-1  | {'loss': 0.4084, 'grad_norm': 11.438249588012695, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-19 22:14:14 client1-1  | {'loss': 0.4241, 'grad_norm': 10.924671173095703, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-19 22:14:23 client1-1  | {'loss': 0.41, 'grad_norm': 8.650117874145508, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-19 22:14:37 client1-1  | {'loss': 0.4575, 'grad_norm': 8.032136917114258, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-19 22:14:47 client1-1  | {'loss': 0.4704, 'grad_norm': 7.791923999786377, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-19 22:12:55 client2-1  | INFO :      
2025-05-19 22:12:55 client2-1  | INFO :      Received: train message e23c08aa-cf8c-4b28-8874-bc6a2805cd31
2025-05-19 22:14:57 client1-1  | {'loss': 0.4268, 'grad_norm': 7.249383449554443, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-19 22:15:07 client1-1  | {'loss': 0.4165, 'grad_norm': 6.913347244262695, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-19 22:15:21 client1-1  | {'loss': 0.4507, 'grad_norm': 11.000382423400879, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-19 22:13:13 client2-1  | {'loss': 0.1953, 'grad_norm': 4.701920032501221, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-19 22:13:23 client2-1  | {'loss': 0.2932, 'grad_norm': 11.074020385742188, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-19 22:13:33 client2-1  | {'loss': 0.3161, 'grad_norm': 8.740823745727539, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-19 22:13:47 client2-1  | {'loss': 0.3099, 'grad_norm': 6.836973190307617, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-19 22:13:57 client2-1  | {'loss': 0.3542, 'grad_norm': 9.999842643737793, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-19 22:14:06 client2-1  | {'loss': 0.3802, 'grad_norm': 6.481639385223389, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-19 22:15:30 client1-1  | {'loss': 0.516, 'grad_norm': 6.952590465545654, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-19 22:15:40 client1-1  | {'loss': 0.5468, 'grad_norm': 8.914732933044434, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-19 22:15:50 client1-1  | {'loss': 0.5027, 'grad_norm': 7.83793830871582, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-19 22:16:03 client1-1  | {'loss': 0.5413, 'grad_norm': 7.631152153015137, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-19 22:16:13 client1-1  | {'loss': 0.4971, 'grad_norm': 10.885692596435547, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-19 22:16:23 client1-1  | {'loss': 0.5193, 'grad_norm': 10.081140518188477, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-19 22:16:33 client1-1  | {'loss': 0.6341, 'grad_norm': 11.616239547729492, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-19 22:16:46 client1-1  | {'loss': 0.6674, 'grad_norm': 10.53507137298584, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-19 22:16:56 client1-1  | {'loss': 0.7507, 'grad_norm': 13.862869262695312, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-19 22:17:06 client1-1  | {'loss': 0.6435, 'grad_norm': 7.700535774230957, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-19 22:17:16 client1-1  | {'loss': 0.6906, 'grad_norm': 9.156842231750488, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-19 22:17:30 client1-1  | {'loss': 0.7284, 'grad_norm': 11.698246002197266, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-19 22:17:40 client1-1  | {'loss': 0.763, 'grad_norm': 9.47888469696045, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-19 22:14:16 client2-1  | {'loss': 0.4199, 'grad_norm': 10.585611343383789, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-19 22:14:30 client2-1  | {'loss': 0.4824, 'grad_norm': 7.603935718536377, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-19 22:14:40 client2-1  | {'loss': 0.4627, 'grad_norm': 12.535714149475098, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-19 22:14:50 client2-1  | {'loss': 0.4814, 'grad_norm': 11.645744323730469, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-19 22:17:49 client1-1  | {'loss': 0.8016, 'grad_norm': 9.72630500793457, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-19 22:17:59 client1-1  | {'loss': 0.7328, 'grad_norm': 8.889607429504395, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-19 22:18:13 client1-1  | {'loss': 0.8791, 'grad_norm': 14.787583351135254, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-19 22:18:23 client1-1  | {'loss': 0.8957, 'grad_norm': 10.622830390930176, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-19 22:18:33 client1-1  | {'loss': 0.9798, 'grad_norm': 12.975730895996094, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-19 22:18:43 client1-1  | {'loss': 0.932, 'grad_norm': 12.524632453918457, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-19 22:15:00 client2-1  | {'loss': 0.4607, 'grad_norm': 9.046867370605469, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-19 22:15:13 client2-1  | {'loss': 0.5073, 'grad_norm': 8.38771915435791, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-19 22:15:23 client2-1  | {'loss': 0.4422, 'grad_norm': 10.059892654418945, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-19 22:18:57 client1-1  | {'loss': 1.0934, 'grad_norm': 10.800402641296387, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-19 22:19:07 client1-1  | {'loss': 1.0944, 'grad_norm': 10.229162216186523, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-19 22:15:33 client2-1  | {'loss': 0.4729, 'grad_norm': 10.391289710998535, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-19 22:19:16 client1-1  | {'loss': 1.0015, 'grad_norm': 12.332111358642578, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-19 22:15:43 client2-1  | {'loss': 0.5235, 'grad_norm': 11.864968299865723, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-19 22:15:56 client2-1  | {'loss': 0.5224, 'grad_norm': 8.09363079071045, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-19 22:19:26 client1-1  | {'loss': 0.9813, 'grad_norm': 10.428547859191895, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-19 22:19:40 client1-1  | {'loss': 0.9895, 'grad_norm': 12.941828727722168, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-19 22:19:50 client1-1  | {'loss': 1.086, 'grad_norm': 9.283498764038086, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-19 22:20:00 client1-1  | {'loss': 0.7363, 'grad_norm': 8.219487190246582, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-19 22:16:06 client2-1  | {'loss': 0.5094, 'grad_norm': 10.366538047790527, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-19 22:16:16 client2-1  | {'loss': 0.5638, 'grad_norm': 10.434895515441895, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-19 22:20:10 client1-1  | {'loss': 0.3797, 'grad_norm': 7.551234722137451, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-19 22:20:10 client1-1  | {'train_runtime': 434.1112, 'train_samples_per_second': 1.843, 'train_steps_per_second': 0.921, 'train_loss': 0.645015857219696, 'epoch': 1.0}
2025-05-19 22:20:17 client1-1  | INFO :      Sent reply
2025-05-19 22:16:30 client2-1  | {'loss': 0.5489, 'grad_norm': 9.646598815917969, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-19 22:20:32 client1-1  | INFO :      
2025-05-19 22:20:32 client1-1  | INFO :      Received: evaluate message 01470cce-d6bd-4a5d-98f0-e8e7ccfd6a49
2025-05-19 22:20:45 client1-1  | {'eval_loss': 1.4729269742965698, 'eval_runtime': 11.0775, 'eval_samples_per_second': 18.055, 'eval_steps_per_second': 2.257, 'epoch': 1.0}
2025-05-19 22:20:45 client1-1  | INFO :      Sent reply
2025-05-19 22:20:47 client1-1  | INFO :      
2025-05-19 22:20:47 client1-1  | INFO :      Received: reconnect message 2630a5f4-9c2f-46b7-ba2b-3ad8e1eeee62
2025-05-19 22:20:47 client1-1  | INFO :      Disconnect and shut down
2025-05-19 22:16:39 client2-1  | {'loss': 0.7321, 'grad_norm': 9.223023414611816, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-19 22:16:49 client2-1  | {'loss': 0.5661, 'grad_norm': 10.274593353271484, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-19 22:16:59 client2-1  | {'loss': 0.5762, 'grad_norm': 10.298903465270996, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-19 22:17:13 client2-1  | {'loss': 0.6315, 'grad_norm': 8.021410942077637, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-19 22:17:23 client2-1  | {'loss': 0.7896, 'grad_norm': 11.537708282470703, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-19 22:17:33 client2-1  | {'loss': 0.6781, 'grad_norm': 10.335805892944336, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-19 22:17:43 client2-1  | {'loss': 0.8497, 'grad_norm': 14.671294212341309, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-19 22:17:56 client2-1  | {'loss': 0.7762, 'grad_norm': 11.32373046875, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-19 22:18:06 client2-1  | {'loss': 0.7529, 'grad_norm': 11.194236755371094, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-19 22:18:16 client2-1  | {'loss': 0.8043, 'grad_norm': 8.335582733154297, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-19 22:18:26 client2-1  | {'loss': 0.8278, 'grad_norm': 12.483955383300781, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-19 22:18:40 client2-1  | {'loss': 0.909, 'grad_norm': 10.050858497619629, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-19 22:18:50 client2-1  | {'loss': 1.0497, 'grad_norm': 12.529306411743164, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-19 22:19:00 client2-1  | {'loss': 1.1864, 'grad_norm': 10.975589752197266, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-19 22:19:10 client2-1  | {'loss': 1.2064, 'grad_norm': 12.729923248291016, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-19 22:19:23 client2-1  | {'loss': 1.0083, 'grad_norm': 11.830711364746094, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-19 22:19:33 client2-1  | {'loss': 1.0778, 'grad_norm': 12.095139503479004, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-19 22:19:43 client2-1  | {'loss': 1.0692, 'grad_norm': 15.788616180419922, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-19 22:19:53 client2-1  | {'loss': 1.0837, 'grad_norm': 14.878055572509766, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-19 22:20:07 client2-1  | {'loss': 0.8404, 'grad_norm': 11.088014602661133, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-19 22:20:16 client2-1  | {'loss': 0.4409, 'grad_norm': 5.666486740112305, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-19 22:20:16 client2-1  | {'train_runtime': 438.853, 'train_samples_per_second': 1.823, 'train_steps_per_second': 0.911, 'train_loss': 0.6525749158859253, 'epoch': 1.0}
2025-05-19 22:20:20 client2-1  | INFO :      Sent reply
2025-05-19 22:20:32 client2-1  | INFO :      
2025-05-19 22:20:32 client2-1  | INFO :      Received: evaluate message a31b9efd-f84f-45eb-a8b0-552ac09b9a97
2025-05-19 22:20:46 client2-1  | {'eval_loss': 1.4297178983688354, 'eval_runtime': 13.2485, 'eval_samples_per_second': 15.096, 'eval_steps_per_second': 1.887, 'epoch': 1.0}
2025-05-19 22:20:46 client2-1  | INFO :      Sent reply
2025-05-19 22:20:47 client2-1  | INFO :      
2025-05-19 22:20:47 client2-1  | INFO :      Received: reconnect message eeee8109-0ad0-4339-9e49-1dad81915d50
2025-05-19 22:20:47 client2-1  | INFO :      Disconnect and shut down
