2025-05-20 22:18:59 
Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]
Generating train split: 100%|██████████| 120000/120000 [00:00<00:00, 1232812.06 examples/s]
2025-05-20 22:18:59 
Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]
Generating test split: 100%|██████████| 7600/7600 [00:00<00:00, 1147180.71 examples/s]
2025-05-20 22:19:01 
Map:   0%|          | 0/500 [00:00<?, ? examples/s]
Map: 100%|██████████| 500/500 [00:00<00:00, 851.72 examples/s]
Map: 100%|██████████| 500/500 [00:00<00:00, 847.22 examples/s]
2025-05-20 22:19:01 
Map:   0%|          | 0/500 [00:00<?, ? examples/s]
Map:  39%|███▊      | 193/500 [00:00<00:00, 1897.02 examples/s]
Map:  97%|█████████▋| 485/500 [00:00<00:00, 1921.74 examples/s]
Map: 100%|██████████| 500/500 [00:00<00:00, 1828.93 examples/s]
2025-05-20 22:19:01 /app/client.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-05-20 22:19:01   trainer = Trainer(
2025-05-20 22:19:02 WARNING :   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
2025-05-20 22:19:02 Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
2025-05-20 22:19:02 flwr.client.start_client(
2025-05-20 22:19:02 server_address='<IP>:<PORT>',
2025-05-20 22:19:02 client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
2025-05-20 22:19:02 )
2025-05-20 22:19:02 Using `start_numpy_client()` is deprecated.
2025-05-20 22:19:02 
2025-05-20 22:19:02             This is a deprecated feature. It will be removed
2025-05-20 22:19:02             entirely in future versions of Flower.
2025-05-20 22:19:02         
2025-05-20 22:19:02 WARNING :   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
2025-05-20 22:19:02 Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:
2025-05-20 22:19:02 
2025-05-20 22:19:02 $ flower-supernode --insecure --superlink='<IP>:<PORT>'
2025-05-20 22:19:02 
2025-05-20 22:19:02 To view all available options, run:
2025-05-20 22:19:02 
2025-05-20 22:19:02 $ flower-supernode --help
2025-05-20 22:19:02 
2025-05-20 22:19:02 Using `start_client()` is deprecated.
2025-05-20 22:19:02 
2025-05-20 22:19:02             This is a deprecated feature. It will be removed
2025-05-20 22:19:02             entirely in future versions of Flower.
2025-05-20 22:19:02         
2025-05-20 22:23:48 INFO :      
2025-05-20 22:23:48 INFO :      Received: evaluate message ec1be414-8338-45d4-86ad-f08037f55d95
2025-05-20 22:23:59 INFO :      Sent reply
2025-05-20 22:24:06 INFO :      
2025-05-20 22:24:06 INFO :      Received: train message be4199f8-3699-4f7c-b67a-9e5e548fcb8b
2025-05-20 22:29:35 INFO :      Sent reply
2025-05-20 22:29:57 INFO :      
2025-05-20 22:29:57 INFO :      Received: evaluate message 88ffda73-a038-4d90-b313-d22e8b650cd7
2025-05-20 22:29:59 INFO :      Sent reply
2025-05-20 22:30:14 INFO :      
2025-05-20 22:30:14 INFO :      Received: train message 696d9a3b-1824-47ac-9a09-f3c0f46c5f6e
2025-05-20 22:35:45 INFO :      Sent reply
2025-05-20 22:36:08 INFO :      
2025-05-20 22:36:08 INFO :      Received: evaluate message 75842c7d-86a1-4cf1-9656-448344b87860
2025-05-20 22:36:13 INFO :      Sent reply
2025-05-20 22:36:28 INFO :      
2025-05-20 22:36:28 INFO :      Received: train message e8c2d6b3-819f-4a6f-bdc7-b70220119f6d
2025-05-20 22:41:59 INFO :      Sent reply
2025-05-20 22:42:27 INFO :      
2025-05-20 22:42:27 INFO :      Received: evaluate message efec1be0-bf69-4013-ad1c-ed75a54781df
2025-05-20 22:42:29 INFO :      Sent reply
2025-05-20 22:42:48 INFO :      
2025-05-20 22:42:48 INFO :      Received: train message df2da7bd-8d4a-4479-80fa-206d036e7ba8
2025-05-20 22:48:23 INFO :      Sent reply
2025-05-20 22:48:47 INFO :      
2025-05-20 22:48:47 INFO :      Received: evaluate message 6fe6c158-1dfb-4ca9-b290-b718c8cf2108
2025-05-20 22:48:54 INFO :      Sent reply
2025-05-20 22:48:57 INFO :      
2025-05-20 22:48:57 INFO :      Received: reconnect message 59160869-67a9-4692-9101-434d5b1fd6e7
2025-05-20 22:48:57 INFO :      Disconnect and shut down
2025-05-20 22:23:59 {'eval_loss': 1.330309271812439, 'eval_model_preparation_time': 0.0041, 'eval_runtime': 8.4829, 'eval_samples_per_second': 11.788, 'eval_steps_per_second': 1.532}
2025-05-20 22:25:01 {'loss': 1.4334, 'grad_norm': 12.057268142700195, 'learning_rate': 4.775e-05, 'epoch': 0.05}
2025-05-20 22:25:16 {'loss': 1.5005, 'grad_norm': 16.170360565185547, 'learning_rate': 4.525e-05, 'epoch': 0.1}
2025-05-20 22:25:37 {'loss': 1.437, 'grad_norm': 11.34149169921875, 'learning_rate': 4.275e-05, 'epoch': 0.15}
2025-05-20 22:25:51 {'loss': 1.5719, 'grad_norm': 11.998580932617188, 'learning_rate': 4.025e-05, 'epoch': 0.2}
2025-05-20 22:26:06 {'loss': 1.6301, 'grad_norm': 13.504171371459961, 'learning_rate': 3.775e-05, 'epoch': 0.25}
2025-05-20 22:26:21 {'loss': 1.5787, 'grad_norm': 10.845495223999023, 'learning_rate': 3.525e-05, 'epoch': 0.3}
2025-05-20 22:26:35 {'loss': 1.3399, 'grad_norm': 12.928462028503418, 'learning_rate': 3.275e-05, 'epoch': 0.35}
2025-05-20 22:26:50 {'loss': 1.4845, 'grad_norm': 13.29612922668457, 'learning_rate': 3.025e-05, 'epoch': 0.4}
2025-05-20 22:27:11 {'loss': 1.4176, 'grad_norm': 11.36730670928955, 'learning_rate': 2.7750000000000004e-05, 'epoch': 0.45}
2025-05-20 22:27:26 {'loss': 1.3988, 'grad_norm': 11.95416259765625, 'learning_rate': 2.525e-05, 'epoch': 0.5}
2025-05-20 22:27:40 {'loss': 1.4693, 'grad_norm': 14.249791145324707, 'learning_rate': 2.275e-05, 'epoch': 0.55}
2025-05-20 22:27:54 {'loss': 1.3025, 'grad_norm': 11.392168045043945, 'learning_rate': 2.025e-05, 'epoch': 0.6}
2025-05-20 22:28:09 {'loss': 1.4665, 'grad_norm': 13.276397705078125, 'learning_rate': 1.775e-05, 'epoch': 0.65}
2025-05-20 22:28:24 {'loss': 1.4678, 'grad_norm': 12.534749031066895, 'learning_rate': 1.525e-05, 'epoch': 0.7}
2025-05-20 22:28:39 {'loss': 1.2522, 'grad_norm': 12.515143394470215, 'learning_rate': 1.2750000000000002e-05, 'epoch': 0.75}
2025-05-20 22:29:00 {'loss': 1.3445, 'grad_norm': 10.832265853881836, 'learning_rate': 1.025e-05, 'epoch': 0.8}
2025-05-20 22:29:14 {'loss': 1.3992, 'grad_norm': 12.76572322845459, 'learning_rate': 7.75e-06, 'epoch': 0.85}
2025-05-20 22:29:27 {'loss': 1.558, 'grad_norm': 13.873610496520996, 'learning_rate': 5.25e-06, 'epoch': 0.9}
2025-05-20 22:29:29 {'loss': 1.433, 'grad_norm': 13.799908638000488, 'learning_rate': 2.7500000000000004e-06, 'epoch': 0.95}
2025-05-20 22:29:31 {'loss': 1.5066, 'grad_norm': 14.549973487854004, 'learning_rate': 2.5000000000000004e-07, 'epoch': 1.0}
2025-05-20 22:29:31 {'train_runtime': 321.6847, 'train_samples_per_second': 1.243, 'train_steps_per_second': 0.622, 'train_loss': 1.449602608680725, 'epoch': 1.0}
2025-05-20 22:29:59 {'eval_loss': 1.315942406654358, 'eval_model_preparation_time': 0.0041, 'eval_runtime': 1.2688, 'eval_samples_per_second': 78.813, 'eval_steps_per_second': 10.246, 'epoch': 1.0}
2025-05-20 22:30:42 {'loss': 0.8419, 'grad_norm': 9.147128105163574, 'learning_rate': 4.775e-05, 'epoch': 0.05}
2025-05-20 22:30:56 {'loss': 1.094, 'grad_norm': 16.438222885131836, 'learning_rate': 4.525e-05, 'epoch': 0.1}
2025-05-20 22:31:17 {'loss': 1.117, 'grad_norm': 9.76750659942627, 'learning_rate': 4.275e-05, 'epoch': 0.15}
2025-05-20 22:31:32 {'loss': 1.2239, 'grad_norm': 9.555747985839844, 'learning_rate': 4.025e-05, 'epoch': 0.2}
2025-05-20 22:31:46 {'loss': 1.2728, 'grad_norm': 10.724247932434082, 'learning_rate': 3.775e-05, 'epoch': 0.25}
2025-05-20 22:32:01 {'loss': 1.2786, 'grad_norm': 9.833939552307129, 'learning_rate': 3.525e-05, 'epoch': 0.3}
2025-05-20 22:32:16 {'loss': 1.0721, 'grad_norm': 11.988424301147461, 'learning_rate': 3.275e-05, 'epoch': 0.35}
2025-05-20 22:32:36 {'loss': 1.1961, 'grad_norm': 12.723313331604004, 'learning_rate': 3.025e-05, 'epoch': 0.4}
2025-05-20 22:32:51 {'loss': 1.1739, 'grad_norm': 9.472513198852539, 'learning_rate': 2.7750000000000004e-05, 'epoch': 0.45}
2025-05-20 22:33:05 {'loss': 1.133, 'grad_norm': 9.833765029907227, 'learning_rate': 2.525e-05, 'epoch': 0.5}
2025-05-20 22:33:20 {'loss': 1.2168, 'grad_norm': 12.495821952819824, 'learning_rate': 2.275e-05, 'epoch': 0.55}
2025-05-20 22:33:35 {'loss': 1.0983, 'grad_norm': 9.885758399963379, 'learning_rate': 2.025e-05, 'epoch': 0.6}
2025-05-20 22:33:55 {'loss': 1.2705, 'grad_norm': 13.675877571105957, 'learning_rate': 1.775e-05, 'epoch': 0.65}
2025-05-20 22:34:10 {'loss': 1.2776, 'grad_norm': 12.371026992797852, 'learning_rate': 1.525e-05, 'epoch': 0.7}
2025-05-20 22:34:24 {'loss': 1.1041, 'grad_norm': 13.703899383544922, 'learning_rate': 1.2750000000000002e-05, 'epoch': 0.75}
2025-05-20 22:34:39 {'loss': 1.1789, 'grad_norm': 9.2692289352417, 'learning_rate': 1.025e-05, 'epoch': 0.8}
2025-05-20 22:34:54 {'loss': 1.2456, 'grad_norm': 10.39271068572998, 'learning_rate': 7.75e-06, 'epoch': 0.85}
2025-05-20 22:35:15 {'loss': 1.3478, 'grad_norm': 10.27834415435791, 'learning_rate': 5.25e-06, 'epoch': 0.9}
2025-05-20 22:35:30 {'loss': 1.0951, 'grad_norm': 9.91811752319336, 'learning_rate': 2.7500000000000004e-06, 'epoch': 0.95}
2025-05-20 22:35:40 {'loss': 0.8569, 'grad_norm': 9.287147521972656, 'learning_rate': 2.5000000000000004e-07, 'epoch': 1.0}
2025-05-20 22:35:40 {'train_runtime': 320.209, 'train_samples_per_second': 1.249, 'train_steps_per_second': 0.625, 'train_loss': 1.1547541475296021, 'epoch': 1.0}
2025-05-20 22:36:13 {'eval_loss': 1.3354878425598145, 'eval_model_preparation_time': 0.0041, 'eval_runtime': 3.5776, 'eval_samples_per_second': 27.951, 'eval_steps_per_second': 3.634, 'epoch': 1.0}
2025-05-20 22:36:53 {'loss': 0.5768, 'grad_norm': 8.73552417755127, 'learning_rate': 4.775e-05, 'epoch': 0.05}
2025-05-20 22:37:07 {'loss': 0.7927, 'grad_norm': 14.948393821716309, 'learning_rate': 4.525e-05, 'epoch': 0.1}
2025-05-20 22:37:28 {'loss': 0.8399, 'grad_norm': 8.817142486572266, 'learning_rate': 4.275e-05, 'epoch': 0.15}
2025-05-20 22:37:43 {'loss': 0.9931, 'grad_norm': 9.320465087890625, 'learning_rate': 4.025e-05, 'epoch': 0.2}
2025-05-20 22:37:57 {'loss': 1.0657, 'grad_norm': 14.345667839050293, 'learning_rate': 3.775e-05, 'epoch': 0.25}
2025-05-20 22:38:12 {'loss': 1.0507, 'grad_norm': 10.006302833557129, 'learning_rate': 3.525e-05, 'epoch': 0.3}
2025-05-20 22:38:27 {'loss': 0.8605, 'grad_norm': 13.422338485717773, 'learning_rate': 3.275e-05, 'epoch': 0.35}
2025-05-20 22:38:42 {'loss': 0.9765, 'grad_norm': 13.652304649353027, 'learning_rate': 3.025e-05, 'epoch': 0.4}
2025-05-20 22:39:02 {'loss': 1.0074, 'grad_norm': 9.382882118225098, 'learning_rate': 2.7750000000000004e-05, 'epoch': 0.45}
2025-05-20 22:39:16 {'loss': 0.9482, 'grad_norm': 11.28031063079834, 'learning_rate': 2.525e-05, 'epoch': 0.5}
2025-05-20 22:39:31 {'loss': 1.0696, 'grad_norm': 11.936710357666016, 'learning_rate': 2.275e-05, 'epoch': 0.55}
2025-05-20 22:39:46 {'loss': 0.98, 'grad_norm': 8.625252723693848, 'learning_rate': 2.025e-05, 'epoch': 0.6}
2025-05-20 22:40:01 {'loss': 1.1646, 'grad_norm': 13.134865760803223, 'learning_rate': 1.775e-05, 'epoch': 0.65}
2025-05-20 22:40:16 {'loss': 1.1726, 'grad_norm': 12.263569831848145, 'learning_rate': 1.525e-05, 'epoch': 0.7}
2025-05-20 22:40:36 {'loss': 1.0469, 'grad_norm': 13.084567070007324, 'learning_rate': 1.2750000000000002e-05, 'epoch': 0.75}
2025-05-20 22:40:51 {'loss': 1.1203, 'grad_norm': 9.799983024597168, 'learning_rate': 1.025e-05, 'epoch': 0.8}
2025-05-20 22:41:06 {'loss': 1.173, 'grad_norm': 10.823609352111816, 'learning_rate': 7.75e-06, 'epoch': 0.85}
2025-05-20 22:41:20 {'loss': 1.284, 'grad_norm': 12.210872650146484, 'learning_rate': 5.25e-06, 'epoch': 0.9}
2025-05-20 22:41:35 {'loss': 1.0017, 'grad_norm': 10.560254096984863, 'learning_rate': 2.7500000000000004e-06, 'epoch': 0.95}
2025-05-20 22:41:55 {'loss': 0.7549, 'grad_norm': 12.409324645996094, 'learning_rate': 2.5000000000000004e-07, 'epoch': 1.0}
2025-05-20 22:41:55 {'train_runtime': 323.0907, 'train_samples_per_second': 1.238, 'train_steps_per_second': 0.619, 'train_loss': 0.9939471888542175, 'epoch': 1.0}
2025-05-20 22:42:29 {'eval_loss': 1.3580067157745361, 'eval_model_preparation_time': 0.0041, 'eval_runtime': 1.2256, 'eval_samples_per_second': 81.591, 'eval_steps_per_second': 10.607, 'epoch': 1.0}
2025-05-20 22:43:15 {'loss': 0.3906, 'grad_norm': 7.723138332366943, 'learning_rate': 4.775e-05, 'epoch': 0.05}
2025-05-20 22:43:29 {'loss': 0.5955, 'grad_norm': 17.7659854888916, 'learning_rate': 4.525e-05, 'epoch': 0.1}
2025-05-20 22:43:44 {'loss': 0.6319, 'grad_norm': 8.532001495361328, 'learning_rate': 4.275e-05, 'epoch': 0.15}
2025-05-20 22:43:58 {'loss': 0.7844, 'grad_norm': 8.587265014648438, 'learning_rate': 4.025e-05, 'epoch': 0.2}
2025-05-20 22:44:19 {'loss': 0.8364, 'grad_norm': 12.229105949401855, 'learning_rate': 3.775e-05, 'epoch': 0.25}
2025-05-20 22:44:34 {'loss': 0.8762, 'grad_norm': 10.585867881774902, 'learning_rate': 3.525e-05, 'epoch': 0.3}
2025-05-20 22:44:49 {'loss': 0.7157, 'grad_norm': 13.95870590209961, 'learning_rate': 3.275e-05, 'epoch': 0.35}
2025-05-20 22:45:03 {'loss': 0.8424, 'grad_norm': 13.710562705993652, 'learning_rate': 3.025e-05, 'epoch': 0.4}
2025-05-20 22:45:18 {'loss': 0.8539, 'grad_norm': 8.596327781677246, 'learning_rate': 2.7750000000000004e-05, 'epoch': 0.45}
2025-05-20 22:45:33 {'loss': 0.8092, 'grad_norm': 9.765705108642578, 'learning_rate': 2.525e-05, 'epoch': 0.5}
2025-05-20 22:45:54 {'loss': 0.9178, 'grad_norm': 11.809721946716309, 'learning_rate': 2.275e-05, 'epoch': 0.55}
2025-05-20 22:46:09 {'loss': 0.8634, 'grad_norm': 8.42884349822998, 'learning_rate': 2.025e-05, 'epoch': 0.6}
2025-05-20 22:46:23 {'loss': 1.0521, 'grad_norm': 12.692302703857422, 'learning_rate': 1.775e-05, 'epoch': 0.65}
2025-05-20 22:46:38 {'loss': 1.0673, 'grad_norm': 12.522231101989746, 'learning_rate': 1.525e-05, 'epoch': 0.7}
2025-05-20 22:46:53 {'loss': 0.9632, 'grad_norm': 13.37452507019043, 'learning_rate': 1.2750000000000002e-05, 'epoch': 0.75}
2025-05-20 22:47:08 {'loss': 1.0381, 'grad_norm': 10.308818817138672, 'learning_rate': 1.025e-05, 'epoch': 0.8}
2025-05-20 22:47:29 {'loss': 1.1181, 'grad_norm': 11.65084457397461, 'learning_rate': 7.75e-06, 'epoch': 0.85}
2025-05-20 22:47:44 {'loss': 1.227, 'grad_norm': 11.444906234741211, 'learning_rate': 5.25e-06, 'epoch': 0.9}
2025-05-20 22:47:58 {'loss': 0.9258, 'grad_norm': 14.157212257385254, 'learning_rate': 2.7500000000000004e-06, 'epoch': 0.95}
2025-05-20 22:48:13 {'loss': 0.6334, 'grad_norm': 9.545594215393066, 'learning_rate': 2.5000000000000004e-07, 'epoch': 1.0}
2025-05-20 22:48:13 {'train_runtime': 320.0095, 'train_samples_per_second': 1.25, 'train_steps_per_second': 0.625, 'train_loss': 0.8571233117580414, 'epoch': 1.0}
2025-05-20 22:48:54 {'eval_loss': 1.3898907899856567, 'eval_model_preparation_time': 0.0041, 'eval_runtime': 5.416, 'eval_samples_per_second': 18.464, 'eval_steps_per_second': 2.4, 'epoch': 1.0}
