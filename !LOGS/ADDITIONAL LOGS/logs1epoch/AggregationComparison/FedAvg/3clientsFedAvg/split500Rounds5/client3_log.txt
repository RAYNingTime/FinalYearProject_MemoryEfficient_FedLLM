2025-05-20 22:19:45 
Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]
Generating train split: 100%|██████████| 120000/120000 [00:00<00:00, 1212956.93 examples/s]
2025-05-20 22:19:45 
Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]
Generating test split: 100%|██████████| 7600/7600 [00:00<00:00, 1070838.16 examples/s]
2025-05-20 22:19:47 
Map:   0%|          | 0/500 [00:00<?, ? examples/s]
Map: 100%|██████████| 500/500 [00:00<00:00, 1271.54 examples/s]
Map: 100%|██████████| 500/500 [00:00<00:00, 1263.20 examples/s]
2025-05-20 22:19:47 
Map:   0%|          | 0/500 [00:00<?, ? examples/s]
Map:  68%|██████▊   | 341/500 [00:00<00:00, 3375.55 examples/s]
Map: 100%|██████████| 500/500 [00:00<00:00, 3061.97 examples/s]
2025-05-20 22:19:47 /app/client.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-05-20 22:19:47   trainer = Trainer(
2025-05-20 22:19:47 WARNING :   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
2025-05-20 22:19:47 Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
2025-05-20 22:19:47 flwr.client.start_client(
2025-05-20 22:19:47 server_address='<IP>:<PORT>',
2025-05-20 22:19:47 client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
2025-05-20 22:19:47 )
2025-05-20 22:19:47 Using `start_numpy_client()` is deprecated.
2025-05-20 22:19:47 
2025-05-20 22:19:47             This is a deprecated feature. It will be removed
2025-05-20 22:19:47             entirely in future versions of Flower.
2025-05-20 22:19:47         
2025-05-20 22:19:47 WARNING :   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
2025-05-20 22:19:47 Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:
2025-05-20 22:19:47 
2025-05-20 22:19:47 $ flower-supernode --insecure --superlink='<IP>:<PORT>'
2025-05-20 22:19:47 
2025-05-20 22:19:47 To view all available options, run:
2025-05-20 22:19:47 
2025-05-20 22:19:47 $ flower-supernode --help
2025-05-20 22:19:47 
2025-05-20 22:19:47 Using `start_client()` is deprecated.
2025-05-20 22:19:47 
2025-05-20 22:19:47             This is a deprecated feature. It will be removed
2025-05-20 22:19:47             entirely in future versions of Flower.
2025-05-20 22:19:47         
2025-05-20 22:19:55 INFO :      
2025-05-20 22:19:55 INFO :      Received: train message 74d67b56-fa54-46c2-8c20-3c56b230e9e1
2025-05-20 22:23:30 INFO :      Sent reply
2025-05-20 22:23:48 INFO :      
2025-05-20 22:23:48 INFO :      Received: evaluate message 80e8cf4e-ad0a-4a82-8bb9-66104ad46c0b
2025-05-20 22:23:58 INFO :      Sent reply
2025-05-20 22:24:06 INFO :      
2025-05-20 22:24:06 INFO :      Received: train message 28d1f07c-9fb5-4adb-bde4-112109ab32ca
2025-05-20 22:29:23 INFO :      Sent reply
2025-05-20 22:29:59 INFO :      
2025-05-20 22:29:59 INFO :      Received: evaluate message 0e194b6e-2efa-46c0-9192-e8e2e534c694
2025-05-20 22:30:05 INFO :      Sent reply
2025-05-20 22:30:14 INFO :      
2025-05-20 22:30:14 INFO :      Received: train message 7837e66a-0fcd-4d2e-9d28-0bd1704c4aae
2025-05-20 22:35:44 INFO :      Sent reply
2025-05-20 22:36:10 INFO :      
2025-05-20 22:36:10 INFO :      Received: evaluate message e64098f0-9153-4155-919c-e0b293beb7fc
2025-05-20 22:36:16 INFO :      Sent reply
2025-05-20 22:36:26 INFO :      
2025-05-20 22:36:26 INFO :      Received: train message e05d72d8-c172-416f-9656-6b5cda018669
2025-05-20 22:20:13 {'loss': 2.7273, 'grad_norm': 19.855600357055664, 'learning_rate': 4.775e-05, 'epoch': 0.05}
2025-05-20 22:20:22 {'loss': 1.4855, 'grad_norm': 22.519296646118164, 'learning_rate': 4.525e-05, 'epoch': 0.1}
2025-05-20 22:20:32 {'loss': 1.5193, 'grad_norm': 15.460755348205566, 'learning_rate': 4.275e-05, 'epoch': 0.15}
2025-05-20 22:20:41 {'loss': 1.2862, 'grad_norm': 10.602859497070312, 'learning_rate': 4.025e-05, 'epoch': 0.2}
2025-05-20 22:20:51 {'loss': 1.4832, 'grad_norm': 13.925564765930176, 'learning_rate': 3.775e-05, 'epoch': 0.25}
2025-05-20 22:21:04 {'loss': 1.5081, 'grad_norm': 12.256221771240234, 'learning_rate': 3.525e-05, 'epoch': 0.3}
2025-05-20 22:21:13 {'loss': 1.4804, 'grad_norm': 15.975773811340332, 'learning_rate': 3.275e-05, 'epoch': 0.35}
2025-05-20 22:21:23 {'loss': 1.4159, 'grad_norm': 9.689958572387695, 'learning_rate': 3.025e-05, 'epoch': 0.4}
2025-05-20 22:21:32 {'loss': 1.5447, 'grad_norm': 12.63994026184082, 'learning_rate': 2.7750000000000004e-05, 'epoch': 0.45}
2025-05-20 22:21:42 {'loss': 1.6107, 'grad_norm': 11.019096374511719, 'learning_rate': 2.525e-05, 'epoch': 0.5}
2025-05-20 22:21:52 {'loss': 1.3785, 'grad_norm': 12.136575698852539, 'learning_rate': 2.275e-05, 'epoch': 0.55}
2025-05-20 22:22:05 {'loss': 1.4658, 'grad_norm': 15.09681510925293, 'learning_rate': 2.025e-05, 'epoch': 0.6}
2025-05-20 22:22:15 {'loss': 1.3622, 'grad_norm': 11.668242454528809, 'learning_rate': 1.775e-05, 'epoch': 0.65}
2025-05-20 22:22:24 {'loss': 1.4117, 'grad_norm': 11.7955322265625, 'learning_rate': 1.525e-05, 'epoch': 0.7}
2025-05-20 22:22:34 {'loss': 1.3894, 'grad_norm': 18.214454650878906, 'learning_rate': 1.2750000000000002e-05, 'epoch': 0.75}
2025-05-20 22:22:43 {'loss': 1.3864, 'grad_norm': 13.759998321533203, 'learning_rate': 1.025e-05, 'epoch': 0.8}
2025-05-20 22:22:53 {'loss': 1.378, 'grad_norm': 12.021543502807617, 'learning_rate': 7.75e-06, 'epoch': 0.85}
2025-05-20 22:23:06 {'loss': 1.3844, 'grad_norm': 10.676137924194336, 'learning_rate': 5.25e-06, 'epoch': 0.9}
2025-05-20 22:23:16 {'loss': 1.3726, 'grad_norm': 13.201231956481934, 'learning_rate': 2.7500000000000004e-06, 'epoch': 0.95}
2025-05-20 22:23:25 {'loss': 1.3212, 'grad_norm': 12.545743942260742, 'learning_rate': 2.5000000000000004e-07, 'epoch': 1.0}
2025-05-20 22:23:25 {'train_runtime': 209.0818, 'train_samples_per_second': 1.913, 'train_steps_per_second': 0.957, 'train_loss': 1.4955673170089723, 'epoch': 1.0}
2025-05-20 22:23:58 {'eval_loss': 1.3453035354614258, 'eval_runtime': 7.8834, 'eval_samples_per_second': 12.685, 'eval_steps_per_second': 1.649, 'epoch': 1.0}
2025-05-20 22:24:21 {'loss': 0.9085, 'grad_norm': 11.077601432800293, 'learning_rate': 4.775e-05, 'epoch': 0.05}
2025-05-20 22:24:32 {'loss': 0.8958, 'grad_norm': 13.063883781433105, 'learning_rate': 4.525e-05, 'epoch': 0.1}
2025-05-20 22:24:44 {'loss': 0.996, 'grad_norm': 12.73843765258789, 'learning_rate': 4.275e-05, 'epoch': 0.15}
2025-05-20 22:24:59 {'loss': 0.883, 'grad_norm': 8.24838638305664, 'learning_rate': 4.025e-05, 'epoch': 0.2}
2025-05-20 22:25:14 {'loss': 1.0497, 'grad_norm': 11.61842155456543, 'learning_rate': 3.775e-05, 'epoch': 0.25}
2025-05-20 22:25:28 {'loss': 1.1106, 'grad_norm': 9.674396514892578, 'learning_rate': 3.525e-05, 'epoch': 0.3}
2025-05-20 22:25:49 {'loss': 1.0599, 'grad_norm': 14.384034156799316, 'learning_rate': 3.275e-05, 'epoch': 0.35}
2025-05-20 22:26:03 {'loss': 1.0657, 'grad_norm': 8.205831527709961, 'learning_rate': 3.025e-05, 'epoch': 0.4}
2025-05-20 22:26:18 {'loss': 1.1672, 'grad_norm': 10.478656768798828, 'learning_rate': 2.7750000000000004e-05, 'epoch': 0.45}
2025-05-20 22:26:33 {'loss': 1.2612, 'grad_norm': 10.868825912475586, 'learning_rate': 2.525e-05, 'epoch': 0.5}
2025-05-20 22:26:54 {'loss': 1.1048, 'grad_norm': 11.091965675354004, 'learning_rate': 2.275e-05, 'epoch': 0.55}
2025-05-20 22:27:09 {'loss': 1.1637, 'grad_norm': 12.482251167297363, 'learning_rate': 2.025e-05, 'epoch': 0.6}
2025-05-20 22:27:23 {'loss': 1.1099, 'grad_norm': 11.182555198669434, 'learning_rate': 1.775e-05, 'epoch': 0.65}
2025-05-20 22:27:38 {'loss': 1.179, 'grad_norm': 10.60455322265625, 'learning_rate': 1.525e-05, 'epoch': 0.7}
2025-05-20 22:27:52 {'loss': 1.157, 'grad_norm': 14.131426811218262, 'learning_rate': 1.2750000000000002e-05, 'epoch': 0.75}
2025-05-20 22:28:13 {'loss': 1.2139, 'grad_norm': 13.189794540405273, 'learning_rate': 1.025e-05, 'epoch': 0.8}
2025-05-20 22:28:29 {'loss': 1.2098, 'grad_norm': 12.52882194519043, 'learning_rate': 7.75e-06, 'epoch': 0.85}
2025-05-20 22:28:44 {'loss': 1.198, 'grad_norm': 10.3051118850708, 'learning_rate': 5.25e-06, 'epoch': 0.9}
2025-05-20 22:29:05 {'loss': 1.0415, 'grad_norm': 9.042678833007812, 'learning_rate': 2.7500000000000004e-06, 'epoch': 0.95}
2025-05-20 22:29:19 {'loss': 0.7608, 'grad_norm': 8.854924201965332, 'learning_rate': 2.5000000000000004e-07, 'epoch': 1.0}
2025-05-20 22:29:19 {'train_runtime': 312.4679, 'train_samples_per_second': 1.28, 'train_steps_per_second': 0.64, 'train_loss': 1.0768018007278441, 'epoch': 1.0}
2025-05-20 22:30:05 {'eval_loss': 1.3410640954971313, 'eval_runtime': 3.3198, 'eval_samples_per_second': 30.122, 'eval_steps_per_second': 3.916, 'epoch': 1.0}
2025-05-20 22:30:30 {'loss': 0.6124, 'grad_norm': 10.733572006225586, 'learning_rate': 4.775e-05, 'epoch': 0.05}
2025-05-20 22:30:51 {'loss': 0.6541, 'grad_norm': 13.671296119689941, 'learning_rate': 4.525e-05, 'epoch': 0.1}
2025-05-20 22:31:06 {'loss': 0.7594, 'grad_norm': 12.571823120117188, 'learning_rate': 4.275e-05, 'epoch': 0.15}
2025-05-20 22:31:20 {'loss': 0.6967, 'grad_norm': 7.660477638244629, 'learning_rate': 4.025e-05, 'epoch': 0.2}
2025-05-20 22:31:35 {'loss': 0.8518, 'grad_norm': 10.316977500915527, 'learning_rate': 3.775e-05, 'epoch': 0.25}
2025-05-20 22:31:49 {'loss': 0.904, 'grad_norm': 9.237899780273438, 'learning_rate': 3.525e-05, 'epoch': 0.3}
2025-05-20 22:32:10 {'loss': 0.8568, 'grad_norm': 14.770864486694336, 'learning_rate': 3.275e-05, 'epoch': 0.35}
2025-05-20 22:32:25 {'loss': 0.872, 'grad_norm': 8.23262882232666, 'learning_rate': 3.025e-05, 'epoch': 0.4}
2025-05-20 22:32:39 {'loss': 0.9797, 'grad_norm': 10.256229400634766, 'learning_rate': 2.7750000000000004e-05, 'epoch': 0.45}
2025-05-20 22:32:54 {'loss': 1.0997, 'grad_norm': 9.682330131530762, 'learning_rate': 2.525e-05, 'epoch': 0.5}
2025-05-20 22:33:15 {'loss': 0.9468, 'grad_norm': 11.493680953979492, 'learning_rate': 2.275e-05, 'epoch': 0.55}
2025-05-20 22:33:29 {'loss': 1.0389, 'grad_norm': 13.082148551940918, 'learning_rate': 2.025e-05, 'epoch': 0.6}
2025-05-20 22:33:44 {'loss': 0.9929, 'grad_norm': 10.215933799743652, 'learning_rate': 1.775e-05, 'epoch': 0.65}
2025-05-20 22:33:58 {'loss': 1.085, 'grad_norm': 10.157007217407227, 'learning_rate': 1.525e-05, 'epoch': 0.7}
2025-05-20 22:34:13 {'loss': 1.0737, 'grad_norm': 15.419146537780762, 'learning_rate': 1.2750000000000002e-05, 'epoch': 0.75}
2025-05-20 22:34:34 {'loss': 1.128, 'grad_norm': 13.056960105895996, 'learning_rate': 1.025e-05, 'epoch': 0.8}
2025-05-20 22:34:48 {'loss': 1.1568, 'grad_norm': 12.350025177001953, 'learning_rate': 7.75e-06, 'epoch': 0.85}
2025-05-20 22:35:03 {'loss': 1.1094, 'grad_norm': 10.279952049255371, 'learning_rate': 5.25e-06, 'epoch': 0.9}
2025-05-20 22:35:18 {'loss': 0.9304, 'grad_norm': 9.69640064239502, 'learning_rate': 2.7500000000000004e-06, 'epoch': 0.95}
2025-05-20 22:35:33 {'loss': 0.6456, 'grad_norm': 10.706035614013672, 'learning_rate': 2.5000000000000004e-07, 'epoch': 1.0}
2025-05-20 22:35:33 {'train_runtime': 317.4295, 'train_samples_per_second': 1.26, 'train_steps_per_second': 0.63, 'train_loss': 0.919699604511261, 'epoch': 1.0}
2025-05-20 22:36:16 {'eval_loss': 1.361717939376831, 'eval_runtime': 5.1615, 'eval_samples_per_second': 19.374, 'eval_steps_per_second': 2.519, 'epoch': 1.0}
2025-05-20 22:36:41 {'loss': 0.4191, 'grad_norm': 9.033382415771484, 'learning_rate': 4.775e-05, 'epoch': 0.05}
2025-05-20 22:37:02 {'loss': 0.4687, 'grad_norm': 13.935415267944336, 'learning_rate': 4.525e-05, 'epoch': 0.1}
2025-05-20 22:37:16 {'loss': 0.5871, 'grad_norm': 9.608573913574219, 'learning_rate': 4.275e-05, 'epoch': 0.15}
2025-05-20 22:37:31 {'loss': 0.534, 'grad_norm': 6.719240188598633, 'learning_rate': 4.025e-05, 'epoch': 0.2}
2025-05-20 22:37:46 {'loss': 0.6629, 'grad_norm': 9.90251350402832, 'learning_rate': 3.775e-05, 'epoch': 0.25}
2025-05-20 22:38:07 {'loss': 0.7464, 'grad_norm': 8.947917938232422, 'learning_rate': 3.525e-05, 'epoch': 0.3}
2025-05-20 22:38:21 {'loss': 0.7191, 'grad_norm': 12.035051345825195, 'learning_rate': 3.275e-05, 'epoch': 0.35}
2025-05-20 22:38:36 {'loss': 0.7235, 'grad_norm': 6.588593482971191, 'learning_rate': 3.025e-05, 'epoch': 0.4}
2025-05-20 22:38:51 {'loss': 0.8484, 'grad_norm': 9.742281913757324, 'learning_rate': 2.7750000000000004e-05, 'epoch': 0.45}
2025-05-20 22:39:05 {'loss': 0.9362, 'grad_norm': 10.652653694152832, 'learning_rate': 2.525e-05, 'epoch': 0.5}
2025-05-20 22:39:26 {'loss': 0.8211, 'grad_norm': 12.783280372619629, 'learning_rate': 2.275e-05, 'epoch': 0.55}
2025-05-20 22:39:41 {'loss': 0.9297, 'grad_norm': 10.855188369750977, 'learning_rate': 2.025e-05, 'epoch': 0.6}
2025-05-20 22:39:55 {'loss': 0.8913, 'grad_norm': 10.54240608215332, 'learning_rate': 1.775e-05, 'epoch': 0.65}
2025-05-20 22:40:11 {'loss': 0.9682, 'grad_norm': 9.404738426208496, 'learning_rate': 1.525e-05, 'epoch': 0.7}
2025-05-20 22:40:25 {'loss': 1.0018, 'grad_norm': 12.915942192077637, 'learning_rate': 1.2750000000000002e-05, 'epoch': 0.75}
2025-05-20 22:40:46 {'loss': 1.0769, 'grad_norm': 13.969083786010742, 'learning_rate': 1.025e-05, 'epoch': 0.8}
2025-05-20 22:41:01 {'loss': 1.1014, 'grad_norm': 11.904402732849121, 'learning_rate': 7.75e-06, 'epoch': 0.85}
2025-05-20 22:41:15 {'loss': 1.0242, 'grad_norm': 10.32941722869873, 'learning_rate': 5.25e-06, 'epoch': 0.9}
2025-05-20 22:41:30 {'loss': 0.871, 'grad_norm': 9.760957717895508, 'learning_rate': 2.7500000000000004e-06, 'epoch': 0.95}
2025-05-20 22:41:44 {'loss': 0.5933, 'grad_norm': 12.07997989654541, 'learning_rate': 2.5000000000000004e-07, 'epoch': 1.0}
2025-05-20 22:41:44 {'train_runtime': 316.3861, 'train_samples_per_second': 1.264, 'train_steps_per_second': 0.632, 'train_loss': 0.7962157273292542, 'epoch': 1.0}
2025-05-20 22:42:41 {'eval_loss': 1.38985276222229, 'eval_runtime': 5.5474, 'eval_samples_per_second': 18.026, 'eval_steps_per_second': 2.343, 'epoch': 1.0}
2025-05-20 22:43:12 {'loss': 0.2949, 'grad_norm': 6.421786785125732, 'learning_rate': 4.775e-05, 'epoch': 0.05}
2025-05-20 22:43:27 {'loss': 0.3351, 'grad_norm': 15.875602722167969, 'learning_rate': 4.525e-05, 'epoch': 0.1}
2025-05-20 22:43:41 {'loss': 0.4519, 'grad_norm': 9.346441268920898, 'learning_rate': 4.275e-05, 'epoch': 0.15}
2025-05-20 22:44:02 {'loss': 0.4236, 'grad_norm': 7.8809285163879395, 'learning_rate': 4.025e-05, 'epoch': 0.2}
2025-05-20 22:44:17 {'loss': 0.5313, 'grad_norm': 7.912704944610596, 'learning_rate': 3.775e-05, 'epoch': 0.25}
2025-05-20 22:44:32 {'loss': 0.5803, 'grad_norm': 8.910787582397461, 'learning_rate': 3.525e-05, 'epoch': 0.3}
2025-05-20 22:44:46 {'loss': 0.6005, 'grad_norm': 11.752466201782227, 'learning_rate': 3.275e-05, 'epoch': 0.35}
2025-05-20 22:45:01 {'loss': 0.6179, 'grad_norm': 7.412156581878662, 'learning_rate': 3.025e-05, 'epoch': 0.4}
2025-05-20 22:45:16 {'loss': 0.711, 'grad_norm': 11.082528114318848, 'learning_rate': 2.7750000000000004e-05, 'epoch': 0.45}
2025-05-20 22:45:37 {'loss': 0.8108, 'grad_norm': 11.561310768127441, 'learning_rate': 2.525e-05, 'epoch': 0.5}
2025-05-20 22:45:52 {'loss': 0.7158, 'grad_norm': 9.467907905578613, 'learning_rate': 2.275e-05, 'epoch': 0.55}
2025-05-20 22:46:06 {'loss': 0.8488, 'grad_norm': 15.155372619628906, 'learning_rate': 2.025e-05, 'epoch': 0.6}
2025-05-20 22:46:21 {'loss': 0.7939, 'grad_norm': 10.689175605773926, 'learning_rate': 1.775e-05, 'epoch': 0.65}
2025-05-20 22:46:36 {'loss': 0.8816, 'grad_norm': 9.03781795501709, 'learning_rate': 1.525e-05, 'epoch': 0.7}
2025-05-20 22:46:51 {'loss': 0.9193, 'grad_norm': 13.385602951049805, 'learning_rate': 1.2750000000000002e-05, 'epoch': 0.75}
2025-05-20 22:47:12 {'loss': 1.0037, 'grad_norm': 14.41104507446289, 'learning_rate': 1.025e-05, 'epoch': 0.8}
2025-05-20 22:47:27 {'loss': 1.0421, 'grad_norm': 11.721979141235352, 'learning_rate': 7.75e-06, 'epoch': 0.85}
2025-05-20 22:47:42 {'loss': 0.9827, 'grad_norm': 9.297013282775879, 'learning_rate': 5.25e-06, 'epoch': 0.9}
2025-05-20 22:47:56 {'loss': 0.8028, 'grad_norm': 9.113593101501465, 'learning_rate': 2.7500000000000004e-06, 'epoch': 0.95}
2025-05-20 22:48:11 {'loss': 0.5222, 'grad_norm': 8.566123008728027, 'learning_rate': 2.5000000000000004e-07, 'epoch': 1.0}
2025-05-20 22:48:11 {'train_runtime': 319.2712, 'train_samples_per_second': 1.253, 'train_steps_per_second': 0.626, 'train_loss': 0.6935034203529358, 'epoch': 1.0}
2025-05-20 22:48:52 {'eval_loss': 1.4199409484863281, 'eval_runtime': 3.3648, 'eval_samples_per_second': 29.72, 'eval_steps_per_second': 3.864, 'epoch': 1.0}
2025-05-20 22:41:56 INFO :      Sent reply
2025-05-20 22:42:33 INFO :      
2025-05-20 22:42:33 INFO :      Received: evaluate message 038f6bc1-e45b-4a7e-a8cd-eff2d2ad1d93
2025-05-20 22:42:41 INFO :      Sent reply
2025-05-20 22:42:48 INFO :      
2025-05-20 22:42:48 INFO :      Received: train message 5ea7bfbf-43f4-47ad-81d4-9d0199b3661b
2025-05-20 22:48:22 INFO :      Sent reply
2025-05-20 22:48:47 INFO :      
2025-05-20 22:48:47 INFO :      Received: evaluate message 219c9e81-9b5e-44fa-adf5-d6a3bf9f680e
2025-05-20 22:48:52 INFO :      Sent reply
2025-05-20 22:48:57 INFO :      
2025-05-20 22:48:57 INFO :      Received: reconnect message 3389984e-7242-47e7-9206-d2bb4d5f1e5d
2025-05-20 22:48:57 INFO :      Disconnect and shut down
