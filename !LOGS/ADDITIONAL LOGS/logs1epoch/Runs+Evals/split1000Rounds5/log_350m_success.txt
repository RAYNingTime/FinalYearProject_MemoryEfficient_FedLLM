2025-05-13 23:41:51 client1-1  | 
Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]
Generating train split: 100%|██████████| 120000/120000 [00:00<00:00, 1213345.84 examples/s]
2025-05-13 23:41:51 client1-1  | 
Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]
Generating test split: 100%|██████████| 7600/7600 [00:00<00:00, 1127780.31 examples/s]
2025-05-13 23:41:53 client1-1  | 
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 1169.36 examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 1164.36 examples/s]
2025-05-13 23:41:54 client1-1  | 
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]
Map:  34%|███▎      | 335/1000 [00:00<00:00, 3317.52 examples/s]
Map:  75%|███████▌  | 753/1000 [00:00<00:00, 2945.35 examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 2827.26 examples/s]
2025-05-13 23:41:25 client2-1  | 
Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]
Generating train split:  75%|███████▌  | 90000/120000 [00:00<00:00, 887420.45 examples/s]
Generating train split: 100%|██████████| 120000/120000 [00:00<00:00, 990205.45 examples/s]
2025-05-13 23:41:54 client1-1  | /app/client.py:49: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-05-13 23:41:54 client1-1  |   trainer = Trainer(
2025-05-13 23:40:02 server-1   | WARNING :   DEPRECATED FEATURE: flwr.server.start_server() is deprecated.
2025-05-13 23:41:25 client2-1  | 
Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]
Generating test split: 100%|██████████| 7600/7600 [00:00<00:00, 997581.22 examples/s]
2025-05-13 23:40:02 server-1   | Instead, use the `flower-superlink` CLI command to start a SuperLink as shown below:
2025-05-13 23:40:02 server-1   | 
2025-05-13 23:41:54 client1-1  | WARNING :   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
2025-05-13 23:40:02 server-1   | $ flower-superlink --insecure
2025-05-13 23:41:54 client1-1  | Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
2025-05-13 23:41:54 client1-1  | flwr.client.start_client(
2025-05-13 23:41:54 client1-1  | server_address='<IP>:<PORT>',
2025-05-13 23:41:54 client1-1  | client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
2025-05-13 23:41:54 client1-1  | )
2025-05-13 23:40:02 server-1   | 
2025-05-13 23:41:27 client2-1  | 
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 1201.18 examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 1196.37 examples/s]
2025-05-13 23:40:02 server-1   | To view usage and all available options, run:
2025-05-13 23:41:54 client1-1  | Using `start_numpy_client()` is deprecated.
2025-05-13 23:41:54 client1-1  | 
2025-05-13 23:40:02 server-1   | 
2025-05-13 23:40:02 server-1   | $ flower-superlink --help
2025-05-13 23:40:02 server-1   | 
2025-05-13 23:41:28 client2-1  | 
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]
Map:  15%|█▍        | 147/1000 [00:00<00:00, 1442.25 examples/s]
Map:  32%|███▏      | 319/1000 [00:00<00:00, 1599.01 examples/s]
Map:  52%|█████▏    | 522/1000 [00:00<00:00, 1790.52 examples/s]
Map:  71%|███████   | 708/1000 [00:00<00:00, 1815.63 examples/s]
Map:  92%|█████████▏| 924/1000 [00:00<00:00, 1937.49 examples/s]
Map: 100%|██████████| 1000/1000 [00:00<00:00, 1798.17 examples/s]
2025-05-13 23:40:02 server-1   | Using `start_server()` is deprecated.
2025-05-13 23:40:02 server-1   | 
2025-05-13 23:41:54 client1-1  |             This is a deprecated feature. It will be removed
2025-05-13 23:40:02 server-1   |             This is a deprecated feature. It will be removed
2025-05-13 23:41:28 client2-1  | /app/client.py:49: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-05-13 23:41:54 client1-1  |             entirely in future versions of Flower.
2025-05-13 23:41:54 client1-1  |         
2025-05-13 23:41:54 client1-1  | WARNING :   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
2025-05-13 23:41:54 client1-1  | Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:
2025-05-13 23:41:54 client1-1  | 
2025-05-13 23:41:54 client1-1  | $ flower-supernode --insecure --superlink='<IP>:<PORT>'
2025-05-13 23:41:54 client1-1  | 
2025-05-13 23:41:54 client1-1  | To view all available options, run:
2025-05-13 23:41:28 client2-1  |   trainer = Trainer(
2025-05-13 23:41:28 client2-1  | WARNING :   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
2025-05-13 23:41:28 client2-1  | Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
2025-05-13 23:41:28 client2-1  | flwr.client.start_client(
2025-05-13 23:40:02 server-1   |             entirely in future versions of Flower.
2025-05-13 23:40:02 server-1   |         
2025-05-13 23:41:28 client2-1  | server_address='<IP>:<PORT>',
2025-05-13 23:40:02 server-1   | INFO :      Starting Flower server, config: num_rounds=5, no round_timeout
2025-05-13 23:40:02 server-1   | INFO :      Flower ECE: gRPC server running (5 rounds), SSL is disabled
2025-05-13 23:41:54 client1-1  | 
2025-05-13 23:41:28 client2-1  | client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
2025-05-13 23:41:54 client1-1  | $ flower-supernode --help
2025-05-13 23:41:28 client2-1  | )
2025-05-13 23:40:02 server-1   | INFO :      [INIT]
2025-05-13 23:41:54 client1-1  | 
2025-05-13 23:41:54 client1-1  | Using `start_client()` is deprecated.
2025-05-13 23:41:54 client1-1  | 
2025-05-13 23:41:28 client2-1  | Using `start_numpy_client()` is deprecated.
2025-05-13 23:41:28 client2-1  | 
2025-05-13 23:41:28 client2-1  |             This is a deprecated feature. It will be removed
2025-05-13 23:40:02 server-1   | INFO :      Requesting initial parameters from one random client
2025-05-13 23:41:28 client2-1  |             entirely in future versions of Flower.
2025-05-13 23:41:28 client2-1  |         
2025-05-13 23:41:54 client1-1  |             This is a deprecated feature. It will be removed
2025-05-13 23:41:54 client1-1  |             entirely in future versions of Flower.
2025-05-13 23:41:54 client1-1  |         
2025-05-13 23:42:02 client1-1  | INFO :      
2025-05-13 23:42:02 client1-1  | INFO :      Received: train message ec986cb5-8f17-45af-8f27-35c406a5c492
2025-05-13 23:41:28 client2-1  | WARNING :   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
2025-05-13 23:41:28 client2-1  | Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:
2025-05-13 23:41:28 client2-1  | 
2025-05-13 23:41:28 client2-1  | $ flower-supernode --insecure --superlink='<IP>:<PORT>'
2025-05-13 23:41:28 client2-1  | 
2025-05-13 23:41:33 server-1   | INFO :      Received initial parameters from one random client
2025-05-13 23:41:28 client2-1  | To view all available options, run:
2025-05-13 23:41:28 client2-1  | 
2025-05-13 23:41:33 server-1   | INFO :      Starting evaluation of initial global parameters
2025-05-13 23:42:17 client1-1  | {'loss': 2.8881, 'grad_norm': 14.509994506835938, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-13 23:42:26 client1-1  | {'loss': 1.5019, 'grad_norm': 14.819618225097656, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-13 23:41:28 client2-1  | $ flower-supernode --help
2025-05-13 23:42:40 client1-1  | {'loss': 1.5985, 'grad_norm': 15.61037826538086, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-13 23:41:28 client2-1  | 
2025-05-13 23:42:50 client1-1  | {'loss': 1.6348, 'grad_norm': 14.701266288757324, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-13 23:41:28 client2-1  | Using `start_client()` is deprecated.
2025-05-13 23:41:33 server-1   | INFO :      Evaluation returned no results (`None`)
2025-05-13 23:41:33 server-1   | INFO :      
2025-05-13 23:41:33 server-1   | INFO :      [ROUND 1]
2025-05-13 23:41:54 server-1   | INFO :      configure_fit: strategy sampled 2 clients (out of 2)
2025-05-13 23:49:23 server-1   | INFO :      aggregate_fit: received 2 results and 0 failures
2025-05-13 23:42:59 client1-1  | {'loss': 1.4699, 'grad_norm': 14.6150484085083, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-13 23:43:13 client1-1  | {'loss': 1.4855, 'grad_norm': 13.35883617401123, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-13 23:43:23 client1-1  | {'loss': 1.3618, 'grad_norm': 12.205069541931152, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-13 23:41:28 client2-1  | 
2025-05-13 23:41:28 client2-1  |             This is a deprecated feature. It will be removed
2025-05-13 23:41:28 client2-1  |             entirely in future versions of Flower.
2025-05-13 23:41:28 client2-1  |         
2025-05-13 23:41:29 client2-1  | INFO :      
2025-05-13 23:41:29 client2-1  | INFO :      Received: get_parameters message e43d3621-645a-462e-a4c6-f4a39331012f
2025-05-13 23:41:32 client2-1  | INFO :      Sent reply
2025-05-13 23:42:02 client2-1  | INFO :      
2025-05-13 23:42:02 client2-1  | INFO :      Received: train message 8fc56059-db2e-4a92-9aff-a917d0801f60
2025-05-13 23:42:18 client2-1  | {'loss': 2.8359, 'grad_norm': 11.833232879638672, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-13 23:42:28 client2-1  | {'loss': 1.6665, 'grad_norm': 14.772207260131836, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-13 23:42:38 client2-1  | {'loss': 1.472, 'grad_norm': 11.770669937133789, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-13 23:43:33 client1-1  | {'loss': 1.614, 'grad_norm': 19.53718376159668, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-13 23:42:51 client2-1  | {'loss': 1.5311, 'grad_norm': 12.373039245605469, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-13 23:43:43 client1-1  | {'loss': 1.551, 'grad_norm': 15.203873634338379, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-13 23:43:01 client2-1  | {'loss': 1.4826, 'grad_norm': 10.75456428527832, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-13 23:49:28 server-1   | WARNING :   No fit_metrics_aggregation_fn provided
2025-05-13 23:43:11 client2-1  | {'loss': 1.563, 'grad_norm': 15.278632164001465, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-13 23:49:29 server-1   | INFO :      configure_evaluate: strategy sampled 2 clients (out of 2)
2025-05-13 23:49:47 server-1   | INFO :      aggregate_evaluate: received 2 results and 0 failures
2025-05-13 23:49:47 server-1   | WARNING :   No evaluate_metrics_aggregation_fn provided
2025-05-13 23:43:56 client1-1  | {'loss': 1.5181, 'grad_norm': 11.805559158325195, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-13 23:44:06 client1-1  | {'loss': 1.3586, 'grad_norm': 11.884358406066895, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-13 23:44:16 client1-1  | {'loss': 1.4981, 'grad_norm': 11.677322387695312, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-13 23:44:29 client1-1  | {'loss': 1.4767, 'grad_norm': 13.01732349395752, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-13 23:44:39 client1-1  | {'loss': 1.4627, 'grad_norm': 12.452225685119629, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-13 23:49:47 server-1   | INFO :      
2025-05-13 23:44:49 client1-1  | {'loss': 1.3407, 'grad_norm': 11.896435737609863, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-13 23:49:47 server-1   | INFO :      [ROUND 2]
2025-05-13 23:49:47 server-1   | INFO :      configure_fit: strategy sampled 2 clients (out of 2)
2025-05-13 23:57:07 server-1   | INFO :      aggregate_fit: received 2 results and 0 failures
2025-05-13 23:44:59 client1-1  | {'loss': 1.4316, 'grad_norm': 14.44339656829834, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-13 23:45:12 client1-1  | {'loss': 1.3589, 'grad_norm': 22.32564926147461, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-13 23:45:22 client1-1  | {'loss': 1.5763, 'grad_norm': 13.0263090133667, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-13 23:45:32 client1-1  | {'loss': 1.5422, 'grad_norm': 11.287859916687012, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-13 23:45:45 client1-1  | {'loss': 1.3338, 'grad_norm': 11.656440734863281, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-13 23:43:21 client2-1  | {'loss': 1.5145, 'grad_norm': 11.560526847839355, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-13 23:43:31 client2-1  | {'loss': 1.5267, 'grad_norm': 14.481712341308594, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-13 23:43:44 client2-1  | {'loss': 1.4157, 'grad_norm': 13.701536178588867, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-13 23:43:54 client2-1  | {'loss': 1.568, 'grad_norm': 13.818229675292969, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-13 23:44:04 client2-1  | {'loss': 1.6816, 'grad_norm': 14.68148422241211, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-13 23:45:55 client1-1  | {'loss': 1.5389, 'grad_norm': 12.617303848266602, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-13 23:46:05 client1-1  | {'loss': 1.4654, 'grad_norm': 13.942719459533691, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-13 23:44:13 client2-1  | {'loss': 1.509, 'grad_norm': 15.683237075805664, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-13 23:46:15 client1-1  | {'loss': 1.5022, 'grad_norm': 11.127248764038086, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-13 23:57:12 server-1   | INFO :      configure_evaluate: strategy sampled 2 clients (out of 2)
2025-05-13 23:57:29 server-1   | INFO :      aggregate_evaluate: received 2 results and 0 failures
2025-05-13 23:57:29 server-1   | INFO :      
2025-05-13 23:44:27 client2-1  | {'loss': 1.6139, 'grad_norm': 16.126102447509766, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-13 23:44:37 client2-1  | {'loss': 1.507, 'grad_norm': 15.058356285095215, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-13 23:46:28 client1-1  | {'loss': 1.6261, 'grad_norm': 12.480464935302734, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-13 23:46:38 client1-1  | {'loss': 1.3646, 'grad_norm': 12.778524398803711, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-13 23:46:48 client1-1  | {'loss': 1.5365, 'grad_norm': 10.834339141845703, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-13 23:44:46 client2-1  | {'loss': 1.3192, 'grad_norm': 10.670262336730957, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-13 23:46:58 client1-1  | {'loss': 1.3852, 'grad_norm': 14.60623836517334, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-13 23:47:11 client1-1  | {'loss': 1.3839, 'grad_norm': 12.616031646728516, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-13 23:47:21 client1-1  | {'loss': 1.3374, 'grad_norm': 10.387107849121094, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-13 23:47:31 client1-1  | {'loss': 1.2998, 'grad_norm': 12.058984756469727, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-13 23:44:56 client2-1  | {'loss': 1.3443, 'grad_norm': 8.939628601074219, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-13 23:47:41 client1-1  | {'loss': 1.5231, 'grad_norm': 18.011005401611328, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-13 23:45:10 client2-1  | {'loss': 1.5009, 'grad_norm': 17.373714447021484, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-13 23:47:54 client1-1  | {'loss': 1.46, 'grad_norm': 13.534549713134766, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-13 23:48:04 client1-1  | {'loss': 1.4107, 'grad_norm': 11.492597579956055, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-13 23:48:14 client1-1  | {'loss': 1.3381, 'grad_norm': 12.21127700805664, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-13 23:45:19 client2-1  | {'loss': 1.3822, 'grad_norm': 14.767770767211914, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-13 23:48:24 client1-1  | {'loss': 1.4224, 'grad_norm': 8.008515357971191, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-13 23:45:29 client2-1  | {'loss': 1.4896, 'grad_norm': 13.010076522827148, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-13 23:48:38 client1-1  | {'loss': 1.3499, 'grad_norm': 7.949653148651123, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-13 23:48:47 client1-1  | {'loss': 1.1974, 'grad_norm': 8.139845848083496, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-13 23:57:29 server-1   | INFO :      [ROUND 3]
2025-05-13 23:57:29 server-1   | INFO :      configure_fit: strategy sampled 2 clients (out of 2)
2025-05-14 00:04:55 server-1   | INFO :      aggregate_fit: received 2 results and 0 failures
2025-05-13 23:48:57 client1-1  | {'loss': 1.3152, 'grad_norm': 15.366461753845215, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-13 23:49:07 client1-1  | {'loss': 1.4156, 'grad_norm': 13.393733978271484, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-14 00:05:00 server-1   | INFO :      configure_evaluate: strategy sampled 2 clients (out of 2)
2025-05-13 23:49:20 client1-1  | {'loss': 1.3302, 'grad_norm': 15.365371704101562, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-13 23:45:39 client2-1  | {'loss': 1.4318, 'grad_norm': 13.907773971557617, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-14 00:05:19 server-1   | INFO :      aggregate_evaluate: received 2 results and 0 failures
2025-05-13 23:49:20 client1-1  | {'train_runtime': 436.2515, 'train_samples_per_second': 1.834, 'train_steps_per_second': 0.917, 'train_loss': 1.4801355981826783, 'epoch': 1.0}
2025-05-13 23:49:22 client1-1  | INFO :      Sent reply
2025-05-13 23:49:35 client1-1  | INFO :      
2025-05-13 23:45:49 client2-1  | {'loss': 1.5022, 'grad_norm': 14.856398582458496, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-13 23:46:02 client2-1  | {'loss': 1.2731, 'grad_norm': 11.053729057312012, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-13 23:46:12 client2-1  | {'loss': 1.332, 'grad_norm': 14.200752258300781, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-13 23:46:22 client2-1  | {'loss': 1.4669, 'grad_norm': 14.191463470458984, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-13 23:46:32 client2-1  | {'loss': 1.4245, 'grad_norm': 16.025882720947266, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-13 23:46:45 client2-1  | {'loss': 1.3886, 'grad_norm': 16.29924964904785, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-13 23:46:55 client2-1  | {'loss': 1.5065, 'grad_norm': 11.224720001220703, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-14 00:05:19 server-1   | INFO :      
2025-05-14 00:05:19 server-1   | INFO :      [ROUND 4]
2025-05-14 00:05:19 server-1   | INFO :      configure_fit: strategy sampled 2 clients (out of 2)
2025-05-14 00:12:37 server-1   | INFO :      aggregate_fit: received 2 results and 0 failures
2025-05-14 00:12:42 server-1   | INFO :      configure_evaluate: strategy sampled 2 clients (out of 2)
2025-05-13 23:47:05 client2-1  | {'loss': 1.4903, 'grad_norm': 11.040513038635254, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-13 23:49:35 client1-1  | INFO :      Received: evaluate message eb42b229-e2dc-4ec7-a1d2-80e1c3c88ec0
2025-05-13 23:47:14 client2-1  | {'loss': 1.4798, 'grad_norm': 13.31263542175293, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-13 23:49:47 client1-1  | {'eval_loss': 1.3070427179336548, 'eval_runtime': 11.2084, 'eval_samples_per_second': 17.844, 'eval_steps_per_second': 2.23, 'epoch': 1.0}
2025-05-13 23:49:47 client1-1  | INFO :      Sent reply
2025-05-13 23:49:51 client1-1  | INFO :      
2025-05-13 23:49:51 client1-1  | INFO :      Received: train message f1cbdbb1-eb2e-4eaf-b94a-c253e5696fdc
2025-05-14 00:12:59 server-1   | INFO :      aggregate_evaluate: received 2 results and 0 failures
2025-05-14 00:12:59 server-1   | INFO :      
2025-05-14 00:12:59 server-1   | INFO :      [ROUND 5]
2025-05-14 00:12:59 server-1   | INFO :      configure_fit: strategy sampled 2 clients (out of 2)
2025-05-13 23:47:28 client2-1  | {'loss': 1.4952, 'grad_norm': 18.71034049987793, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-13 23:47:38 client2-1  | {'loss': 1.5022, 'grad_norm': 10.11998462677002, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-13 23:50:03 client1-1  | {'loss': 1.0779, 'grad_norm': 9.421201705932617, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-14 00:20:20 server-1   | INFO :      aggregate_fit: received 2 results and 0 failures
2025-05-14 00:20:25 server-1   | INFO :      configure_evaluate: strategy sampled 2 clients (out of 2)
2025-05-14 00:20:43 server-1   | INFO :      aggregate_evaluate: received 2 results and 0 failures
2025-05-13 23:47:48 client2-1  | {'loss': 1.4893, 'grad_norm': 12.327836036682129, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-13 23:47:58 client2-1  | {'loss': 1.3428, 'grad_norm': 10.509584426879883, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-13 23:48:11 client2-1  | {'loss': 1.3129, 'grad_norm': 9.70826244354248, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-14 00:20:43 server-1   | INFO :      
2025-05-14 00:20:43 server-1   | INFO :      [SUMMARY]
2025-05-14 00:20:43 server-1   | INFO :      Run finished 5 round(s) in 2349.60s
2025-05-14 00:20:43 server-1   | INFO :      History (loss, distributed):
2025-05-13 23:48:21 client2-1  | {'loss': 1.3406, 'grad_norm': 11.765420913696289, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-14 00:20:43 server-1   | INFO :      round 1: 1.2819404602050781
2025-05-14 00:20:43 server-1   | INFO :      round 2: 1.3034246563911438
2025-05-13 23:50:16 client1-1  | {'loss': 0.9472, 'grad_norm': 11.26240348815918, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-13 23:50:26 client1-1  | {'loss': 1.0871, 'grad_norm': 11.32408618927002, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-13 23:50:35 client1-1  | {'loss': 1.0853, 'grad_norm': 11.60766315460205, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-13 23:50:45 client1-1  | {'loss': 1.0243, 'grad_norm': 10.646954536437988, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-13 23:50:58 client1-1  | {'loss': 1.0458, 'grad_norm': 12.297441482543945, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-13 23:51:08 client1-1  | {'loss': 0.9509, 'grad_norm': 9.562708854675293, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-14 00:20:43 server-1   | INFO :      round 3: 1.341423213481903
2025-05-13 23:48:31 client2-1  | {'loss': 1.4809, 'grad_norm': 15.418951034545898, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-14 00:20:43 server-1   | INFO :      round 4: 1.3798942565917969
2025-05-14 00:20:43 server-1   | INFO :      round 5: 1.4231421947479248
2025-05-13 23:48:41 client2-1  | {'loss': 1.3479, 'grad_norm': 11.311444282531738, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-14 00:20:43 server-1   | INFO :      
2025-05-13 23:48:54 client2-1  | {'loss': 1.3017, 'grad_norm': 10.590008735656738, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-13 23:49:04 client2-1  | {'loss': 1.3419, 'grad_norm': 9.180866241455078, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-13 23:49:14 client2-1  | {'loss': 1.2788, 'grad_norm': 10.382658004760742, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-13 23:49:14 client2-1  | {'train_runtime': 430.603, 'train_samples_per_second': 1.858, 'train_steps_per_second': 0.929, 'train_loss': 1.4863416266441345, 'epoch': 1.0}
2025-05-13 23:49:19 client2-1  | INFO :      Sent reply
2025-05-13 23:49:35 client2-1  | INFO :      
2025-05-13 23:49:35 client2-1  | INFO :      Received: evaluate message 229cb217-2166-4b84-83cd-3ea192c011a6
2025-05-13 23:49:47 client2-1  | {'eval_loss': 1.2568382024765015, 'eval_runtime': 11.4442, 'eval_samples_per_second': 17.476, 'eval_steps_per_second': 2.185, 'epoch': 1.0}
2025-05-13 23:49:47 client2-1  | INFO :      Sent reply
2025-05-13 23:49:52 client2-1  | INFO :      
2025-05-13 23:49:52 client2-1  | INFO :      Received: train message 36b4b84a-011e-476f-91b9-554cb9285425
2025-05-13 23:51:17 client1-1  | {'loss': 1.1404, 'grad_norm': 15.771296501159668, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-13 23:51:27 client1-1  | {'loss': 1.1057, 'grad_norm': 11.207722663879395, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-13 23:51:40 client1-1  | {'loss': 1.1025, 'grad_norm': 9.177412033081055, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-13 23:51:50 client1-1  | {'loss': 0.9678, 'grad_norm': 10.342706680297852, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-13 23:50:05 client2-1  | {'loss': 0.9174, 'grad_norm': 8.03165054321289, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-13 23:50:19 client2-1  | {'loss': 1.0399, 'grad_norm': 10.99633502960205, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-13 23:50:28 client2-1  | {'loss': 0.9669, 'grad_norm': 8.381280899047852, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-13 23:50:38 client2-1  | {'loss': 1.0252, 'grad_norm': 11.590067863464355, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-13 23:50:47 client2-1  | {'loss': 1.0361, 'grad_norm': 9.045004844665527, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-13 23:51:01 client2-1  | {'loss': 1.0955, 'grad_norm': 13.905756950378418, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-13 23:51:10 client2-1  | {'loss': 1.0574, 'grad_norm': 9.754847526550293, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-13 23:51:20 client2-1  | {'loss': 1.0686, 'grad_norm': 12.418198585510254, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-13 23:51:30 client2-1  | {'loss': 1.0153, 'grad_norm': 11.87138557434082, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-13 23:51:59 client1-1  | {'loss': 1.1012, 'grad_norm': 13.343647003173828, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-13 23:52:09 client1-1  | {'loss': 1.0615, 'grad_norm': 11.565826416015625, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-13 23:52:22 client1-1  | {'loss': 1.0802, 'grad_norm': 10.76162052154541, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-13 23:51:43 client2-1  | {'loss': 1.1406, 'grad_norm': 13.124619483947754, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-13 23:51:52 client2-1  | {'loss': 1.1643, 'grad_norm': 12.559067726135254, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-13 23:52:32 client1-1  | {'loss': 0.9996, 'grad_norm': 10.777084350585938, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-13 23:52:02 client2-1  | {'loss': 1.1071, 'grad_norm': 13.427496910095215, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-13 23:52:11 client2-1  | {'loss': 1.1732, 'grad_norm': 13.397223472595215, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-13 23:52:25 client2-1  | {'loss': 1.1078, 'grad_norm': 13.16054916381836, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-13 23:52:41 client1-1  | {'loss': 1.085, 'grad_norm': 13.665982246398926, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-13 23:52:34 client2-1  | {'loss': 0.9604, 'grad_norm': 10.663999557495117, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-13 23:52:44 client2-1  | {'loss': 1.0085, 'grad_norm': 8.931010246276855, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-13 23:52:57 client2-1  | {'loss': 1.1506, 'grad_norm': 14.513155937194824, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-13 23:53:07 client2-1  | {'loss': 1.0397, 'grad_norm': 11.66607666015625, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-13 23:53:16 client2-1  | {'loss': 1.128, 'grad_norm': 11.967126846313477, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-13 23:53:26 client2-1  | {'loss': 1.1144, 'grad_norm': 11.186237335205078, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-13 23:53:39 client2-1  | {'loss': 1.1868, 'grad_norm': 12.947714805603027, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-13 23:52:51 client1-1  | {'loss': 0.995, 'grad_norm': 19.982053756713867, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-13 23:53:04 client1-1  | {'loss': 1.2079, 'grad_norm': 15.66383171081543, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-13 23:53:14 client1-1  | {'loss': 1.207, 'grad_norm': 9.813035011291504, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-13 23:53:23 client1-1  | {'loss': 1.0558, 'grad_norm': 11.476167678833008, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-13 23:53:33 client1-1  | {'loss': 1.2351, 'grad_norm': 11.058319091796875, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-13 23:53:46 client1-1  | {'loss': 1.1848, 'grad_norm': 12.411019325256348, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-13 23:53:56 client1-1  | {'loss': 1.1692, 'grad_norm': 10.50750732421875, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-13 23:54:05 client1-1  | {'loss': 1.3271, 'grad_norm': 19.635347366333008, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-13 23:54:15 client1-1  | {'loss': 1.0803, 'grad_norm': 10.718063354492188, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-13 23:54:28 client1-1  | {'loss': 1.2531, 'grad_norm': 8.75662612915039, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-13 23:54:38 client1-1  | {'loss': 1.1585, 'grad_norm': 11.518332481384277, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-13 23:53:49 client2-1  | {'loss': 0.9988, 'grad_norm': 9.79275894165039, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-13 23:53:58 client2-1  | {'loss': 1.044, 'grad_norm': 11.067865371704102, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-13 23:54:47 client1-1  | {'loss': 1.1343, 'grad_norm': 11.479347229003906, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-13 23:54:57 client1-1  | {'loss': 1.1086, 'grad_norm': 9.882884979248047, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-13 23:54:12 client2-1  | {'loss': 1.1821, 'grad_norm': 11.957479476928711, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-13 23:54:22 client2-1  | {'loss': 1.1313, 'grad_norm': 13.771163940429688, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-13 23:54:31 client2-1  | {'loss': 1.1322, 'grad_norm': 13.942913055419922, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-13 23:54:45 client2-1  | {'loss': 1.2745, 'grad_norm': 11.652156829833984, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-13 23:54:55 client2-1  | {'loss': 1.2869, 'grad_norm': 9.846256256103516, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-13 23:55:10 client1-1  | {'loss': 1.0978, 'grad_norm': 11.83859634399414, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-13 23:55:20 client1-1  | {'loss': 1.3529, 'grad_norm': 17.682811737060547, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-13 23:55:30 client1-1  | {'loss': 1.27, 'grad_norm': 11.059072494506836, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-13 23:55:43 client1-1  | {'loss': 1.2531, 'grad_norm': 10.927520751953125, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-13 23:55:52 client1-1  | {'loss': 1.2104, 'grad_norm': 11.060629844665527, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-13 23:56:02 client1-1  | {'loss': 1.2608, 'grad_norm': 7.4776740074157715, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-13 23:55:04 client2-1  | {'loss': 1.2667, 'grad_norm': 12.321659088134766, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-13 23:55:17 client2-1  | {'loss': 1.2776, 'grad_norm': 13.261341094970703, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-13 23:55:27 client2-1  | {'loss': 1.3169, 'grad_norm': 10.162222862243652, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-13 23:56:15 client1-1  | {'loss': 1.2184, 'grad_norm': 8.51595401763916, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-13 23:55:36 client2-1  | {'loss': 1.3227, 'grad_norm': 13.057095527648926, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-13 23:56:25 client1-1  | {'loss': 1.0915, 'grad_norm': 8.271750450134277, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-13 23:56:35 client1-1  | {'loss': 1.1677, 'grad_norm': 13.403828620910645, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-13 23:56:48 client1-1  | {'loss': 1.1008, 'grad_norm': 10.160863876342773, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-13 23:55:50 client2-1  | {'loss': 1.1693, 'grad_norm': 10.928949356079102, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-13 23:56:58 client1-1  | {'loss': 0.8093, 'grad_norm': 14.785208702087402, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-13 23:55:59 client2-1  | {'loss': 1.1699, 'grad_norm': 13.382718086242676, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-13 23:56:58 client1-1  | {'train_runtime': 424.9892, 'train_samples_per_second': 1.882, 'train_steps_per_second': 0.941, 'train_loss': 1.120299744606018, 'epoch': 1.0}
2025-05-13 23:57:03 client1-1  | INFO :      Sent reply
2025-05-13 23:56:09 client2-1  | {'loss': 1.2055, 'grad_norm': 16.419952392578125, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-13 23:57:18 client1-1  | INFO :      
2025-05-13 23:57:18 client1-1  | INFO :      Received: evaluate message ff45b843-42de-4c5a-807b-edbee912b135
2025-05-13 23:57:29 client1-1  | {'eval_loss': 1.3318387269973755, 'eval_runtime': 8.9365, 'eval_samples_per_second': 22.38, 'eval_steps_per_second': 2.798, 'epoch': 1.0}
2025-05-13 23:57:29 client1-1  | INFO :      Sent reply
2025-05-13 23:56:18 client2-1  | {'loss': 1.3398, 'grad_norm': 14.931025505065918, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-13 23:56:32 client2-1  | {'loss': 1.2195, 'grad_norm': 11.848389625549316, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-13 23:57:34 client1-1  | INFO :      
2025-05-13 23:57:34 client1-1  | INFO :      Received: train message 40ea188e-8943-4b21-b75a-f24d3f6afa56
2025-05-13 23:57:45 client1-1  | {'loss': 0.6793, 'grad_norm': 7.618364334106445, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-13 23:56:41 client2-1  | {'loss': 1.154, 'grad_norm': 9.901905059814453, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-13 23:57:59 client1-1  | {'loss': 0.6313, 'grad_norm': 10.117018699645996, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-13 23:56:51 client2-1  | {'loss': 1.0863, 'grad_norm': 6.5593109130859375, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-13 23:58:09 client1-1  | {'loss': 0.7311, 'grad_norm': 10.24669075012207, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-13 23:58:18 client1-1  | {'loss': 0.7966, 'grad_norm': 11.422799110412598, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-13 23:58:28 client1-1  | {'loss': 0.7134, 'grad_norm': 10.158923149108887, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-13 23:58:41 client1-1  | {'loss': 0.787, 'grad_norm': 11.216429710388184, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-13 23:57:03 client2-1  | {'loss': 0.7613, 'grad_norm': 6.608029365539551, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-13 23:57:03 client2-1  | {'train_runtime': 428.3985, 'train_samples_per_second': 1.867, 'train_steps_per_second': 0.934, 'train_loss': 1.1210706102848054, 'epoch': 1.0}
2025-05-13 23:58:51 client1-1  | {'loss': 0.7155, 'grad_norm': 9.62509536743164, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-13 23:59:01 client1-1  | {'loss': 0.9223, 'grad_norm': 12.332911491394043, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-13 23:59:14 client1-1  | {'loss': 0.8389, 'grad_norm': 12.707061767578125, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-13 23:59:24 client1-1  | {'loss': 0.8121, 'grad_norm': 9.52481746673584, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-13 23:57:06 client2-1  | INFO :      Sent reply
2025-05-13 23:57:18 client2-1  | INFO :      
2025-05-13 23:57:18 client2-1  | INFO :      Received: evaluate message 4b6980e0-b274-4b33-9369-948192200a8a
2025-05-13 23:57:29 client2-1  | {'eval_loss': 1.275010585784912, 'eval_runtime': 10.4927, 'eval_samples_per_second': 19.061, 'eval_steps_per_second': 2.383, 'epoch': 1.0}
2025-05-13 23:57:29 client2-1  | INFO :      Sent reply
2025-05-13 23:57:34 client2-1  | INFO :      
2025-05-13 23:59:34 client1-1  | {'loss': 0.7297, 'grad_norm': 10.770312309265137, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-13 23:57:34 client2-1  | INFO :      Received: train message 17d54f6d-4308-4bd6-a373-b152375e7826
2025-05-13 23:59:47 client1-1  | {'loss': 0.8657, 'grad_norm': 10.359127044677734, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-13 23:57:48 client2-1  | {'loss': 0.576, 'grad_norm': 7.711186408996582, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-13 23:58:01 client2-1  | {'loss': 0.6995, 'grad_norm': 10.920966148376465, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-13 23:59:57 client1-1  | {'loss': 0.8126, 'grad_norm': 8.627802848815918, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-14 00:00:06 client1-1  | {'loss': 0.8333, 'grad_norm': 11.285573959350586, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-14 00:00:20 client1-1  | {'loss': 0.7594, 'grad_norm': 10.259966850280762, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-13 23:58:11 client2-1  | {'loss': 0.6502, 'grad_norm': 7.830295085906982, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-13 23:58:20 client2-1  | {'loss': 0.7682, 'grad_norm': 8.578587532043457, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-13 23:58:30 client2-1  | {'loss': 0.7406, 'grad_norm': 8.572749137878418, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-13 23:58:43 client2-1  | {'loss': 0.7861, 'grad_norm': 13.328805923461914, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-13 23:58:53 client2-1  | {'loss': 0.7974, 'grad_norm': 8.097073554992676, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-14 00:00:29 client1-1  | {'loss': 0.8863, 'grad_norm': 9.802433013916016, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-14 00:00:43 client1-1  | {'loss': 0.7931, 'grad_norm': 18.663352966308594, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-13 23:59:03 client2-1  | {'loss': 0.8095, 'grad_norm': 10.29559326171875, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-13 23:59:13 client2-1  | {'loss': 0.7696, 'grad_norm': 12.152390480041504, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-13 23:59:26 client2-1  | {'loss': 0.874, 'grad_norm': 13.008609771728516, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-13 23:59:36 client2-1  | {'loss': 0.9069, 'grad_norm': 10.1702299118042, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-13 23:59:45 client2-1  | {'loss': 0.8631, 'grad_norm': 12.373173713684082, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-14 00:00:53 client1-1  | {'loss': 0.9806, 'grad_norm': 10.676671981811523, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-14 00:01:02 client1-1  | {'loss': 1.0042, 'grad_norm': 10.306574821472168, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-14 00:01:16 client1-1  | {'loss': 0.8385, 'grad_norm': 9.68712329864502, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-13 23:59:55 client2-1  | {'loss': 0.9146, 'grad_norm': 14.514252662658691, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-14 00:00:08 client2-1  | {'loss': 0.8741, 'grad_norm': 14.828767776489258, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-14 00:01:26 client1-1  | {'loss': 1.0197, 'grad_norm': 11.321016311645508, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-14 00:00:18 client2-1  | {'loss': 0.7448, 'grad_norm': 9.522262573242188, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-14 00:00:27 client2-1  | {'loss': 0.8024, 'grad_norm': 9.413633346557617, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-14 00:00:41 client2-1  | {'loss': 0.8942, 'grad_norm': 11.59377670288086, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-14 00:01:39 client1-1  | {'loss': 0.9738, 'grad_norm': 12.049076080322266, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-14 00:01:49 client1-1  | {'loss': 0.9689, 'grad_norm': 9.412429809570312, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-14 00:01:58 client1-1  | {'loss': 1.1255, 'grad_norm': 11.513736724853516, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-14 00:02:12 client1-1  | {'loss': 0.9052, 'grad_norm': 9.75855541229248, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-14 00:00:50 client2-1  | {'loss': 0.8404, 'grad_norm': 10.99032974243164, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-14 00:02:22 client1-1  | {'loss': 1.0716, 'grad_norm': 8.156261444091797, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-14 00:02:31 client1-1  | {'loss': 1.0052, 'grad_norm': 12.505304336547852, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-14 00:01:00 client2-1  | {'loss': 0.917, 'grad_norm': 11.912426948547363, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-14 00:01:13 client2-1  | {'loss': 0.9182, 'grad_norm': 10.392837524414062, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-14 00:01:23 client2-1  | {'loss': 0.9803, 'grad_norm': 11.652697563171387, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-14 00:01:33 client2-1  | {'loss': 0.8197, 'grad_norm': 9.028671264648438, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-14 00:02:44 client1-1  | {'loss': 0.9855, 'grad_norm': 10.989995002746582, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-14 00:01:42 client2-1  | {'loss': 0.8829, 'grad_norm': 10.873189926147461, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-14 00:02:54 client1-1  | {'loss': 0.9889, 'grad_norm': 9.77403450012207, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-14 00:01:55 client2-1  | {'loss': 1.0062, 'grad_norm': 11.024165153503418, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-14 00:02:05 client2-1  | {'loss': 0.9532, 'grad_norm': 11.733979225158691, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-14 00:02:15 client2-1  | {'loss': 1.0108, 'grad_norm': 13.050004005432129, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-14 00:02:24 client2-1  | {'loss': 1.0975, 'grad_norm': 10.975845336914062, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-14 00:02:38 client2-1  | {'loss': 1.1302, 'grad_norm': 9.016470909118652, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-14 00:02:47 client2-1  | {'loss': 1.1088, 'grad_norm': 11.975434303283691, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-14 00:02:57 client2-1  | {'loss': 1.1416, 'grad_norm': 13.618136405944824, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-14 00:03:04 client1-1  | {'loss': 0.9724, 'grad_norm': 11.34981918334961, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-14 00:03:17 client1-1  | {'loss': 1.2318, 'grad_norm': 19.215614318847656, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-14 00:03:10 client2-1  | {'loss': 1.1917, 'grad_norm': 10.92953109741211, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-14 00:03:27 client1-1  | {'loss': 1.1879, 'grad_norm': 10.937034606933594, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-14 00:03:20 client2-1  | {'loss': 1.2218, 'grad_norm': 12.157708168029785, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-14 00:03:29 client2-1  | {'loss': 1.1032, 'grad_norm': 11.733880996704102, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-14 00:03:37 client1-1  | {'loss': 1.1454, 'grad_norm': 10.659521102905273, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-14 00:03:50 client1-1  | {'loss': 1.1273, 'grad_norm': 11.322507858276367, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-14 00:04:00 client1-1  | {'loss': 1.1883, 'grad_norm': 7.10891056060791, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-14 00:04:09 client1-1  | {'loss': 1.1994, 'grad_norm': 9.293497085571289, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-14 00:04:23 client1-1  | {'loss': 1.035, 'grad_norm': 7.679876327514648, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-14 00:04:33 client1-1  | {'loss': 1.0985, 'grad_norm': 11.826513290405273, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-14 00:04:42 client1-1  | {'loss': 0.9726, 'grad_norm': 10.336206436157227, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-14 00:03:39 client2-1  | {'loss': 1.1195, 'grad_norm': 9.28095531463623, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-14 00:03:52 client2-1  | {'loss': 1.1548, 'grad_norm': 13.663228034973145, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-14 00:04:02 client2-1  | {'loss': 1.3041, 'grad_norm': 16.05413055419922, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-14 00:04:51 client1-1  | {'loss': 0.6349, 'grad_norm': 9.50929069519043, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-14 00:04:11 client2-1  | {'loss': 1.1643, 'grad_norm': 12.141547203063965, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-14 00:04:21 client2-1  | {'loss': 1.073, 'grad_norm': 8.581539154052734, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-14 00:04:51 client1-1  | {'train_runtime': 435.6666, 'train_samples_per_second': 1.836, 'train_steps_per_second': 0.918, 'train_loss': 0.9242192709445953, 'epoch': 1.0}
2025-05-14 00:04:54 client1-1  | INFO :      Sent reply
2025-05-14 00:04:34 client2-1  | {'loss': 0.9844, 'grad_norm': 6.7237067222595215, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-14 00:04:44 client2-1  | {'loss': 0.5959, 'grad_norm': 7.692801475524902, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-14 00:04:44 client2-1  | {'train_runtime': 426.8109, 'train_samples_per_second': 1.874, 'train_steps_per_second': 0.937, 'train_loss': 0.9297593915462494, 'epoch': 1.0}
2025-05-14 00:04:50 client2-1  | INFO :      Sent reply
2025-05-14 00:05:05 client2-1  | INFO :      
2025-05-14 00:05:05 client2-1  | INFO :      Received: evaluate message 8b5a0978-6556-447b-b657-7e0c3d16fea0
2025-05-14 00:05:17 client2-1  | {'eval_loss': 1.3084546327590942, 'eval_runtime': 11.0318, 'eval_samples_per_second': 18.129, 'eval_steps_per_second': 2.266, 'epoch': 1.0}
2025-05-14 00:05:17 client2-1  | INFO :      Sent reply
2025-05-14 00:05:22 client2-1  | INFO :      
2025-05-14 00:05:22 client2-1  | INFO :      Received: train message ec2c8e3e-3331-4a89-a87b-3b7754e6251a
2025-05-14 00:05:37 client2-1  | {'loss': 0.3716, 'grad_norm': 4.578009128570557, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-14 00:05:47 client2-1  | {'loss': 0.4738, 'grad_norm': 20.20256805419922, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-14 00:05:57 client2-1  | {'loss': 0.4402, 'grad_norm': 7.2308244705200195, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-14 00:06:07 client2-1  | {'loss': 0.5622, 'grad_norm': 7.751237392425537, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-14 00:06:20 client2-1  | {'loss': 0.5405, 'grad_norm': 7.977698802947998, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-14 00:05:06 client1-1  | INFO :      
2025-05-14 00:06:30 client2-1  | {'loss': 0.5848, 'grad_norm': 12.450109481811523, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-14 00:05:06 client1-1  | INFO :      Received: evaluate message a31313f1-f846-47c4-aee4-a0d52dbe7ccd
2025-05-14 00:06:39 client2-1  | {'loss': 0.6007, 'grad_norm': 9.969364166259766, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-14 00:06:53 client2-1  | {'loss': 0.6308, 'grad_norm': 9.505171775817871, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-14 00:07:02 client2-1  | {'loss': 0.5616, 'grad_norm': 10.480755805969238, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-14 00:05:19 client1-1  | {'eval_loss': 1.374391794204712, 'eval_runtime': 11.2037, 'eval_samples_per_second': 17.851, 'eval_steps_per_second': 2.231, 'epoch': 1.0}
2025-05-14 00:07:12 client2-1  | {'loss': 0.6619, 'grad_norm': 9.833456039428711, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-14 00:05:19 client1-1  | INFO :      Sent reply
2025-05-14 00:07:22 client2-1  | {'loss': 0.6651, 'grad_norm': 10.731574058532715, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-14 00:07:35 client2-1  | {'loss': 0.6432, 'grad_norm': 11.925728797912598, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-14 00:07:45 client2-1  | {'loss': 0.7188, 'grad_norm': 12.398531913757324, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-14 00:07:55 client2-1  | {'loss': 0.6809, 'grad_norm': 19.3343505859375, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-14 00:08:04 client2-1  | {'loss': 0.5749, 'grad_norm': 8.44909381866455, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-14 00:05:24 client1-1  | INFO :      
2025-05-14 00:08:17 client2-1  | {'loss': 0.6311, 'grad_norm': 8.262167930603027, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-14 00:08:27 client2-1  | {'loss': 0.7228, 'grad_norm': 11.463051795959473, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-14 00:08:36 client2-1  | {'loss': 0.6782, 'grad_norm': 11.148550987243652, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-14 00:08:46 client2-1  | {'loss': 0.755, 'grad_norm': 12.481939315795898, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-14 00:05:24 client1-1  | INFO :      Received: train message 2a164443-0b00-401e-8812-89f56071002d
2025-05-14 00:05:36 client1-1  | {'loss': 0.4293, 'grad_norm': 6.479063987731934, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-14 00:05:49 client1-1  | {'loss': 0.4072, 'grad_norm': 9.494466781616211, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-14 00:08:56 client2-1  | {'loss': 0.7615, 'grad_norm': 9.942144393920898, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-14 00:09:09 client2-1  | {'loss': 0.7947, 'grad_norm': 12.178473472595215, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-14 00:09:19 client2-1  | {'loss': 0.685, 'grad_norm': 9.24905776977539, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-14 00:09:28 client2-1  | {'loss': 0.7295, 'grad_norm': 10.668279647827148, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-14 00:09:38 client2-1  | {'loss': 0.8525, 'grad_norm': 10.93152904510498, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-14 00:05:59 client1-1  | {'loss': 0.5241, 'grad_norm': 9.205389976501465, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-14 00:06:09 client1-1  | {'loss': 0.5524, 'grad_norm': 8.260433197021484, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-14 00:09:51 client2-1  | {'loss': 0.8049, 'grad_norm': 10.837730407714844, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-14 00:06:22 client1-1  | {'loss': 0.5104, 'grad_norm': 10.409605026245117, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-14 00:10:01 client2-1  | {'loss': 0.8637, 'grad_norm': 15.377058982849121, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-14 00:06:32 client1-1  | {'loss': 0.5882, 'grad_norm': 12.089949607849121, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-14 00:10:11 client2-1  | {'loss': 0.9747, 'grad_norm': 10.549739837646484, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-14 00:06:42 client1-1  | {'loss': 0.519, 'grad_norm': 12.801994323730469, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-14 00:10:20 client2-1  | {'loss': 1.0118, 'grad_norm': 8.532174110412598, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-14 00:06:55 client1-1  | {'loss': 0.6863, 'grad_norm': 12.677596092224121, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-14 00:10:34 client2-1  | {'loss': 1.0114, 'grad_norm': 11.772921562194824, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-14 00:10:43 client2-1  | {'loss': 1.0514, 'grad_norm': 12.650588035583496, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-14 00:10:53 client2-1  | {'loss': 1.1037, 'grad_norm': 10.526087760925293, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-14 00:11:02 client2-1  | {'loss': 1.1341, 'grad_norm': 12.476998329162598, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-14 00:07:05 client1-1  | {'loss': 0.6034, 'grad_norm': 9.670327186584473, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-14 00:11:16 client2-1  | {'loss': 1.0266, 'grad_norm': 11.497047424316406, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-14 00:11:25 client2-1  | {'loss': 1.0455, 'grad_norm': 10.986613273620605, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-14 00:11:35 client2-1  | {'loss': 1.1023, 'grad_norm': 13.729174613952637, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-14 00:11:44 client2-1  | {'loss': 1.2502, 'grad_norm': 17.465307235717773, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-14 00:11:58 client2-1  | {'loss': 1.1259, 'grad_norm': 11.47940444946289, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-14 00:12:07 client2-1  | {'loss': 1.0318, 'grad_norm': 9.470080375671387, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-14 00:12:17 client2-1  | {'loss': 0.8904, 'grad_norm': 6.09428596496582, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-14 00:07:15 client1-1  | {'loss': 0.5849, 'grad_norm': 7.345310211181641, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-14 00:07:24 client1-1  | {'loss': 0.5566, 'grad_norm': 14.974078178405762, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-14 00:12:26 client2-1  | {'loss': 0.4858, 'grad_norm': 6.777072906494141, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-14 00:07:38 client1-1  | {'loss': 0.6634, 'grad_norm': 10.09888744354248, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-14 00:12:26 client2-1  | {'train_runtime': 422.6701, 'train_samples_per_second': 1.893, 'train_steps_per_second': 0.946, 'train_loss': 0.7808915036916733, 'epoch': 1.0}
2025-05-14 00:07:47 client1-1  | {'loss': 0.6292, 'grad_norm': 8.450109481811523, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-14 00:07:57 client1-1  | {'loss': 0.6577, 'grad_norm': 9.166420936584473, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-14 00:08:07 client1-1  | {'loss': 0.5798, 'grad_norm': 9.426483154296875, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-14 00:08:20 client1-1  | {'loss': 0.6944, 'grad_norm': 10.301871299743652, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-14 00:08:29 client1-1  | {'loss': 0.6207, 'grad_norm': 13.042903900146484, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-14 00:08:39 client1-1  | {'loss': 0.7823, 'grad_norm': 11.972015380859375, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-14 00:08:49 client1-1  | {'loss': 0.8108, 'grad_norm': 9.138616561889648, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-14 00:09:02 client1-1  | {'loss': 0.6808, 'grad_norm': 8.602715492248535, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-14 00:09:12 client1-1  | {'loss': 0.8458, 'grad_norm': 10.885074615478516, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-14 00:12:34 client2-1  | INFO :      Sent reply
2025-05-14 00:12:47 client2-1  | INFO :      
2025-05-14 00:12:47 client2-1  | INFO :      Received: evaluate message c345b42c-60f0-4de1-ae58-573887752522
2025-05-14 00:12:58 client2-1  | {'eval_loss': 1.344972848892212, 'eval_runtime': 8.9423, 'eval_samples_per_second': 22.366, 'eval_steps_per_second': 2.796, 'epoch': 1.0}
2025-05-14 00:09:21 client1-1  | {'loss': 0.8149, 'grad_norm': 13.494722366333008, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-14 00:09:31 client1-1  | {'loss': 0.8253, 'grad_norm': 13.518714904785156, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-14 00:09:44 client1-1  | {'loss': 0.9598, 'grad_norm': 11.381998062133789, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-14 00:12:58 client2-1  | INFO :      Sent reply
2025-05-14 00:09:54 client1-1  | {'loss': 0.7602, 'grad_norm': 9.370162963867188, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-14 00:10:04 client1-1  | {'loss': 0.9247, 'grad_norm': 8.82486629486084, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-14 00:10:17 client1-1  | {'loss': 0.8841, 'grad_norm': 10.187431335449219, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-14 00:10:27 client1-1  | {'loss': 0.8852, 'grad_norm': 10.731983184814453, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-14 00:10:36 client1-1  | {'loss': 0.9006, 'grad_norm': 9.350317001342773, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-14 00:10:46 client1-1  | {'loss': 0.8694, 'grad_norm': 12.861525535583496, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-14 00:13:03 client2-1  | INFO :      
2025-05-14 00:10:59 client1-1  | {'loss': 1.1276, 'grad_norm': 18.747051239013672, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-14 00:13:03 client2-1  | INFO :      Received: train message d5653d1c-dc55-46a2-b58a-2a39df0c0bbc
2025-05-14 00:11:09 client1-1  | {'loss': 1.0896, 'grad_norm': 10.43625545501709, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-14 00:11:18 client1-1  | {'loss': 1.0734, 'grad_norm': 10.711421966552734, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-14 00:11:28 client1-1  | {'loss': 1.0905, 'grad_norm': 10.899091720581055, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-14 00:11:41 client1-1  | {'loss': 1.1158, 'grad_norm': 8.95704460144043, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-14 00:13:14 client2-1  | {'loss': 0.2452, 'grad_norm': 3.1274423599243164, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-14 00:13:28 client2-1  | {'loss': 0.2911, 'grad_norm': 11.263669967651367, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-14 00:11:51 client1-1  | {'loss': 1.1446, 'grad_norm': 8.897972106933594, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-14 00:12:00 client1-1  | {'loss': 1.0136, 'grad_norm': 7.812210559844971, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-14 00:12:10 client1-1  | {'loss': 1.0388, 'grad_norm': 11.516084671020508, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-14 00:12:23 client1-1  | {'loss': 0.9003, 'grad_norm': 8.843372344970703, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-14 00:12:33 client1-1  | {'loss': 0.5172, 'grad_norm': 8.749916076660156, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-14 00:13:38 client2-1  | {'loss': 0.3299, 'grad_norm': 6.566863059997559, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-14 00:13:47 client2-1  | {'loss': 0.3893, 'grad_norm': 6.9173197746276855, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-14 00:13:57 client2-1  | {'loss': 0.3819, 'grad_norm': 7.251829147338867, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-14 00:14:10 client2-1  | {'loss': 0.4298, 'grad_norm': 10.251423835754395, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-14 00:14:20 client2-1  | {'loss': 0.4378, 'grad_norm': 9.106754302978516, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-14 00:14:29 client2-1  | {'loss': 0.4786, 'grad_norm': 9.213274955749512, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-14 00:14:39 client2-1  | {'loss': 0.4399, 'grad_norm': 10.260887145996094, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-14 00:12:33 client1-1  | {'train_runtime': 427.0521, 'train_samples_per_second': 1.873, 'train_steps_per_second': 0.937, 'train_loss': 0.7715625441074372, 'epoch': 1.0}
2025-05-14 00:12:36 client1-1  | INFO :      Sent reply
2025-05-14 00:12:47 client1-1  | INFO :      
2025-05-14 00:14:53 client2-1  | {'loss': 0.4752, 'grad_norm': 9.987123489379883, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-14 00:15:02 client2-1  | {'loss': 0.5321, 'grad_norm': 9.53819465637207, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-14 00:15:12 client2-1  | {'loss': 0.4721, 'grad_norm': 10.635310173034668, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-14 00:15:25 client2-1  | {'loss': 0.5503, 'grad_norm': 13.148061752319336, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-14 00:15:35 client2-1  | {'loss': 0.5288, 'grad_norm': 13.245824813842773, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-14 00:15:45 client2-1  | {'loss': 0.4264, 'grad_norm': 8.213385581970215, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-14 00:15:55 client2-1  | {'loss': 0.4904, 'grad_norm': 7.582978248596191, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-14 00:16:08 client2-1  | {'loss': 0.5597, 'grad_norm': 10.841626167297363, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-14 00:12:47 client1-1  | INFO :      Received: evaluate message fd05ed6a-5068-4c80-ab61-ba68916a2d31
2025-05-14 00:12:59 client1-1  | {'eval_loss': 1.4148156642913818, 'eval_runtime': 10.7331, 'eval_samples_per_second': 18.634, 'eval_steps_per_second': 2.329, 'epoch': 1.0}
2025-05-14 00:16:18 client2-1  | {'loss': 0.5339, 'grad_norm': 32.125389099121094, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-14 00:16:27 client2-1  | {'loss': 0.608, 'grad_norm': 11.896987915039062, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-14 00:16:41 client2-1  | {'loss': 0.6142, 'grad_norm': 9.272685050964355, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-14 00:16:50 client2-1  | {'loss': 0.648, 'grad_norm': 11.193283081054688, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-14 00:12:59 client1-1  | INFO :      Sent reply
2025-05-14 00:17:00 client2-1  | {'loss': 0.5718, 'grad_norm': 8.85865592956543, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-14 00:17:13 client2-1  | {'loss': 0.5943, 'grad_norm': 9.067593574523926, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-14 00:17:23 client2-1  | {'loss': 0.7284, 'grad_norm': 11.628840446472168, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-14 00:17:33 client2-1  | {'loss': 0.6758, 'grad_norm': 8.920940399169922, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-14 00:17:46 client2-1  | {'loss': 0.7888, 'grad_norm': 10.320897102355957, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-14 00:13:03 client1-1  | INFO :      
2025-05-14 00:13:03 client1-1  | INFO :      Received: train message b696e1ad-a782-44ea-8c48-4c8abf24e5ca
2025-05-14 00:17:56 client2-1  | {'loss': 0.8571, 'grad_norm': 9.140032768249512, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-14 00:18:05 client2-1  | {'loss': 0.8968, 'grad_norm': 8.918479919433594, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-14 00:18:19 client2-1  | {'loss': 0.8927, 'grad_norm': 10.802200317382812, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-14 00:18:28 client2-1  | {'loss': 0.952, 'grad_norm': 15.572965621948242, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-14 00:18:38 client2-1  | {'loss': 1.015, 'grad_norm': 11.282855987548828, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-14 00:18:51 client2-1  | {'loss': 1.0529, 'grad_norm': 13.16288948059082, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-14 00:19:01 client2-1  | {'loss': 0.9761, 'grad_norm': 15.913928985595703, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-14 00:19:11 client2-1  | {'loss': 0.9817, 'grad_norm': 10.469013214111328, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-14 00:13:17 client1-1  | {'loss': 0.2604, 'grad_norm': 4.900480270385742, 'learning_rate': 4.8875e-05, 'epoch': 0.025}
2025-05-14 00:13:30 client1-1  | {'loss': 0.2729, 'grad_norm': 7.815065860748291, 'learning_rate': 4.7625000000000006e-05, 'epoch': 0.05}
2025-05-14 00:13:40 client1-1  | {'loss': 0.3793, 'grad_norm': 9.638405799865723, 'learning_rate': 4.6375e-05, 'epoch': 0.075}
2025-05-14 00:19:24 client2-1  | {'loss': 1.0712, 'grad_norm': 12.485574722290039, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-14 00:19:34 client2-1  | {'loss': 1.2128, 'grad_norm': 17.245515823364258, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-14 00:19:44 client2-1  | {'loss': 1.0954, 'grad_norm': 12.605133056640625, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-14 00:19:57 client2-1  | {'loss': 0.9743, 'grad_norm': 9.746246337890625, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-14 00:20:07 client2-1  | {'loss': 0.7976, 'grad_norm': 6.227327823638916, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-14 00:20:16 client2-1  | {'loss': 0.3811, 'grad_norm': 5.881375312805176, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-14 00:20:16 client2-1  | {'train_runtime': 431.9155, 'train_samples_per_second': 1.852, 'train_steps_per_second': 0.926, 'train_loss': 0.6594616663455963, 'epoch': 1.0}
2025-05-14 00:20:19 client2-1  | INFO :      Sent reply
2025-05-14 00:20:30 client2-1  | INFO :      
2025-05-14 00:13:49 client1-1  | {'loss': 0.4003, 'grad_norm': 8.455364227294922, 'learning_rate': 4.5125e-05, 'epoch': 0.1}
2025-05-14 00:13:59 client1-1  | {'loss': 0.3763, 'grad_norm': 8.71031665802002, 'learning_rate': 4.3875e-05, 'epoch': 0.125}
2025-05-14 00:14:13 client1-1  | {'loss': 0.4482, 'grad_norm': 12.116847038269043, 'learning_rate': 4.2625000000000006e-05, 'epoch': 0.15}
2025-05-14 00:14:22 client1-1  | {'loss': 0.3868, 'grad_norm': 8.628692626953125, 'learning_rate': 4.1375e-05, 'epoch': 0.175}
2025-05-14 00:20:30 client2-1  | INFO :      Received: evaluate message 79828035-362b-4e8a-819a-6842bdab3249
2025-05-14 00:14:36 client1-1  | {'loss': 0.505, 'grad_norm': 11.599163055419922, 'learning_rate': 4.0125e-05, 'epoch': 0.2}
2025-05-14 00:14:45 client1-1  | {'loss': 0.4419, 'grad_norm': 10.291972160339355, 'learning_rate': 3.8875e-05, 'epoch': 0.225}
2025-05-14 00:20:42 client2-1  | {'eval_loss': 1.3868533372879028, 'eval_runtime': 11.2533, 'eval_samples_per_second': 17.773, 'eval_steps_per_second': 2.222, 'epoch': 1.0}
2025-05-14 00:20:42 client2-1  | INFO :      Sent reply
2025-05-14 00:20:43 client2-1  | INFO :      
2025-05-14 00:14:55 client1-1  | {'loss': 0.4289, 'grad_norm': 7.8320207595825195, 'learning_rate': 3.7625e-05, 'epoch': 0.25}
2025-05-14 00:15:05 client1-1  | {'loss': 0.4152, 'grad_norm': 10.140283584594727, 'learning_rate': 3.6375e-05, 'epoch': 0.275}
2025-05-14 00:20:43 client2-1  | INFO :      Received: reconnect message 2e1e9b37-efe7-4cdc-b812-994e2baaea33
2025-05-14 00:20:43 client2-1  | INFO :      Disconnect and shut down
2025-05-14 00:15:18 client1-1  | {'loss': 0.4769, 'grad_norm': 13.837664604187012, 'learning_rate': 3.5125e-05, 'epoch': 0.3}
2025-05-14 00:15:28 client1-1  | {'loss': 0.47, 'grad_norm': 9.533321380615234, 'learning_rate': 3.3875000000000003e-05, 'epoch': 0.325}
2025-05-14 00:15:38 client1-1  | {'loss': 0.4873, 'grad_norm': 7.817811965942383, 'learning_rate': 3.2625e-05, 'epoch': 0.35}
2025-05-14 00:15:48 client1-1  | {'loss': 0.4504, 'grad_norm': 9.170889854431152, 'learning_rate': 3.1375e-05, 'epoch': 0.375}
2025-05-14 00:16:01 client1-1  | {'loss': 0.5595, 'grad_norm': 10.483356475830078, 'learning_rate': 3.0125000000000004e-05, 'epoch': 0.4}
2025-05-14 00:16:11 client1-1  | {'loss': 0.4784, 'grad_norm': 12.054849624633789, 'learning_rate': 2.8875e-05, 'epoch': 0.425}
2025-05-14 00:16:20 client1-1  | {'loss': 0.6399, 'grad_norm': 10.879364013671875, 'learning_rate': 2.7625e-05, 'epoch': 0.45}
2025-05-14 00:16:30 client1-1  | {'loss': 0.6559, 'grad_norm': 8.748809814453125, 'learning_rate': 2.6375e-05, 'epoch': 0.475}
2025-05-14 00:16:43 client1-1  | {'loss': 0.5623, 'grad_norm': 9.111099243164062, 'learning_rate': 2.5124999999999997e-05, 'epoch': 0.5}
2025-05-14 00:16:53 client1-1  | {'loss': 0.6874, 'grad_norm': 9.729989051818848, 'learning_rate': 2.3875e-05, 'epoch': 0.525}
2025-05-14 00:17:02 client1-1  | {'loss': 0.6817, 'grad_norm': 12.230145454406738, 'learning_rate': 2.2625e-05, 'epoch': 0.55}
2025-05-14 00:17:12 client1-1  | {'loss': 0.6608, 'grad_norm': 8.868091583251953, 'learning_rate': 2.1375e-05, 'epoch': 0.575}
2025-05-14 00:17:25 client1-1  | {'loss': 0.8158, 'grad_norm': 11.528562545776367, 'learning_rate': 2.0125e-05, 'epoch': 0.6}
2025-05-14 00:17:35 client1-1  | {'loss': 0.6453, 'grad_norm': 9.90334701538086, 'learning_rate': 1.8875e-05, 'epoch': 0.625}
2025-05-14 00:17:44 client1-1  | {'loss': 0.8027, 'grad_norm': 7.958888053894043, 'learning_rate': 1.7625e-05, 'epoch': 0.65}
2025-05-14 00:17:54 client1-1  | {'loss': 0.7607, 'grad_norm': 10.879297256469727, 'learning_rate': 1.6375e-05, 'epoch': 0.675}
2025-05-14 00:18:07 client1-1  | {'loss': 0.7701, 'grad_norm': 10.285727500915527, 'learning_rate': 1.5125e-05, 'epoch': 0.7}
2025-05-14 00:18:17 client1-1  | {'loss': 0.787, 'grad_norm': 8.751362800598145, 'learning_rate': 1.3875000000000002e-05, 'epoch': 0.725}
2025-05-14 00:18:26 client1-1  | {'loss': 0.7866, 'grad_norm': 11.628190040588379, 'learning_rate': 1.2625e-05, 'epoch': 0.75}
2025-05-14 00:18:36 client1-1  | {'loss': 1.03, 'grad_norm': 19.48154067993164, 'learning_rate': 1.1375e-05, 'epoch': 0.775}
2025-05-14 00:18:49 client1-1  | {'loss': 0.9948, 'grad_norm': 11.245537757873535, 'learning_rate': 1.0125e-05, 'epoch': 0.8}
2025-05-14 00:18:59 client1-1  | {'loss': 1.0183, 'grad_norm': 11.199914932250977, 'learning_rate': 8.875e-06, 'epoch': 0.825}
2025-05-14 00:19:08 client1-1  | {'loss': 1.0105, 'grad_norm': 10.24120044708252, 'learning_rate': 7.625e-06, 'epoch': 0.85}
2025-05-14 00:19:18 client1-1  | {'loss': 1.0774, 'grad_norm': 7.652767181396484, 'learning_rate': 6.375000000000001e-06, 'epoch': 0.875}
2025-05-14 00:19:27 client1-1  | {'loss': 1.1245, 'grad_norm': 10.45531940460205, 'learning_rate': 5.125e-06, 'epoch': 0.9}
2025-05-14 00:19:41 client1-1  | {'loss': 0.9868, 'grad_norm': 8.450227737426758, 'learning_rate': 3.875e-06, 'epoch': 0.925}
2025-05-14 00:19:50 client1-1  | {'loss': 1.0084, 'grad_norm': 14.743152618408203, 'learning_rate': 2.625e-06, 'epoch': 0.95}
2025-05-14 00:20:00 client1-1  | {'loss': 0.7965, 'grad_norm': 9.964486122131348, 'learning_rate': 1.3750000000000002e-06, 'epoch': 0.975}
2025-05-14 00:20:13 client1-1  | {'loss': 0.408, 'grad_norm': 8.223390579223633, 'learning_rate': 1.2500000000000002e-07, 'epoch': 1.0}
2025-05-14 00:20:13 client1-1  | {'train_runtime': 426.9689, 'train_samples_per_second': 1.874, 'train_steps_per_second': 0.937, 'train_loss': 0.6487226736545563, 'epoch': 1.0}
2025-05-14 00:20:18 client1-1  | INFO :      Sent reply
2025-05-14 00:20:30 client1-1  | INFO :      
2025-05-14 00:20:30 client1-1  | INFO :      Received: evaluate message 72201ac0-69b4-4477-a3a4-e86ae0d37836
2025-05-14 00:20:43 client1-1  | {'eval_loss': 1.4594310522079468, 'eval_runtime': 11.3058, 'eval_samples_per_second': 17.69, 'eval_steps_per_second': 2.211, 'epoch': 1.0}
2025-05-14 00:20:43 client1-1  | INFO :      Sent reply
2025-05-14 00:20:43 client1-1  | INFO :      
2025-05-14 00:20:43 client1-1  | INFO :      Received: reconnect message 8adb3bb6-3468-483c-86fc-90ef74534dbb
2025-05-14 00:20:43 client1-1  | INFO :      Disconnect and shut down
